{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3420021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch:  2.0 ; cuda:  cu117\n",
      "detectron2: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvcc' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "from helpers.helper import Helper\n",
    "from pathlib import Path\n",
    "import copy\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2. __version__)\n",
    "nc = 2\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "070219b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import HookBase\n",
    "from detectron2.data import build_detection_train_loader\n",
    "import detectron2.utils.comm as comm\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "class ValidationLoss(HookBase):\n",
    "    \"\"\"\n",
    "    A hook that computes validation loss during training.\n",
    "\n",
    "    Attributes:\n",
    "        cfg (CfgNode): The detectron2 config node.\n",
    "        _loader (iterator): An iterator over the validation dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cfg,\n",
    "                 metric   = \"segm/AP50\", \n",
    "                 min_max  = \"max\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            cfg (CfgNode): The detectron2 config node.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.cfg = cfg.clone()\n",
    "        # Switch to the validation dataset\n",
    "        self.cfg.DATASETS.TRAIN = cfg.DATASETS.TEST\n",
    "        # Build the validation data loader iterator\n",
    "        self._loader = iter(build_detection_train_loader(self.cfg))\n",
    "        #best accuracy calculate\n",
    "        self._period = cfg.TEST.EVAL_PERIOD\n",
    "        self.metric = metric\n",
    "        self.min_max = min_max\n",
    "        self.best_value = float(\"-inf\") if min_max == \"max\" else float(\"inf\")\n",
    "        logger = logging.getLogger(\"detectron2\")\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "        logger.propagate = False\n",
    "        self._logger = logger\n",
    "    \n",
    "    def _take_latest_metrics(self):\n",
    "      with torch.no_grad():\n",
    "        latest_metrics = self.trainer.storage.latest()\n",
    "        return latest_metrics\n",
    "    \n",
    "    def after_step(self):\n",
    "        next_iter = self.trainer.iter + 1\n",
    "        is_final = next_iter == self.trainer.max_iter\n",
    "        if is_final or (self._period > 0 and next_iter % self._period == 0):\n",
    "          latest_metrics = self._take_latest_metrics()\n",
    "          for (key, (value, iter)) in latest_metrics.items():\n",
    "            if key == self.metric:\n",
    "              if (self.min_max == \"min\" and value < self.best_value) or (self.min_max == \"max\" and value > self.best_value):\n",
    "                self._logger.info(\"Updating best model at iteration {} with {} = {}\".format(iter, self.metric, value))\n",
    "                self.best_value = value\n",
    "                self.trainer.checkpointer.save(\"model_best\")\n",
    "        \"\"\"\n",
    "        Computes the validation loss after each training step.\n",
    "        \"\"\"\n",
    "        # Get the next batch of data from the validation data loader\n",
    "        data = next(self._loader)\n",
    "        with torch.no_grad():\n",
    "            # Compute the validation loss on the current batch of data\n",
    "            loss_dict = self.trainer.model(data)\n",
    "\n",
    "            # Check for invalid losses\n",
    "            losses = sum(loss_dict.values())\n",
    "            assert torch.isfinite(losses).all(), loss_dict\n",
    "\n",
    "            # Reduce the loss across all workers\n",
    "            loss_dict_reduced = {\"val_\" + k: v.item() for k, v in\n",
    "                                 comm.reduce_dict(loss_dict).items()}\n",
    "            losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
    "\n",
    "            # Save the validation loss in the trainer storage\n",
    "            if comm.is_main_process():\n",
    "                self.trainer.storage.put_scalars(total_val_loss=losses_reduced,\n",
    "                                                 **loss_dict_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3fd96de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "from detectron2.engine import DefaultTrainer\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a23f204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "cur_dir = os.getcwd()\n",
    "# dataset path\n",
    "\n",
    "data_dir = r\"D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\"\n",
    "training_dataset_name = \"training_data\"\n",
    "training_json_file = os.path.join(data_dir, \"training_images\\\\0_SideLane_addedversion_Training_COCO.json\")\n",
    "training_img_dir = os.path.join(data_dir, \"training_images\")\n",
    "register_coco_instances(training_dataset_name, {}, training_json_file, training_img_dir)\n",
    "\n",
    "test_dataset_name = \"test_data\"\n",
    "test_json_file =  os.path.join(data_dir, \"testing_images\\\\0_SideLane_addedversion_Testing_COCO.json\")\n",
    "test_img_dir =  os.path.join(data_dir, \"testing_images\")\n",
    "register_coco_instances(test_dataset_name, {}, test_json_file, test_img_dir)\n",
    "\n",
    "#val_dataset_name = \"val_data\"\n",
    "#val_json_file =  os.path.join(data_dir, \"validation_annotations_coco.json\")\n",
    "#val_img_dir =  os.path.join(data_dir, \"validation_images\")\n",
    "#register_coco_instances(val_dataset_name, {}, val_json_file, val_img_dir)\n",
    "# output weight file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8399a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 20000\n",
    "weight_output = str(Helper.increment_path(Path('models') /'Side Lane September 2025'/ f'Base_rtx8000_26_September_2025_{max_iter}_v',mkdir=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fcf7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0de355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.MODEL.MASK_ON = True\n",
    "# Create a configuration and set up the model and datasets\n",
    "#model_file = \"models\\\\December 2024\\\\Sumiyoshi_dec16_v2_human_2024_10000_iters_v1\"\n",
    "#model_file = \"models\\\\April 2025\\\\April_Day_Night_10000_iters_v1\" #Sumiyoshi_2024_10000_iters_v4\n",
    "#model_file = \"models\\May 2025\\KNP_Sumi_26_May_2025_10000_v1\" #latest v3 not so go accuracy\n",
    "model_file = \"models\\\\Side Lane August 2025\\Base_rtx8000_10_August_2025_20000_v1\"\n",
    "#loading initial configuration file (can change here with above model file or previous dataset weight to update)\n",
    "cfg.merge_from_file(f\"{model_file}\\\\config.yml\")\n",
    "#loading initial weight file\n",
    "cfg.MODEL.WEIGHTS = f\"{model_file}\\\\model_best.pth\"\n",
    "\n",
    "#base weight file \n",
    "#model_file = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",
    "#cfg.merge_from_file(model_zoo.get_config_file(model_file)) \n",
    "#cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model_file)\n",
    "\n",
    "#set dataset\n",
    "cfg.DATASETS.TRAIN = (training_dataset_name,)\n",
    "cfg.DATASETS.TEST = (test_dataset_name,)\n",
    "# cfg.DATASETS.PRECOMPUTED_PROPOSAL_TOPK_TRAIN = 2500\n",
    "# cfg.DATASETS.PRECOMPUTED_PROPOSAL_TOPK_TEST = 1500\n",
    "# Workers\n",
    "cfg.DATALOADER.NUM_WORKERS = 8\n",
    "# Options: TrainingSampler, RepeatFactorTrainingSampler\n",
    "cfg.DATALOADER.SAMPLER_TRAIN = \"TrainingSampler\"\n",
    "# Repeat threshold for RepeatFactorTrainingSampler\n",
    "cfg.DATALOADER.REPEAT_THRESHOLD = 0.3\n",
    "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = False\n",
    "\n",
    "# cfg.MODEL.FPN.NORM = \"GN\"\n",
    "# cfg.MODEL.FPN.FUSE_TYPE = \"avg\"\n",
    "\n",
    "# cfg.MODEL.PROPOSAL_GENERATOR.NAME = \"RPN\"\n",
    "# cfg.MODEL.ROI_MASK_HEAD.NORM = \"GN\"\n",
    "# Solver\n",
    "cfg.SOLVER.IMS_PER_BATCH = 8\n",
    "cfg.SOLVER.BASE_LR = 0.0025 #0.0025\n",
    "cfg.SOLVER.WARMUP_ITERS = 2000 #5-10% of \n",
    "cfg.SOLVER.MOMENTUM = 0.9\n",
    "cfg.SOLVER.STEPS = (8000, 16000) #\n",
    "cfg.SOLVER.GAMMA = 0.1\n",
    "cfg.SOLVER.MAX_ITER = max_iter\n",
    "cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupMultiStepLR\"  # Use the warmup scheduler\n",
    "# checkpoint\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 1000\n",
    "#[192.02035868 119.79467167 169.64932096 150.05893666 220.94671905]\n",
    "#ratios [0.73263128 1.5411869  0.45270707]\n",
    "#cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[215.62343506,  86.09196645, 155.51176415, 184.45140588, 122.96515762]]  #sumiyoshi 07 feb 2025\n",
    "#cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [0.68256319, 0.45821762, 1.49434463]  #sumiyoshi 07 feb 2025\n",
    "cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[149.95695869, 90.25478231, 179.26082761, 119.37182681, 213.92048847]] #sumiyoshi 07 feb 2025\n",
    "cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [1.36056301, 0.71964180, 0.44608757] #sumiyoshi 07 feb 2025\n",
    "#sizes [149.95695869, 90.25478231, 179.26082761, 119.37182681, 213.92048847]\n",
    "#ratios [1.36056301, 0.71964180, 0.44608757]\n",
    "\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = cfg.SOLVER.CHECKPOINT_PERIOD\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6\n",
    "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.4\n",
    "# Classes\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = nc\n",
    "cfg.MODEL.DEVICE = device\n",
    "cfg.OUTPUT_DIR = weight_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c0c1dbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDNN_BENCHMARK: false\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: true\n",
      "  FILTER_EMPTY_ANNOTATIONS: false\n",
      "  NUM_WORKERS: 8\n",
      "  REPEAT_SQRT: true\n",
      "  REPEAT_THRESHOLD: 0.3\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: []\n",
      "  PROPOSAL_FILES_TRAIN: []\n",
      "  TEST:\n",
      "  - test_data\n",
      "  TRAIN:\n",
      "  - training_data\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: false\n",
      "    SIZE:\n",
      "    - 0.9\n",
      "    - 0.9\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN:\n",
      "  - 640\n",
      "  - 672\n",
      "  - 704\n",
      "  - 736\n",
      "  - 768\n",
      "  - 800\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "  RANDOM_FLIP: horizontal\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES:\n",
      "    - - -90\n",
      "      - 0\n",
      "      - 90\n",
      "    ASPECT_RATIOS:\n",
      "    - 1.36056301\n",
      "    - 0.7196418\n",
      "    - 0.44608757\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES:\n",
      "    - - 149.95695869\n",
      "      - 90.25478231\n",
      "      - 179.26082761\n",
      "      - 119.37182681\n",
      "      - 213.92048847\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_resnet_fpn_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES:\n",
      "    - res2\n",
      "    - res3\n",
      "    - res4\n",
      "    - res5\n",
      "    NORM: ''\n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: false\n",
      "  LOAD_PROPOSALS: false\n",
      "  MASK_ON: true\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: true\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN:\n",
      "  - 103.53\n",
      "  - 116.28\n",
      "  - 123.675\n",
      "  PIXEL_STD:\n",
      "  - 1.0\n",
      "  - 1.0\n",
      "  - 1.0\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: false\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE:\n",
      "    - false\n",
      "    - false\n",
      "    - false\n",
      "    - false\n",
      "    DEPTH: 101\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES:\n",
      "    - res2\n",
      "    - res3\n",
      "    - res4\n",
      "    - res5\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: true\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_WEIGHTS:\n",
      "    - 1.0\n",
      "    - 1.0\n",
      "    - 1.0\n",
      "    - 1.0\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES:\n",
      "    - p3\n",
      "    - p4\n",
      "    - p5\n",
      "    - p6\n",
      "    - p7\n",
      "    IOU_LABELS:\n",
      "    - 0\n",
      "    - -1\n",
      "    - 1\n",
      "    IOU_THRESHOLDS:\n",
      "    - 0.4\n",
      "    - 0.5\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NORM: ''\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.1\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS:\n",
      "    - - 10.0\n",
      "      - 10.0\n",
      "      - 5.0\n",
      "      - 5.0\n",
      "    - - 20.0\n",
      "      - 20.0\n",
      "      - 10.0\n",
      "      - 10.0\n",
      "    - - 30.0\n",
      "      - 30.0\n",
      "      - 15.0\n",
      "      - 15.0\n",
      "    IOUS:\n",
      "    - 0.5\n",
      "    - 0.6\n",
      "    - 0.7\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS:\n",
      "    - 10.0\n",
      "    - 10.0\n",
      "    - 5.0\n",
      "    - 5.0\n",
      "    CLS_AGNOSTIC_BBOX_REG: false\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    FED_LOSS_FREQ_WEIGHT_POWER: 0.5\n",
      "    FED_LOSS_NUM_CLASSES: 50\n",
      "    NAME: FastRCNNConvFCHead\n",
      "    NORM: ''\n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 2\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: false\n",
      "    USE_FED_LOSS: false\n",
      "    USE_SIGMOID_CE: false\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES:\n",
      "    - p2\n",
      "    - p3\n",
      "    - p4\n",
      "    - p5\n",
      "    IOU_LABELS:\n",
      "    - 0\n",
      "    - 1\n",
      "    IOU_THRESHOLDS:\n",
      "    - 0.5\n",
      "    NAME: StandardROIHeads\n",
      "    NMS_THRESH_TEST: 0.4\n",
      "    NUM_CLASSES: 2\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: true\n",
      "    SCORE_THRESH_TEST: 0.6\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS:\n",
      "    - 512\n",
      "    - 512\n",
      "    - 512\n",
      "    - 512\n",
      "    - 512\n",
      "    - 512\n",
      "    - 512\n",
      "    - 512\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: false\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: ''\n",
      "    NUM_CONV: 4\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS:\n",
      "    - 1.0\n",
      "    - 1.0\n",
      "    - 1.0\n",
      "    - 1.0\n",
      "    BOUNDARY_THRESH: -1\n",
      "    CONV_DIMS:\n",
      "    - -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES:\n",
      "    - p2\n",
      "    - p3\n",
      "    - p4\n",
      "    - p5\n",
      "    - p6\n",
      "    IOU_LABELS:\n",
      "    - 0\n",
      "    - -1\n",
      "    - 1\n",
      "    IOU_THRESHOLDS:\n",
      "    - 0.3\n",
      "    - 0.7\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 1000\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 2000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES:\n",
      "    - p2\n",
      "    - p3\n",
      "    - p4\n",
      "    - p5\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: models\\Side Lane August 2025\\Base_rtx8000_10_August_2025_20000_v1\\model_best.pth\n",
      "OUTPUT_DIR: models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\n",
      "SEED: -1\n",
      "SOLVER:\n",
      "  AMP:\n",
      "    ENABLED: false\n",
      "  BASE_LR: 0.0025\n",
      "  BASE_LR_END: 0.0\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 1000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: false\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 8\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 20000\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: false\n",
      "  NUM_DECAYS: 3\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  RESCALE_INTERVAL: false\n",
      "  STEPS:\n",
      "  - 8000\n",
      "  - 16000\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 2000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: null\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: false\n",
      "    FLIP: true\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES:\n",
      "    - 400\n",
      "    - 500\n",
      "    - 600\n",
      "    - 700\n",
      "    - 800\n",
      "    - 900\n",
      "    - 1000\n",
      "    - 1100\n",
      "    - 1200\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 1000\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: false\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "for fname in os.listdir(cfg.OUTPUT_DIR):\n",
    "    if \"tfevents\" in fname:\n",
    "        os.remove(os.path.join(cfg.OUTPUT_DIR, fname))\n",
    "print(cfg.dump())    \n",
    "f = open(f'{weight_output}\\\\config.yml', 'w')\n",
    "f.write(cfg.dump())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e620b01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "import detectron2.data.transforms as T\n",
    "from detectron2.data import DatasetMapper\n",
    "from detectron2.data import build_detection_train_loader\n",
    "class MyTrainer(DefaultTrainer):\n",
    "  @classmethod\n",
    "  def build_train_loader(cls, cfg):\n",
    "    \n",
    "        augs = []\n",
    "        # Aug 1: Add RandomBrightness with 50% chance\n",
    "        augs.append(\n",
    "            T.RandomApply(\n",
    "              T.RandomBrightness(\n",
    "                  intensity_min = 0.5,\n",
    "                  intensity_max = 1.5),\n",
    "              prob = 0.5\n",
    "            ))\n",
    "        augs.append(\n",
    "            T.RandomApply(\n",
    "              T.RandomSaturation(\n",
    "                  intensity_min = 0.5,\n",
    "                  intensity_max = 1.5),\n",
    "              prob = 0.5\n",
    "            ))\n",
    "            \n",
    "        augs.append(T.RandomApply(T.RandomRotation(\n",
    "               angle         = [-30, 30],\n",
    "               sample_style  = \"range\",\n",
    "               center        = [[0.4, 0.6], [0.4, 0.6]],\n",
    "               expand        = False\n",
    "             ), prob=0.5))\n",
    "        # Aug 2: Add ResizeShortestEdge\n",
    "        min_size = cfg.INPUT.MIN_SIZE_TRAIN\n",
    "        max_size = cfg.INPUT.MAX_SIZE_TRAIN\n",
    "        sample_style = cfg.INPUT.MIN_SIZE_TRAIN_SAMPLING\n",
    "        augs.append(T.ResizeShortestEdge(\n",
    "                min_size, \n",
    "                max_size, \n",
    "                sample_style)\n",
    "            )\n",
    "\n",
    "        # Aug 3: Add RandomFlipping\n",
    "        if cfg.INPUT.RANDOM_FLIP != \"none\":\n",
    "              augs.append(T.RandomFlip(\n",
    "              horizontal=cfg.INPUT.RANDOM_FLIP == \"horizontal\",\n",
    "              vertical=cfg.INPUT.RANDOM_FLIP == \"vertical\",\n",
    "            )\n",
    "          )\n",
    "        data_loader = build_detection_train_loader(cfg,\n",
    "            mapper=DatasetMapper(cfg, is_train=True, \n",
    "                                 augmentations=augs))\n",
    "        \n",
    "        #return build_detection_train_loader(cfg, mapper=custom_mapper) \n",
    "        return data_loader\n",
    "  \n",
    "  #@classmethod\n",
    "  #def build_test_loader(cls, cfg, dataset_name):\n",
    "  #  return build_test_loader_with_mosaic(cfg, dataset_name)\n",
    "  \n",
    "  @classmethod\n",
    "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "    if output_folder == None:\n",
    "      output_folder = cfg.OUTPUT_DIR\n",
    "    else:\n",
    "      output_folder = os.path.join(cfg.OUTPUT_DIR, output_folder)\n",
    "      os.makedirs(output_folder)\n",
    "    # Use \n",
    "    return COCOEvaluator(dataset_name, distributed=False, output_dir=output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cceebda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from detectron2.data import detection_utils as utils\n",
    "\n",
    "\n",
    "def mosaic_augmentation(dataset_dicts, image_size=(1024, 1024)):\n",
    "    \"\"\"Applies Mosaic augmentation to a dataset.\"\"\"\n",
    "    num_images = len(dataset_dicts)\n",
    "    mosaic_image = np.zeros((image_size[0], image_size[1], 3), dtype=np.uint8)\n",
    "    mosaic_annotations = []\n",
    "\n",
    "    # Randomly select 4 images\n",
    "    indices = np.random.choice(num_images, 4, replace=False)\n",
    "    offsets = [\n",
    "        (0, 0),\n",
    "        (0, image_size[1] // 2),\n",
    "        (image_size[0] // 2, 0),\n",
    "        (image_size[0] // 2, image_size[1] // 2),\n",
    "    ]\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        dataset_dict = dataset_dicts[idx]\n",
    "        image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
    "        h, w = image.shape[:2]\n",
    "\n",
    "        # Resize the image to fit into the mosaic\n",
    "        resized_image = cv2.resize(image, (image_size[1] // 2, image_size[0] // 2))\n",
    "        x_offset, y_offset = offsets[i]\n",
    "        mosaic_image[y_offset:y_offset + resized_image.shape[0], x_offset:x_offset + resized_image.shape[1]] = resized_image\n",
    "\n",
    "        # Adjust annotations\n",
    "        if \"annotations\" in dataset_dict:\n",
    "            for annotation in dataset_dict[\"annotations\"]:\n",
    "                bbox = annotation[\"bbox\"]\n",
    "                # Scale bounding box\n",
    "                bbox = [\n",
    "                    bbox[0] * resized_image.shape[1] / w + x_offset,\n",
    "                    bbox[1] * resized_image.shape[0] / h + y_offset,\n",
    "                    bbox[2] * resized_image.shape[1] / w + x_offset,\n",
    "                    bbox[3] * resized_image.shape[0] / h + y_offset,\n",
    "                ]\n",
    "                annotation[\"bbox\"] = bbox\n",
    "                mosaic_annotations.append(annotation)\n",
    "\n",
    "    return {\n",
    "        \"image\": mosaic_image,\n",
    "        \"annotations\": mosaic_annotations,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35855172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "def build_test_loader_with_mosaic(cfg, dataset_name):\n",
    "    return build_detection_test_loader(\n",
    "        cfg, dataset_name, mapper=test_mapper_with_mosaic\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c0fc056",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_mapper_with_mosaic(dataset_dict):\n",
    "    # Read the image\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)  # Ensure the original dict is not modified\n",
    "    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
    "    \n",
    "    # Apply Mosaic Augmentation or other transformations\n",
    "    transform_list = [\n",
    "        T.Resize((800, 800)),  # Example: Resize the image\n",
    "        T.RandomRotation([-30, 30]),  # Example: Random rotation\n",
    "    ]\n",
    "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
    "    \n",
    "    # Update the dataset dictionary with the transformed image\n",
    "    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1))  # Convert to Tensor\n",
    "    return dataset_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bee01329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from detectron2.layers import batched_nms\n",
    "from detectron2.structures import Boxes, Instances\n",
    "from typing import Callable, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "# rebuild\n",
    "def _inference(self, predictions: Tuple[torch.Tensor, torch.Tensor], proposals: List[Instances]):\n",
    "        boxes = self.predict_boxes(predictions, proposals)\n",
    "        scores = self.predict_probs(predictions, proposals)\n",
    "        image_shapes = [x.image_size for x in proposals]\n",
    "        return fast_rcnn_inference(\n",
    "            boxes,\n",
    "            scores,\n",
    "            image_shapes,\n",
    "            self.test_score_thresh,\n",
    "            self.test_nms_thresh,\n",
    "            self.test_topk_per_image,\n",
    "        )\n",
    "\n",
    "def fast_rcnn_inference(\n",
    "    boxes: List[torch.Tensor],\n",
    "    scores: List[torch.Tensor],\n",
    "    image_shapes: List[Tuple[int, int]],\n",
    "    score_thresh: float,\n",
    "    nms_thresh: float,\n",
    "    topk_per_image: int,\n",
    "):\n",
    "    result_per_image = [\n",
    "        fast_rcnn_inference_single_image(\n",
    "            boxes_per_image, scores_per_image, image_shape, score_thresh, nms_thresh, topk_per_image\n",
    "        )\n",
    "        for scores_per_image, boxes_per_image, image_shape in zip(scores, boxes, image_shapes)\n",
    "    ]\n",
    "    return [x[0] for x in result_per_image], [x[1] for x in result_per_image]\n",
    "\n",
    "def fast_rcnn_inference_single_image(\n",
    "    boxes,\n",
    "    scores,\n",
    "    image_shape: Tuple[int, int],\n",
    "    score_thresh: float,\n",
    "    nms_thresh: float,\n",
    "    topk_per_image: int,\n",
    "):\n",
    "    valid_mask = torch.isfinite(boxes).all(dim=1) & torch.isfinite(scores).all(dim=1)\n",
    "    if not valid_mask.all():\n",
    "        boxes = boxes[valid_mask]\n",
    "        scores = scores[valid_mask]\n",
    "\n",
    "    scores = scores[:, :-1]\n",
    "    num_bbox_reg_classes = boxes.shape[1] // 4\n",
    "    # Convert to Boxes to use the `clip` function ...\n",
    "    boxes = Boxes(boxes.reshape(-1, 4))\n",
    "    boxes.clip(image_shape)\n",
    "    boxes = boxes.tensor.view(-1, num_bbox_reg_classes, 4)  # R x C x 4\n",
    "\n",
    "    # 1. Filter results based on detection scores. It can make NMS more efficient\n",
    "    #    by filtering out low-confidence detections.\n",
    "    filter_mask = scores > score_thresh  # R x K\n",
    "    # R' x 2. First column contains indices of the R predictions;\n",
    "    # Second column contains indices of classes.\n",
    "    filter_inds = filter_mask.nonzero()\n",
    "    if num_bbox_reg_classes == 1:\n",
    "        boxes = boxes[filter_inds[:, 0], 0]\n",
    "    else:\n",
    "        boxes = boxes[filter_mask]\n",
    "    scores = scores[filter_mask]\n",
    "\n",
    "    # begin of changes\n",
    "    # 2. Apply NMS for all classes.\n",
    "    filter_inds1 = torch.ones_like(filter_inds) # make them all same class\n",
    "    keep = batched_nms(boxes, scores, filter_inds1[:,1] , nms_thresh)\n",
    "    # end of changes\n",
    "    if topk_per_image >= 0:\n",
    "        keep = keep[:topk_per_image]\n",
    "    boxes, scores, filter_inds = boxes[keep], scores[keep], filter_inds[keep]\n",
    "\n",
    "    result = Instances(image_shape)\n",
    "    result.pred_boxes = Boxes(boxes)\n",
    "    result.scores = scores\n",
    "    result.pred_classes = filter_inds[:, 1]\n",
    "    return result, filter_inds[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95ee87ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/26 14:05:22 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[09/26 14:05:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [<detectron2.data.transforms.augmentation_impl.RandomApply object at 0x000001B97DECEC90>, <detectron2.data.transforms.augmentation_impl.RandomApply object at 0x000001B97E0D2C10>, <detectron2.data.transforms.augmentation_impl.RandomApply object at 0x000001B97E151F90>, ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[09/26 14:05:22 d2.data.datasets.coco]: \u001b[0mLoaded 2260 images in COCO format from D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\training_images\\0_SideLane_addedversion_Training_COCO.json\n",
      "\u001b[32m[09/26 14:05:22 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|\n",
      "|    cow     | 8984         | background | 0            |\n",
      "|            |              |            |              |\n",
      "|   total    | 8984         |            |              |\u001b[0m\n",
      "\u001b[32m[09/26 14:05:22 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[09/26 14:05:22 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/26 14:05:22 d2.data.common]: \u001b[0mSerializing 2260 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/26 14:05:22 d2.data.common]: \u001b[0mSerialized dataset takes 25.12 MiB\n",
      "\u001b[32m[09/26 14:05:22 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=8\n",
      "\u001b[32m[09/26 14:05:23 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\testing_images\\0_SideLane_addedversion_Testing_COCO.json\n",
      "\u001b[32m[09/26 14:05:23 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|\n",
      "|    cow     | 2149         | background | 0            |\n",
      "|            |              |            |              |\n",
      "|   total    | 2149         |            |              |\u001b[0m\n",
      "\u001b[32m[09/26 14:05:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[09/26 14:05:23 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[09/26 14:05:23 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/26 14:05:23 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/26 14:05:23 d2.data.common]: \u001b[0mSerialized dataset takes 6.03 MiB\n",
      "\u001b[32m[09/26 14:05:23 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=8\n"
     ]
    }
   ],
   "source": [
    "import types\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.model.roi_heads.box_predictor.inference = types.MethodType(_inference, trainer.model.roi_heads.box_predictor)\n",
    "bm_hook = ValidationLoss(cfg, \n",
    "                        metric  = \"segm/AP50\", \n",
    "                        min_max = \"max\")\n",
    "trainer.register_hooks(hooks=[bm_hook])\n",
    "# Swap the positions of the evaluation and checkpointing hooks so that the validation loss is logged correctly\n",
    "trainer._hooks = trainer._hooks[:-2] + trainer._hooks[-2:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8729dd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "def imshow(image):\n",
    "  dpi = plt.rcParams[\"figure.dpi\"]\n",
    "  im_data = image[:,:, ::-1]\n",
    "  height, width, depth = im_data.shape\n",
    "  figsize = width / float(dpi), height / float(dpi)\n",
    "  fig = plt.figure(figsize=figsize)\n",
    "  plt.imshow(im_data)\n",
    "  plt.imshow(im_data)\n",
    "  plt.axis(\"off\")\n",
    "  plt.show()\n",
    "\n",
    "def visualize_image_boxes(img,masks,boxes,labels,colors=['r','g','b']):\n",
    "  v = Visualizer(img, metadata={})\n",
    "  v = v.overlay_instances(\n",
    "      masks=masks,\n",
    "      boxes=boxes, \n",
    "      labels=labels,\n",
    "      assigned_colors=colors*len(boxes)\n",
    "      )\n",
    "  im_data = v.get_image()\n",
    "  imshow(im_data)\n",
    "  \n",
    "def visualize_sample(sample):\n",
    "  img = sample['image'].to(\"cpu\").numpy()\n",
    "  img = np.moveaxis(img, 0, -1)\n",
    "  masks = sample['instances'].get('gt_masks')  \n",
    "  boxes = sample['instances'].get('gt_boxes')\n",
    "  labels = sample['instances'].get('gt_classes').to(\"cpu\").numpy()\n",
    "  visualize_image_boxes(img,masks, boxes,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c823162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display 2 training batch\n",
    "# import numpy as np\n",
    "# tli = iter(trainer.data_loader)\n",
    "# for i in range(2):\n",
    "#   batch = next(tli)\n",
    "#   for sample in batch:\n",
    "#     visualize_sample(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d53e3f70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/26 14:05:23 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from models\\Side Lane August 2025\\Base_rtx8000_10_August_2025_20000_v1\\model_best.pth ...\n",
      "\u001b[32m[09/26 14:05:28 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\choni\\anaconda3\\envs\\clone_from_super_venv\\Lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/26 14:06:21 d2.utils.events]: \u001b[0m eta: 8:22:30  iter: 19  total_loss: 0.5444  loss_cls: 0.05023  loss_box_reg: 0.1006  loss_mask: 0.0839  loss_rpn_cls: 0.1114  loss_rpn_loc: 0.2113  total_val_loss: 0.4867  val_loss_cls: 0.04023  val_loss_box_reg: 0.08127  val_loss_mask: 0.08432  val_loss_rpn_cls: 0.04277  val_loss_rpn_loc: 0.2271    time: 1.4992  last_time: 1.4380  data_time: 0.1451  last_data_time: 0.0078   lr: 2.6226e-05  max_mem: 15214M\n",
      "\u001b[32m[09/26 14:07:04 d2.utils.events]: \u001b[0m eta: 8:27:06  iter: 39  total_loss: 0.5557  loss_cls: 0.04903  loss_box_reg: 0.09777  loss_mask: 0.09179  loss_rpn_cls: 0.1173  loss_rpn_loc: 0.1993  total_val_loss: 0.4214  val_loss_cls: 0.03555  val_loss_box_reg: 0.06605  val_loss_mask: 0.08324  val_loss_rpn_cls: 0.03267  val_loss_rpn_loc: 0.1979    time: 1.5153  last_time: 1.6086  data_time: 0.0074  last_data_time: 0.0065   lr: 5.1201e-05  max_mem: 15214M\n",
      "\u001b[32m[09/26 14:07:49 d2.utils.events]: \u001b[0m eta: 8:28:14  iter: 59  total_loss: 0.492  loss_cls: 0.0499  loss_box_reg: 0.08997  loss_mask: 0.0906  loss_rpn_cls: 0.05749  loss_rpn_loc: 0.1842  total_val_loss: 0.3619  val_loss_cls: 0.03142  val_loss_box_reg: 0.06213  val_loss_mask: 0.08647  val_loss_rpn_cls: 0.02847  val_loss_rpn_loc: 0.1591    time: 1.5308  last_time: 1.6492  data_time: 0.0079  last_data_time: 0.0068   lr: 7.6176e-05  max_mem: 15214M\n",
      "\u001b[32m[09/26 14:08:32 d2.utils.events]: \u001b[0m eta: 8:27:51  iter: 79  total_loss: 0.4228  loss_cls: 0.04002  loss_box_reg: 0.08632  loss_mask: 0.08138  loss_rpn_cls: 0.05003  loss_rpn_loc: 0.1686  total_val_loss: 0.4046  val_loss_cls: 0.03486  val_loss_box_reg: 0.07538  val_loss_mask: 0.08222  val_loss_rpn_cls: 0.03271  val_loss_rpn_loc: 0.1526    time: 1.5319  last_time: 1.5239  data_time: 0.0078  last_data_time: 0.0095   lr: 0.00010115  max_mem: 15214M\n",
      "\u001b[32m[09/26 14:09:17 d2.utils.events]: \u001b[0m eta: 8:28:04  iter: 99  total_loss: 0.4066  loss_cls: 0.04565  loss_box_reg: 0.08715  loss_mask: 0.08412  loss_rpn_cls: 0.04812  loss_rpn_loc: 0.1395  total_val_loss: 0.3578  val_loss_cls: 0.03747  val_loss_box_reg: 0.06653  val_loss_mask: 0.0877  val_loss_rpn_cls: 0.0242  val_loss_rpn_loc: 0.1316    time: 1.5377  last_time: 1.8809  data_time: 0.0075  last_data_time: 0.0066   lr: 0.00012613  max_mem: 15215M\n",
      "\u001b[32m[09/26 14:10:16 d2.utils.events]: \u001b[0m eta: 8:32:14  iter: 119  total_loss: 0.3721  loss_cls: 0.03997  loss_box_reg: 0.08867  loss_mask: 0.08745  loss_rpn_cls: 0.03901  loss_rpn_loc: 0.1295  total_val_loss: 0.323  val_loss_cls: 0.03209  val_loss_box_reg: 0.06612  val_loss_mask: 0.08263  val_loss_rpn_cls: 0.02501  val_loss_rpn_loc: 0.1069    time: 1.6231  last_time: 2.6108  data_time: 0.0070  last_data_time: 0.0078   lr: 0.0001511  max_mem: 15215M\n",
      "\u001b[32m[09/26 14:11:18 d2.utils.events]: \u001b[0m eta: 8:35:11  iter: 139  total_loss: 0.3779  loss_cls: 0.04707  loss_box_reg: 0.09197  loss_mask: 0.08662  loss_rpn_cls: 0.04557  loss_rpn_loc: 0.1106  total_val_loss: 0.2617  val_loss_cls: 0.02492  val_loss_box_reg: 0.056  val_loss_mask: 0.08349  val_loss_rpn_cls: 0.01829  val_loss_rpn_loc: 0.08189    time: 1.7013  last_time: 1.7434  data_time: 0.0075  last_data_time: 0.0058   lr: 0.00017608  max_mem: 15215M\n",
      "\u001b[32m[09/26 14:12:20 d2.utils.events]: \u001b[0m eta: 8:40:59  iter: 159  total_loss: 0.3819  loss_cls: 0.04748  loss_box_reg: 0.09891  loss_mask: 0.08819  loss_rpn_cls: 0.03519  loss_rpn_loc: 0.1026  total_val_loss: 0.3153  val_loss_cls: 0.03593  val_loss_box_reg: 0.07454  val_loss_mask: 0.08435  val_loss_rpn_cls: 0.02681  val_loss_rpn_loc: 0.07974    time: 1.7702  last_time: 2.2885  data_time: 0.0071  last_data_time: 0.0066   lr: 0.00020105  max_mem: 15215M\n",
      "\u001b[32m[09/26 14:13:21 d2.utils.events]: \u001b[0m eta: 8:50:49  iter: 179  total_loss: 0.3768  loss_cls: 0.04847  loss_box_reg: 0.1035  loss_mask: 0.09099  loss_rpn_cls: 0.04364  loss_rpn_loc: 0.09535  total_val_loss: 0.2748  val_loss_cls: 0.03167  val_loss_box_reg: 0.06616  val_loss_mask: 0.08246  val_loss_rpn_cls: 0.01883  val_loss_rpn_loc: 0.0776    time: 1.8151  last_time: 1.9810  data_time: 0.0071  last_data_time: 0.0071   lr: 0.00022603  max_mem: 15215M\n",
      "\u001b[32m[09/26 14:14:21 d2.utils.events]: \u001b[0m eta: 8:56:16  iter: 199  total_loss: 0.3428  loss_cls: 0.0437  loss_box_reg: 0.09454  loss_mask: 0.0842  loss_rpn_cls: 0.02959  loss_rpn_loc: 0.07941  total_val_loss: 0.2783  val_loss_cls: 0.03152  val_loss_box_reg: 0.06632  val_loss_mask: 0.09015  val_loss_rpn_cls: 0.01434  val_loss_rpn_loc: 0.07345    time: 1.8490  last_time: 2.4257  data_time: 0.0072  last_data_time: 0.0068   lr: 0.000251  max_mem: 15215M\n",
      "\u001b[32m[09/26 14:15:21 d2.utils.events]: \u001b[0m eta: 9:18:48  iter: 219  total_loss: 0.3162  loss_cls: 0.04184  loss_box_reg: 0.09244  loss_mask: 0.08211  loss_rpn_cls: 0.02552  loss_rpn_loc: 0.07357  total_val_loss: 0.2635  val_loss_cls: 0.03388  val_loss_box_reg: 0.07278  val_loss_mask: 0.08504  val_loss_rpn_cls: 0.01739  val_loss_rpn_loc: 0.05758    time: 1.8739  last_time: 2.2121  data_time: 0.0069  last_data_time: 0.0072   lr: 0.00027598  max_mem: 15215M\n",
      "\u001b[32m[09/26 14:16:25 d2.utils.events]: \u001b[0m eta: 10:38:05  iter: 239  total_loss: 0.3428  loss_cls: 0.04299  loss_box_reg: 0.1047  loss_mask: 0.08407  loss_rpn_cls: 0.03236  loss_rpn_loc: 0.06196  total_val_loss: 0.2568  val_loss_cls: 0.03073  val_loss_box_reg: 0.06592  val_loss_mask: 0.08242  val_loss_rpn_cls: 0.01214  val_loss_rpn_loc: 0.05949    time: 1.9084  last_time: 2.1353  data_time: 0.0071  last_data_time: 0.0073   lr: 0.00030095  max_mem: 15215M\n",
      "\u001b[32m[09/26 14:17:19 d2.utils.events]: \u001b[0m eta: 10:37:26  iter: 259  total_loss: 0.2972  loss_cls: 0.03755  loss_box_reg: 0.08903  loss_mask: 0.08915  loss_rpn_cls: 0.02205  loss_rpn_loc: 0.05902  total_val_loss: 0.2435  val_loss_cls: 0.03261  val_loss_box_reg: 0.07027  val_loss_mask: 0.07876  val_loss_rpn_cls: 0.01369  val_loss_rpn_loc: 0.05217    time: 1.9047  last_time: 2.5736  data_time: 0.0078  last_data_time: 0.0091   lr: 0.00032593  max_mem: 15215M\n",
      "\u001b[32m[09/26 14:18:20 d2.utils.events]: \u001b[0m eta: 10:49:34  iter: 279  total_loss: 0.2797  loss_cls: 0.03345  loss_box_reg: 0.07763  loss_mask: 0.08272  loss_rpn_cls: 0.01987  loss_rpn_loc: 0.05672  total_val_loss: 0.2507  val_loss_cls: 0.03039  val_loss_box_reg: 0.07025  val_loss_mask: 0.09012  val_loss_rpn_cls: 0.01691  val_loss_rpn_loc: 0.04861    time: 1.9252  last_time: 2.2122  data_time: 0.0071  last_data_time: 0.0065   lr: 0.0003509  max_mem: 15215M\n",
      "\u001b[32m[09/26 14:19:24 d2.utils.events]: \u001b[0m eta: 10:53:06  iter: 299  total_loss: 0.2693  loss_cls: 0.03377  loss_box_reg: 0.0784  loss_mask: 0.08261  loss_rpn_cls: 0.01946  loss_rpn_loc: 0.04625  total_val_loss: 0.2212  val_loss_cls: 0.02461  val_loss_box_reg: 0.05764  val_loss_mask: 0.08132  val_loss_rpn_cls: 0.01381  val_loss_rpn_loc: 0.04085    time: 1.9433  last_time: 2.4344  data_time: 0.0072  last_data_time: 0.0081   lr: 0.00037588  max_mem: 15215M\n",
      "\u001b[32m[09/26 14:20:26 d2.utils.events]: \u001b[0m eta: 10:56:47  iter: 319  total_loss: 0.3053  loss_cls: 0.03843  loss_box_reg: 0.09428  loss_mask: 0.08626  loss_rpn_cls: 0.01943  loss_rpn_loc: 0.05503  total_val_loss: 0.2292  val_loss_cls: 0.0265  val_loss_box_reg: 0.06776  val_loss_mask: 0.08494  val_loss_rpn_cls: 0.01249  val_loss_rpn_loc: 0.04419    time: 1.9615  last_time: 2.6396  data_time: 0.0071  last_data_time: 0.0071   lr: 0.00040085  max_mem: 15215M\n",
      "\u001b[32m[09/26 14:21:27 d2.utils.events]: \u001b[0m eta: 10:57:28  iter: 339  total_loss: 0.3048  loss_cls: 0.03722  loss_box_reg: 0.1012  loss_mask: 0.08386  loss_rpn_cls: 0.02843  loss_rpn_loc: 0.05473  total_val_loss: 0.2249  val_loss_cls: 0.02677  val_loss_box_reg: 0.06546  val_loss_mask: 0.07973  val_loss_rpn_cls: 0.01235  val_loss_rpn_loc: 0.04079    time: 1.9689  last_time: 1.8854  data_time: 0.0074  last_data_time: 0.0074   lr: 0.00042583  max_mem: 15215M\n",
      "\u001b[32m[09/26 14:22:29 d2.utils.events]: \u001b[0m eta: 11:00:33  iter: 359  total_loss: 0.2714  loss_cls: 0.03346  loss_box_reg: 0.08927  loss_mask: 0.08269  loss_rpn_cls: 0.01987  loss_rpn_loc: 0.04541  total_val_loss: 0.2231  val_loss_cls: 0.02571  val_loss_box_reg: 0.06435  val_loss_mask: 0.08491  val_loss_rpn_cls: 0.01044  val_loss_rpn_loc: 0.03593    time: 1.9786  last_time: 2.1421  data_time: 0.0076  last_data_time: 0.0059   lr: 0.0004508  max_mem: 15215M\n",
      "\u001b[32m[09/26 14:23:51 d2.utils.events]: \u001b[0m eta: 11:02:21  iter: 379  total_loss: 0.2866  loss_cls: 0.03483  loss_box_reg: 0.09554  loss_mask: 0.08087  loss_rpn_cls: 0.02313  loss_rpn_loc: 0.05333  total_val_loss: 0.2279  val_loss_cls: 0.02878  val_loss_box_reg: 0.06523  val_loss_mask: 0.0829  val_loss_rpn_cls: 0.01013  val_loss_rpn_loc: 0.03741    time: 2.0275  last_time: 4.4252  data_time: 0.0074  last_data_time: 0.0062   lr: 0.00047578  max_mem: 15215M\n",
      "\u001b[32m[09/26 14:25:47 d2.utils.events]: \u001b[0m eta: 11:06:40  iter: 399  total_loss: 0.263  loss_cls: 0.03204  loss_box_reg: 0.08309  loss_mask: 0.08619  loss_rpn_cls: 0.01598  loss_rpn_loc: 0.03963  total_val_loss: 0.2117  val_loss_cls: 0.02459  val_loss_box_reg: 0.06029  val_loss_mask: 0.08138  val_loss_rpn_cls: 0.008304  val_loss_rpn_loc: 0.03316    time: 2.1317  last_time: 4.5015  data_time: 0.0079  last_data_time: 0.0060   lr: 0.00050075  max_mem: 15215M\n",
      "\u001b[32m[09/26 14:26:56 d2.utils.events]: \u001b[0m eta: 11:05:35  iter: 419  total_loss: 0.2677  loss_cls: 0.03226  loss_box_reg: 0.0803  loss_mask: 0.07657  loss_rpn_cls: 0.01511  loss_rpn_loc: 0.04036  total_val_loss: 0.2217  val_loss_cls: 0.02518  val_loss_box_reg: 0.06524  val_loss_mask: 0.08264  val_loss_rpn_cls: 0.0105  val_loss_rpn_loc: 0.03313    time: 2.1458  last_time: 1.5037  data_time: 0.0072  last_data_time: 0.0069   lr: 0.00052573  max_mem: 15215M\n",
      "\u001b[32m[09/26 14:27:40 d2.utils.events]: \u001b[0m eta: 11:00:01  iter: 439  total_loss: 0.2901  loss_cls: 0.03572  loss_box_reg: 0.09856  loss_mask: 0.08816  loss_rpn_cls: 0.02066  loss_rpn_loc: 0.04724  total_val_loss: 0.2287  val_loss_cls: 0.0249  val_loss_box_reg: 0.06633  val_loss_mask: 0.08728  val_loss_rpn_cls: 0.01041  val_loss_rpn_loc: 0.03106    time: 2.1197  last_time: 1.6180  data_time: 0.0071  last_data_time: 0.0077   lr: 0.0005507  max_mem: 15215M\n",
      "\u001b[32m[09/26 14:28:24 d2.utils.events]: \u001b[0m eta: 10:53:18  iter: 459  total_loss: 0.2747  loss_cls: 0.03534  loss_box_reg: 0.08672  loss_mask: 0.08548  loss_rpn_cls: 0.01881  loss_rpn_loc: 0.04877  total_val_loss: 0.2084  val_loss_cls: 0.02339  val_loss_box_reg: 0.06296  val_loss_mask: 0.08398  val_loss_rpn_cls: 0.007367  val_loss_rpn_loc: 0.03312    time: 2.0937  last_time: 1.5113  data_time: 0.0079  last_data_time: 0.0100   lr: 0.00057568  max_mem: 15215M\n",
      "\u001b[32m[09/26 14:29:08 d2.utils.events]: \u001b[0m eta: 10:47:08  iter: 479  total_loss: 0.2708  loss_cls: 0.03911  loss_box_reg: 0.09429  loss_mask: 0.08146  loss_rpn_cls: 0.01636  loss_rpn_loc: 0.04041  total_val_loss: 0.2173  val_loss_cls: 0.02361  val_loss_box_reg: 0.06427  val_loss_mask: 0.07993  val_loss_rpn_cls: 0.009273  val_loss_rpn_loc: 0.03027    time: 2.0709  last_time: 1.4795  data_time: 0.0076  last_data_time: 0.0068   lr: 0.00060065  max_mem: 15216M\n",
      "\u001b[32m[09/26 14:29:52 d2.utils.events]: \u001b[0m eta: 10:38:13  iter: 499  total_loss: 0.2678  loss_cls: 0.03231  loss_box_reg: 0.08111  loss_mask: 0.0804  loss_rpn_cls: 0.01753  loss_rpn_loc: 0.04625  total_val_loss: 0.2093  val_loss_cls: 0.02628  val_loss_box_reg: 0.06761  val_loss_mask: 0.08114  val_loss_rpn_cls: 0.008819  val_loss_rpn_loc: 0.03147    time: 2.0496  last_time: 1.6556  data_time: 0.0071  last_data_time: 0.0067   lr: 0.00062563  max_mem: 15216M\n",
      "\u001b[32m[09/26 14:30:38 d2.utils.events]: \u001b[0m eta: 10:24:13  iter: 519  total_loss: 0.2582  loss_cls: 0.03165  loss_box_reg: 0.08677  loss_mask: 0.09013  loss_rpn_cls: 0.01158  loss_rpn_loc: 0.03783  total_val_loss: 0.2152  val_loss_cls: 0.02434  val_loss_box_reg: 0.06407  val_loss_mask: 0.08226  val_loss_rpn_cls: 0.0093  val_loss_rpn_loc: 0.03156    time: 2.0324  last_time: 1.5644  data_time: 0.0142  last_data_time: 0.0086   lr: 0.0006506  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:31:25 d2.utils.events]: \u001b[0m eta: 9:51:12  iter: 539  total_loss: 0.277  loss_cls: 0.03696  loss_box_reg: 0.09535  loss_mask: 0.08598  loss_rpn_cls: 0.0146  loss_rpn_loc: 0.04389  total_val_loss: 0.2042  val_loss_cls: 0.02356  val_loss_box_reg: 0.06715  val_loss_mask: 0.08244  val_loss_rpn_cls: 0.006193  val_loss_rpn_loc: 0.03084    time: 2.0165  last_time: 1.5663  data_time: 0.0153  last_data_time: 0.0141   lr: 0.00067558  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:32:12 d2.utils.events]: \u001b[0m eta: 9:16:52  iter: 559  total_loss: 0.2484  loss_cls: 0.0332  loss_box_reg: 0.07871  loss_mask: 0.07814  loss_rpn_cls: 0.01168  loss_rpn_loc: 0.03981  total_val_loss: 0.2045  val_loss_cls: 0.02227  val_loss_box_reg: 0.05923  val_loss_mask: 0.08151  val_loss_rpn_cls: 0.008136  val_loss_rpn_loc: 0.03115    time: 2.0020  last_time: 1.5554  data_time: 0.0151  last_data_time: 0.0128   lr: 0.00070055  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:33:01 d2.utils.events]: \u001b[0m eta: 9:12:10  iter: 579  total_loss: 0.2938  loss_cls: 0.04289  loss_box_reg: 0.09268  loss_mask: 0.08311  loss_rpn_cls: 0.01681  loss_rpn_loc: 0.04602  total_val_loss: 0.2072  val_loss_cls: 0.02185  val_loss_box_reg: 0.06401  val_loss_mask: 0.08255  val_loss_rpn_cls: 0.007949  val_loss_rpn_loc: 0.03034    time: 1.9899  last_time: 1.6398  data_time: 0.0161  last_data_time: 0.0179   lr: 0.00072553  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:33:48 d2.utils.events]: \u001b[0m eta: 9:06:44  iter: 599  total_loss: 0.2609  loss_cls: 0.03095  loss_box_reg: 0.08237  loss_mask: 0.08086  loss_rpn_cls: 0.01568  loss_rpn_loc: 0.04157  total_val_loss: 0.2161  val_loss_cls: 0.0244  val_loss_box_reg: 0.06628  val_loss_mask: 0.08212  val_loss_rpn_cls: 0.007425  val_loss_rpn_loc: 0.03083    time: 1.9780  last_time: 1.6029  data_time: 0.0155  last_data_time: 0.0158   lr: 0.0007505  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:34:36 d2.utils.events]: \u001b[0m eta: 9:04:59  iter: 619  total_loss: 0.2714  loss_cls: 0.03067  loss_box_reg: 0.09081  loss_mask: 0.08592  loss_rpn_cls: 0.01391  loss_rpn_loc: 0.04115  total_val_loss: 0.1992  val_loss_cls: 0.02227  val_loss_box_reg: 0.06136  val_loss_mask: 0.08319  val_loss_rpn_cls: 0.008481  val_loss_rpn_loc: 0.02997    time: 1.9672  last_time: 1.6018  data_time: 0.0153  last_data_time: 0.0149   lr: 0.00077548  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:35:23 d2.utils.events]: \u001b[0m eta: 9:01:57  iter: 639  total_loss: 0.2581  loss_cls: 0.02857  loss_box_reg: 0.07889  loss_mask: 0.08399  loss_rpn_cls: 0.01284  loss_rpn_loc: 0.04169  total_val_loss: 0.1996  val_loss_cls: 0.01856  val_loss_box_reg: 0.05725  val_loss_mask: 0.07876  val_loss_rpn_cls: 0.007043  val_loss_rpn_loc: 0.02957    time: 1.9563  last_time: 1.6317  data_time: 0.0159  last_data_time: 0.0142   lr: 0.00080045  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:36:10 d2.utils.events]: \u001b[0m eta: 8:59:01  iter: 659  total_loss: 0.2652  loss_cls: 0.03407  loss_box_reg: 0.09459  loss_mask: 0.08497  loss_rpn_cls: 0.01182  loss_rpn_loc: 0.04089  total_val_loss: 0.2032  val_loss_cls: 0.02368  val_loss_box_reg: 0.06727  val_loss_mask: 0.08042  val_loss_rpn_cls: 0.004974  val_loss_rpn_loc: 0.03127    time: 1.9466  last_time: 1.4791  data_time: 0.0145  last_data_time: 0.0061   lr: 0.00082543  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:36:55 d2.utils.events]: \u001b[0m eta: 8:55:25  iter: 679  total_loss: 0.2976  loss_cls: 0.03557  loss_box_reg: 0.09429  loss_mask: 0.08955  loss_rpn_cls: 0.01225  loss_rpn_loc: 0.04091  total_val_loss: 0.2015  val_loss_cls: 0.02594  val_loss_box_reg: 0.06208  val_loss_mask: 0.08276  val_loss_rpn_cls: 0.005921  val_loss_rpn_loc: 0.02901    time: 1.9351  last_time: 1.5418  data_time: 0.0077  last_data_time: 0.0068   lr: 0.0008504  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:37:38 d2.utils.events]: \u001b[0m eta: 8:52:20  iter: 699  total_loss: 0.2625  loss_cls: 0.03332  loss_box_reg: 0.09371  loss_mask: 0.08603  loss_rpn_cls: 0.01244  loss_rpn_loc: 0.0438  total_val_loss: 0.202  val_loss_cls: 0.02453  val_loss_box_reg: 0.05865  val_loss_mask: 0.08453  val_loss_rpn_cls: 0.004356  val_loss_rpn_loc: 0.02983    time: 1.9238  last_time: 1.6311  data_time: 0.0076  last_data_time: 0.0071   lr: 0.00087538  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:38:23 d2.utils.events]: \u001b[0m eta: 8:49:16  iter: 719  total_loss: 0.2435  loss_cls: 0.02946  loss_box_reg: 0.08074  loss_mask: 0.07731  loss_rpn_cls: 0.01357  loss_rpn_loc: 0.04464  total_val_loss: 0.2136  val_loss_cls: 0.02481  val_loss_box_reg: 0.06749  val_loss_mask: 0.08233  val_loss_rpn_cls: 0.005534  val_loss_rpn_loc: 0.03088    time: 1.9135  last_time: 1.5205  data_time: 0.0078  last_data_time: 0.0062   lr: 0.00090035  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:39:07 d2.utils.events]: \u001b[0m eta: 8:47:08  iter: 739  total_loss: 0.3005  loss_cls: 0.03838  loss_box_reg: 0.09868  loss_mask: 0.08976  loss_rpn_cls: 0.01118  loss_rpn_loc: 0.04709  total_val_loss: 0.2098  val_loss_cls: 0.02681  val_loss_box_reg: 0.06477  val_loss_mask: 0.08509  val_loss_rpn_cls: 0.006018  val_loss_rpn_loc: 0.03103    time: 1.9037  last_time: 1.7124  data_time: 0.0080  last_data_time: 0.0076   lr: 0.00092533  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:39:50 d2.utils.events]: \u001b[0m eta: 8:44:51  iter: 759  total_loss: 0.2669  loss_cls: 0.02844  loss_box_reg: 0.08298  loss_mask: 0.08313  loss_rpn_cls: 0.01014  loss_rpn_loc: 0.03685  total_val_loss: 0.2062  val_loss_cls: 0.02252  val_loss_box_reg: 0.06212  val_loss_mask: 0.08232  val_loss_rpn_cls: 0.005833  val_loss_rpn_loc: 0.02881    time: 1.8929  last_time: 1.5075  data_time: 0.0079  last_data_time: 0.0066   lr: 0.0009503  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:40:34 d2.utils.events]: \u001b[0m eta: 8:42:51  iter: 779  total_loss: 0.2429  loss_cls: 0.02855  loss_box_reg: 0.08364  loss_mask: 0.08679  loss_rpn_cls: 0.007963  loss_rpn_loc: 0.03934  total_val_loss: 0.2137  val_loss_cls: 0.02242  val_loss_box_reg: 0.06463  val_loss_mask: 0.0829  val_loss_rpn_cls: 0.007605  val_loss_rpn_loc: 0.02941    time: 1.8839  last_time: 1.5639  data_time: 0.0074  last_data_time: 0.0078   lr: 0.00097528  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:41:18 d2.utils.events]: \u001b[0m eta: 8:40:37  iter: 799  total_loss: 0.2403  loss_cls: 0.03017  loss_box_reg: 0.07744  loss_mask: 0.07674  loss_rpn_cls: 0.009908  loss_rpn_loc: 0.03437  total_val_loss: 0.2161  val_loss_cls: 0.02485  val_loss_box_reg: 0.06676  val_loss_mask: 0.08297  val_loss_rpn_cls: 0.006976  val_loss_rpn_loc: 0.03362    time: 1.8760  last_time: 1.6258  data_time: 0.0076  last_data_time: 0.0069   lr: 0.0010003  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:42:02 d2.utils.events]: \u001b[0m eta: 8:38:26  iter: 819  total_loss: 0.2348  loss_cls: 0.03109  loss_box_reg: 0.07943  loss_mask: 0.07763  loss_rpn_cls: 0.01169  loss_rpn_loc: 0.03695  total_val_loss: 0.198  val_loss_cls: 0.02328  val_loss_box_reg: 0.0617  val_loss_mask: 0.08229  val_loss_rpn_cls: 0.005035  val_loss_rpn_loc: 0.02824    time: 1.8679  last_time: 1.6653  data_time: 0.0088  last_data_time: 0.0066   lr: 0.0010252  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:42:46 d2.utils.events]: \u001b[0m eta: 8:36:48  iter: 839  total_loss: 0.2599  loss_cls: 0.03315  loss_box_reg: 0.09219  loss_mask: 0.09107  loss_rpn_cls: 0.008732  loss_rpn_loc: 0.04162  total_val_loss: 0.1912  val_loss_cls: 0.02022  val_loss_box_reg: 0.05639  val_loss_mask: 0.08447  val_loss_rpn_cls: 0.005113  val_loss_rpn_loc: 0.03    time: 1.8604  last_time: 1.5555  data_time: 0.0075  last_data_time: 0.0104   lr: 0.0010502  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:43:31 d2.utils.events]: \u001b[0m eta: 8:35:59  iter: 859  total_loss: 0.2503  loss_cls: 0.02911  loss_box_reg: 0.08615  loss_mask: 0.08351  loss_rpn_cls: 0.01072  loss_rpn_loc: 0.03713  total_val_loss: 0.202  val_loss_cls: 0.02201  val_loss_box_reg: 0.06121  val_loss_mask: 0.08081  val_loss_rpn_cls: 0.004514  val_loss_rpn_loc: 0.03061    time: 1.8534  last_time: 1.5082  data_time: 0.0081  last_data_time: 0.0102   lr: 0.0010752  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:44:15 d2.utils.events]: \u001b[0m eta: 8:34:12  iter: 879  total_loss: 0.2712  loss_cls: 0.03176  loss_box_reg: 0.09919  loss_mask: 0.08383  loss_rpn_cls: 0.01053  loss_rpn_loc: 0.03936  total_val_loss: 0.2059  val_loss_cls: 0.02338  val_loss_box_reg: 0.06084  val_loss_mask: 0.0864  val_loss_rpn_cls: 0.00522  val_loss_rpn_loc: 0.02691    time: 1.8466  last_time: 1.6452  data_time: 0.0077  last_data_time: 0.0066   lr: 0.0011002  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:44:58 d2.utils.events]: \u001b[0m eta: 8:32:11  iter: 899  total_loss: 0.2371  loss_cls: 0.02604  loss_box_reg: 0.08326  loss_mask: 0.0803  loss_rpn_cls: 0.006238  loss_rpn_loc: 0.03945  total_val_loss: 0.2114  val_loss_cls: 0.02137  val_loss_box_reg: 0.06037  val_loss_mask: 0.08566  val_loss_rpn_cls: 0.003999  val_loss_rpn_loc: 0.03057    time: 1.8393  last_time: 1.4629  data_time: 0.0075  last_data_time: 0.0071   lr: 0.0011251  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:45:43 d2.utils.events]: \u001b[0m eta: 8:30:55  iter: 919  total_loss: 0.2357  loss_cls: 0.02725  loss_box_reg: 0.07972  loss_mask: 0.08717  loss_rpn_cls: 0.006341  loss_rpn_loc: 0.03709  total_val_loss: 0.1962  val_loss_cls: 0.02091  val_loss_box_reg: 0.06137  val_loss_mask: 0.08261  val_loss_rpn_cls: 0.005317  val_loss_rpn_loc: 0.02862    time: 1.8328  last_time: 1.5324  data_time: 0.0078  last_data_time: 0.0075   lr: 0.0011501  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:46:26 d2.utils.events]: \u001b[0m eta: 8:29:21  iter: 939  total_loss: 0.2289  loss_cls: 0.02956  loss_box_reg: 0.07643  loss_mask: 0.08218  loss_rpn_cls: 0.007142  loss_rpn_loc: 0.0334  total_val_loss: 0.2078  val_loss_cls: 0.02049  val_loss_box_reg: 0.06662  val_loss_mask: 0.08989  val_loss_rpn_cls: 0.005584  val_loss_rpn_loc: 0.03214    time: 1.8267  last_time: 1.4911  data_time: 0.0078  last_data_time: 0.0082   lr: 0.0011751  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:47:10 d2.utils.events]: \u001b[0m eta: 8:28:30  iter: 959  total_loss: 0.2515  loss_cls: 0.03336  loss_box_reg: 0.07856  loss_mask: 0.08499  loss_rpn_cls: 0.007798  loss_rpn_loc: 0.03894  total_val_loss: 0.2146  val_loss_cls: 0.02484  val_loss_box_reg: 0.067  val_loss_mask: 0.08328  val_loss_rpn_cls: 0.004907  val_loss_rpn_loc: 0.03124    time: 1.8206  last_time: 1.5524  data_time: 0.0078  last_data_time: 0.0093   lr: 0.0012001  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:47:54 d2.utils.events]: \u001b[0m eta: 8:27:37  iter: 979  total_loss: 0.268  loss_cls: 0.03109  loss_box_reg: 0.09055  loss_mask: 0.08882  loss_rpn_cls: 0.008274  loss_rpn_loc: 0.04136  total_val_loss: 0.1962  val_loss_cls: 0.02518  val_loss_box_reg: 0.06167  val_loss_mask: 0.08207  val_loss_rpn_cls: 0.003303  val_loss_rpn_loc: 0.03443    time: 1.8149  last_time: 1.5761  data_time: 0.0078  last_data_time: 0.0089   lr: 0.001225  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:48:39 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\testing_images\\0_SideLane_addedversion_Testing_COCO.json\n",
      "\u001b[32m[09/26 14:48:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/26 14:48:39 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/26 14:48:39 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/26 14:48:39 d2.data.common]: \u001b[0mSerialized dataset takes 6.03 MiB\n",
      "\u001b[32m[09/26 14:48:39 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[09/26 14:48:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 566 batches\n",
      "\u001b[32m[09/26 14:48:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/566. Dataloading: 0.0004 s/iter. Inference: 0.0764 s/iter. Eval: 0.0066 s/iter. Total: 0.0834 s/iter. ETA=0:00:46\n",
      "\u001b[32m[09/26 14:48:48 d2.evaluation.evaluator]: \u001b[0mInference done 76/566. Dataloading: 0.0006 s/iter. Inference: 0.0745 s/iter. Eval: 0.0030 s/iter. Total: 0.0781 s/iter. ETA=0:00:38\n",
      "\u001b[32m[09/26 14:48:53 d2.evaluation.evaluator]: \u001b[0mInference done 140/566. Dataloading: 0.0006 s/iter. Inference: 0.0738 s/iter. Eval: 0.0039 s/iter. Total: 0.0783 s/iter. ETA=0:00:33\n",
      "\u001b[32m[09/26 14:48:58 d2.evaluation.evaluator]: \u001b[0mInference done 203/566. Dataloading: 0.0006 s/iter. Inference: 0.0743 s/iter. Eval: 0.0039 s/iter. Total: 0.0789 s/iter. ETA=0:00:28\n",
      "\u001b[32m[09/26 14:49:03 d2.evaluation.evaluator]: \u001b[0mInference done 264/566. Dataloading: 0.0006 s/iter. Inference: 0.0753 s/iter. Eval: 0.0038 s/iter. Total: 0.0798 s/iter. ETA=0:00:24\n",
      "\u001b[32m[09/26 14:49:08 d2.evaluation.evaluator]: \u001b[0mInference done 331/566. Dataloading: 0.0006 s/iter. Inference: 0.0747 s/iter. Eval: 0.0035 s/iter. Total: 0.0789 s/iter. ETA=0:00:18\n",
      "\u001b[32m[09/26 14:49:13 d2.evaluation.evaluator]: \u001b[0mInference done 397/566. Dataloading: 0.0006 s/iter. Inference: 0.0746 s/iter. Eval: 0.0032 s/iter. Total: 0.0784 s/iter. ETA=0:00:13\n",
      "\u001b[32m[09/26 14:49:18 d2.evaluation.evaluator]: \u001b[0mInference done 460/566. Dataloading: 0.0006 s/iter. Inference: 0.0745 s/iter. Eval: 0.0034 s/iter. Total: 0.0786 s/iter. ETA=0:00:08\n",
      "\u001b[32m[09/26 14:49:23 d2.evaluation.evaluator]: \u001b[0mInference done 523/566. Dataloading: 0.0006 s/iter. Inference: 0.0748 s/iter. Eval: 0.0034 s/iter. Total: 0.0788 s/iter. ETA=0:00:03\n",
      "\u001b[32m[09/26 14:49:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:44.811731 (0.079878 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 14:49:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.074938 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 14:49:27 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/26 14:49:27 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\coco_instances_results.json\n",
      "\u001b[32m[09/26 14:49:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.23s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.933\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.932\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.933\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.936\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.951\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.946\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.954\n",
      "\u001b[32m[09/26 14:49:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 93.287 | 99.009 | 98.955 |  nan  | 93.231 | 93.335 |\n",
      "\u001b[32m[09/26 14:49:27 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 14:49:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 93.287 | background | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.34s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.861\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.832\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.880\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.881\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.894\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.868\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.911\n",
      "\u001b[32m[09/26 14:49:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 86.085 | 99.009 | 98.961 |  nan  | 83.208 | 87.969 |\n",
      "\u001b[32m[09/26 14:49:28 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 14:49:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 86.085 | background | nan  |\n",
      "\u001b[32m[09/26 14:49:28 d2.engine.defaults]: \u001b[0mEvaluation results for test_data in csv format:\n",
      "\u001b[32m[09/26 14:49:28 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/26 14:49:28 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 14:49:28 d2.evaluation.testing]: \u001b[0mcopypaste: 93.2873,99.0090,98.9554,nan,93.2312,93.3353\n",
      "\u001b[32m[09/26 14:49:28 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/26 14:49:28 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 14:49:28 d2.evaluation.testing]: \u001b[0mcopypaste: 86.0855,99.0090,98.9614,nan,83.2079,87.9690\n",
      "\u001b[32m[09/26 14:49:28 detectron2]: \u001b[0mUpdating best model at iteration 999 with segm/AP50 = 99.00897131966718\n",
      "\u001b[32m[09/26 14:49:29 d2.utils.events]: \u001b[0m eta: 8:26:06  iter: 999  total_loss: 0.2683  loss_cls: 0.03625  loss_box_reg: 0.09837  loss_mask: 0.08735  loss_rpn_cls: 0.01165  loss_rpn_loc: 0.04471  total_val_loss: 0.2072  val_loss_cls: 0.02457  val_loss_box_reg: 0.06528  val_loss_mask: 0.08026  val_loss_rpn_cls: 0.003637  val_loss_rpn_loc: 0.02774    time: 1.8098  last_time: 1.6023  data_time: 0.0077  last_data_time: 0.0075   lr: 0.00125  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:50:13 d2.utils.events]: \u001b[0m eta: 8:26:22  iter: 1019  total_loss: 0.2672  loss_cls: 0.03525  loss_box_reg: 0.09671  loss_mask: 0.08184  loss_rpn_cls: 0.005884  loss_rpn_loc: 0.0352  total_val_loss: 0.227  val_loss_cls: 0.02577  val_loss_box_reg: 0.06746  val_loss_mask: 0.08713  val_loss_rpn_cls: 0.004769  val_loss_rpn_loc: 0.03089    time: 1.8046  last_time: 1.4644  data_time: 0.0079  last_data_time: 0.0069   lr: 0.001275  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:51:01 d2.utils.events]: \u001b[0m eta: 8:26:26  iter: 1039  total_loss: 0.2488  loss_cls: 0.02795  loss_box_reg: 0.08701  loss_mask: 0.08177  loss_rpn_cls: 0.007778  loss_rpn_loc: 0.03854  total_val_loss: 0.209  val_loss_cls: 0.02276  val_loss_box_reg: 0.06791  val_loss_mask: 0.08547  val_loss_rpn_cls: 0.005367  val_loss_rpn_loc: 0.02947    time: 1.8017  last_time: 1.7700  data_time: 0.0159  last_data_time: 0.0155   lr: 0.0013  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:51:49 d2.utils.events]: \u001b[0m eta: 8:26:54  iter: 1059  total_loss: 0.277  loss_cls: 0.03836  loss_box_reg: 0.0981  loss_mask: 0.08828  loss_rpn_cls: 0.009566  loss_rpn_loc: 0.04642  total_val_loss: 0.1907  val_loss_cls: 0.02065  val_loss_box_reg: 0.05791  val_loss_mask: 0.08192  val_loss_rpn_cls: 0.003455  val_loss_rpn_loc: 0.02944    time: 1.7989  last_time: 1.6694  data_time: 0.0159  last_data_time: 0.0170   lr: 0.0013249  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:52:36 d2.utils.events]: \u001b[0m eta: 8:26:38  iter: 1079  total_loss: 0.2206  loss_cls: 0.02667  loss_box_reg: 0.07087  loss_mask: 0.08571  loss_rpn_cls: 0.005628  loss_rpn_loc: 0.03265  total_val_loss: 0.2009  val_loss_cls: 0.02288  val_loss_box_reg: 0.05931  val_loss_mask: 0.08154  val_loss_rpn_cls: 0.0052  val_loss_rpn_loc: 0.02894    time: 1.7953  last_time: 1.6584  data_time: 0.0157  last_data_time: 0.0179   lr: 0.0013499  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:53:23 d2.utils.events]: \u001b[0m eta: 8:26:53  iter: 1099  total_loss: 0.2581  loss_cls: 0.03242  loss_box_reg: 0.08666  loss_mask: 0.0833  loss_rpn_cls: 0.008681  loss_rpn_loc: 0.04021  total_val_loss: 0.2137  val_loss_cls: 0.02439  val_loss_box_reg: 0.06709  val_loss_mask: 0.08744  val_loss_rpn_cls: 0.004251  val_loss_rpn_loc: 0.03317    time: 1.7924  last_time: 1.6517  data_time: 0.0150  last_data_time: 0.0126   lr: 0.0013749  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:54:10 d2.utils.events]: \u001b[0m eta: 8:26:06  iter: 1119  total_loss: 0.2392  loss_cls: 0.03028  loss_box_reg: 0.08492  loss_mask: 0.08492  loss_rpn_cls: 0.007322  loss_rpn_loc: 0.04011  total_val_loss: 0.227  val_loss_cls: 0.02801  val_loss_box_reg: 0.07032  val_loss_mask: 0.08654  val_loss_rpn_cls: 0.004354  val_loss_rpn_loc: 0.03383    time: 1.7893  last_time: 1.5877  data_time: 0.0165  last_data_time: 0.0146   lr: 0.0013999  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:54:59 d2.utils.events]: \u001b[0m eta: 8:25:25  iter: 1139  total_loss: 0.2891  loss_cls: 0.0365  loss_box_reg: 0.09922  loss_mask: 0.08469  loss_rpn_cls: 0.00693  loss_rpn_loc: 0.04962  total_val_loss: 0.2097  val_loss_cls: 0.0256  val_loss_box_reg: 0.07027  val_loss_mask: 0.08306  val_loss_rpn_cls: 0.005211  val_loss_rpn_loc: 0.03389    time: 1.7870  last_time: 1.6747  data_time: 0.0160  last_data_time: 0.0143   lr: 0.0014248  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:55:46 d2.utils.events]: \u001b[0m eta: 8:24:26  iter: 1159  total_loss: 0.2542  loss_cls: 0.03582  loss_box_reg: 0.09201  loss_mask: 0.08466  loss_rpn_cls: 0.006633  loss_rpn_loc: 0.04145  total_val_loss: 0.2045  val_loss_cls: 0.02329  val_loss_box_reg: 0.0619  val_loss_mask: 0.07848  val_loss_rpn_cls: 0.004734  val_loss_rpn_loc: 0.02963    time: 1.7846  last_time: 1.5709  data_time: 0.0169  last_data_time: 0.0131   lr: 0.0014498  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:56:34 d2.utils.events]: \u001b[0m eta: 8:23:21  iter: 1179  total_loss: 0.2717  loss_cls: 0.03728  loss_box_reg: 0.09527  loss_mask: 0.08145  loss_rpn_cls: 0.007589  loss_rpn_loc: 0.04648  total_val_loss: 0.2086  val_loss_cls: 0.02347  val_loss_box_reg: 0.06791  val_loss_mask: 0.08419  val_loss_rpn_cls: 0.003604  val_loss_rpn_loc: 0.03075    time: 1.7821  last_time: 1.5850  data_time: 0.0151  last_data_time: 0.0148   lr: 0.0014748  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:57:22 d2.utils.events]: \u001b[0m eta: 8:22:49  iter: 1199  total_loss: 0.2548  loss_cls: 0.03492  loss_box_reg: 0.09123  loss_mask: 0.08457  loss_rpn_cls: 0.006894  loss_rpn_loc: 0.04462  total_val_loss: 0.2067  val_loss_cls: 0.02091  val_loss_box_reg: 0.05932  val_loss_mask: 0.08562  val_loss_rpn_cls: 0.003788  val_loss_rpn_loc: 0.02935    time: 1.7799  last_time: 1.7065  data_time: 0.0158  last_data_time: 0.0163   lr: 0.0014998  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:58:09 d2.utils.events]: \u001b[0m eta: 8:21:37  iter: 1219  total_loss: 0.2555  loss_cls: 0.0338  loss_box_reg: 0.08417  loss_mask: 0.08162  loss_rpn_cls: 0.007719  loss_rpn_loc: 0.03635  total_val_loss: 0.218  val_loss_cls: 0.02527  val_loss_box_reg: 0.06611  val_loss_mask: 0.08661  val_loss_rpn_cls: 0.0028  val_loss_rpn_loc: 0.02947    time: 1.7771  last_time: 1.6484  data_time: 0.0161  last_data_time: 0.0157   lr: 0.0015247  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:58:56 d2.utils.events]: \u001b[0m eta: 8:20:37  iter: 1239  total_loss: 0.2816  loss_cls: 0.03988  loss_box_reg: 0.0943  loss_mask: 0.08588  loss_rpn_cls: 0.007946  loss_rpn_loc: 0.03997  total_val_loss: 0.2106  val_loss_cls: 0.02318  val_loss_box_reg: 0.06355  val_loss_mask: 0.08094  val_loss_rpn_cls: 0.003613  val_loss_rpn_loc: 0.03069    time: 1.7745  last_time: 1.5805  data_time: 0.0151  last_data_time: 0.0099   lr: 0.0015497  max_mem: 15217M\n",
      "\u001b[32m[09/26 14:59:43 d2.utils.events]: \u001b[0m eta: 8:20:14  iter: 1259  total_loss: 0.2563  loss_cls: 0.03543  loss_box_reg: 0.08698  loss_mask: 0.08677  loss_rpn_cls: 0.005276  loss_rpn_loc: 0.03976  total_val_loss: 0.2061  val_loss_cls: 0.02296  val_loss_box_reg: 0.0657  val_loss_mask: 0.08544  val_loss_rpn_cls: 0.004354  val_loss_rpn_loc: 0.03245    time: 1.7724  last_time: 1.6185  data_time: 0.0161  last_data_time: 0.0097   lr: 0.0015747  max_mem: 15217M\n",
      "\u001b[32m[09/26 15:00:30 d2.utils.events]: \u001b[0m eta: 8:19:02  iter: 1279  total_loss: 0.2262  loss_cls: 0.02421  loss_box_reg: 0.07843  loss_mask: 0.08297  loss_rpn_cls: 0.004763  loss_rpn_loc: 0.03613  total_val_loss: 0.2054  val_loss_cls: 0.0243  val_loss_box_reg: 0.06773  val_loss_mask: 0.08068  val_loss_rpn_cls: 0.004355  val_loss_rpn_loc: 0.03333    time: 1.7698  last_time: 1.5542  data_time: 0.0144  last_data_time: 0.0113   lr: 0.0015997  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:01:18 d2.utils.events]: \u001b[0m eta: 8:18:06  iter: 1299  total_loss: 0.2825  loss_cls: 0.03642  loss_box_reg: 0.1021  loss_mask: 0.08817  loss_rpn_cls: 0.006992  loss_rpn_loc: 0.04751  total_val_loss: 0.2005  val_loss_cls: 0.02545  val_loss_box_reg: 0.06748  val_loss_mask: 0.08065  val_loss_rpn_cls: 0.00341  val_loss_rpn_loc: 0.03279    time: 1.7679  last_time: 1.6636  data_time: 0.0151  last_data_time: 0.0089   lr: 0.0016246  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:02:06 d2.utils.events]: \u001b[0m eta: 8:17:16  iter: 1319  total_loss: 0.2479  loss_cls: 0.02973  loss_box_reg: 0.08621  loss_mask: 0.08301  loss_rpn_cls: 0.005952  loss_rpn_loc: 0.03745  total_val_loss: 0.2318  val_loss_cls: 0.02934  val_loss_box_reg: 0.07497  val_loss_mask: 0.08773  val_loss_rpn_cls: 0.004656  val_loss_rpn_loc: 0.0346    time: 1.7657  last_time: 1.6400  data_time: 0.0158  last_data_time: 0.0178   lr: 0.0016496  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:02:54 d2.utils.events]: \u001b[0m eta: 8:16:29  iter: 1339  total_loss: 0.2515  loss_cls: 0.03185  loss_box_reg: 0.09037  loss_mask: 0.08206  loss_rpn_cls: 0.005584  loss_rpn_loc: 0.04119  total_val_loss: 0.1982  val_loss_cls: 0.02361  val_loss_box_reg: 0.05824  val_loss_mask: 0.08116  val_loss_rpn_cls: 0.005974  val_loss_rpn_loc: 0.02884    time: 1.7640  last_time: 1.6053  data_time: 0.0153  last_data_time: 0.0188   lr: 0.0016746  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:03:41 d2.utils.events]: \u001b[0m eta: 8:15:23  iter: 1359  total_loss: 0.2619  loss_cls: 0.0335  loss_box_reg: 0.09632  loss_mask: 0.0872  loss_rpn_cls: 0.005591  loss_rpn_loc: 0.04269  total_val_loss: 0.2075  val_loss_cls: 0.02217  val_loss_box_reg: 0.06474  val_loss_mask: 0.08935  val_loss_rpn_cls: 0.003102  val_loss_rpn_loc: 0.0291    time: 1.7620  last_time: 1.6302  data_time: 0.0147  last_data_time: 0.0140   lr: 0.0016996  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:04:29 d2.utils.events]: \u001b[0m eta: 8:14:51  iter: 1379  total_loss: 0.2811  loss_cls: 0.03539  loss_box_reg: 0.1022  loss_mask: 0.08651  loss_rpn_cls: 0.00696  loss_rpn_loc: 0.04629  total_val_loss: 0.1927  val_loss_cls: 0.02138  val_loss_box_reg: 0.05956  val_loss_mask: 0.07959  val_loss_rpn_cls: 0.002202  val_loss_rpn_loc: 0.02613    time: 1.7602  last_time: 1.7351  data_time: 0.0163  last_data_time: 0.0205   lr: 0.0017245  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:05:16 d2.utils.events]: \u001b[0m eta: 8:13:36  iter: 1399  total_loss: 0.2848  loss_cls: 0.0434  loss_box_reg: 0.1023  loss_mask: 0.08539  loss_rpn_cls: 0.006505  loss_rpn_loc: 0.04181  total_val_loss: 0.2151  val_loss_cls: 0.02404  val_loss_box_reg: 0.06441  val_loss_mask: 0.08353  val_loss_rpn_cls: 0.00533  val_loss_rpn_loc: 0.03253    time: 1.7581  last_time: 1.5717  data_time: 0.0172  last_data_time: 0.0137   lr: 0.0017495  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:06:02 d2.utils.events]: \u001b[0m eta: 8:12:59  iter: 1419  total_loss: 0.2645  loss_cls: 0.03653  loss_box_reg: 0.09112  loss_mask: 0.08044  loss_rpn_cls: 0.004969  loss_rpn_loc: 0.0402  total_val_loss: 0.2051  val_loss_cls: 0.02062  val_loss_box_reg: 0.06414  val_loss_mask: 0.08113  val_loss_rpn_cls: 0.003788  val_loss_rpn_loc: 0.03193    time: 1.7558  last_time: 1.6406  data_time: 0.0153  last_data_time: 0.0120   lr: 0.0017745  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:06:50 d2.utils.events]: \u001b[0m eta: 8:12:51  iter: 1439  total_loss: 0.2691  loss_cls: 0.03368  loss_box_reg: 0.09992  loss_mask: 0.09108  loss_rpn_cls: 0.007051  loss_rpn_loc: 0.04688  total_val_loss: 0.2191  val_loss_cls: 0.02448  val_loss_box_reg: 0.06948  val_loss_mask: 0.09283  val_loss_rpn_cls: 0.003347  val_loss_rpn_loc: 0.03443    time: 1.7540  last_time: 1.6433  data_time: 0.0159  last_data_time: 0.0191   lr: 0.0017995  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:07:37 d2.utils.events]: \u001b[0m eta: 8:13:18  iter: 1459  total_loss: 0.2683  loss_cls: 0.03258  loss_box_reg: 0.08779  loss_mask: 0.08324  loss_rpn_cls: 0.006  loss_rpn_loc: 0.05082  total_val_loss: 0.2006  val_loss_cls: 0.02107  val_loss_box_reg: 0.06459  val_loss_mask: 0.08246  val_loss_rpn_cls: 0.002958  val_loss_rpn_loc: 0.03298    time: 1.7523  last_time: 1.6280  data_time: 0.0152  last_data_time: 0.0164   lr: 0.0018244  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:08:25 d2.utils.events]: \u001b[0m eta: 8:13:18  iter: 1479  total_loss: 0.264  loss_cls: 0.03369  loss_box_reg: 0.09143  loss_mask: 0.08277  loss_rpn_cls: 0.006373  loss_rpn_loc: 0.04861  total_val_loss: 0.2239  val_loss_cls: 0.02749  val_loss_box_reg: 0.06925  val_loss_mask: 0.09021  val_loss_rpn_cls: 0.003189  val_loss_rpn_loc: 0.03856    time: 1.7506  last_time: 1.6179  data_time: 0.0167  last_data_time: 0.0211   lr: 0.0018494  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:09:13 d2.utils.events]: \u001b[0m eta: 8:13:56  iter: 1499  total_loss: 0.2765  loss_cls: 0.03663  loss_box_reg: 0.1001  loss_mask: 0.08398  loss_rpn_cls: 0.006032  loss_rpn_loc: 0.04067  total_val_loss: 0.2071  val_loss_cls: 0.02473  val_loss_box_reg: 0.06198  val_loss_mask: 0.08325  val_loss_rpn_cls: 0.003458  val_loss_rpn_loc: 0.03435    time: 1.7493  last_time: 1.5277  data_time: 0.0155  last_data_time: 0.0132   lr: 0.0018744  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:10:00 d2.utils.events]: \u001b[0m eta: 8:13:29  iter: 1519  total_loss: 0.274  loss_cls: 0.03879  loss_box_reg: 0.09469  loss_mask: 0.08409  loss_rpn_cls: 0.005777  loss_rpn_loc: 0.04198  total_val_loss: 0.1995  val_loss_cls: 0.02385  val_loss_box_reg: 0.06469  val_loss_mask: 0.08801  val_loss_rpn_cls: 0.003472  val_loss_rpn_loc: 0.0285    time: 1.7478  last_time: 1.4572  data_time: 0.0142  last_data_time: 0.0122   lr: 0.0018994  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:10:47 d2.utils.events]: \u001b[0m eta: 8:12:45  iter: 1539  total_loss: 0.2522  loss_cls: 0.0342  loss_box_reg: 0.08639  loss_mask: 0.08358  loss_rpn_cls: 0.005055  loss_rpn_loc: 0.03786  total_val_loss: 0.23  val_loss_cls: 0.02928  val_loss_box_reg: 0.07506  val_loss_mask: 0.08575  val_loss_rpn_cls: 0.003434  val_loss_rpn_loc: 0.03485    time: 1.7458  last_time: 1.5984  data_time: 0.0150  last_data_time: 0.0178   lr: 0.0019243  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:11:35 d2.utils.events]: \u001b[0m eta: 8:12:25  iter: 1559  total_loss: 0.3002  loss_cls: 0.03877  loss_box_reg: 0.09853  loss_mask: 0.0844  loss_rpn_cls: 0.008774  loss_rpn_loc: 0.04851  total_val_loss: 0.2134  val_loss_cls: 0.02503  val_loss_box_reg: 0.06937  val_loss_mask: 0.08581  val_loss_rpn_cls: 0.003103  val_loss_rpn_loc: 0.03235    time: 1.7447  last_time: 1.5531  data_time: 0.0152  last_data_time: 0.0119   lr: 0.0019493  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:12:23 d2.utils.events]: \u001b[0m eta: 8:11:55  iter: 1579  total_loss: 0.2615  loss_cls: 0.03496  loss_box_reg: 0.08967  loss_mask: 0.0847  loss_rpn_cls: 0.008799  loss_rpn_loc: 0.04363  total_val_loss: 0.2171  val_loss_cls: 0.02419  val_loss_box_reg: 0.07067  val_loss_mask: 0.08048  val_loss_rpn_cls: 0.004303  val_loss_rpn_loc: 0.03504    time: 1.7435  last_time: 1.7025  data_time: 0.0153  last_data_time: 0.0168   lr: 0.0019743  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:13:11 d2.utils.events]: \u001b[0m eta: 8:11:34  iter: 1599  total_loss: 0.2783  loss_cls: 0.0362  loss_box_reg: 0.1031  loss_mask: 0.08626  loss_rpn_cls: 0.006325  loss_rpn_loc: 0.04317  total_val_loss: 0.2193  val_loss_cls: 0.02734  val_loss_box_reg: 0.06706  val_loss_mask: 0.08872  val_loss_rpn_cls: 0.003222  val_loss_rpn_loc: 0.03331    time: 1.7424  last_time: 1.6660  data_time: 0.0154  last_data_time: 0.0106   lr: 0.0019993  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:13:58 d2.utils.events]: \u001b[0m eta: 8:10:58  iter: 1619  total_loss: 0.2754  loss_cls: 0.03349  loss_box_reg: 0.09312  loss_mask: 0.08954  loss_rpn_cls: 0.006436  loss_rpn_loc: 0.04431  total_val_loss: 0.2289  val_loss_cls: 0.02899  val_loss_box_reg: 0.07285  val_loss_mask: 0.08592  val_loss_rpn_cls: 0.00417  val_loss_rpn_loc: 0.03264    time: 1.7412  last_time: 1.7069  data_time: 0.0161  last_data_time: 0.0181   lr: 0.0020242  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:14:45 d2.utils.events]: \u001b[0m eta: 8:10:21  iter: 1639  total_loss: 0.2521  loss_cls: 0.03291  loss_box_reg: 0.08859  loss_mask: 0.08514  loss_rpn_cls: 0.006465  loss_rpn_loc: 0.04416  total_val_loss: 0.2129  val_loss_cls: 0.02379  val_loss_box_reg: 0.06402  val_loss_mask: 0.08592  val_loss_rpn_cls: 0.003341  val_loss_rpn_loc: 0.03387    time: 1.7395  last_time: 1.4969  data_time: 0.0149  last_data_time: 0.0217   lr: 0.0020492  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:15:32 d2.utils.events]: \u001b[0m eta: 8:09:36  iter: 1659  total_loss: 0.257  loss_cls: 0.03478  loss_box_reg: 0.08499  loss_mask: 0.09078  loss_rpn_cls: 0.006417  loss_rpn_loc: 0.04439  total_val_loss: 0.2247  val_loss_cls: 0.02589  val_loss_box_reg: 0.07389  val_loss_mask: 0.0858  val_loss_rpn_cls: 0.003705  val_loss_rpn_loc: 0.03921    time: 1.7377  last_time: 1.6023  data_time: 0.0143  last_data_time: 0.0068   lr: 0.0020742  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:16:19 d2.utils.events]: \u001b[0m eta: 8:09:36  iter: 1679  total_loss: 0.2644  loss_cls: 0.03583  loss_box_reg: 0.08939  loss_mask: 0.08314  loss_rpn_cls: 0.00656  loss_rpn_loc: 0.04037  total_val_loss: 0.2031  val_loss_cls: 0.02426  val_loss_box_reg: 0.05957  val_loss_mask: 0.08309  val_loss_rpn_cls: 0.003963  val_loss_rpn_loc: 0.0277    time: 1.7366  last_time: 1.6117  data_time: 0.0151  last_data_time: 0.0131   lr: 0.0020992  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:17:07 d2.utils.events]: \u001b[0m eta: 8:09:53  iter: 1699  total_loss: 0.2736  loss_cls: 0.03423  loss_box_reg: 0.09618  loss_mask: 0.08985  loss_rpn_cls: 0.005066  loss_rpn_loc: 0.04247  total_val_loss: 0.2232  val_loss_cls: 0.02828  val_loss_box_reg: 0.07241  val_loss_mask: 0.09014  val_loss_rpn_cls: 0.003882  val_loss_rpn_loc: 0.03169    time: 1.7353  last_time: 1.4957  data_time: 0.0146  last_data_time: 0.0073   lr: 0.0021241  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:17:54 d2.utils.events]: \u001b[0m eta: 8:10:01  iter: 1719  total_loss: 0.2665  loss_cls: 0.03747  loss_box_reg: 0.08882  loss_mask: 0.08467  loss_rpn_cls: 0.00626  loss_rpn_loc: 0.0479  total_val_loss: 0.2277  val_loss_cls: 0.02749  val_loss_box_reg: 0.06992  val_loss_mask: 0.08723  val_loss_rpn_cls: 0.003655  val_loss_rpn_loc: 0.03586    time: 1.7340  last_time: 1.5918  data_time: 0.0150  last_data_time: 0.0110   lr: 0.0021491  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:18:41 d2.utils.events]: \u001b[0m eta: 8:09:45  iter: 1739  total_loss: 0.2414  loss_cls: 0.03087  loss_box_reg: 0.08309  loss_mask: 0.08791  loss_rpn_cls: 0.00591  loss_rpn_loc: 0.0456  total_val_loss: 0.2008  val_loss_cls: 0.02269  val_loss_box_reg: 0.05982  val_loss_mask: 0.08744  val_loss_rpn_cls: 0.003563  val_loss_rpn_loc: 0.02837    time: 1.7325  last_time: 1.6514  data_time: 0.0137  last_data_time: 0.0180   lr: 0.0021741  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:19:28 d2.utils.events]: \u001b[0m eta: 8:10:09  iter: 1759  total_loss: 0.2587  loss_cls: 0.03598  loss_box_reg: 0.0911  loss_mask: 0.08819  loss_rpn_cls: 0.005469  loss_rpn_loc: 0.0389  total_val_loss: 0.2164  val_loss_cls: 0.02732  val_loss_box_reg: 0.06718  val_loss_mask: 0.08162  val_loss_rpn_cls: 0.004777  val_loss_rpn_loc: 0.03603    time: 1.7312  last_time: 1.6541  data_time: 0.0138  last_data_time: 0.0160   lr: 0.0021991  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:20:15 d2.utils.events]: \u001b[0m eta: 8:10:24  iter: 1779  total_loss: 0.2608  loss_cls: 0.03536  loss_box_reg: 0.09292  loss_mask: 0.08942  loss_rpn_cls: 0.00544  loss_rpn_loc: 0.04106  total_val_loss: 0.2221  val_loss_cls: 0.02768  val_loss_box_reg: 0.07089  val_loss_mask: 0.08856  val_loss_rpn_cls: 0.002957  val_loss_rpn_loc: 0.03224    time: 1.7299  last_time: 1.6387  data_time: 0.0144  last_data_time: 0.0109   lr: 0.002224  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:21:02 d2.utils.events]: \u001b[0m eta: 8:09:55  iter: 1799  total_loss: 0.2622  loss_cls: 0.03272  loss_box_reg: 0.0851  loss_mask: 0.08312  loss_rpn_cls: 0.005435  loss_rpn_loc: 0.04072  total_val_loss: 0.2141  val_loss_cls: 0.02504  val_loss_box_reg: 0.06439  val_loss_mask: 0.0862  val_loss_rpn_cls: 0.003145  val_loss_rpn_loc: 0.03143    time: 1.7285  last_time: 1.7221  data_time: 0.0147  last_data_time: 0.0089   lr: 0.002249  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:21:49 d2.utils.events]: \u001b[0m eta: 8:09:49  iter: 1819  total_loss: 0.2817  loss_cls: 0.03637  loss_box_reg: 0.1012  loss_mask: 0.08599  loss_rpn_cls: 0.007612  loss_rpn_loc: 0.04716  total_val_loss: 0.218  val_loss_cls: 0.02697  val_loss_box_reg: 0.06922  val_loss_mask: 0.08193  val_loss_rpn_cls: 0.003294  val_loss_rpn_loc: 0.0361    time: 1.7275  last_time: 1.7640  data_time: 0.0154  last_data_time: 0.0170   lr: 0.002274  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:22:37 d2.utils.events]: \u001b[0m eta: 8:09:51  iter: 1839  total_loss: 0.2821  loss_cls: 0.03931  loss_box_reg: 0.0974  loss_mask: 0.08976  loss_rpn_cls: 0.006458  loss_rpn_loc: 0.04976  total_val_loss: 0.2164  val_loss_cls: 0.02741  val_loss_box_reg: 0.06814  val_loss_mask: 0.08127  val_loss_rpn_cls: 0.002733  val_loss_rpn_loc: 0.02935    time: 1.7267  last_time: 1.6743  data_time: 0.0160  last_data_time: 0.0178   lr: 0.002299  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:23:25 d2.utils.events]: \u001b[0m eta: 8:09:47  iter: 1859  total_loss: 0.253  loss_cls: 0.03541  loss_box_reg: 0.08699  loss_mask: 0.08693  loss_rpn_cls: 0.005263  loss_rpn_loc: 0.03998  total_val_loss: 0.2229  val_loss_cls: 0.02938  val_loss_box_reg: 0.06936  val_loss_mask: 0.08549  val_loss_rpn_cls: 0.003142  val_loss_rpn_loc: 0.03299    time: 1.7258  last_time: 1.6187  data_time: 0.0150  last_data_time: 0.0145   lr: 0.0023239  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:24:12 d2.utils.events]: \u001b[0m eta: 8:09:31  iter: 1879  total_loss: 0.2692  loss_cls: 0.0377  loss_box_reg: 0.0912  loss_mask: 0.08771  loss_rpn_cls: 0.005562  loss_rpn_loc: 0.04573  total_val_loss: 0.2238  val_loss_cls: 0.02553  val_loss_box_reg: 0.06913  val_loss_mask: 0.08527  val_loss_rpn_cls: 0.00411  val_loss_rpn_loc: 0.03354    time: 1.7247  last_time: 1.5871  data_time: 0.0147  last_data_time: 0.0142   lr: 0.0023489  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:25:00 d2.utils.events]: \u001b[0m eta: 8:09:30  iter: 1899  total_loss: 0.287  loss_cls: 0.03731  loss_box_reg: 0.1001  loss_mask: 0.08839  loss_rpn_cls: 0.006531  loss_rpn_loc: 0.04568  total_val_loss: 0.2415  val_loss_cls: 0.03209  val_loss_box_reg: 0.07874  val_loss_mask: 0.08943  val_loss_rpn_cls: 0.005029  val_loss_rpn_loc: 0.04007    time: 1.7237  last_time: 1.5633  data_time: 0.0154  last_data_time: 0.0132   lr: 0.0023739  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:25:48 d2.utils.events]: \u001b[0m eta: 8:09:56  iter: 1919  total_loss: 0.2803  loss_cls: 0.04024  loss_box_reg: 0.1007  loss_mask: 0.08726  loss_rpn_cls: 0.00685  loss_rpn_loc: 0.04812  total_val_loss: 0.216  val_loss_cls: 0.02487  val_loss_box_reg: 0.06705  val_loss_mask: 0.08309  val_loss_rpn_cls: 0.003234  val_loss_rpn_loc: 0.0341    time: 1.7233  last_time: 1.7296  data_time: 0.0162  last_data_time: 0.0160   lr: 0.0023989  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:26:35 d2.utils.events]: \u001b[0m eta: 8:09:52  iter: 1939  total_loss: 0.2762  loss_cls: 0.03865  loss_box_reg: 0.1039  loss_mask: 0.08374  loss_rpn_cls: 0.005314  loss_rpn_loc: 0.04458  total_val_loss: 0.2311  val_loss_cls: 0.02739  val_loss_box_reg: 0.07412  val_loss_mask: 0.08885  val_loss_rpn_cls: 0.003937  val_loss_rpn_loc: 0.03887    time: 1.7223  last_time: 1.6062  data_time: 0.0150  last_data_time: 0.0133   lr: 0.0024238  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:27:23 d2.utils.events]: \u001b[0m eta: 8:09:52  iter: 1959  total_loss: 0.3026  loss_cls: 0.03991  loss_box_reg: 0.1196  loss_mask: 0.08781  loss_rpn_cls: 0.00776  loss_rpn_loc: 0.04851  total_val_loss: 0.2203  val_loss_cls: 0.0277  val_loss_box_reg: 0.07339  val_loss_mask: 0.0864  val_loss_rpn_cls: 0.003117  val_loss_rpn_loc: 0.03323    time: 1.7214  last_time: 1.5901  data_time: 0.0153  last_data_time: 0.0132   lr: 0.0024488  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:28:10 d2.utils.events]: \u001b[0m eta: 8:09:53  iter: 1979  total_loss: 0.2607  loss_cls: 0.03263  loss_box_reg: 0.08994  loss_mask: 0.0838  loss_rpn_cls: 0.006822  loss_rpn_loc: 0.04639  total_val_loss: 0.2193  val_loss_cls: 0.02644  val_loss_box_reg: 0.07264  val_loss_mask: 0.07809  val_loss_rpn_cls: 0.004108  val_loss_rpn_loc: 0.0359    time: 1.7205  last_time: 1.6000  data_time: 0.0148  last_data_time: 0.0173   lr: 0.0024738  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:28:58 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\testing_images\\0_SideLane_addedversion_Testing_COCO.json\n",
      "\u001b[32m[09/26 15:28:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/26 15:28:58 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/26 15:28:58 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/26 15:28:58 d2.data.common]: \u001b[0mSerialized dataset takes 6.03 MiB\n",
      "\u001b[32m[09/26 15:28:58 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[09/26 15:28:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 566 batches\n",
      "\u001b[32m[09/26 15:29:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/566. Dataloading: 0.0008 s/iter. Inference: 0.0909 s/iter. Eval: 0.0140 s/iter. Total: 0.1058 s/iter. ETA=0:00:58\n",
      "\u001b[32m[09/26 15:29:07 d2.evaluation.evaluator]: \u001b[0mInference done 72/566. Dataloading: 0.0010 s/iter. Inference: 0.0782 s/iter. Eval: 0.0057 s/iter. Total: 0.0850 s/iter. ETA=0:00:42\n",
      "\u001b[32m[09/26 15:29:12 d2.evaluation.evaluator]: \u001b[0mInference done 131/566. Dataloading: 0.0010 s/iter. Inference: 0.0775 s/iter. Eval: 0.0068 s/iter. Total: 0.0853 s/iter. ETA=0:00:37\n",
      "\u001b[32m[09/26 15:29:17 d2.evaluation.evaluator]: \u001b[0mInference done 189/566. Dataloading: 0.0010 s/iter. Inference: 0.0776 s/iter. Eval: 0.0071 s/iter. Total: 0.0857 s/iter. ETA=0:00:32\n",
      "\u001b[32m[09/26 15:29:22 d2.evaluation.evaluator]: \u001b[0mInference done 248/566. Dataloading: 0.0010 s/iter. Inference: 0.0779 s/iter. Eval: 0.0066 s/iter. Total: 0.0856 s/iter. ETA=0:00:27\n",
      "\u001b[32m[09/26 15:29:27 d2.evaluation.evaluator]: \u001b[0mInference done 308/566. Dataloading: 0.0010 s/iter. Inference: 0.0778 s/iter. Eval: 0.0063 s/iter. Total: 0.0852 s/iter. ETA=0:00:21\n",
      "\u001b[32m[09/26 15:29:32 d2.evaluation.evaluator]: \u001b[0mInference done 370/566. Dataloading: 0.0010 s/iter. Inference: 0.0777 s/iter. Eval: 0.0058 s/iter. Total: 0.0846 s/iter. ETA=0:00:16\n",
      "\u001b[32m[09/26 15:29:37 d2.evaluation.evaluator]: \u001b[0mInference done 433/566. Dataloading: 0.0010 s/iter. Inference: 0.0775 s/iter. Eval: 0.0053 s/iter. Total: 0.0839 s/iter. ETA=0:00:11\n",
      "\u001b[32m[09/26 15:29:42 d2.evaluation.evaluator]: \u001b[0mInference done 487/566. Dataloading: 0.0010 s/iter. Inference: 0.0777 s/iter. Eval: 0.0061 s/iter. Total: 0.0850 s/iter. ETA=0:00:06\n",
      "\u001b[32m[09/26 15:29:47 d2.evaluation.evaluator]: \u001b[0mInference done 544/566. Dataloading: 0.0011 s/iter. Inference: 0.0783 s/iter. Eval: 0.0060 s/iter. Total: 0.0854 s/iter. ETA=0:00:01\n",
      "\u001b[32m[09/26 15:29:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.484026 (0.086424 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 15:29:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:43 (0.078268 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 15:29:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/26 15:29:50 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\coco_instances_results.json\n",
      "\u001b[32m[09/26 15:29:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.45s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.920\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.918\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.923\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.194\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.928\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.942\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.931\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.948\n",
      "\u001b[32m[09/26 15:29:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 91.990 | 99.007 | 98.952 |  nan  | 91.804 | 92.349 |\n",
      "\u001b[32m[09/26 15:29:50 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 15:29:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 91.990 | background | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.65s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.853\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.989\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.822\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.874\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.876\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.889\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.862\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.906\n",
      "\u001b[32m[09/26 15:29:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 85.347 | 98.987 | 98.934 |  nan  | 82.201 | 87.426 |\n",
      "\u001b[32m[09/26 15:29:51 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 15:29:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 85.347 | background | nan  |\n",
      "\u001b[32m[09/26 15:29:51 d2.engine.defaults]: \u001b[0mEvaluation results for test_data in csv format:\n",
      "\u001b[32m[09/26 15:29:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/26 15:29:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 15:29:51 d2.evaluation.testing]: \u001b[0mcopypaste: 91.9905,99.0071,98.9521,nan,91.8037,92.3495\n",
      "\u001b[32m[09/26 15:29:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/26 15:29:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 15:29:51 d2.evaluation.testing]: \u001b[0mcopypaste: 85.3473,98.9875,98.9339,nan,82.2014,87.4256\n",
      "\u001b[32m[09/26 15:29:52 d2.utils.events]: \u001b[0m eta: 8:10:16  iter: 1999  total_loss: 0.2954  loss_cls: 0.03717  loss_box_reg: 0.08759  loss_mask: 0.08554  loss_rpn_cls: 0.007373  loss_rpn_loc: 0.04062  total_val_loss: 0.2286  val_loss_cls: 0.02839  val_loss_box_reg: 0.08038  val_loss_mask: 0.08277  val_loss_rpn_cls: 0.004821  val_loss_rpn_loc: 0.03499    time: 1.7195  last_time: 1.6977  data_time: 0.0139  last_data_time: 0.0185   lr: 0.0024988  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:30:39 d2.utils.events]: \u001b[0m eta: 8:10:03  iter: 2019  total_loss: 0.2744  loss_cls: 0.03554  loss_box_reg: 0.09206  loss_mask: 0.08391  loss_rpn_cls: 0.008299  loss_rpn_loc: 0.04654  total_val_loss: 0.2236  val_loss_cls: 0.02638  val_loss_box_reg: 0.071  val_loss_mask: 0.08801  val_loss_rpn_cls: 0.003789  val_loss_rpn_loc: 0.0344    time: 1.7186  last_time: 1.5916  data_time: 0.0147  last_data_time: 0.0113   lr: 0.0025  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:31:26 d2.utils.events]: \u001b[0m eta: 8:09:16  iter: 2039  total_loss: 0.2584  loss_cls: 0.03351  loss_box_reg: 0.08971  loss_mask: 0.08018  loss_rpn_cls: 0.004473  loss_rpn_loc: 0.04123  total_val_loss: 0.2073  val_loss_cls: 0.02356  val_loss_box_reg: 0.0638  val_loss_mask: 0.07944  val_loss_rpn_cls: 0.003301  val_loss_rpn_loc: 0.03246    time: 1.7176  last_time: 1.6299  data_time: 0.0154  last_data_time: 0.0164   lr: 0.0025  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:32:14 d2.utils.events]: \u001b[0m eta: 8:08:05  iter: 2059  total_loss: 0.2788  loss_cls: 0.03764  loss_box_reg: 0.09815  loss_mask: 0.08387  loss_rpn_cls: 0.005707  loss_rpn_loc: 0.04642  total_val_loss: 0.2169  val_loss_cls: 0.02567  val_loss_box_reg: 0.07059  val_loss_mask: 0.08305  val_loss_rpn_cls: 0.003854  val_loss_rpn_loc: 0.0375    time: 1.7167  last_time: 1.6334  data_time: 0.0159  last_data_time: 0.0186   lr: 0.0025  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:33:01 d2.utils.events]: \u001b[0m eta: 8:07:56  iter: 2079  total_loss: 0.278  loss_cls: 0.03364  loss_box_reg: 0.1005  loss_mask: 0.08775  loss_rpn_cls: 0.004431  loss_rpn_loc: 0.04379  total_val_loss: 0.2251  val_loss_cls: 0.03082  val_loss_box_reg: 0.07231  val_loss_mask: 0.08414  val_loss_rpn_cls: 0.003435  val_loss_rpn_loc: 0.03728    time: 1.7156  last_time: 1.6565  data_time: 0.0160  last_data_time: 0.0162   lr: 0.0025  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:33:48 d2.utils.events]: \u001b[0m eta: 8:07:04  iter: 2099  total_loss: 0.2891  loss_cls: 0.03753  loss_box_reg: 0.1057  loss_mask: 0.08855  loss_rpn_cls: 0.007274  loss_rpn_loc: 0.04725  total_val_loss: 0.2361  val_loss_cls: 0.03147  val_loss_box_reg: 0.07935  val_loss_mask: 0.08315  val_loss_rpn_cls: 0.004399  val_loss_rpn_loc: 0.03571    time: 1.7148  last_time: 1.6052  data_time: 0.0151  last_data_time: 0.0149   lr: 0.0025  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:34:35 d2.utils.events]: \u001b[0m eta: 8:06:12  iter: 2119  total_loss: 0.2442  loss_cls: 0.02854  loss_box_reg: 0.08576  loss_mask: 0.08511  loss_rpn_cls: 0.005385  loss_rpn_loc: 0.04403  total_val_loss: 0.2112  val_loss_cls: 0.02325  val_loss_box_reg: 0.06754  val_loss_mask: 0.08263  val_loss_rpn_cls: 0.00444  val_loss_rpn_loc: 0.03586    time: 1.7139  last_time: 1.5682  data_time: 0.0155  last_data_time: 0.0147   lr: 0.0025  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:35:22 d2.utils.events]: \u001b[0m eta: 8:05:18  iter: 2139  total_loss: 0.2935  loss_cls: 0.04161  loss_box_reg: 0.1021  loss_mask: 0.08116  loss_rpn_cls: 0.007223  loss_rpn_loc: 0.0508  total_val_loss: 0.207  val_loss_cls: 0.0236  val_loss_box_reg: 0.06436  val_loss_mask: 0.0818  val_loss_rpn_cls: 0.002799  val_loss_rpn_loc: 0.03215    time: 1.7131  last_time: 1.7451  data_time: 0.0153  last_data_time: 0.0136   lr: 0.0025  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:36:10 d2.utils.events]: \u001b[0m eta: 8:04:51  iter: 2159  total_loss: 0.3043  loss_cls: 0.04322  loss_box_reg: 0.1105  loss_mask: 0.09239  loss_rpn_cls: 0.007141  loss_rpn_loc: 0.04599  total_val_loss: 0.2322  val_loss_cls: 0.02766  val_loss_box_reg: 0.07913  val_loss_mask: 0.08769  val_loss_rpn_cls: 0.00392  val_loss_rpn_loc: 0.03469    time: 1.7125  last_time: 1.5682  data_time: 0.0166  last_data_time: 0.0185   lr: 0.0025  max_mem: 15218M\n",
      "\u001b[32m[09/26 15:36:58 d2.utils.events]: \u001b[0m eta: 8:04:24  iter: 2179  total_loss: 0.3088  loss_cls: 0.04532  loss_box_reg: 0.1167  loss_mask: 0.08412  loss_rpn_cls: 0.006005  loss_rpn_loc: 0.05095  total_val_loss: 0.2357  val_loss_cls: 0.02689  val_loss_box_reg: 0.07696  val_loss_mask: 0.09322  val_loss_rpn_cls: 0.003282  val_loss_rpn_loc: 0.03751    time: 1.7119  last_time: 1.4732  data_time: 0.0154  last_data_time: 0.0139   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:37:45 d2.utils.events]: \u001b[0m eta: 8:03:40  iter: 2199  total_loss: 0.2271  loss_cls: 0.03074  loss_box_reg: 0.07605  loss_mask: 0.07981  loss_rpn_cls: 0.004697  loss_rpn_loc: 0.038  total_val_loss: 0.221  val_loss_cls: 0.02838  val_loss_box_reg: 0.07218  val_loss_mask: 0.08236  val_loss_rpn_cls: 0.003818  val_loss_rpn_loc: 0.03715    time: 1.7110  last_time: 1.6324  data_time: 0.0141  last_data_time: 0.0133   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:38:32 d2.utils.events]: \u001b[0m eta: 8:03:02  iter: 2219  total_loss: 0.2609  loss_cls: 0.03215  loss_box_reg: 0.09143  loss_mask: 0.09149  loss_rpn_cls: 0.005383  loss_rpn_loc: 0.04234  total_val_loss: 0.2236  val_loss_cls: 0.0282  val_loss_box_reg: 0.07041  val_loss_mask: 0.0861  val_loss_rpn_cls: 0.003205  val_loss_rpn_loc: 0.03314    time: 1.7100  last_time: 1.5107  data_time: 0.0138  last_data_time: 0.0129   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:39:19 d2.utils.events]: \u001b[0m eta: 8:02:32  iter: 2239  total_loss: 0.2748  loss_cls: 0.03512  loss_box_reg: 0.09385  loss_mask: 0.08393  loss_rpn_cls: 0.005686  loss_rpn_loc: 0.05397  total_val_loss: 0.2238  val_loss_cls: 0.02558  val_loss_box_reg: 0.07013  val_loss_mask: 0.08884  val_loss_rpn_cls: 0.004068  val_loss_rpn_loc: 0.03742    time: 1.7092  last_time: 1.7505  data_time: 0.0149  last_data_time: 0.0115   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:40:07 d2.utils.events]: \u001b[0m eta: 8:02:10  iter: 2259  total_loss: 0.2733  loss_cls: 0.03703  loss_box_reg: 0.09741  loss_mask: 0.08677  loss_rpn_cls: 0.007378  loss_rpn_loc: 0.04372  total_val_loss: 0.2262  val_loss_cls: 0.03028  val_loss_box_reg: 0.07147  val_loss_mask: 0.08137  val_loss_rpn_cls: 0.004507  val_loss_rpn_loc: 0.03608    time: 1.7085  last_time: 1.6482  data_time: 0.0143  last_data_time: 0.0167   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:40:54 d2.utils.events]: \u001b[0m eta: 8:01:47  iter: 2279  total_loss: 0.2923  loss_cls: 0.03343  loss_box_reg: 0.09601  loss_mask: 0.08347  loss_rpn_cls: 0.005849  loss_rpn_loc: 0.04928  total_val_loss: 0.2319  val_loss_cls: 0.02875  val_loss_box_reg: 0.07732  val_loss_mask: 0.0811  val_loss_rpn_cls: 0.003268  val_loss_rpn_loc: 0.03613    time: 1.7079  last_time: 1.6767  data_time: 0.0150  last_data_time: 0.0211   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:41:42 d2.utils.events]: \u001b[0m eta: 8:01:12  iter: 2299  total_loss: 0.2785  loss_cls: 0.03886  loss_box_reg: 0.1011  loss_mask: 0.08312  loss_rpn_cls: 0.006306  loss_rpn_loc: 0.04329  total_val_loss: 0.2313  val_loss_cls: 0.02803  val_loss_box_reg: 0.07377  val_loss_mask: 0.08625  val_loss_rpn_cls: 0.003651  val_loss_rpn_loc: 0.03796    time: 1.7073  last_time: 1.6043  data_time: 0.0162  last_data_time: 0.0164   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:42:30 d2.utils.events]: \u001b[0m eta: 8:00:41  iter: 2319  total_loss: 0.2849  loss_cls: 0.03761  loss_box_reg: 0.09138  loss_mask: 0.08693  loss_rpn_cls: 0.005956  loss_rpn_loc: 0.04515  total_val_loss: 0.2433  val_loss_cls: 0.03433  val_loss_box_reg: 0.07678  val_loss_mask: 0.0869  val_loss_rpn_cls: 0.004023  val_loss_rpn_loc: 0.03558    time: 1.7067  last_time: 1.6851  data_time: 0.0151  last_data_time: 0.0156   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:43:17 d2.utils.events]: \u001b[0m eta: 7:59:59  iter: 2339  total_loss: 0.2508  loss_cls: 0.03554  loss_box_reg: 0.08971  loss_mask: 0.08319  loss_rpn_cls: 0.005418  loss_rpn_loc: 0.03849  total_val_loss: 0.2092  val_loss_cls: 0.02712  val_loss_box_reg: 0.06571  val_loss_mask: 0.08604  val_loss_rpn_cls: 0.003924  val_loss_rpn_loc: 0.02968    time: 1.7061  last_time: 1.5317  data_time: 0.0154  last_data_time: 0.0145   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:44:05 d2.utils.events]: \u001b[0m eta: 7:59:36  iter: 2359  total_loss: 0.2752  loss_cls: 0.03752  loss_box_reg: 0.1008  loss_mask: 0.08844  loss_rpn_cls: 0.007517  loss_rpn_loc: 0.044  total_val_loss: 0.2432  val_loss_cls: 0.03173  val_loss_box_reg: 0.07642  val_loss_mask: 0.09002  val_loss_rpn_cls: 0.003251  val_loss_rpn_loc: 0.03325    time: 1.7056  last_time: 1.6930  data_time: 0.0178  last_data_time: 0.0172   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:44:52 d2.utils.events]: \u001b[0m eta: 7:58:49  iter: 2379  total_loss: 0.2692  loss_cls: 0.03294  loss_box_reg: 0.09417  loss_mask: 0.08429  loss_rpn_cls: 0.006569  loss_rpn_loc: 0.039  total_val_loss: 0.2221  val_loss_cls: 0.02891  val_loss_box_reg: 0.07408  val_loss_mask: 0.08506  val_loss_rpn_cls: 0.003549  val_loss_rpn_loc: 0.03343    time: 1.7046  last_time: 1.5273  data_time: 0.0149  last_data_time: 0.0131   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:45:39 d2.utils.events]: \u001b[0m eta: 7:58:22  iter: 2399  total_loss: 0.2693  loss_cls: 0.04057  loss_box_reg: 0.09326  loss_mask: 0.08494  loss_rpn_cls: 0.006106  loss_rpn_loc: 0.04278  total_val_loss: 0.2303  val_loss_cls: 0.03013  val_loss_box_reg: 0.07899  val_loss_mask: 0.08476  val_loss_rpn_cls: 0.003103  val_loss_rpn_loc: 0.03634    time: 1.7040  last_time: 1.6695  data_time: 0.0150  last_data_time: 0.0129   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:46:26 d2.utils.events]: \u001b[0m eta: 7:57:38  iter: 2419  total_loss: 0.2731  loss_cls: 0.0382  loss_box_reg: 0.09728  loss_mask: 0.08132  loss_rpn_cls: 0.004961  loss_rpn_loc: 0.04613  total_val_loss: 0.2332  val_loss_cls: 0.02968  val_loss_box_reg: 0.07431  val_loss_mask: 0.0878  val_loss_rpn_cls: 0.004266  val_loss_rpn_loc: 0.03307    time: 1.7033  last_time: 1.7469  data_time: 0.0144  last_data_time: 0.0181   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:47:14 d2.utils.events]: \u001b[0m eta: 7:57:07  iter: 2439  total_loss: 0.2658  loss_cls: 0.03745  loss_box_reg: 0.09141  loss_mask: 0.08401  loss_rpn_cls: 0.007074  loss_rpn_loc: 0.04473  total_val_loss: 0.2435  val_loss_cls: 0.031  val_loss_box_reg: 0.06732  val_loss_mask: 0.08698  val_loss_rpn_cls: 0.004403  val_loss_rpn_loc: 0.03718    time: 1.7028  last_time: 1.6240  data_time: 0.0162  last_data_time: 0.0147   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:48:01 d2.utils.events]: \u001b[0m eta: 7:56:33  iter: 2459  total_loss: 0.285  loss_cls: 0.0372  loss_box_reg: 0.105  loss_mask: 0.07982  loss_rpn_cls: 0.006689  loss_rpn_loc: 0.05002  total_val_loss: 0.2133  val_loss_cls: 0.02829  val_loss_box_reg: 0.07299  val_loss_mask: 0.08658  val_loss_rpn_cls: 0.004322  val_loss_rpn_loc: 0.03472    time: 1.7021  last_time: 1.7051  data_time: 0.0161  last_data_time: 0.0135   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:48:48 d2.utils.events]: \u001b[0m eta: 7:56:00  iter: 2479  total_loss: 0.2878  loss_cls: 0.03598  loss_box_reg: 0.1056  loss_mask: 0.08617  loss_rpn_cls: 0.007126  loss_rpn_loc: 0.04854  total_val_loss: 0.2311  val_loss_cls: 0.02705  val_loss_box_reg: 0.07014  val_loss_mask: 0.08795  val_loss_rpn_cls: 0.003208  val_loss_rpn_loc: 0.03824    time: 1.7016  last_time: 1.6512  data_time: 0.0153  last_data_time: 0.0176   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:49:36 d2.utils.events]: \u001b[0m eta: 7:55:28  iter: 2499  total_loss: 0.2802  loss_cls: 0.03828  loss_box_reg: 0.09349  loss_mask: 0.08433  loss_rpn_cls: 0.005334  loss_rpn_loc: 0.05078  total_val_loss: 0.2496  val_loss_cls: 0.0323  val_loss_box_reg: 0.08863  val_loss_mask: 0.08496  val_loss_rpn_cls: 0.004189  val_loss_rpn_loc: 0.0398    time: 1.7011  last_time: 1.7021  data_time: 0.0160  last_data_time: 0.0122   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:50:24 d2.utils.events]: \u001b[0m eta: 7:54:57  iter: 2519  total_loss: 0.2735  loss_cls: 0.03582  loss_box_reg: 0.1008  loss_mask: 0.08973  loss_rpn_cls: 0.005723  loss_rpn_loc: 0.04699  total_val_loss: 0.2296  val_loss_cls: 0.0293  val_loss_box_reg: 0.07402  val_loss_mask: 0.08566  val_loss_rpn_cls: 0.002985  val_loss_rpn_loc: 0.03448    time: 1.7007  last_time: 1.6047  data_time: 0.0161  last_data_time: 0.0161   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:51:11 d2.utils.events]: \u001b[0m eta: 7:54:42  iter: 2539  total_loss: 0.2757  loss_cls: 0.037  loss_box_reg: 0.09444  loss_mask: 0.09183  loss_rpn_cls: 0.006686  loss_rpn_loc: 0.04434  total_val_loss: 0.2204  val_loss_cls: 0.02896  val_loss_box_reg: 0.06901  val_loss_mask: 0.08998  val_loss_rpn_cls: 0.003465  val_loss_rpn_loc: 0.03341    time: 1.7001  last_time: 1.5612  data_time: 0.0161  last_data_time: 0.0121   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:51:58 d2.utils.events]: \u001b[0m eta: 7:54:07  iter: 2559  total_loss: 0.2944  loss_cls: 0.04191  loss_box_reg: 0.1046  loss_mask: 0.09023  loss_rpn_cls: 0.006217  loss_rpn_loc: 0.0477  total_val_loss: 0.2119  val_loss_cls: 0.02394  val_loss_box_reg: 0.06517  val_loss_mask: 0.08942  val_loss_rpn_cls: 0.002619  val_loss_rpn_loc: 0.03078    time: 1.6996  last_time: 1.6274  data_time: 0.0152  last_data_time: 0.0135   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:52:46 d2.utils.events]: \u001b[0m eta: 7:53:37  iter: 2579  total_loss: 0.2948  loss_cls: 0.03723  loss_box_reg: 0.1026  loss_mask: 0.08871  loss_rpn_cls: 0.006056  loss_rpn_loc: 0.04673  total_val_loss: 0.2324  val_loss_cls: 0.03006  val_loss_box_reg: 0.07514  val_loss_mask: 0.08725  val_loss_rpn_cls: 0.004087  val_loss_rpn_loc: 0.03419    time: 1.6992  last_time: 1.7605  data_time: 0.0155  last_data_time: 0.0240   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:53:33 d2.utils.events]: \u001b[0m eta: 7:52:51  iter: 2599  total_loss: 0.2922  loss_cls: 0.03785  loss_box_reg: 0.1043  loss_mask: 0.08865  loss_rpn_cls: 0.01033  loss_rpn_loc: 0.05299  total_val_loss: 0.2409  val_loss_cls: 0.02962  val_loss_box_reg: 0.07188  val_loss_mask: 0.08732  val_loss_rpn_cls: 0.004552  val_loss_rpn_loc: 0.035    time: 1.6987  last_time: 1.5912  data_time: 0.0156  last_data_time: 0.0135   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:54:21 d2.utils.events]: \u001b[0m eta: 7:52:26  iter: 2619  total_loss: 0.2821  loss_cls: 0.04135  loss_box_reg: 0.09994  loss_mask: 0.08428  loss_rpn_cls: 0.00704  loss_rpn_loc: 0.04784  total_val_loss: 0.2438  val_loss_cls: 0.03384  val_loss_box_reg: 0.07853  val_loss_mask: 0.08753  val_loss_rpn_cls: 0.004704  val_loss_rpn_loc: 0.04421    time: 1.6982  last_time: 1.5920  data_time: 0.0158  last_data_time: 0.0145   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:55:08 d2.utils.events]: \u001b[0m eta: 7:51:46  iter: 2639  total_loss: 0.3031  loss_cls: 0.04072  loss_box_reg: 0.1066  loss_mask: 0.08597  loss_rpn_cls: 0.005762  loss_rpn_loc: 0.04967  total_val_loss: 0.2319  val_loss_cls: 0.02931  val_loss_box_reg: 0.07752  val_loss_mask: 0.08383  val_loss_rpn_cls: 0.004219  val_loss_rpn_loc: 0.03565    time: 1.6977  last_time: 1.5902  data_time: 0.0148  last_data_time: 0.0177   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:55:56 d2.utils.events]: \u001b[0m eta: 7:51:28  iter: 2659  total_loss: 0.279  loss_cls: 0.03464  loss_box_reg: 0.0969  loss_mask: 0.08258  loss_rpn_cls: 0.006691  loss_rpn_loc: 0.04153  total_val_loss: 0.2423  val_loss_cls: 0.02946  val_loss_box_reg: 0.07847  val_loss_mask: 0.08616  val_loss_rpn_cls: 0.003668  val_loss_rpn_loc: 0.03706    time: 1.6972  last_time: 1.6774  data_time: 0.0148  last_data_time: 0.0135   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:56:44 d2.utils.events]: \u001b[0m eta: 7:50:56  iter: 2679  total_loss: 0.2687  loss_cls: 0.03217  loss_box_reg: 0.09198  loss_mask: 0.08976  loss_rpn_cls: 0.006655  loss_rpn_loc: 0.03972  total_val_loss: 0.231  val_loss_cls: 0.02898  val_loss_box_reg: 0.07444  val_loss_mask: 0.09726  val_loss_rpn_cls: 0.003174  val_loss_rpn_loc: 0.0304    time: 1.6968  last_time: 1.6783  data_time: 0.0150  last_data_time: 0.0151   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:57:29 d2.utils.events]: \u001b[0m eta: 7:50:01  iter: 2699  total_loss: 0.2575  loss_cls: 0.03578  loss_box_reg: 0.08489  loss_mask: 0.08225  loss_rpn_cls: 0.006094  loss_rpn_loc: 0.04046  total_val_loss: 0.2153  val_loss_cls: 0.02411  val_loss_box_reg: 0.06433  val_loss_mask: 0.08321  val_loss_rpn_cls: 0.003214  val_loss_rpn_loc: 0.03543    time: 1.6960  last_time: 1.3781  data_time: 0.0091  last_data_time: 0.0050   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:58:13 d2.utils.events]: \u001b[0m eta: 7:49:06  iter: 2719  total_loss: 0.2469  loss_cls: 0.03534  loss_box_reg: 0.0789  loss_mask: 0.07754  loss_rpn_cls: 0.005367  loss_rpn_loc: 0.04104  total_val_loss: 0.226  val_loss_cls: 0.02717  val_loss_box_reg: 0.06892  val_loss_mask: 0.08787  val_loss_rpn_cls: 0.003941  val_loss_rpn_loc: 0.03456    time: 1.6947  last_time: 1.5732  data_time: 0.0073  last_data_time: 0.0073   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:58:57 d2.utils.events]: \u001b[0m eta: 7:48:00  iter: 2739  total_loss: 0.2779  loss_cls: 0.03943  loss_box_reg: 0.09732  loss_mask: 0.08232  loss_rpn_cls: 0.007323  loss_rpn_loc: 0.04997  total_val_loss: 0.2378  val_loss_cls: 0.02975  val_loss_box_reg: 0.07566  val_loss_mask: 0.08954  val_loss_rpn_cls: 0.003068  val_loss_rpn_loc: 0.03672    time: 1.6936  last_time: 1.5366  data_time: 0.0082  last_data_time: 0.0096   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 15:59:41 d2.utils.events]: \u001b[0m eta: 7:47:07  iter: 2759  total_loss: 0.2738  loss_cls: 0.03446  loss_box_reg: 0.0946  loss_mask: 0.07919  loss_rpn_cls: 0.00465  loss_rpn_loc: 0.04683  total_val_loss: 0.2252  val_loss_cls: 0.02807  val_loss_box_reg: 0.06982  val_loss_mask: 0.07852  val_loss_rpn_cls: 0.003075  val_loss_rpn_loc: 0.03679    time: 1.6926  last_time: 1.4530  data_time: 0.0077  last_data_time: 0.0070   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:00:25 d2.utils.events]: \u001b[0m eta: 7:45:50  iter: 2779  total_loss: 0.2712  loss_cls: 0.0366  loss_box_reg: 0.09094  loss_mask: 0.08698  loss_rpn_cls: 0.005312  loss_rpn_loc: 0.04278  total_val_loss: 0.2207  val_loss_cls: 0.02631  val_loss_box_reg: 0.07144  val_loss_mask: 0.08927  val_loss_rpn_cls: 0.003315  val_loss_rpn_loc: 0.03255    time: 1.6915  last_time: 1.4829  data_time: 0.0079  last_data_time: 0.0083   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:01:08 d2.utils.events]: \u001b[0m eta: 7:45:12  iter: 2799  total_loss: 0.2713  loss_cls: 0.0352  loss_box_reg: 0.09122  loss_mask: 0.08812  loss_rpn_cls: 0.006217  loss_rpn_loc: 0.04349  total_val_loss: 0.2322  val_loss_cls: 0.03162  val_loss_box_reg: 0.06831  val_loss_mask: 0.08337  val_loss_rpn_cls: 0.003981  val_loss_rpn_loc: 0.03446    time: 1.6904  last_time: 1.4764  data_time: 0.0080  last_data_time: 0.0069   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:01:51 d2.utils.events]: \u001b[0m eta: 7:44:14  iter: 2819  total_loss: 0.2786  loss_cls: 0.03862  loss_box_reg: 0.1093  loss_mask: 0.08307  loss_rpn_cls: 0.005293  loss_rpn_loc: 0.0513  total_val_loss: 0.2272  val_loss_cls: 0.02869  val_loss_box_reg: 0.0699  val_loss_mask: 0.0864  val_loss_rpn_cls: 0.004177  val_loss_rpn_loc: 0.03521    time: 1.6890  last_time: 1.4002  data_time: 0.0080  last_data_time: 0.0120   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:02:34 d2.utils.events]: \u001b[0m eta: 7:42:40  iter: 2839  total_loss: 0.2942  loss_cls: 0.03733  loss_box_reg: 0.09819  loss_mask: 0.0863  loss_rpn_cls: 0.006908  loss_rpn_loc: 0.05338  total_val_loss: 0.2398  val_loss_cls: 0.03173  val_loss_box_reg: 0.07787  val_loss_mask: 0.08735  val_loss_rpn_cls: 0.004985  val_loss_rpn_loc: 0.03895    time: 1.6877  last_time: 1.4426  data_time: 0.0083  last_data_time: 0.0085   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:03:19 d2.utils.events]: \u001b[0m eta: 7:41:28  iter: 2859  total_loss: 0.2724  loss_cls: 0.03839  loss_box_reg: 0.103  loss_mask: 0.07965  loss_rpn_cls: 0.007121  loss_rpn_loc: 0.04571  total_val_loss: 0.2361  val_loss_cls: 0.03065  val_loss_box_reg: 0.07854  val_loss_mask: 0.08157  val_loss_rpn_cls: 0.004227  val_loss_rpn_loc: 0.03495    time: 1.6868  last_time: 1.5713  data_time: 0.0094  last_data_time: 0.0093   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:04:02 d2.utils.events]: \u001b[0m eta: 7:40:23  iter: 2879  total_loss: 0.2712  loss_cls: 0.03635  loss_box_reg: 0.09142  loss_mask: 0.08403  loss_rpn_cls: 0.005974  loss_rpn_loc: 0.04132  total_val_loss: 0.2276  val_loss_cls: 0.03182  val_loss_box_reg: 0.07166  val_loss_mask: 0.08439  val_loss_rpn_cls: 0.00324  val_loss_rpn_loc: 0.03556    time: 1.6857  last_time: 1.5454  data_time: 0.0083  last_data_time: 0.0073   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:04:47 d2.utils.events]: \u001b[0m eta: 7:38:57  iter: 2899  total_loss: 0.268  loss_cls: 0.03982  loss_box_reg: 0.09474  loss_mask: 0.08189  loss_rpn_cls: 0.006283  loss_rpn_loc: 0.04328  total_val_loss: 0.2302  val_loss_cls: 0.02948  val_loss_box_reg: 0.07728  val_loss_mask: 0.08485  val_loss_rpn_cls: 0.003757  val_loss_rpn_loc: 0.03256    time: 1.6848  last_time: 1.6169  data_time: 0.0074  last_data_time: 0.0063   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:05:30 d2.utils.events]: \u001b[0m eta: 7:37:13  iter: 2919  total_loss: 0.2667  loss_cls: 0.0408  loss_box_reg: 0.09707  loss_mask: 0.08211  loss_rpn_cls: 0.006247  loss_rpn_loc: 0.04485  total_val_loss: 0.2128  val_loss_cls: 0.03005  val_loss_box_reg: 0.06761  val_loss_mask: 0.08009  val_loss_rpn_cls: 0.002947  val_loss_rpn_loc: 0.03259    time: 1.6837  last_time: 1.5927  data_time: 0.0071  last_data_time: 0.0059   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:06:14 d2.utils.events]: \u001b[0m eta: 7:36:31  iter: 2939  total_loss: 0.2995  loss_cls: 0.0441  loss_box_reg: 0.1086  loss_mask: 0.08486  loss_rpn_cls: 0.006192  loss_rpn_loc: 0.05196  total_val_loss: 0.2375  val_loss_cls: 0.03313  val_loss_box_reg: 0.07741  val_loss_mask: 0.0861  val_loss_rpn_cls: 0.003242  val_loss_rpn_loc: 0.03506    time: 1.6829  last_time: 1.4179  data_time: 0.0082  last_data_time: 0.0070   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:06:58 d2.utils.events]: \u001b[0m eta: 7:35:37  iter: 2959  total_loss: 0.302  loss_cls: 0.04539  loss_box_reg: 0.09798  loss_mask: 0.08628  loss_rpn_cls: 0.00682  loss_rpn_loc: 0.05216  total_val_loss: 0.2071  val_loss_cls: 0.02588  val_loss_box_reg: 0.06742  val_loss_mask: 0.08465  val_loss_rpn_cls: 0.002428  val_loss_rpn_loc: 0.02999    time: 1.6820  last_time: 1.5651  data_time: 0.0074  last_data_time: 0.0068   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:07:42 d2.utils.events]: \u001b[0m eta: 7:34:47  iter: 2979  total_loss: 0.2875  loss_cls: 0.04049  loss_box_reg: 0.09747  loss_mask: 0.08892  loss_rpn_cls: 0.005192  loss_rpn_loc: 0.04615  total_val_loss: 0.2246  val_loss_cls: 0.02905  val_loss_box_reg: 0.07332  val_loss_mask: 0.08623  val_loss_rpn_cls: 0.003127  val_loss_rpn_loc: 0.03493    time: 1.6810  last_time: 1.5471  data_time: 0.0078  last_data_time: 0.0080   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:08:27 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\testing_images\\0_SideLane_addedversion_Testing_COCO.json\n",
      "\u001b[32m[09/26 16:08:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/26 16:08:27 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/26 16:08:27 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/26 16:08:27 d2.data.common]: \u001b[0mSerialized dataset takes 6.03 MiB\n",
      "\u001b[32m[09/26 16:08:27 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[09/26 16:08:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 566 batches\n",
      "\u001b[32m[09/26 16:08:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/566. Dataloading: 0.0004 s/iter. Inference: 0.0714 s/iter. Eval: 0.0058 s/iter. Total: 0.0776 s/iter. ETA=0:00:43\n",
      "\u001b[32m[09/26 16:08:35 d2.evaluation.evaluator]: \u001b[0mInference done 78/566. Dataloading: 0.0006 s/iter. Inference: 0.0720 s/iter. Eval: 0.0026 s/iter. Total: 0.0752 s/iter. ETA=0:00:36\n",
      "\u001b[32m[09/26 16:08:41 d2.evaluation.evaluator]: \u001b[0mInference done 143/566. Dataloading: 0.0006 s/iter. Inference: 0.0724 s/iter. Eval: 0.0036 s/iter. Total: 0.0766 s/iter. ETA=0:00:32\n",
      "\u001b[32m[09/26 16:08:46 d2.evaluation.evaluator]: \u001b[0mInference done 207/566. Dataloading: 0.0006 s/iter. Inference: 0.0730 s/iter. Eval: 0.0036 s/iter. Total: 0.0772 s/iter. ETA=0:00:27\n",
      "\u001b[32m[09/26 16:08:51 d2.evaluation.evaluator]: \u001b[0mInference done 271/566. Dataloading: 0.0006 s/iter. Inference: 0.0732 s/iter. Eval: 0.0036 s/iter. Total: 0.0774 s/iter. ETA=0:00:22\n",
      "\u001b[32m[09/26 16:08:56 d2.evaluation.evaluator]: \u001b[0mInference done 340/566. Dataloading: 0.0006 s/iter. Inference: 0.0726 s/iter. Eval: 0.0033 s/iter. Total: 0.0765 s/iter. ETA=0:00:17\n",
      "\u001b[32m[09/26 16:09:01 d2.evaluation.evaluator]: \u001b[0mInference done 406/566. Dataloading: 0.0006 s/iter. Inference: 0.0728 s/iter. Eval: 0.0029 s/iter. Total: 0.0764 s/iter. ETA=0:00:12\n",
      "\u001b[32m[09/26 16:09:06 d2.evaluation.evaluator]: \u001b[0mInference done 470/566. Dataloading: 0.0006 s/iter. Inference: 0.0729 s/iter. Eval: 0.0032 s/iter. Total: 0.0767 s/iter. ETA=0:00:07\n",
      "\u001b[32m[09/26 16:09:11 d2.evaluation.evaluator]: \u001b[0mInference done 533/566. Dataloading: 0.0006 s/iter. Inference: 0.0732 s/iter. Eval: 0.0032 s/iter. Total: 0.0771 s/iter. ETA=0:00:02\n",
      "\u001b[32m[09/26 16:09:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:43.830463 (0.078129 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 16:09:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.073358 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 16:09:14 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/26 16:09:14 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\coco_instances_results.json\n",
      "\u001b[32m[09/26 16:09:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.22s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.923\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.925\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.926\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.194\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.930\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.944\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.935\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.950\n",
      "\u001b[32m[09/26 16:09:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 92.296 | 99.008 | 98.976 |  nan  | 92.487 | 92.631 |\n",
      "\u001b[32m[09/26 16:09:14 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 16:09:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 92.296 | background | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.34s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.858\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.830\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.879\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.877\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.891\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.862\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.910\n",
      "\u001b[32m[09/26 16:09:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 85.768 | 99.008 | 98.966 |  nan  | 82.953 | 87.904 |\n",
      "\u001b[32m[09/26 16:09:14 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 16:09:14 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 85.768 | background | nan  |\n",
      "\u001b[32m[09/26 16:09:14 d2.engine.defaults]: \u001b[0mEvaluation results for test_data in csv format:\n",
      "\u001b[32m[09/26 16:09:14 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/26 16:09:14 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 16:09:14 d2.evaluation.testing]: \u001b[0mcopypaste: 92.2964,99.0080,98.9761,nan,92.4866,92.6311\n",
      "\u001b[32m[09/26 16:09:14 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/26 16:09:14 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 16:09:14 d2.evaluation.testing]: \u001b[0mcopypaste: 85.7682,99.0080,98.9661,nan,82.9527,87.9036\n",
      "\u001b[32m[09/26 16:09:15 d2.utils.events]: \u001b[0m eta: 7:33:32  iter: 2999  total_loss: 0.2825  loss_cls: 0.03831  loss_box_reg: 0.09356  loss_mask: 0.09009  loss_rpn_cls: 0.005626  loss_rpn_loc: 0.04132  total_val_loss: 0.2165  val_loss_cls: 0.02719  val_loss_box_reg: 0.06939  val_loss_mask: 0.0867  val_loss_rpn_cls: 0.00285  val_loss_rpn_loc: 0.03209    time: 1.6801  last_time: 1.6518  data_time: 0.0073  last_data_time: 0.0071   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:09:59 d2.utils.events]: \u001b[0m eta: 7:32:36  iter: 3019  total_loss: 0.2471  loss_cls: 0.03255  loss_box_reg: 0.0896  loss_mask: 0.08717  loss_rpn_cls: 0.003511  loss_rpn_loc: 0.03898  total_val_loss: 0.2407  val_loss_cls: 0.03229  val_loss_box_reg: 0.08071  val_loss_mask: 0.08634  val_loss_rpn_cls: 0.003777  val_loss_rpn_loc: 0.03616    time: 1.6791  last_time: 1.4936  data_time: 0.0074  last_data_time: 0.0074   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:10:43 d2.utils.events]: \u001b[0m eta: 7:31:49  iter: 3039  total_loss: 0.2773  loss_cls: 0.03997  loss_box_reg: 0.1035  loss_mask: 0.08498  loss_rpn_cls: 0.004455  loss_rpn_loc: 0.04384  total_val_loss: 0.2078  val_loss_cls: 0.02607  val_loss_box_reg: 0.0633  val_loss_mask: 0.08453  val_loss_rpn_cls: 0.002617  val_loss_rpn_loc: 0.02921    time: 1.6781  last_time: 1.3946  data_time: 0.0080  last_data_time: 0.0057   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:11:26 d2.utils.events]: \u001b[0m eta: 7:30:57  iter: 3059  total_loss: 0.2548  loss_cls: 0.03284  loss_box_reg: 0.09135  loss_mask: 0.08966  loss_rpn_cls: 0.004769  loss_rpn_loc: 0.03899  total_val_loss: 0.2332  val_loss_cls: 0.03333  val_loss_box_reg: 0.07233  val_loss_mask: 0.08557  val_loss_rpn_cls: 0.002399  val_loss_rpn_loc: 0.03576    time: 1.6772  last_time: 1.5798  data_time: 0.0078  last_data_time: 0.0073   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:12:10 d2.utils.events]: \u001b[0m eta: 7:29:50  iter: 3079  total_loss: 0.2655  loss_cls: 0.04253  loss_box_reg: 0.08999  loss_mask: 0.08615  loss_rpn_cls: 0.007207  loss_rpn_loc: 0.04497  total_val_loss: 0.2252  val_loss_cls: 0.02917  val_loss_box_reg: 0.07533  val_loss_mask: 0.08174  val_loss_rpn_cls: 0.003498  val_loss_rpn_loc: 0.03385    time: 1.6762  last_time: 1.4537  data_time: 0.0081  last_data_time: 0.0086   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:12:53 d2.utils.events]: \u001b[0m eta: 7:28:54  iter: 3099  total_loss: 0.2767  loss_cls: 0.0406  loss_box_reg: 0.09852  loss_mask: 0.08829  loss_rpn_cls: 0.006144  loss_rpn_loc: 0.04795  total_val_loss: 0.2364  val_loss_cls: 0.0337  val_loss_box_reg: 0.07542  val_loss_mask: 0.08417  val_loss_rpn_cls: 0.004161  val_loss_rpn_loc: 0.03825    time: 1.6752  last_time: 1.3397  data_time: 0.0073  last_data_time: 0.0060   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:13:36 d2.utils.events]: \u001b[0m eta: 7:27:38  iter: 3119  total_loss: 0.2379  loss_cls: 0.03524  loss_box_reg: 0.07807  loss_mask: 0.08046  loss_rpn_cls: 0.005053  loss_rpn_loc: 0.04015  total_val_loss: 0.2003  val_loss_cls: 0.02493  val_loss_box_reg: 0.06501  val_loss_mask: 0.07966  val_loss_rpn_cls: 0.00268  val_loss_rpn_loc: 0.02986    time: 1.6740  last_time: 1.5155  data_time: 0.0073  last_data_time: 0.0092   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:14:19 d2.utils.events]: \u001b[0m eta: 7:26:31  iter: 3139  total_loss: 0.2974  loss_cls: 0.04097  loss_box_reg: 0.1008  loss_mask: 0.08494  loss_rpn_cls: 0.00621  loss_rpn_loc: 0.05354  total_val_loss: 0.2246  val_loss_cls: 0.02696  val_loss_box_reg: 0.07  val_loss_mask: 0.08813  val_loss_rpn_cls: 0.004468  val_loss_rpn_loc: 0.0337    time: 1.6730  last_time: 1.4398  data_time: 0.0083  last_data_time: 0.0078   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:15:03 d2.utils.events]: \u001b[0m eta: 7:25:06  iter: 3159  total_loss: 0.2919  loss_cls: 0.04425  loss_box_reg: 0.1043  loss_mask: 0.08826  loss_rpn_cls: 0.006316  loss_rpn_loc: 0.04534  total_val_loss: 0.2276  val_loss_cls: 0.02954  val_loss_box_reg: 0.07172  val_loss_mask: 0.08621  val_loss_rpn_cls: 0.003974  val_loss_rpn_loc: 0.0333    time: 1.6721  last_time: 1.5096  data_time: 0.0078  last_data_time: 0.0077   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:15:46 d2.utils.events]: \u001b[0m eta: 7:24:00  iter: 3179  total_loss: 0.2676  loss_cls: 0.0359  loss_box_reg: 0.08894  loss_mask: 0.08526  loss_rpn_cls: 0.006428  loss_rpn_loc: 0.04558  total_val_loss: 0.2293  val_loss_cls: 0.03117  val_loss_box_reg: 0.07247  val_loss_mask: 0.08236  val_loss_rpn_cls: 0.003356  val_loss_rpn_loc: 0.03362    time: 1.6712  last_time: 1.5582  data_time: 0.0074  last_data_time: 0.0079   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:16:29 d2.utils.events]: \u001b[0m eta: 7:22:49  iter: 3199  total_loss: 0.2619  loss_cls: 0.03525  loss_box_reg: 0.0854  loss_mask: 0.08616  loss_rpn_cls: 0.005925  loss_rpn_loc: 0.04536  total_val_loss: 0.2181  val_loss_cls: 0.02922  val_loss_box_reg: 0.07227  val_loss_mask: 0.08168  val_loss_rpn_cls: 0.004007  val_loss_rpn_loc: 0.03429    time: 1.6702  last_time: 1.4375  data_time: 0.0074  last_data_time: 0.0071   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:17:12 d2.utils.events]: \u001b[0m eta: 7:21:59  iter: 3219  total_loss: 0.2584  loss_cls: 0.03299  loss_box_reg: 0.08984  loss_mask: 0.08729  loss_rpn_cls: 0.005695  loss_rpn_loc: 0.03955  total_val_loss: 0.2262  val_loss_cls: 0.0295  val_loss_box_reg: 0.06738  val_loss_mask: 0.08299  val_loss_rpn_cls: 0.003185  val_loss_rpn_loc: 0.03474    time: 1.6692  last_time: 1.4667  data_time: 0.0077  last_data_time: 0.0068   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:17:56 d2.utils.events]: \u001b[0m eta: 7:20:38  iter: 3239  total_loss: 0.258  loss_cls: 0.03728  loss_box_reg: 0.09185  loss_mask: 0.07908  loss_rpn_cls: 0.005589  loss_rpn_loc: 0.0419  total_val_loss: 0.2283  val_loss_cls: 0.02753  val_loss_box_reg: 0.079  val_loss_mask: 0.08399  val_loss_rpn_cls: 0.003168  val_loss_rpn_loc: 0.03343    time: 1.6683  last_time: 1.4572  data_time: 0.0074  last_data_time: 0.0069   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:18:40 d2.utils.events]: \u001b[0m eta: 7:19:22  iter: 3259  total_loss: 0.2785  loss_cls: 0.03772  loss_box_reg: 0.1013  loss_mask: 0.09344  loss_rpn_cls: 0.005364  loss_rpn_loc: 0.04307  total_val_loss: 0.2301  val_loss_cls: 0.03134  val_loss_box_reg: 0.07688  val_loss_mask: 0.08639  val_loss_rpn_cls: 0.003524  val_loss_rpn_loc: 0.03483    time: 1.6675  last_time: 1.5228  data_time: 0.0077  last_data_time: 0.0070   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:19:23 d2.utils.events]: \u001b[0m eta: 7:18:25  iter: 3279  total_loss: 0.3137  loss_cls: 0.04423  loss_box_reg: 0.1076  loss_mask: 0.08612  loss_rpn_cls: 0.006646  loss_rpn_loc: 0.05648  total_val_loss: 0.2259  val_loss_cls: 0.02664  val_loss_box_reg: 0.07078  val_loss_mask: 0.08796  val_loss_rpn_cls: 0.003145  val_loss_rpn_loc: 0.03658    time: 1.6667  last_time: 1.4905  data_time: 0.0074  last_data_time: 0.0064   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:20:07 d2.utils.events]: \u001b[0m eta: 7:17:04  iter: 3299  total_loss: 0.3104  loss_cls: 0.04746  loss_box_reg: 0.1105  loss_mask: 0.08964  loss_rpn_cls: 0.006946  loss_rpn_loc: 0.04216  total_val_loss: 0.2459  val_loss_cls: 0.0313  val_loss_box_reg: 0.08194  val_loss_mask: 0.08481  val_loss_rpn_cls: 0.003058  val_loss_rpn_loc: 0.04006    time: 1.6658  last_time: 1.5333  data_time: 0.0076  last_data_time: 0.0065   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:20:51 d2.utils.events]: \u001b[0m eta: 7:15:40  iter: 3319  total_loss: 0.285  loss_cls: 0.04371  loss_box_reg: 0.1018  loss_mask: 0.08231  loss_rpn_cls: 0.005815  loss_rpn_loc: 0.04597  total_val_loss: 0.2412  val_loss_cls: 0.03174  val_loss_box_reg: 0.08144  val_loss_mask: 0.08867  val_loss_rpn_cls: 0.004453  val_loss_rpn_loc: 0.03621    time: 1.6650  last_time: 1.4744  data_time: 0.0079  last_data_time: 0.0074   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:21:34 d2.utils.events]: \u001b[0m eta: 7:14:25  iter: 3339  total_loss: 0.284  loss_cls: 0.03846  loss_box_reg: 0.09689  loss_mask: 0.08956  loss_rpn_cls: 0.00544  loss_rpn_loc: 0.03865  total_val_loss: 0.2356  val_loss_cls: 0.03523  val_loss_box_reg: 0.07488  val_loss_mask: 0.08029  val_loss_rpn_cls: 0.004468  val_loss_rpn_loc: 0.03655    time: 1.6643  last_time: 1.4526  data_time: 0.0075  last_data_time: 0.0080   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:22:18 d2.utils.events]: \u001b[0m eta: 7:12:32  iter: 3359  total_loss: 0.2571  loss_cls: 0.04048  loss_box_reg: 0.09097  loss_mask: 0.07925  loss_rpn_cls: 0.007449  loss_rpn_loc: 0.03792  total_val_loss: 0.2278  val_loss_cls: 0.0294  val_loss_box_reg: 0.07122  val_loss_mask: 0.08259  val_loss_rpn_cls: 0.003194  val_loss_rpn_loc: 0.03202    time: 1.6633  last_time: 1.6338  data_time: 0.0074  last_data_time: 0.0070   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:23:02 d2.utils.events]: \u001b[0m eta: 7:11:55  iter: 3379  total_loss: 0.2969  loss_cls: 0.04435  loss_box_reg: 0.1072  loss_mask: 0.08949  loss_rpn_cls: 0.005519  loss_rpn_loc: 0.05426  total_val_loss: 0.231  val_loss_cls: 0.02731  val_loss_box_reg: 0.07458  val_loss_mask: 0.08432  val_loss_rpn_cls: 0.003062  val_loss_rpn_loc: 0.03823    time: 1.6627  last_time: 1.8064  data_time: 0.0077  last_data_time: 0.0074   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:23:46 d2.utils.events]: \u001b[0m eta: 7:10:42  iter: 3399  total_loss: 0.2974  loss_cls: 0.04099  loss_box_reg: 0.1079  loss_mask: 0.08972  loss_rpn_cls: 0.005716  loss_rpn_loc: 0.04754  total_val_loss: 0.2327  val_loss_cls: 0.03534  val_loss_box_reg: 0.07332  val_loss_mask: 0.08867  val_loss_rpn_cls: 0.003395  val_loss_rpn_loc: 0.03379    time: 1.6621  last_time: 1.5309  data_time: 0.0081  last_data_time: 0.0104   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:24:30 d2.utils.events]: \u001b[0m eta: 7:09:46  iter: 3419  total_loss: 0.2671  loss_cls: 0.04215  loss_box_reg: 0.09736  loss_mask: 0.08108  loss_rpn_cls: 0.005921  loss_rpn_loc: 0.04651  total_val_loss: 0.227  val_loss_cls: 0.03317  val_loss_box_reg: 0.07424  val_loss_mask: 0.08617  val_loss_rpn_cls: 0.003923  val_loss_rpn_loc: 0.03416    time: 1.6615  last_time: 1.5452  data_time: 0.0073  last_data_time: 0.0064   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:25:15 d2.utils.events]: \u001b[0m eta: 7:08:53  iter: 3439  total_loss: 0.2714  loss_cls: 0.03912  loss_box_reg: 0.09653  loss_mask: 0.08752  loss_rpn_cls: 0.004987  loss_rpn_loc: 0.04523  total_val_loss: 0.2313  val_loss_cls: 0.03071  val_loss_box_reg: 0.07948  val_loss_mask: 0.08176  val_loss_rpn_cls: 0.004882  val_loss_rpn_loc: 0.03778    time: 1.6609  last_time: 1.4860  data_time: 0.0079  last_data_time: 0.0063   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:25:59 d2.utils.events]: \u001b[0m eta: 7:08:07  iter: 3459  total_loss: 0.2798  loss_cls: 0.03756  loss_box_reg: 0.1042  loss_mask: 0.08647  loss_rpn_cls: 0.005912  loss_rpn_loc: 0.04384  total_val_loss: 0.2195  val_loss_cls: 0.02748  val_loss_box_reg: 0.06822  val_loss_mask: 0.08356  val_loss_rpn_cls: 0.003175  val_loss_rpn_loc: 0.03295    time: 1.6603  last_time: 1.6336  data_time: 0.0077  last_data_time: 0.0071   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:26:44 d2.utils.events]: \u001b[0m eta: 7:07:04  iter: 3479  total_loss: 0.2861  loss_cls: 0.03801  loss_box_reg: 0.1038  loss_mask: 0.08708  loss_rpn_cls: 0.005463  loss_rpn_loc: 0.04655  total_val_loss: 0.2335  val_loss_cls: 0.03406  val_loss_box_reg: 0.0771  val_loss_mask: 0.08495  val_loss_rpn_cls: 0.003165  val_loss_rpn_loc: 0.0337    time: 1.6597  last_time: 1.5218  data_time: 0.0076  last_data_time: 0.0097   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:27:29 d2.utils.events]: \u001b[0m eta: 7:06:26  iter: 3499  total_loss: 0.2506  loss_cls: 0.03983  loss_box_reg: 0.09065  loss_mask: 0.07976  loss_rpn_cls: 0.00535  loss_rpn_loc: 0.04336  total_val_loss: 0.2358  val_loss_cls: 0.0321  val_loss_box_reg: 0.07486  val_loss_mask: 0.08229  val_loss_rpn_cls: 0.002934  val_loss_rpn_loc: 0.0345    time: 1.6593  last_time: 1.5702  data_time: 0.0080  last_data_time: 0.0087   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:28:12 d2.utils.events]: \u001b[0m eta: 7:05:17  iter: 3519  total_loss: 0.2659  loss_cls: 0.03635  loss_box_reg: 0.09039  loss_mask: 0.0822  loss_rpn_cls: 0.004755  loss_rpn_loc: 0.0438  total_val_loss: 0.2448  val_loss_cls: 0.03212  val_loss_box_reg: 0.08485  val_loss_mask: 0.09357  val_loss_rpn_cls: 0.00312  val_loss_rpn_loc: 0.0375    time: 1.6585  last_time: 1.5113  data_time: 0.0077  last_data_time: 0.0066   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:28:55 d2.utils.events]: \u001b[0m eta: 7:04:29  iter: 3539  total_loss: 0.2578  loss_cls: 0.03407  loss_box_reg: 0.08839  loss_mask: 0.08611  loss_rpn_cls: 0.004909  loss_rpn_loc: 0.04385  total_val_loss: 0.2235  val_loss_cls: 0.03163  val_loss_box_reg: 0.07185  val_loss_mask: 0.08013  val_loss_rpn_cls: 0.003347  val_loss_rpn_loc: 0.03468    time: 1.6578  last_time: 1.4188  data_time: 0.0075  last_data_time: 0.0066   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:29:39 d2.utils.events]: \u001b[0m eta: 7:03:19  iter: 3559  total_loss: 0.2834  loss_cls: 0.04238  loss_box_reg: 0.0934  loss_mask: 0.08657  loss_rpn_cls: 0.005705  loss_rpn_loc: 0.04117  total_val_loss: 0.2199  val_loss_cls: 0.02752  val_loss_box_reg: 0.07251  val_loss_mask: 0.08092  val_loss_rpn_cls: 0.003376  val_loss_rpn_loc: 0.03423    time: 1.6570  last_time: 1.3577  data_time: 0.0072  last_data_time: 0.0088   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:30:22 d2.utils.events]: \u001b[0m eta: 7:02:16  iter: 3579  total_loss: 0.2768  loss_cls: 0.04109  loss_box_reg: 0.09813  loss_mask: 0.08399  loss_rpn_cls: 0.004648  loss_rpn_loc: 0.04815  total_val_loss: 0.2514  val_loss_cls: 0.03658  val_loss_box_reg: 0.08695  val_loss_mask: 0.08777  val_loss_rpn_cls: 0.003104  val_loss_rpn_loc: 0.0349    time: 1.6561  last_time: 1.5024  data_time: 0.0072  last_data_time: 0.0073   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:31:05 d2.utils.events]: \u001b[0m eta: 7:01:00  iter: 3599  total_loss: 0.2903  loss_cls: 0.04102  loss_box_reg: 0.09891  loss_mask: 0.0849  loss_rpn_cls: 0.0049  loss_rpn_loc: 0.04613  total_val_loss: 0.229  val_loss_cls: 0.033  val_loss_box_reg: 0.07771  val_loss_mask: 0.08466  val_loss_rpn_cls: 0.003669  val_loss_rpn_loc: 0.03593    time: 1.6554  last_time: 1.5053  data_time: 0.0075  last_data_time: 0.0072   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:31:49 d2.utils.events]: \u001b[0m eta: 7:00:00  iter: 3619  total_loss: 0.2633  loss_cls: 0.03461  loss_box_reg: 0.08385  loss_mask: 0.09515  loss_rpn_cls: 0.005444  loss_rpn_loc: 0.04081  total_val_loss: 0.2404  val_loss_cls: 0.0315  val_loss_box_reg: 0.07548  val_loss_mask: 0.09018  val_loss_rpn_cls: 0.003302  val_loss_rpn_loc: 0.03742    time: 1.6547  last_time: 1.5462  data_time: 0.0074  last_data_time: 0.0068   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:32:33 d2.utils.events]: \u001b[0m eta: 6:59:07  iter: 3639  total_loss: 0.2618  loss_cls: 0.03893  loss_box_reg: 0.0922  loss_mask: 0.08198  loss_rpn_cls: 0.005167  loss_rpn_loc: 0.04808  total_val_loss: 0.2235  val_loss_cls: 0.02885  val_loss_box_reg: 0.07072  val_loss_mask: 0.07891  val_loss_rpn_cls: 0.004083  val_loss_rpn_loc: 0.03844    time: 1.6540  last_time: 1.4886  data_time: 0.0077  last_data_time: 0.0080   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:33:17 d2.utils.events]: \u001b[0m eta: 6:58:10  iter: 3659  total_loss: 0.2688  loss_cls: 0.04014  loss_box_reg: 0.09728  loss_mask: 0.07998  loss_rpn_cls: 0.004838  loss_rpn_loc: 0.04467  total_val_loss: 0.2165  val_loss_cls: 0.0281  val_loss_box_reg: 0.06675  val_loss_mask: 0.08743  val_loss_rpn_cls: 0.002916  val_loss_rpn_loc: 0.03216    time: 1.6534  last_time: 1.4665  data_time: 0.0079  last_data_time: 0.0059   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:34:01 d2.utils.events]: \u001b[0m eta: 6:57:29  iter: 3679  total_loss: 0.285  loss_cls: 0.03886  loss_box_reg: 0.102  loss_mask: 0.08905  loss_rpn_cls: 0.004713  loss_rpn_loc: 0.04364  total_val_loss: 0.2361  val_loss_cls: 0.03528  val_loss_box_reg: 0.07692  val_loss_mask: 0.08803  val_loss_rpn_cls: 0.002783  val_loss_rpn_loc: 0.03486    time: 1.6529  last_time: 1.6090  data_time: 0.0082  last_data_time: 0.0068   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:34:47 d2.utils.events]: \u001b[0m eta: 6:56:53  iter: 3699  total_loss: 0.2679  loss_cls: 0.0373  loss_box_reg: 0.0966  loss_mask: 0.08561  loss_rpn_cls: 0.004353  loss_rpn_loc: 0.04261  total_val_loss: 0.2379  val_loss_cls: 0.03529  val_loss_box_reg: 0.07807  val_loss_mask: 0.08879  val_loss_rpn_cls: 0.003387  val_loss_rpn_loc: 0.03448    time: 1.6526  last_time: 1.5198  data_time: 0.0079  last_data_time: 0.0071   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:35:31 d2.utils.events]: \u001b[0m eta: 6:56:28  iter: 3719  total_loss: 0.2672  loss_cls: 0.03498  loss_box_reg: 0.08973  loss_mask: 0.08425  loss_rpn_cls: 0.004367  loss_rpn_loc: 0.04323  total_val_loss: 0.2272  val_loss_cls: 0.0327  val_loss_box_reg: 0.07407  val_loss_mask: 0.0843  val_loss_rpn_cls: 0.0025  val_loss_rpn_loc: 0.03209    time: 1.6520  last_time: 1.5010  data_time: 0.0077  last_data_time: 0.0069   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:36:15 d2.utils.events]: \u001b[0m eta: 6:56:08  iter: 3739  total_loss: 0.2582  loss_cls: 0.03602  loss_box_reg: 0.08787  loss_mask: 0.08645  loss_rpn_cls: 0.004393  loss_rpn_loc: 0.0452  total_val_loss: 0.2231  val_loss_cls: 0.02888  val_loss_box_reg: 0.07273  val_loss_mask: 0.07859  val_loss_rpn_cls: 0.002925  val_loss_rpn_loc: 0.0348    time: 1.6515  last_time: 1.6088  data_time: 0.0074  last_data_time: 0.0063   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:36:59 d2.utils.events]: \u001b[0m eta: 6:55:28  iter: 3759  total_loss: 0.2715  loss_cls: 0.03954  loss_box_reg: 0.1005  loss_mask: 0.08483  loss_rpn_cls: 0.003987  loss_rpn_loc: 0.03815  total_val_loss: 0.2349  val_loss_cls: 0.03137  val_loss_box_reg: 0.07534  val_loss_mask: 0.08878  val_loss_rpn_cls: 0.002989  val_loss_rpn_loc: 0.03176    time: 1.6508  last_time: 1.5820  data_time: 0.0076  last_data_time: 0.0086   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:37:43 d2.utils.events]: \u001b[0m eta: 6:55:13  iter: 3779  total_loss: 0.2848  loss_cls: 0.04155  loss_box_reg: 0.1032  loss_mask: 0.07903  loss_rpn_cls: 0.006054  loss_rpn_loc: 0.05071  total_val_loss: 0.2409  val_loss_cls: 0.03422  val_loss_box_reg: 0.07619  val_loss_mask: 0.09422  val_loss_rpn_cls: 0.002876  val_loss_rpn_loc: 0.03146    time: 1.6504  last_time: 1.6371  data_time: 0.0072  last_data_time: 0.0085   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:38:27 d2.utils.events]: \u001b[0m eta: 6:54:47  iter: 3799  total_loss: 0.3142  loss_cls: 0.04479  loss_box_reg: 0.1075  loss_mask: 0.08842  loss_rpn_cls: 0.006379  loss_rpn_loc: 0.0487  total_val_loss: 0.246  val_loss_cls: 0.03216  val_loss_box_reg: 0.08306  val_loss_mask: 0.08229  val_loss_rpn_cls: 0.004244  val_loss_rpn_loc: 0.03469    time: 1.6498  last_time: 1.5459  data_time: 0.0076  last_data_time: 0.0081   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:39:10 d2.utils.events]: \u001b[0m eta: 6:54:28  iter: 3819  total_loss: 0.2728  loss_cls: 0.03569  loss_box_reg: 0.09822  loss_mask: 0.08271  loss_rpn_cls: 0.005437  loss_rpn_loc: 0.04287  total_val_loss: 0.2289  val_loss_cls: 0.03212  val_loss_box_reg: 0.07482  val_loss_mask: 0.08437  val_loss_rpn_cls: 0.003487  val_loss_rpn_loc: 0.0351    time: 1.6492  last_time: 1.4561  data_time: 0.0079  last_data_time: 0.0073   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:40:01 d2.utils.events]: \u001b[0m eta: 6:54:23  iter: 3839  total_loss: 0.2669  loss_cls: 0.03745  loss_box_reg: 0.08952  loss_mask: 0.08921  loss_rpn_cls: 0.004955  loss_rpn_loc: 0.04522  total_val_loss: 0.2279  val_loss_cls: 0.02846  val_loss_box_reg: 0.06966  val_loss_mask: 0.08886  val_loss_rpn_cls: 0.003037  val_loss_rpn_loc: 0.03194    time: 1.6496  last_time: 2.4170  data_time: 0.0080  last_data_time: 0.0075   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:41:05 d2.utils.events]: \u001b[0m eta: 6:54:16  iter: 3859  total_loss: 0.2993  loss_cls: 0.03899  loss_box_reg: 0.101  loss_mask: 0.09197  loss_rpn_cls: 0.0052  loss_rpn_loc: 0.04598  total_val_loss: 0.2553  val_loss_cls: 0.03889  val_loss_box_reg: 0.08255  val_loss_mask: 0.08688  val_loss_rpn_cls: 0.003349  val_loss_rpn_loc: 0.03722    time: 1.6528  last_time: 1.8043  data_time: 0.0153  last_data_time: 0.0103   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:42:10 d2.utils.events]: \u001b[0m eta: 6:54:29  iter: 3879  total_loss: 0.2594  loss_cls: 0.03687  loss_box_reg: 0.0838  loss_mask: 0.08509  loss_rpn_cls: 0.00519  loss_rpn_loc: 0.04196  total_val_loss: 0.2212  val_loss_cls: 0.02821  val_loss_box_reg: 0.07374  val_loss_mask: 0.08435  val_loss_rpn_cls: 0.002762  val_loss_rpn_loc: 0.03547    time: 1.6557  last_time: 2.2364  data_time: 0.0146  last_data_time: 0.0105   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:43:11 d2.utils.events]: \u001b[0m eta: 6:54:19  iter: 3899  total_loss: 0.2653  loss_cls: 0.03734  loss_box_reg: 0.08948  loss_mask: 0.09102  loss_rpn_cls: 0.006587  loss_rpn_loc: 0.04647  total_val_loss: 0.2302  val_loss_cls: 0.02848  val_loss_box_reg: 0.07704  val_loss_mask: 0.08267  val_loss_rpn_cls: 0.003882  val_loss_rpn_loc: 0.03294    time: 1.6581  last_time: 2.0983  data_time: 0.0146  last_data_time: 0.0077   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:44:17 d2.utils.events]: \u001b[0m eta: 6:54:20  iter: 3919  total_loss: 0.3133  loss_cls: 0.04362  loss_box_reg: 0.1122  loss_mask: 0.08408  loss_rpn_cls: 0.007878  loss_rpn_loc: 0.04993  total_val_loss: 0.232  val_loss_cls: 0.03313  val_loss_box_reg: 0.07673  val_loss_mask: 0.08525  val_loss_rpn_cls: 0.003686  val_loss_rpn_loc: 0.03603    time: 1.6611  last_time: 2.2867  data_time: 0.0150  last_data_time: 0.0165   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:45:20 d2.utils.events]: \u001b[0m eta: 6:54:04  iter: 3939  total_loss: 0.2686  loss_cls: 0.03691  loss_box_reg: 0.101  loss_mask: 0.08092  loss_rpn_cls: 0.004847  loss_rpn_loc: 0.04537  total_val_loss: 0.235  val_loss_cls: 0.03224  val_loss_box_reg: 0.07656  val_loss_mask: 0.08433  val_loss_rpn_cls: 0.003813  val_loss_rpn_loc: 0.03816    time: 1.6638  last_time: 2.6028  data_time: 0.0121  last_data_time: 0.0070   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:46:19 d2.utils.events]: \u001b[0m eta: 6:53:49  iter: 3959  total_loss: 0.2881  loss_cls: 0.03942  loss_box_reg: 0.1012  loss_mask: 0.08271  loss_rpn_cls: 0.005317  loss_rpn_loc: 0.0464  total_val_loss: 0.25  val_loss_cls: 0.03467  val_loss_box_reg: 0.08538  val_loss_mask: 0.09216  val_loss_rpn_cls: 0.002461  val_loss_rpn_loc: 0.03427    time: 1.6658  last_time: 2.0684  data_time: 0.0070  last_data_time: 0.0071   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:47:24 d2.utils.events]: \u001b[0m eta: 6:53:49  iter: 3979  total_loss: 0.2856  loss_cls: 0.04069  loss_box_reg: 0.1011  loss_mask: 0.08801  loss_rpn_cls: 0.006056  loss_rpn_loc: 0.04522  total_val_loss: 0.2186  val_loss_cls: 0.02921  val_loss_box_reg: 0.06884  val_loss_mask: 0.07999  val_loss_rpn_cls: 0.002904  val_loss_rpn_loc: 0.03314    time: 1.6689  last_time: 2.1355  data_time: 0.0086  last_data_time: 0.0079   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:48:17 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\testing_images\\0_SideLane_addedversion_Testing_COCO.json\n",
      "\u001b[32m[09/26 16:48:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/26 16:48:17 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/26 16:48:17 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/26 16:48:17 d2.data.common]: \u001b[0mSerialized dataset takes 6.03 MiB\n",
      "\u001b[32m[09/26 16:48:17 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[09/26 16:48:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 566 batches\n",
      "\u001b[32m[09/26 16:48:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/566. Dataloading: 0.0003 s/iter. Inference: 0.0722 s/iter. Eval: 0.0065 s/iter. Total: 0.0790 s/iter. ETA=0:00:43\n",
      "\u001b[32m[09/26 16:48:26 d2.evaluation.evaluator]: \u001b[0mInference done 78/566. Dataloading: 0.0006 s/iter. Inference: 0.0723 s/iter. Eval: 0.0028 s/iter. Total: 0.0757 s/iter. ETA=0:00:36\n",
      "\u001b[32m[09/26 16:48:31 d2.evaluation.evaluator]: \u001b[0mInference done 142/566. Dataloading: 0.0006 s/iter. Inference: 0.0725 s/iter. Eval: 0.0038 s/iter. Total: 0.0769 s/iter. ETA=0:00:32\n",
      "\u001b[32m[09/26 16:48:36 d2.evaluation.evaluator]: \u001b[0mInference done 205/566. Dataloading: 0.0006 s/iter. Inference: 0.0733 s/iter. Eval: 0.0039 s/iter. Total: 0.0779 s/iter. ETA=0:00:28\n",
      "\u001b[32m[09/26 16:48:41 d2.evaluation.evaluator]: \u001b[0mInference done 268/566. Dataloading: 0.0006 s/iter. Inference: 0.0737 s/iter. Eval: 0.0039 s/iter. Total: 0.0783 s/iter. ETA=0:00:23\n",
      "\u001b[32m[09/26 16:48:46 d2.evaluation.evaluator]: \u001b[0mInference done 335/566. Dataloading: 0.0006 s/iter. Inference: 0.0735 s/iter. Eval: 0.0035 s/iter. Total: 0.0776 s/iter. ETA=0:00:17\n",
      "\u001b[32m[09/26 16:48:51 d2.evaluation.evaluator]: \u001b[0mInference done 401/566. Dataloading: 0.0006 s/iter. Inference: 0.0736 s/iter. Eval: 0.0032 s/iter. Total: 0.0775 s/iter. ETA=0:00:12\n",
      "\u001b[32m[09/26 16:48:56 d2.evaluation.evaluator]: \u001b[0mInference done 464/566. Dataloading: 0.0006 s/iter. Inference: 0.0737 s/iter. Eval: 0.0035 s/iter. Total: 0.0778 s/iter. ETA=0:00:07\n",
      "\u001b[32m[09/26 16:49:01 d2.evaluation.evaluator]: \u001b[0mInference done 527/566. Dataloading: 0.0006 s/iter. Inference: 0.0741 s/iter. Eval: 0.0035 s/iter. Total: 0.0782 s/iter. ETA=0:00:03\n",
      "\u001b[32m[09/26 16:49:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:44.510719 (0.079342 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 16:49:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.074279 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 16:49:05 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/26 16:49:05 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\coco_instances_results.json\n",
      "\u001b[32m[09/26 16:49:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.24s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.917\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.913\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.920\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.193\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.925\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.939\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.927\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.947\n",
      "\u001b[32m[09/26 16:49:05 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 91.721 | 99.007 | 98.957 |  nan  | 91.258 | 91.993 |\n",
      "\u001b[32m[09/26 16:49:05 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 16:49:05 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 91.721 | background | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.41s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.853\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.989\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.820\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.877\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.875\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.889\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.858\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.908\n",
      "\u001b[32m[09/26 16:49:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 85.300 | 99.007 | 98.936 |  nan  | 82.002 | 87.698 |\n",
      "\u001b[32m[09/26 16:49:06 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 16:49:06 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 85.300 | background | nan  |\n",
      "\u001b[32m[09/26 16:49:06 d2.engine.defaults]: \u001b[0mEvaluation results for test_data in csv format:\n",
      "\u001b[32m[09/26 16:49:06 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/26 16:49:06 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 16:49:06 d2.evaluation.testing]: \u001b[0mcopypaste: 91.7209,99.0066,98.9569,nan,91.2578,91.9931\n",
      "\u001b[32m[09/26 16:49:06 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/26 16:49:06 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 16:49:06 d2.evaluation.testing]: \u001b[0mcopypaste: 85.2999,99.0066,98.9361,nan,82.0023,87.6982\n",
      "\u001b[32m[09/26 16:49:06 d2.utils.events]: \u001b[0m eta: 6:53:41  iter: 3999  total_loss: 0.2787  loss_cls: 0.04088  loss_box_reg: 0.09284  loss_mask: 0.08909  loss_rpn_cls: 0.005944  loss_rpn_loc: 0.04166  total_val_loss: 0.2322  val_loss_cls: 0.03249  val_loss_box_reg: 0.07823  val_loss_mask: 0.08622  val_loss_rpn_cls: 0.002718  val_loss_rpn_loc: 0.035    time: 1.6696  last_time: 1.4216  data_time: 0.0079  last_data_time: 0.0085   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:49:51 d2.utils.events]: \u001b[0m eta: 6:53:26  iter: 4019  total_loss: 0.2737  loss_cls: 0.04072  loss_box_reg: 0.0972  loss_mask: 0.08112  loss_rpn_cls: 0.004646  loss_rpn_loc: 0.04604  total_val_loss: 0.2293  val_loss_cls: 0.03063  val_loss_box_reg: 0.07603  val_loss_mask: 0.08841  val_loss_rpn_cls: 0.00402  val_loss_rpn_loc: 0.0338    time: 1.6691  last_time: 1.5697  data_time: 0.0082  last_data_time: 0.0100   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:50:36 d2.utils.events]: \u001b[0m eta: 6:53:22  iter: 4039  total_loss: 0.2618  loss_cls: 0.04006  loss_box_reg: 0.09456  loss_mask: 0.08383  loss_rpn_cls: 0.004058  loss_rpn_loc: 0.04433  total_val_loss: 0.2407  val_loss_cls: 0.03589  val_loss_box_reg: 0.07887  val_loss_mask: 0.07994  val_loss_rpn_cls: 0.003806  val_loss_rpn_loc: 0.03473    time: 1.6686  last_time: 1.4718  data_time: 0.0077  last_data_time: 0.0071   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:51:20 d2.utils.events]: \u001b[0m eta: 6:52:54  iter: 4059  total_loss: 0.2448  loss_cls: 0.03641  loss_box_reg: 0.08883  loss_mask: 0.07631  loss_rpn_cls: 0.00498  loss_rpn_loc: 0.04311  total_val_loss: 0.2333  val_loss_cls: 0.0331  val_loss_box_reg: 0.07266  val_loss_mask: 0.08346  val_loss_rpn_cls: 0.003516  val_loss_rpn_loc: 0.03559    time: 1.6680  last_time: 1.6289  data_time: 0.0081  last_data_time: 0.0067   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:52:05 d2.utils.events]: \u001b[0m eta: 6:52:34  iter: 4079  total_loss: 0.2769  loss_cls: 0.0434  loss_box_reg: 0.103  loss_mask: 0.08475  loss_rpn_cls: 0.006384  loss_rpn_loc: 0.04426  total_val_loss: 0.2315  val_loss_cls: 0.03389  val_loss_box_reg: 0.07818  val_loss_mask: 0.08547  val_loss_rpn_cls: 0.00333  val_loss_rpn_loc: 0.03481    time: 1.6675  last_time: 1.5145  data_time: 0.0082  last_data_time: 0.0071   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:52:51 d2.utils.events]: \u001b[0m eta: 6:52:40  iter: 4099  total_loss: 0.2715  loss_cls: 0.03824  loss_box_reg: 0.09995  loss_mask: 0.0815  loss_rpn_cls: 0.004686  loss_rpn_loc: 0.04404  total_val_loss: 0.2345  val_loss_cls: 0.02895  val_loss_box_reg: 0.07156  val_loss_mask: 0.08836  val_loss_rpn_cls: 0.003012  val_loss_rpn_loc: 0.03249    time: 1.6671  last_time: 1.5334  data_time: 0.0078  last_data_time: 0.0068   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:53:35 d2.utils.events]: \u001b[0m eta: 6:52:30  iter: 4119  total_loss: 0.2449  loss_cls: 0.03782  loss_box_reg: 0.08447  loss_mask: 0.08401  loss_rpn_cls: 0.004958  loss_rpn_loc: 0.04148  total_val_loss: 0.2198  val_loss_cls: 0.03  val_loss_box_reg: 0.07104  val_loss_mask: 0.09271  val_loss_rpn_cls: 0.002598  val_loss_rpn_loc: 0.03065    time: 1.6666  last_time: 1.5284  data_time: 0.0082  last_data_time: 0.0094   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:54:20 d2.utils.events]: \u001b[0m eta: 6:52:10  iter: 4139  total_loss: 0.2575  loss_cls: 0.03811  loss_box_reg: 0.08977  loss_mask: 0.08163  loss_rpn_cls: 0.005072  loss_rpn_loc: 0.03937  total_val_loss: 0.2214  val_loss_cls: 0.02683  val_loss_box_reg: 0.06786  val_loss_mask: 0.08701  val_loss_rpn_cls: 0.002781  val_loss_rpn_loc: 0.03336    time: 1.6661  last_time: 1.5849  data_time: 0.0078  last_data_time: 0.0071   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:55:05 d2.utils.events]: \u001b[0m eta: 6:51:47  iter: 4159  total_loss: 0.2494  loss_cls: 0.03322  loss_box_reg: 0.09015  loss_mask: 0.0857  loss_rpn_cls: 0.005728  loss_rpn_loc: 0.04277  total_val_loss: 0.2403  val_loss_cls: 0.03466  val_loss_box_reg: 0.08715  val_loss_mask: 0.08389  val_loss_rpn_cls: 0.003047  val_loss_rpn_loc: 0.03673    time: 1.6657  last_time: 1.5223  data_time: 0.0076  last_data_time: 0.0071   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:55:49 d2.utils.events]: \u001b[0m eta: 6:51:23  iter: 4179  total_loss: 0.2527  loss_cls: 0.03604  loss_box_reg: 0.09566  loss_mask: 0.08572  loss_rpn_cls: 0.006478  loss_rpn_loc: 0.04321  total_val_loss: 0.2448  val_loss_cls: 0.0337  val_loss_box_reg: 0.07634  val_loss_mask: 0.08673  val_loss_rpn_cls: 0.002862  val_loss_rpn_loc: 0.03693    time: 1.6652  last_time: 1.6006  data_time: 0.0080  last_data_time: 0.0063   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:56:35 d2.utils.events]: \u001b[0m eta: 6:51:25  iter: 4199  total_loss: 0.2734  loss_cls: 0.0424  loss_box_reg: 0.08856  loss_mask: 0.09001  loss_rpn_cls: 0.005345  loss_rpn_loc: 0.04341  total_val_loss: 0.2226  val_loss_cls: 0.0315  val_loss_box_reg: 0.06898  val_loss_mask: 0.08437  val_loss_rpn_cls: 0.00347  val_loss_rpn_loc: 0.03231    time: 1.6648  last_time: 1.6095  data_time: 0.0083  last_data_time: 0.0095   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:57:19 d2.utils.events]: \u001b[0m eta: 6:51:01  iter: 4219  total_loss: 0.2632  loss_cls: 0.03636  loss_box_reg: 0.09089  loss_mask: 0.08434  loss_rpn_cls: 0.005252  loss_rpn_loc: 0.0445  total_val_loss: 0.2121  val_loss_cls: 0.02871  val_loss_box_reg: 0.06772  val_loss_mask: 0.08204  val_loss_rpn_cls: 0.002758  val_loss_rpn_loc: 0.03269    time: 1.6642  last_time: 1.5452  data_time: 0.0079  last_data_time: 0.0094   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:58:03 d2.utils.events]: \u001b[0m eta: 6:50:23  iter: 4239  total_loss: 0.2787  loss_cls: 0.04159  loss_box_reg: 0.09654  loss_mask: 0.08889  loss_rpn_cls: 0.006786  loss_rpn_loc: 0.0459  total_val_loss: 0.2293  val_loss_cls: 0.02875  val_loss_box_reg: 0.07162  val_loss_mask: 0.07987  val_loss_rpn_cls: 0.003111  val_loss_rpn_loc: 0.03235    time: 1.6637  last_time: 1.5501  data_time: 0.0079  last_data_time: 0.0073   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:58:47 d2.utils.events]: \u001b[0m eta: 6:49:59  iter: 4259  total_loss: 0.2636  loss_cls: 0.03571  loss_box_reg: 0.09588  loss_mask: 0.08591  loss_rpn_cls: 0.00519  loss_rpn_loc: 0.04351  total_val_loss: 0.2329  val_loss_cls: 0.03127  val_loss_box_reg: 0.07675  val_loss_mask: 0.08689  val_loss_rpn_cls: 0.002619  val_loss_rpn_loc: 0.03271    time: 1.6631  last_time: 1.5520  data_time: 0.0081  last_data_time: 0.0094   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 16:59:32 d2.utils.events]: \u001b[0m eta: 6:49:27  iter: 4279  total_loss: 0.261  loss_cls: 0.0365  loss_box_reg: 0.09521  loss_mask: 0.0867  loss_rpn_cls: 0.004872  loss_rpn_loc: 0.04082  total_val_loss: 0.2247  val_loss_cls: 0.02712  val_loss_box_reg: 0.07443  val_loss_mask: 0.08515  val_loss_rpn_cls: 0.003044  val_loss_rpn_loc: 0.0343    time: 1.6626  last_time: 1.6785  data_time: 0.0083  last_data_time: 0.0072   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:00:17 d2.utils.events]: \u001b[0m eta: 6:49:42  iter: 4299  total_loss: 0.3093  loss_cls: 0.04398  loss_box_reg: 0.1033  loss_mask: 0.08689  loss_rpn_cls: 0.005879  loss_rpn_loc: 0.05473  total_val_loss: 0.2262  val_loss_cls: 0.03228  val_loss_box_reg: 0.0684  val_loss_mask: 0.08368  val_loss_rpn_cls: 0.003142  val_loss_rpn_loc: 0.03176    time: 1.6623  last_time: 1.5208  data_time: 0.0090  last_data_time: 0.0094   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:01:02 d2.utils.events]: \u001b[0m eta: 6:49:12  iter: 4319  total_loss: 0.2533  loss_cls: 0.03924  loss_box_reg: 0.08712  loss_mask: 0.08591  loss_rpn_cls: 0.004435  loss_rpn_loc: 0.04141  total_val_loss: 0.2251  val_loss_cls: 0.03377  val_loss_box_reg: 0.06991  val_loss_mask: 0.08659  val_loss_rpn_cls: 0.003326  val_loss_rpn_loc: 0.03702    time: 1.6618  last_time: 1.6937  data_time: 0.0081  last_data_time: 0.0102   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:01:46 d2.utils.events]: \u001b[0m eta: 6:48:47  iter: 4339  total_loss: 0.2601  loss_cls: 0.04072  loss_box_reg: 0.09253  loss_mask: 0.08136  loss_rpn_cls: 0.004397  loss_rpn_loc: 0.04541  total_val_loss: 0.2105  val_loss_cls: 0.02896  val_loss_box_reg: 0.06921  val_loss_mask: 0.08256  val_loss_rpn_cls: 0.003756  val_loss_rpn_loc: 0.03142    time: 1.6614  last_time: 1.5622  data_time: 0.0080  last_data_time: 0.0066   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:02:31 d2.utils.events]: \u001b[0m eta: 6:48:44  iter: 4359  total_loss: 0.2586  loss_cls: 0.0375  loss_box_reg: 0.08935  loss_mask: 0.08359  loss_rpn_cls: 0.004091  loss_rpn_loc: 0.04062  total_val_loss: 0.239  val_loss_cls: 0.03496  val_loss_box_reg: 0.07732  val_loss_mask: 0.08313  val_loss_rpn_cls: 0.00325  val_loss_rpn_loc: 0.03569    time: 1.6609  last_time: 1.4639  data_time: 0.0077  last_data_time: 0.0074   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:03:16 d2.utils.events]: \u001b[0m eta: 6:48:31  iter: 4379  total_loss: 0.2828  loss_cls: 0.04252  loss_box_reg: 0.09143  loss_mask: 0.08747  loss_rpn_cls: 0.005222  loss_rpn_loc: 0.04406  total_val_loss: 0.2458  val_loss_cls: 0.03407  val_loss_box_reg: 0.08026  val_loss_mask: 0.08539  val_loss_rpn_cls: 0.003934  val_loss_rpn_loc: 0.03487    time: 1.6605  last_time: 1.7265  data_time: 0.0083  last_data_time: 0.0099   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:04:00 d2.utils.events]: \u001b[0m eta: 6:48:05  iter: 4399  total_loss: 0.2781  loss_cls: 0.04249  loss_box_reg: 0.1  loss_mask: 0.07546  loss_rpn_cls: 0.004439  loss_rpn_loc: 0.04656  total_val_loss: 0.2325  val_loss_cls: 0.03167  val_loss_box_reg: 0.074  val_loss_mask: 0.08594  val_loss_rpn_cls: 0.003032  val_loss_rpn_loc: 0.03404    time: 1.6600  last_time: 1.4099  data_time: 0.0077  last_data_time: 0.0068   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:04:46 d2.utils.events]: \u001b[0m eta: 6:47:43  iter: 4419  total_loss: 0.2883  loss_cls: 0.04155  loss_box_reg: 0.1052  loss_mask: 0.08743  loss_rpn_cls: 0.007145  loss_rpn_loc: 0.04541  total_val_loss: 0.2406  val_loss_cls: 0.03364  val_loss_box_reg: 0.07914  val_loss_mask: 0.08297  val_loss_rpn_cls: 0.003458  val_loss_rpn_loc: 0.03684    time: 1.6597  last_time: 1.6123  data_time: 0.0083  last_data_time: 0.0091   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:05:31 d2.utils.events]: \u001b[0m eta: 6:47:13  iter: 4439  total_loss: 0.2482  loss_cls: 0.03361  loss_box_reg: 0.08576  loss_mask: 0.08665  loss_rpn_cls: 0.005349  loss_rpn_loc: 0.0407  total_val_loss: 0.2434  val_loss_cls: 0.03078  val_loss_box_reg: 0.07512  val_loss_mask: 0.08593  val_loss_rpn_cls: 0.002938  val_loss_rpn_loc: 0.03085    time: 1.6594  last_time: 1.6022  data_time: 0.0081  last_data_time: 0.0087   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:06:15 d2.utils.events]: \u001b[0m eta: 6:46:44  iter: 4459  total_loss: 0.2713  loss_cls: 0.03824  loss_box_reg: 0.09445  loss_mask: 0.07818  loss_rpn_cls: 0.003509  loss_rpn_loc: 0.04359  total_val_loss: 0.2143  val_loss_cls: 0.02993  val_loss_box_reg: 0.07595  val_loss_mask: 0.08733  val_loss_rpn_cls: 0.002668  val_loss_rpn_loc: 0.03173    time: 1.6589  last_time: 1.6195  data_time: 0.0078  last_data_time: 0.0085   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:07:00 d2.utils.events]: \u001b[0m eta: 6:46:27  iter: 4479  total_loss: 0.2649  loss_cls: 0.03716  loss_box_reg: 0.0962  loss_mask: 0.0817  loss_rpn_cls: 0.005243  loss_rpn_loc: 0.04563  total_val_loss: 0.2408  val_loss_cls: 0.03551  val_loss_box_reg: 0.07831  val_loss_mask: 0.08582  val_loss_rpn_cls: 0.00261  val_loss_rpn_loc: 0.03551    time: 1.6585  last_time: 1.6151  data_time: 0.0086  last_data_time: 0.0068   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:07:45 d2.utils.events]: \u001b[0m eta: 6:45:41  iter: 4499  total_loss: 0.3086  loss_cls: 0.04751  loss_box_reg: 0.1071  loss_mask: 0.08629  loss_rpn_cls: 0.008911  loss_rpn_loc: 0.05034  total_val_loss: 0.2394  val_loss_cls: 0.03504  val_loss_box_reg: 0.07758  val_loss_mask: 0.08432  val_loss_rpn_cls: 0.003315  val_loss_rpn_loc: 0.03396    time: 1.6581  last_time: 1.5351  data_time: 0.0083  last_data_time: 0.0088   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:08:29 d2.utils.events]: \u001b[0m eta: 6:45:09  iter: 4519  total_loss: 0.2606  loss_cls: 0.03393  loss_box_reg: 0.095  loss_mask: 0.08396  loss_rpn_cls: 0.005938  loss_rpn_loc: 0.04133  total_val_loss: 0.2306  val_loss_cls: 0.03297  val_loss_box_reg: 0.07619  val_loss_mask: 0.08243  val_loss_rpn_cls: 0.002532  val_loss_rpn_loc: 0.03412    time: 1.6576  last_time: 1.5112  data_time: 0.0082  last_data_time: 0.0077   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:09:12 d2.utils.events]: \u001b[0m eta: 6:44:36  iter: 4539  total_loss: 0.2697  loss_cls: 0.03601  loss_box_reg: 0.08943  loss_mask: 0.0787  loss_rpn_cls: 0.005645  loss_rpn_loc: 0.04335  total_val_loss: 0.2467  val_loss_cls: 0.03577  val_loss_box_reg: 0.08114  val_loss_mask: 0.09269  val_loss_rpn_cls: 0.002917  val_loss_rpn_loc: 0.03415    time: 1.6570  last_time: 1.5795  data_time: 0.0076  last_data_time: 0.0073   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:09:57 d2.utils.events]: \u001b[0m eta: 6:44:23  iter: 4559  total_loss: 0.3204  loss_cls: 0.0395  loss_box_reg: 0.1108  loss_mask: 0.08629  loss_rpn_cls: 0.006338  loss_rpn_loc: 0.05315  total_val_loss: 0.2186  val_loss_cls: 0.02862  val_loss_box_reg: 0.06689  val_loss_mask: 0.083  val_loss_rpn_cls: 0.002412  val_loss_rpn_loc: 0.03679    time: 1.6566  last_time: 1.6124  data_time: 0.0082  last_data_time: 0.0072   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:10:41 d2.utils.events]: \u001b[0m eta: 6:44:04  iter: 4579  total_loss: 0.2785  loss_cls: 0.03925  loss_box_reg: 0.09316  loss_mask: 0.08778  loss_rpn_cls: 0.006939  loss_rpn_loc: 0.04186  total_val_loss: 0.2554  val_loss_cls: 0.03632  val_loss_box_reg: 0.08833  val_loss_mask: 0.08197  val_loss_rpn_cls: 0.003129  val_loss_rpn_loc: 0.03743    time: 1.6562  last_time: 1.6320  data_time: 0.0072  last_data_time: 0.0085   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:11:26 d2.utils.events]: \u001b[0m eta: 6:43:43  iter: 4599  total_loss: 0.272  loss_cls: 0.03519  loss_box_reg: 0.09597  loss_mask: 0.08393  loss_rpn_cls: 0.005728  loss_rpn_loc: 0.04418  total_val_loss: 0.236  val_loss_cls: 0.03361  val_loss_box_reg: 0.07561  val_loss_mask: 0.0836  val_loss_rpn_cls: 0.003525  val_loss_rpn_loc: 0.03664    time: 1.6558  last_time: 1.6813  data_time: 0.0081  last_data_time: 0.0090   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:12:14 d2.utils.events]: \u001b[0m eta: 6:43:39  iter: 4619  total_loss: 0.2714  loss_cls: 0.03519  loss_box_reg: 0.09655  loss_mask: 0.086  loss_rpn_cls: 0.004174  loss_rpn_loc: 0.04012  total_val_loss: 0.2265  val_loss_cls: 0.03077  val_loss_box_reg: 0.07086  val_loss_mask: 0.08635  val_loss_rpn_cls: 0.002609  val_loss_rpn_loc: 0.03216    time: 1.6558  last_time: 1.7584  data_time: 0.0148  last_data_time: 0.0117   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:13:01 d2.utils.events]: \u001b[0m eta: 6:43:50  iter: 4639  total_loss: 0.2775  loss_cls: 0.04027  loss_box_reg: 0.09497  loss_mask: 0.08393  loss_rpn_cls: 0.005269  loss_rpn_loc: 0.04835  total_val_loss: 0.2275  val_loss_cls: 0.03019  val_loss_box_reg: 0.07165  val_loss_mask: 0.08691  val_loss_rpn_cls: 0.003244  val_loss_rpn_loc: 0.03766    time: 1.6557  last_time: 1.6638  data_time: 0.0144  last_data_time: 0.0138   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:13:49 d2.utils.events]: \u001b[0m eta: 6:43:29  iter: 4659  total_loss: 0.2434  loss_cls: 0.03303  loss_box_reg: 0.08688  loss_mask: 0.082  loss_rpn_cls: 0.004859  loss_rpn_loc: 0.04547  total_val_loss: 0.2273  val_loss_cls: 0.02974  val_loss_box_reg: 0.0747  val_loss_mask: 0.08595  val_loss_rpn_cls: 0.003234  val_loss_rpn_loc: 0.03552    time: 1.6555  last_time: 1.5747  data_time: 0.0133  last_data_time: 0.0112   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:14:37 d2.utils.events]: \u001b[0m eta: 6:43:41  iter: 4679  total_loss: 0.2769  loss_cls: 0.04144  loss_box_reg: 0.09962  loss_mask: 0.08516  loss_rpn_cls: 0.005106  loss_rpn_loc: 0.04403  total_val_loss: 0.243  val_loss_cls: 0.03605  val_loss_box_reg: 0.08607  val_loss_mask: 0.08484  val_loss_rpn_cls: 0.003699  val_loss_rpn_loc: 0.03799    time: 1.6555  last_time: 1.7209  data_time: 0.0133  last_data_time: 0.0099   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:15:24 d2.utils.events]: \u001b[0m eta: 6:43:35  iter: 4699  total_loss: 0.2841  loss_cls: 0.04357  loss_box_reg: 0.1085  loss_mask: 0.08335  loss_rpn_cls: 0.004602  loss_rpn_loc: 0.04395  total_val_loss: 0.2271  val_loss_cls: 0.03418  val_loss_box_reg: 0.07467  val_loss_mask: 0.08979  val_loss_rpn_cls: 0.003425  val_loss_rpn_loc: 0.03526    time: 1.6555  last_time: 1.6445  data_time: 0.0130  last_data_time: 0.0119   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:16:13 d2.utils.events]: \u001b[0m eta: 6:43:50  iter: 4719  total_loss: 0.2566  loss_cls: 0.03449  loss_box_reg: 0.08111  loss_mask: 0.08441  loss_rpn_cls: 0.005285  loss_rpn_loc: 0.03902  total_val_loss: 0.2393  val_loss_cls: 0.03326  val_loss_box_reg: 0.07952  val_loss_mask: 0.08784  val_loss_rpn_cls: 0.00333  val_loss_rpn_loc: 0.03388    time: 1.6555  last_time: 1.6189  data_time: 0.0136  last_data_time: 0.0118   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:17:00 d2.utils.events]: \u001b[0m eta: 6:43:44  iter: 4739  total_loss: 0.2184  loss_cls: 0.03066  loss_box_reg: 0.07354  loss_mask: 0.0836  loss_rpn_cls: 0.004188  loss_rpn_loc: 0.03377  total_val_loss: 0.2167  val_loss_cls: 0.03133  val_loss_box_reg: 0.06818  val_loss_mask: 0.08272  val_loss_rpn_cls: 0.003154  val_loss_rpn_loc: 0.03019    time: 1.6554  last_time: 1.4296  data_time: 0.0134  last_data_time: 0.0135   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:17:48 d2.utils.events]: \u001b[0m eta: 6:43:56  iter: 4759  total_loss: 0.2571  loss_cls: 0.03643  loss_box_reg: 0.08944  loss_mask: 0.08931  loss_rpn_cls: 0.003882  loss_rpn_loc: 0.03629  total_val_loss: 0.2253  val_loss_cls: 0.03193  val_loss_box_reg: 0.07214  val_loss_mask: 0.08622  val_loss_rpn_cls: 0.003388  val_loss_rpn_loc: 0.0313    time: 1.6554  last_time: 1.6208  data_time: 0.0142  last_data_time: 0.0158   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:18:36 d2.utils.events]: \u001b[0m eta: 6:43:35  iter: 4779  total_loss: 0.2538  loss_cls: 0.03402  loss_box_reg: 0.08939  loss_mask: 0.08037  loss_rpn_cls: 0.005957  loss_rpn_loc: 0.04347  total_val_loss: 0.2309  val_loss_cls: 0.03365  val_loss_box_reg: 0.07443  val_loss_mask: 0.08222  val_loss_rpn_cls: 0.003355  val_loss_rpn_loc: 0.03366    time: 1.6553  last_time: 1.5430  data_time: 0.0141  last_data_time: 0.0147   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:19:23 d2.utils.events]: \u001b[0m eta: 6:44:26  iter: 4799  total_loss: 0.2615  loss_cls: 0.03627  loss_box_reg: 0.09464  loss_mask: 0.08821  loss_rpn_cls: 0.00429  loss_rpn_loc: 0.03974  total_val_loss: 0.224  val_loss_cls: 0.03228  val_loss_box_reg: 0.07483  val_loss_mask: 0.08657  val_loss_rpn_cls: 0.003111  val_loss_rpn_loc: 0.03198    time: 1.6551  last_time: 1.6140  data_time: 0.0162  last_data_time: 0.0153   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:20:11 d2.utils.events]: \u001b[0m eta: 6:44:40  iter: 4819  total_loss: 0.2429  loss_cls: 0.03435  loss_box_reg: 0.08299  loss_mask: 0.08235  loss_rpn_cls: 0.004308  loss_rpn_loc: 0.0405  total_val_loss: 0.2155  val_loss_cls: 0.02809  val_loss_box_reg: 0.06892  val_loss_mask: 0.08746  val_loss_rpn_cls: 0.002348  val_loss_rpn_loc: 0.02927    time: 1.6550  last_time: 1.7515  data_time: 0.0137  last_data_time: 0.0101   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:20:58 d2.utils.events]: \u001b[0m eta: 6:44:22  iter: 4839  total_loss: 0.2666  loss_cls: 0.03731  loss_box_reg: 0.09965  loss_mask: 0.08283  loss_rpn_cls: 0.004797  loss_rpn_loc: 0.04356  total_val_loss: 0.2275  val_loss_cls: 0.03351  val_loss_box_reg: 0.07908  val_loss_mask: 0.0874  val_loss_rpn_cls: 0.00263  val_loss_rpn_loc: 0.03156    time: 1.6550  last_time: 1.6011  data_time: 0.0149  last_data_time: 0.0106   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:21:46 d2.utils.events]: \u001b[0m eta: 6:43:37  iter: 4859  total_loss: 0.2608  loss_cls: 0.03784  loss_box_reg: 0.087  loss_mask: 0.07909  loss_rpn_cls: 0.004899  loss_rpn_loc: 0.0452  total_val_loss: 0.2436  val_loss_cls: 0.03438  val_loss_box_reg: 0.08014  val_loss_mask: 0.08579  val_loss_rpn_cls: 0.003189  val_loss_rpn_loc: 0.03984    time: 1.6551  last_time: 1.6194  data_time: 0.0138  last_data_time: 0.0196   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:22:35 d2.utils.events]: \u001b[0m eta: 6:42:47  iter: 4879  total_loss: 0.2701  loss_cls: 0.0432  loss_box_reg: 0.09627  loss_mask: 0.08278  loss_rpn_cls: 0.004869  loss_rpn_loc: 0.04609  total_val_loss: 0.244  val_loss_cls: 0.03574  val_loss_box_reg: 0.07872  val_loss_mask: 0.08745  val_loss_rpn_cls: 0.003199  val_loss_rpn_loc: 0.04056    time: 1.6551  last_time: 1.7306  data_time: 0.0141  last_data_time: 0.0133   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:23:23 d2.utils.events]: \u001b[0m eta: 6:42:00  iter: 4899  total_loss: 0.2574  loss_cls: 0.03798  loss_box_reg: 0.0871  loss_mask: 0.07826  loss_rpn_cls: 0.00416  loss_rpn_loc: 0.04263  total_val_loss: 0.2452  val_loss_cls: 0.03361  val_loss_box_reg: 0.07335  val_loss_mask: 0.09098  val_loss_rpn_cls: 0.002778  val_loss_rpn_loc: 0.03362    time: 1.6551  last_time: 1.6441  data_time: 0.0133  last_data_time: 0.0175   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:24:11 d2.utils.events]: \u001b[0m eta: 6:41:15  iter: 4919  total_loss: 0.2822  loss_cls: 0.04115  loss_box_reg: 0.1002  loss_mask: 0.08593  loss_rpn_cls: 0.0047  loss_rpn_loc: 0.04434  total_val_loss: 0.2509  val_loss_cls: 0.03397  val_loss_box_reg: 0.085  val_loss_mask: 0.08555  val_loss_rpn_cls: 0.002572  val_loss_rpn_loc: 0.03523    time: 1.6551  last_time: 1.6131  data_time: 0.0138  last_data_time: 0.0161   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:24:59 d2.utils.events]: \u001b[0m eta: 6:39:41  iter: 4939  total_loss: 0.2437  loss_cls: 0.03575  loss_box_reg: 0.08372  loss_mask: 0.07893  loss_rpn_cls: 0.004346  loss_rpn_loc: 0.04217  total_val_loss: 0.2125  val_loss_cls: 0.02786  val_loss_box_reg: 0.06843  val_loss_mask: 0.08133  val_loss_rpn_cls: 0.00326  val_loss_rpn_loc: 0.02937    time: 1.6550  last_time: 1.5586  data_time: 0.0128  last_data_time: 0.0165   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:25:46 d2.utils.events]: \u001b[0m eta: 6:39:12  iter: 4959  total_loss: 0.2667  loss_cls: 0.03855  loss_box_reg: 0.08905  loss_mask: 0.08466  loss_rpn_cls: 0.005636  loss_rpn_loc: 0.04158  total_val_loss: 0.2284  val_loss_cls: 0.03162  val_loss_box_reg: 0.07206  val_loss_mask: 0.08748  val_loss_rpn_cls: 0.003165  val_loss_rpn_loc: 0.03361    time: 1.6550  last_time: 1.5178  data_time: 0.0131  last_data_time: 0.0105   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:26:33 d2.utils.events]: \u001b[0m eta: 6:38:15  iter: 4979  total_loss: 0.2712  loss_cls: 0.03942  loss_box_reg: 0.09556  loss_mask: 0.09191  loss_rpn_cls: 0.003392  loss_rpn_loc: 0.04044  total_val_loss: 0.238  val_loss_cls: 0.03202  val_loss_box_reg: 0.08018  val_loss_mask: 0.08719  val_loss_rpn_cls: 0.002664  val_loss_rpn_loc: 0.03768    time: 1.6547  last_time: 1.6770  data_time: 0.0127  last_data_time: 0.0122   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:27:24 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\testing_images\\0_SideLane_addedversion_Testing_COCO.json\n",
      "\u001b[32m[09/26 17:27:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/26 17:27:24 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/26 17:27:24 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/26 17:27:24 d2.data.common]: \u001b[0mSerialized dataset takes 6.03 MiB\n",
      "\u001b[32m[09/26 17:27:24 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[09/26 17:27:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 566 batches\n",
      "\u001b[32m[09/26 17:27:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/566. Dataloading: 0.0006 s/iter. Inference: 0.0789 s/iter. Eval: 0.0123 s/iter. Total: 0.0917 s/iter. ETA=0:00:50\n",
      "\u001b[32m[09/26 17:27:33 d2.evaluation.evaluator]: \u001b[0mInference done 70/566. Dataloading: 0.0009 s/iter. Inference: 0.0785 s/iter. Eval: 0.0059 s/iter. Total: 0.0854 s/iter. ETA=0:00:42\n",
      "\u001b[32m[09/26 17:27:38 d2.evaluation.evaluator]: \u001b[0mInference done 129/566. Dataloading: 0.0009 s/iter. Inference: 0.0777 s/iter. Eval: 0.0067 s/iter. Total: 0.0853 s/iter. ETA=0:00:37\n",
      "\u001b[32m[09/26 17:27:43 d2.evaluation.evaluator]: \u001b[0mInference done 188/566. Dataloading: 0.0009 s/iter. Inference: 0.0775 s/iter. Eval: 0.0070 s/iter. Total: 0.0854 s/iter. ETA=0:00:32\n",
      "\u001b[32m[09/26 17:27:48 d2.evaluation.evaluator]: \u001b[0mInference done 246/566. Dataloading: 0.0009 s/iter. Inference: 0.0781 s/iter. Eval: 0.0067 s/iter. Total: 0.0858 s/iter. ETA=0:00:27\n",
      "\u001b[32m[09/26 17:27:53 d2.evaluation.evaluator]: \u001b[0mInference done 306/566. Dataloading: 0.0009 s/iter. Inference: 0.0781 s/iter. Eval: 0.0064 s/iter. Total: 0.0854 s/iter. ETA=0:00:22\n",
      "\u001b[32m[09/26 17:27:58 d2.evaluation.evaluator]: \u001b[0mInference done 368/566. Dataloading: 0.0009 s/iter. Inference: 0.0780 s/iter. Eval: 0.0058 s/iter. Total: 0.0848 s/iter. ETA=0:00:16\n",
      "\u001b[32m[09/26 17:28:03 d2.evaluation.evaluator]: \u001b[0mInference done 430/566. Dataloading: 0.0009 s/iter. Inference: 0.0780 s/iter. Eval: 0.0054 s/iter. Total: 0.0844 s/iter. ETA=0:00:11\n",
      "\u001b[32m[09/26 17:28:08 d2.evaluation.evaluator]: \u001b[0mInference done 484/566. Dataloading: 0.0009 s/iter. Inference: 0.0782 s/iter. Eval: 0.0061 s/iter. Total: 0.0854 s/iter. ETA=0:00:06\n",
      "\u001b[32m[09/26 17:28:13 d2.evaluation.evaluator]: \u001b[0mInference done 540/566. Dataloading: 0.0009 s/iter. Inference: 0.0789 s/iter. Eval: 0.0061 s/iter. Total: 0.0859 s/iter. ETA=0:00:02\n",
      "\u001b[32m[09/26 17:28:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.864275 (0.087102 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 17:28:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:44 (0.079009 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 17:28:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/26 17:28:16 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\coco_instances_results.json\n",
      "\u001b[32m[09/26 17:28:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.47s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.920\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.920\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.921\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.193\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.927\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.941\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.932\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.947\n",
      "\u001b[32m[09/26 17:28:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 92.021 | 99.006 | 98.968 |  nan  | 91.954 | 92.115 |\n",
      "\u001b[32m[09/26 17:28:17 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 17:28:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 92.021 | background | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.64s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.851\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.979\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.820\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.873\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.181\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.873\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.887\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.857\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.906\n",
      "\u001b[32m[09/26 17:28:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 85.137 | 99.006 | 97.925 |  nan  | 81.972 | 87.253 |\n",
      "\u001b[32m[09/26 17:28:17 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 17:28:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 85.137 | background | nan  |\n",
      "\u001b[32m[09/26 17:28:17 d2.engine.defaults]: \u001b[0mEvaluation results for test_data in csv format:\n",
      "\u001b[32m[09/26 17:28:17 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/26 17:28:17 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 17:28:17 d2.evaluation.testing]: \u001b[0mcopypaste: 92.0209,99.0062,98.9682,nan,91.9536,92.1148\n",
      "\u001b[32m[09/26 17:28:17 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/26 17:28:17 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 17:28:17 d2.evaluation.testing]: \u001b[0mcopypaste: 85.1374,99.0062,97.9252,nan,81.9721,87.2526\n",
      "\u001b[32m[09/26 17:28:18 d2.utils.events]: \u001b[0m eta: 6:37:49  iter: 4999  total_loss: 0.2666  loss_cls: 0.03262  loss_box_reg: 0.09075  loss_mask: 0.08143  loss_rpn_cls: 0.005734  loss_rpn_loc: 0.03905  total_val_loss: 0.2319  val_loss_cls: 0.03302  val_loss_box_reg: 0.07444  val_loss_mask: 0.08236  val_loss_rpn_cls: 0.003313  val_loss_rpn_loc: 0.03257    time: 1.6547  last_time: 1.5510  data_time: 0.0133  last_data_time: 0.0090   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:29:06 d2.utils.events]: \u001b[0m eta: 6:38:19  iter: 5019  total_loss: 0.2633  loss_cls: 0.03736  loss_box_reg: 0.09076  loss_mask: 0.08369  loss_rpn_cls: 0.004409  loss_rpn_loc: 0.03989  total_val_loss: 0.2437  val_loss_cls: 0.03409  val_loss_box_reg: 0.08165  val_loss_mask: 0.09115  val_loss_rpn_cls: 0.003056  val_loss_rpn_loc: 0.03473    time: 1.6547  last_time: 1.6537  data_time: 0.0139  last_data_time: 0.0133   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:29:54 d2.utils.events]: \u001b[0m eta: 6:38:16  iter: 5039  total_loss: 0.2494  loss_cls: 0.03374  loss_box_reg: 0.08617  loss_mask: 0.08355  loss_rpn_cls: 0.004105  loss_rpn_loc: 0.03947  total_val_loss: 0.2431  val_loss_cls: 0.03195  val_loss_box_reg: 0.07687  val_loss_mask: 0.08723  val_loss_rpn_cls: 0.003035  val_loss_rpn_loc: 0.03667    time: 1.6546  last_time: 1.7836  data_time: 0.0129  last_data_time: 0.0149   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:30:41 d2.utils.events]: \u001b[0m eta: 6:38:17  iter: 5059  total_loss: 0.2744  loss_cls: 0.03884  loss_box_reg: 0.09005  loss_mask: 0.08643  loss_rpn_cls: 0.004848  loss_rpn_loc: 0.04393  total_val_loss: 0.2194  val_loss_cls: 0.02741  val_loss_box_reg: 0.0739  val_loss_mask: 0.08303  val_loss_rpn_cls: 0.002589  val_loss_rpn_loc: 0.03194    time: 1.6545  last_time: 1.7005  data_time: 0.0122  last_data_time: 0.0132   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:31:29 d2.utils.events]: \u001b[0m eta: 6:38:01  iter: 5079  total_loss: 0.2802  loss_cls: 0.04085  loss_box_reg: 0.09236  loss_mask: 0.08306  loss_rpn_cls: 0.004999  loss_rpn_loc: 0.04239  total_val_loss: 0.2467  val_loss_cls: 0.03426  val_loss_box_reg: 0.07819  val_loss_mask: 0.08479  val_loss_rpn_cls: 0.004324  val_loss_rpn_loc: 0.0361    time: 1.6544  last_time: 1.5791  data_time: 0.0131  last_data_time: 0.0107   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:32:16 d2.utils.events]: \u001b[0m eta: 6:37:42  iter: 5099  total_loss: 0.2554  loss_cls: 0.0379  loss_box_reg: 0.09138  loss_mask: 0.08885  loss_rpn_cls: 0.003907  loss_rpn_loc: 0.037  total_val_loss: 0.2311  val_loss_cls: 0.03137  val_loss_box_reg: 0.07432  val_loss_mask: 0.08356  val_loss_rpn_cls: 0.00336  val_loss_rpn_loc: 0.03123    time: 1.6544  last_time: 1.6084  data_time: 0.0134  last_data_time: 0.0151   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:33:04 d2.utils.events]: \u001b[0m eta: 6:37:23  iter: 5119  total_loss: 0.2962  loss_cls: 0.04438  loss_box_reg: 0.1031  loss_mask: 0.09265  loss_rpn_cls: 0.005399  loss_rpn_loc: 0.04122  total_val_loss: 0.2238  val_loss_cls: 0.03189  val_loss_box_reg: 0.074  val_loss_mask: 0.08308  val_loss_rpn_cls: 0.002568  val_loss_rpn_loc: 0.03256    time: 1.6543  last_time: 1.6243  data_time: 0.0135  last_data_time: 0.0135   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:33:51 d2.utils.events]: \u001b[0m eta: 6:37:26  iter: 5139  total_loss: 0.28  loss_cls: 0.04156  loss_box_reg: 0.09475  loss_mask: 0.09109  loss_rpn_cls: 0.006108  loss_rpn_loc: 0.04405  total_val_loss: 0.2081  val_loss_cls: 0.02843  val_loss_box_reg: 0.06625  val_loss_mask: 0.08078  val_loss_rpn_cls: 0.002528  val_loss_rpn_loc: 0.03169    time: 1.6542  last_time: 1.6149  data_time: 0.0139  last_data_time: 0.0141   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:34:39 d2.utils.events]: \u001b[0m eta: 6:37:13  iter: 5159  total_loss: 0.2508  loss_cls: 0.03394  loss_box_reg: 0.07911  loss_mask: 0.08202  loss_rpn_cls: 0.003649  loss_rpn_loc: 0.03969  total_val_loss: 0.2339  val_loss_cls: 0.0344  val_loss_box_reg: 0.0787  val_loss_mask: 0.08293  val_loss_rpn_cls: 0.002906  val_loss_rpn_loc: 0.03239    time: 1.6542  last_time: 1.6985  data_time: 0.0138  last_data_time: 0.0120   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:35:28 d2.utils.events]: \u001b[0m eta: 6:37:22  iter: 5179  total_loss: 0.2645  loss_cls: 0.03774  loss_box_reg: 0.09445  loss_mask: 0.08657  loss_rpn_cls: 0.004494  loss_rpn_loc: 0.04315  total_val_loss: 0.2238  val_loss_cls: 0.03185  val_loss_box_reg: 0.07432  val_loss_mask: 0.0788  val_loss_rpn_cls: 0.002295  val_loss_rpn_loc: 0.03405    time: 1.6542  last_time: 1.6821  data_time: 0.0130  last_data_time: 0.0128   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:36:15 d2.utils.events]: \u001b[0m eta: 6:36:49  iter: 5199  total_loss: 0.2966  loss_cls: 0.04101  loss_box_reg: 0.09953  loss_mask: 0.08917  loss_rpn_cls: 0.005351  loss_rpn_loc: 0.0473  total_val_loss: 0.2169  val_loss_cls: 0.02814  val_loss_box_reg: 0.06851  val_loss_mask: 0.08358  val_loss_rpn_cls: 0.002633  val_loss_rpn_loc: 0.03339    time: 1.6542  last_time: 1.5764  data_time: 0.0138  last_data_time: 0.0137   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:37:03 d2.utils.events]: \u001b[0m eta: 6:36:59  iter: 5219  total_loss: 0.2731  loss_cls: 0.03709  loss_box_reg: 0.09915  loss_mask: 0.08544  loss_rpn_cls: 0.005282  loss_rpn_loc: 0.04867  total_val_loss: 0.2383  val_loss_cls: 0.03294  val_loss_box_reg: 0.07554  val_loss_mask: 0.0876  val_loss_rpn_cls: 0.00319  val_loss_rpn_loc: 0.03332    time: 1.6541  last_time: 1.5923  data_time: 0.0138  last_data_time: 0.0136   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:37:51 d2.utils.events]: \u001b[0m eta: 6:37:05  iter: 5239  total_loss: 0.2683  loss_cls: 0.03935  loss_box_reg: 0.09468  loss_mask: 0.08335  loss_rpn_cls: 0.005906  loss_rpn_loc: 0.04637  total_val_loss: 0.2388  val_loss_cls: 0.0321  val_loss_box_reg: 0.07689  val_loss_mask: 0.09255  val_loss_rpn_cls: 0.002801  val_loss_rpn_loc: 0.03327    time: 1.6540  last_time: 1.6032  data_time: 0.0128  last_data_time: 0.0122   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:38:38 d2.utils.events]: \u001b[0m eta: 6:36:45  iter: 5259  total_loss: 0.2476  loss_cls: 0.03052  loss_box_reg: 0.08366  loss_mask: 0.08511  loss_rpn_cls: 0.00424  loss_rpn_loc: 0.03878  total_val_loss: 0.2157  val_loss_cls: 0.02873  val_loss_box_reg: 0.06726  val_loss_mask: 0.08067  val_loss_rpn_cls: 0.002224  val_loss_rpn_loc: 0.02821    time: 1.6539  last_time: 1.6611  data_time: 0.0134  last_data_time: 0.0153   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:39:26 d2.utils.events]: \u001b[0m eta: 6:36:41  iter: 5279  total_loss: 0.2601  loss_cls: 0.03756  loss_box_reg: 0.08714  loss_mask: 0.08247  loss_rpn_cls: 0.00471  loss_rpn_loc: 0.03967  total_val_loss: 0.2407  val_loss_cls: 0.03274  val_loss_box_reg: 0.08032  val_loss_mask: 0.09063  val_loss_rpn_cls: 0.002767  val_loss_rpn_loc: 0.03297    time: 1.6538  last_time: 1.5987  data_time: 0.0131  last_data_time: 0.0119   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:40:13 d2.utils.events]: \u001b[0m eta: 6:36:19  iter: 5299  total_loss: 0.2459  loss_cls: 0.03257  loss_box_reg: 0.08345  loss_mask: 0.08002  loss_rpn_cls: 0.004582  loss_rpn_loc: 0.04449  total_val_loss: 0.2352  val_loss_cls: 0.0345  val_loss_box_reg: 0.07547  val_loss_mask: 0.08315  val_loss_rpn_cls: 0.00277  val_loss_rpn_loc: 0.03318    time: 1.6538  last_time: 1.5477  data_time: 0.0129  last_data_time: 0.0143   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:41:01 d2.utils.events]: \u001b[0m eta: 6:36:11  iter: 5319  total_loss: 0.2565  loss_cls: 0.03691  loss_box_reg: 0.08583  loss_mask: 0.07958  loss_rpn_cls: 0.005712  loss_rpn_loc: 0.04868  total_val_loss: 0.2355  val_loss_cls: 0.03317  val_loss_box_reg: 0.07882  val_loss_mask: 0.08476  val_loss_rpn_cls: 0.002887  val_loss_rpn_loc: 0.03493    time: 1.6537  last_time: 1.6281  data_time: 0.0120  last_data_time: 0.0100   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:41:49 d2.utils.events]: \u001b[0m eta: 6:35:55  iter: 5339  total_loss: 0.2799  loss_cls: 0.04459  loss_box_reg: 0.1055  loss_mask: 0.07948  loss_rpn_cls: 0.007125  loss_rpn_loc: 0.04551  total_val_loss: 0.2106  val_loss_cls: 0.02938  val_loss_box_reg: 0.06734  val_loss_mask: 0.08109  val_loss_rpn_cls: 0.002687  val_loss_rpn_loc: 0.02948    time: 1.6536  last_time: 1.7046  data_time: 0.0145  last_data_time: 0.0133   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:42:34 d2.utils.events]: \u001b[0m eta: 6:35:43  iter: 5359  total_loss: 0.2656  loss_cls: 0.0378  loss_box_reg: 0.09861  loss_mask: 0.08082  loss_rpn_cls: 0.004805  loss_rpn_loc: 0.04539  total_val_loss: 0.2106  val_loss_cls: 0.0289  val_loss_box_reg: 0.07182  val_loss_mask: 0.07838  val_loss_rpn_cls: 0.002857  val_loss_rpn_loc: 0.03309    time: 1.6533  last_time: 1.5763  data_time: 0.0103  last_data_time: 0.0085   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:43:18 d2.utils.events]: \u001b[0m eta: 6:35:18  iter: 5379  total_loss: 0.2649  loss_cls: 0.03664  loss_box_reg: 0.09714  loss_mask: 0.08239  loss_rpn_cls: 0.004149  loss_rpn_loc: 0.04307  total_val_loss: 0.256  val_loss_cls: 0.03654  val_loss_box_reg: 0.08579  val_loss_mask: 0.09028  val_loss_rpn_cls: 0.003135  val_loss_rpn_loc: 0.03598    time: 1.6529  last_time: 1.5388  data_time: 0.0072  last_data_time: 0.0073   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:44:02 d2.utils.events]: \u001b[0m eta: 6:34:52  iter: 5399  total_loss: 0.2522  loss_cls: 0.03481  loss_box_reg: 0.08156  loss_mask: 0.08878  loss_rpn_cls: 0.004741  loss_rpn_loc: 0.04051  total_val_loss: 0.2414  val_loss_cls: 0.03471  val_loss_box_reg: 0.08078  val_loss_mask: 0.08929  val_loss_rpn_cls: 0.003096  val_loss_rpn_loc: 0.03539    time: 1.6525  last_time: 1.5296  data_time: 0.0079  last_data_time: 0.0063   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:44:47 d2.utils.events]: \u001b[0m eta: 6:34:13  iter: 5419  total_loss: 0.2701  loss_cls: 0.04182  loss_box_reg: 0.09798  loss_mask: 0.08508  loss_rpn_cls: 0.004246  loss_rpn_loc: 0.04143  total_val_loss: 0.2144  val_loss_cls: 0.0285  val_loss_box_reg: 0.0675  val_loss_mask: 0.08828  val_loss_rpn_cls: 0.003114  val_loss_rpn_loc: 0.03125    time: 1.6522  last_time: 1.5710  data_time: 0.0080  last_data_time: 0.0077   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:45:30 d2.utils.events]: \u001b[0m eta: 6:33:06  iter: 5439  total_loss: 0.2465  loss_cls: 0.03544  loss_box_reg: 0.08503  loss_mask: 0.08116  loss_rpn_cls: 0.004235  loss_rpn_loc: 0.04427  total_val_loss: 0.2254  val_loss_cls: 0.03102  val_loss_box_reg: 0.07236  val_loss_mask: 0.08395  val_loss_rpn_cls: 0.003245  val_loss_rpn_loc: 0.03372    time: 1.6518  last_time: 1.4702  data_time: 0.0072  last_data_time: 0.0071   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:46:14 d2.utils.events]: \u001b[0m eta: 6:32:24  iter: 5459  total_loss: 0.2558  loss_cls: 0.03425  loss_box_reg: 0.08585  loss_mask: 0.08251  loss_rpn_cls: 0.005209  loss_rpn_loc: 0.04157  total_val_loss: 0.2285  val_loss_cls: 0.03455  val_loss_box_reg: 0.07439  val_loss_mask: 0.0845  val_loss_rpn_cls: 0.003675  val_loss_rpn_loc: 0.03319    time: 1.6513  last_time: 1.5239  data_time: 0.0072  last_data_time: 0.0058   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:46:58 d2.utils.events]: \u001b[0m eta: 6:31:46  iter: 5479  total_loss: 0.2891  loss_cls: 0.03718  loss_box_reg: 0.09785  loss_mask: 0.08749  loss_rpn_cls: 0.004856  loss_rpn_loc: 0.04874  total_val_loss: 0.2256  val_loss_cls: 0.03089  val_loss_box_reg: 0.07177  val_loss_mask: 0.08366  val_loss_rpn_cls: 0.002493  val_loss_rpn_loc: 0.03409    time: 1.6509  last_time: 1.5472  data_time: 0.0073  last_data_time: 0.0073   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:47:43 d2.utils.events]: \u001b[0m eta: 6:31:19  iter: 5499  total_loss: 0.2712  loss_cls: 0.03575  loss_box_reg: 0.09444  loss_mask: 0.08403  loss_rpn_cls: 0.005874  loss_rpn_loc: 0.04483  total_val_loss: 0.2236  val_loss_cls: 0.02829  val_loss_box_reg: 0.07247  val_loss_mask: 0.08432  val_loss_rpn_cls: 0.00305  val_loss_rpn_loc: 0.03284    time: 1.6506  last_time: 1.6189  data_time: 0.0075  last_data_time: 0.0066   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:48:27 d2.utils.events]: \u001b[0m eta: 6:30:48  iter: 5519  total_loss: 0.2519  loss_cls: 0.03559  loss_box_reg: 0.08755  loss_mask: 0.07986  loss_rpn_cls: 0.005398  loss_rpn_loc: 0.03859  total_val_loss: 0.2238  val_loss_cls: 0.03337  val_loss_box_reg: 0.07274  val_loss_mask: 0.08643  val_loss_rpn_cls: 0.002077  val_loss_rpn_loc: 0.03112    time: 1.6503  last_time: 1.5773  data_time: 0.0074  last_data_time: 0.0082   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:49:12 d2.utils.events]: \u001b[0m eta: 6:30:17  iter: 5539  total_loss: 0.2623  loss_cls: 0.03806  loss_box_reg: 0.09683  loss_mask: 0.08462  loss_rpn_cls: 0.003843  loss_rpn_loc: 0.04105  total_val_loss: 0.2384  val_loss_cls: 0.03382  val_loss_box_reg: 0.07677  val_loss_mask: 0.08476  val_loss_rpn_cls: 0.003236  val_loss_rpn_loc: 0.03365    time: 1.6499  last_time: 1.5230  data_time: 0.0077  last_data_time: 0.0088   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:49:55 d2.utils.events]: \u001b[0m eta: 6:29:35  iter: 5559  total_loss: 0.2469  loss_cls: 0.03688  loss_box_reg: 0.08736  loss_mask: 0.08414  loss_rpn_cls: 0.004044  loss_rpn_loc: 0.03664  total_val_loss: 0.1992  val_loss_cls: 0.02791  val_loss_box_reg: 0.06165  val_loss_mask: 0.08324  val_loss_rpn_cls: 0.002195  val_loss_rpn_loc: 0.02751    time: 1.6494  last_time: 1.4608  data_time: 0.0071  last_data_time: 0.0071   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:50:37 d2.utils.events]: \u001b[0m eta: 6:28:50  iter: 5579  total_loss: 0.2724  loss_cls: 0.04201  loss_box_reg: 0.09716  loss_mask: 0.07981  loss_rpn_cls: 0.005863  loss_rpn_loc: 0.04664  total_val_loss: 0.2413  val_loss_cls: 0.03232  val_loss_box_reg: 0.07872  val_loss_mask: 0.08729  val_loss_rpn_cls: 0.002729  val_loss_rpn_loc: 0.03264    time: 1.6488  last_time: 1.5854  data_time: 0.0073  last_data_time: 0.0062   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:51:21 d2.utils.events]: \u001b[0m eta: 6:28:09  iter: 5599  total_loss: 0.2691  loss_cls: 0.03793  loss_box_reg: 0.09589  loss_mask: 0.09073  loss_rpn_cls: 0.005356  loss_rpn_loc: 0.04161  total_val_loss: 0.2291  val_loss_cls: 0.03032  val_loss_box_reg: 0.07327  val_loss_mask: 0.08661  val_loss_rpn_cls: 0.002515  val_loss_rpn_loc: 0.03322    time: 1.6484  last_time: 1.4589  data_time: 0.0072  last_data_time: 0.0068   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:52:04 d2.utils.events]: \u001b[0m eta: 6:27:07  iter: 5619  total_loss: 0.2772  loss_cls: 0.0412  loss_box_reg: 0.09472  loss_mask: 0.08191  loss_rpn_cls: 0.005636  loss_rpn_loc: 0.04511  total_val_loss: 0.2279  val_loss_cls: 0.03664  val_loss_box_reg: 0.07385  val_loss_mask: 0.08691  val_loss_rpn_cls: 0.003446  val_loss_rpn_loc: 0.03059    time: 1.6479  last_time: 1.4413  data_time: 0.0068  last_data_time: 0.0058   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:52:47 d2.utils.events]: \u001b[0m eta: 6:26:07  iter: 5639  total_loss: 0.2522  loss_cls: 0.03757  loss_box_reg: 0.0829  loss_mask: 0.08323  loss_rpn_cls: 0.004341  loss_rpn_loc: 0.04236  total_val_loss: 0.229  val_loss_cls: 0.03188  val_loss_box_reg: 0.07471  val_loss_mask: 0.08244  val_loss_rpn_cls: 0.003611  val_loss_rpn_loc: 0.03268    time: 1.6474  last_time: 1.4796  data_time: 0.0064  last_data_time: 0.0079   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:53:30 d2.utils.events]: \u001b[0m eta: 6:25:02  iter: 5659  total_loss: 0.2653  loss_cls: 0.03882  loss_box_reg: 0.09371  loss_mask: 0.08626  loss_rpn_cls: 0.003824  loss_rpn_loc: 0.04197  total_val_loss: 0.2215  val_loss_cls: 0.03225  val_loss_box_reg: 0.06836  val_loss_mask: 0.09068  val_loss_rpn_cls: 0.001989  val_loss_rpn_loc: 0.03026    time: 1.6469  last_time: 1.4887  data_time: 0.0069  last_data_time: 0.0074   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:54:13 d2.utils.events]: \u001b[0m eta: 6:23:46  iter: 5679  total_loss: 0.2611  loss_cls: 0.0374  loss_box_reg: 0.08528  loss_mask: 0.085  loss_rpn_cls: 0.004476  loss_rpn_loc: 0.04091  total_val_loss: 0.2253  val_loss_cls: 0.03359  val_loss_box_reg: 0.07134  val_loss_mask: 0.08249  val_loss_rpn_cls: 0.002253  val_loss_rpn_loc: 0.03397    time: 1.6465  last_time: 1.5692  data_time: 0.0071  last_data_time: 0.0064   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:54:56 d2.utils.events]: \u001b[0m eta: 6:22:26  iter: 5699  total_loss: 0.2383  loss_cls: 0.03175  loss_box_reg: 0.08281  loss_mask: 0.08029  loss_rpn_cls: 0.004069  loss_rpn_loc: 0.03602  total_val_loss: 0.2138  val_loss_cls: 0.03337  val_loss_box_reg: 0.0663  val_loss_mask: 0.08433  val_loss_rpn_cls: 0.002405  val_loss_rpn_loc: 0.03154    time: 1.6460  last_time: 1.4570  data_time: 0.0074  last_data_time: 0.0092   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:55:40 d2.utils.events]: \u001b[0m eta: 6:21:21  iter: 5719  total_loss: 0.2669  loss_cls: 0.03871  loss_box_reg: 0.08605  loss_mask: 0.08628  loss_rpn_cls: 0.004958  loss_rpn_loc: 0.04406  total_val_loss: 0.2353  val_loss_cls: 0.03116  val_loss_box_reg: 0.07178  val_loss_mask: 0.08824  val_loss_rpn_cls: 0.002858  val_loss_rpn_loc: 0.03656    time: 1.6456  last_time: 1.5433  data_time: 0.0081  last_data_time: 0.0071   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:56:25 d2.utils.events]: \u001b[0m eta: 6:20:34  iter: 5739  total_loss: 0.2518  loss_cls: 0.03479  loss_box_reg: 0.08642  loss_mask: 0.08848  loss_rpn_cls: 0.004299  loss_rpn_loc: 0.04528  total_val_loss: 0.2248  val_loss_cls: 0.03108  val_loss_box_reg: 0.07876  val_loss_mask: 0.08592  val_loss_rpn_cls: 0.002926  val_loss_rpn_loc: 0.03353    time: 1.6455  last_time: 1.6307  data_time: 0.0075  last_data_time: 0.0065   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:57:10 d2.utils.events]: \u001b[0m eta: 6:19:12  iter: 5759  total_loss: 0.2603  loss_cls: 0.03765  loss_box_reg: 0.0894  loss_mask: 0.08742  loss_rpn_cls: 0.004655  loss_rpn_loc: 0.04416  total_val_loss: 0.2208  val_loss_cls: 0.03317  val_loss_box_reg: 0.07397  val_loss_mask: 0.08768  val_loss_rpn_cls: 0.002632  val_loss_rpn_loc: 0.03233    time: 1.6452  last_time: 1.4709  data_time: 0.0081  last_data_time: 0.0082   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:57:54 d2.utils.events]: \u001b[0m eta: 6:18:12  iter: 5779  total_loss: 0.2592  loss_cls: 0.03935  loss_box_reg: 0.09119  loss_mask: 0.08395  loss_rpn_cls: 0.00384  loss_rpn_loc: 0.04062  total_val_loss: 0.2266  val_loss_cls: 0.0303  val_loss_box_reg: 0.06676  val_loss_mask: 0.08292  val_loss_rpn_cls: 0.002934  val_loss_rpn_loc: 0.02815    time: 1.6448  last_time: 1.5352  data_time: 0.0074  last_data_time: 0.0062   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:58:38 d2.utils.events]: \u001b[0m eta: 6:16:53  iter: 5799  total_loss: 0.2745  loss_cls: 0.04116  loss_box_reg: 0.1048  loss_mask: 0.07781  loss_rpn_cls: 0.003493  loss_rpn_loc: 0.04437  total_val_loss: 0.2345  val_loss_cls: 0.03408  val_loss_box_reg: 0.077  val_loss_mask: 0.08142  val_loss_rpn_cls: 0.002494  val_loss_rpn_loc: 0.03425    time: 1.6445  last_time: 1.6583  data_time: 0.0076  last_data_time: 0.0075   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 17:59:23 d2.utils.events]: \u001b[0m eta: 6:16:04  iter: 5819  total_loss: 0.2923  loss_cls: 0.04434  loss_box_reg: 0.1062  loss_mask: 0.0851  loss_rpn_cls: 0.005975  loss_rpn_loc: 0.04707  total_val_loss: 0.2281  val_loss_cls: 0.03139  val_loss_box_reg: 0.07698  val_loss_mask: 0.08341  val_loss_rpn_cls: 0.002471  val_loss_rpn_loc: 0.0343    time: 1.6442  last_time: 1.5168  data_time: 0.0079  last_data_time: 0.0071   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:00:07 d2.utils.events]: \u001b[0m eta: 6:14:48  iter: 5839  total_loss: 0.2367  loss_cls: 0.0339  loss_box_reg: 0.08113  loss_mask: 0.08335  loss_rpn_cls: 0.003122  loss_rpn_loc: 0.03649  total_val_loss: 0.2461  val_loss_cls: 0.03686  val_loss_box_reg: 0.08209  val_loss_mask: 0.08387  val_loss_rpn_cls: 0.002725  val_loss_rpn_loc: 0.0368    time: 1.6439  last_time: 1.5304  data_time: 0.0076  last_data_time: 0.0070   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:00:51 d2.utils.events]: \u001b[0m eta: 6:13:38  iter: 5859  total_loss: 0.2771  loss_cls: 0.04042  loss_box_reg: 0.1021  loss_mask: 0.08368  loss_rpn_cls: 0.003943  loss_rpn_loc: 0.04066  total_val_loss: 0.2401  val_loss_cls: 0.03418  val_loss_box_reg: 0.07524  val_loss_mask: 0.08974  val_loss_rpn_cls: 0.002146  val_loss_rpn_loc: 0.03322    time: 1.6436  last_time: 1.5113  data_time: 0.0079  last_data_time: 0.0100   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:01:35 d2.utils.events]: \u001b[0m eta: 6:12:16  iter: 5879  total_loss: 0.2638  loss_cls: 0.03943  loss_box_reg: 0.09884  loss_mask: 0.08312  loss_rpn_cls: 0.003636  loss_rpn_loc: 0.04531  total_val_loss: 0.235  val_loss_cls: 0.03574  val_loss_box_reg: 0.0757  val_loss_mask: 0.08455  val_loss_rpn_cls: 0.002418  val_loss_rpn_loc: 0.03276    time: 1.6432  last_time: 1.5484  data_time: 0.0077  last_data_time: 0.0097   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:02:19 d2.utils.events]: \u001b[0m eta: 6:10:56  iter: 5899  total_loss: 0.2584  loss_cls: 0.03732  loss_box_reg: 0.09124  loss_mask: 0.08018  loss_rpn_cls: 0.004664  loss_rpn_loc: 0.04074  total_val_loss: 0.2421  val_loss_cls: 0.0335  val_loss_box_reg: 0.08078  val_loss_mask: 0.08456  val_loss_rpn_cls: 0.002788  val_loss_rpn_loc: 0.03712    time: 1.6430  last_time: 1.6405  data_time: 0.0085  last_data_time: 0.0079   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:03:04 d2.utils.events]: \u001b[0m eta: 6:09:57  iter: 5919  total_loss: 0.2748  loss_cls: 0.04371  loss_box_reg: 0.09483  loss_mask: 0.08753  loss_rpn_cls: 0.004615  loss_rpn_loc: 0.04308  total_val_loss: 0.234  val_loss_cls: 0.03054  val_loss_box_reg: 0.07559  val_loss_mask: 0.09234  val_loss_rpn_cls: 0.002598  val_loss_rpn_loc: 0.03367    time: 1.6427  last_time: 1.6070  data_time: 0.0082  last_data_time: 0.0084   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:03:48 d2.utils.events]: \u001b[0m eta: 6:09:05  iter: 5939  total_loss: 0.2576  loss_cls: 0.03637  loss_box_reg: 0.09193  loss_mask: 0.08275  loss_rpn_cls: 0.004816  loss_rpn_loc: 0.03947  total_val_loss: 0.2225  val_loss_cls: 0.03178  val_loss_box_reg: 0.07432  val_loss_mask: 0.08745  val_loss_rpn_cls: 0.002852  val_loss_rpn_loc: 0.0323    time: 1.6424  last_time: 1.4573  data_time: 0.0076  last_data_time: 0.0065   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:04:32 d2.utils.events]: \u001b[0m eta: 6:07:55  iter: 5959  total_loss: 0.2817  loss_cls: 0.04239  loss_box_reg: 0.1058  loss_mask: 0.08206  loss_rpn_cls: 0.005691  loss_rpn_loc: 0.04406  total_val_loss: 0.2503  val_loss_cls: 0.03719  val_loss_box_reg: 0.07977  val_loss_mask: 0.08732  val_loss_rpn_cls: 0.003737  val_loss_rpn_loc: 0.03652    time: 1.6421  last_time: 1.6290  data_time: 0.0072  last_data_time: 0.0092   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:05:16 d2.utils.events]: \u001b[0m eta: 6:07:12  iter: 5979  total_loss: 0.2867  loss_cls: 0.04235  loss_box_reg: 0.0996  loss_mask: 0.08473  loss_rpn_cls: 0.004575  loss_rpn_loc: 0.04493  total_val_loss: 0.263  val_loss_cls: 0.03715  val_loss_box_reg: 0.09007  val_loss_mask: 0.08951  val_loss_rpn_cls: 0.002483  val_loss_rpn_loc: 0.04007    time: 1.6417  last_time: 1.4331  data_time: 0.0076  last_data_time: 0.0074   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:06:01 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\testing_images\\0_SideLane_addedversion_Testing_COCO.json\n",
      "\u001b[32m[09/26 18:06:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/26 18:06:01 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/26 18:06:01 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/26 18:06:01 d2.data.common]: \u001b[0mSerialized dataset takes 6.03 MiB\n",
      "\u001b[32m[09/26 18:06:01 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[09/26 18:06:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 566 batches\n",
      "\u001b[32m[09/26 18:06:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/566. Dataloading: 0.0004 s/iter. Inference: 0.0718 s/iter. Eval: 0.0072 s/iter. Total: 0.0794 s/iter. ETA=0:00:44\n",
      "\u001b[32m[09/26 18:06:10 d2.evaluation.evaluator]: \u001b[0mInference done 76/566. Dataloading: 0.0005 s/iter. Inference: 0.0736 s/iter. Eval: 0.0030 s/iter. Total: 0.0772 s/iter. ETA=0:00:37\n",
      "\u001b[32m[09/26 18:06:15 d2.evaluation.evaluator]: \u001b[0mInference done 141/566. Dataloading: 0.0006 s/iter. Inference: 0.0729 s/iter. Eval: 0.0038 s/iter. Total: 0.0773 s/iter. ETA=0:00:32\n",
      "\u001b[32m[09/26 18:06:20 d2.evaluation.evaluator]: \u001b[0mInference done 204/566. Dataloading: 0.0006 s/iter. Inference: 0.0737 s/iter. Eval: 0.0039 s/iter. Total: 0.0782 s/iter. ETA=0:00:28\n",
      "\u001b[32m[09/26 18:06:25 d2.evaluation.evaluator]: \u001b[0mInference done 268/566. Dataloading: 0.0006 s/iter. Inference: 0.0739 s/iter. Eval: 0.0038 s/iter. Total: 0.0784 s/iter. ETA=0:00:23\n",
      "\u001b[32m[09/26 18:06:30 d2.evaluation.evaluator]: \u001b[0mInference done 336/566. Dataloading: 0.0006 s/iter. Inference: 0.0735 s/iter. Eval: 0.0034 s/iter. Total: 0.0776 s/iter. ETA=0:00:17\n",
      "\u001b[32m[09/26 18:06:35 d2.evaluation.evaluator]: \u001b[0mInference done 402/566. Dataloading: 0.0006 s/iter. Inference: 0.0737 s/iter. Eval: 0.0031 s/iter. Total: 0.0775 s/iter. ETA=0:00:12\n",
      "\u001b[32m[09/26 18:06:40 d2.evaluation.evaluator]: \u001b[0mInference done 465/566. Dataloading: 0.0006 s/iter. Inference: 0.0738 s/iter. Eval: 0.0034 s/iter. Total: 0.0778 s/iter. ETA=0:00:07\n",
      "\u001b[32m[09/26 18:06:45 d2.evaluation.evaluator]: \u001b[0mInference done 528/566. Dataloading: 0.0006 s/iter. Inference: 0.0741 s/iter. Eval: 0.0034 s/iter. Total: 0.0781 s/iter. ETA=0:00:02\n",
      "\u001b[32m[09/26 18:06:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:44.386384 (0.079120 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 18:06:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.074240 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 18:06:49 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/26 18:06:49 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\coco_instances_results.json\n",
      "\u001b[32m[09/26 18:06:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.23s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.904\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.905\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.907\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.915\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.930\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.917\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.937\n",
      "\u001b[32m[09/26 18:06:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 90.353 | 99.001 | 98.963 |  nan  | 90.484 | 90.717 |\n",
      "\u001b[32m[09/26 18:06:49 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 18:06:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 90.353 | background | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.37s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.852\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.989\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.817\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.874\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.872\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.886\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.853\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.907\n",
      "\u001b[32m[09/26 18:06:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 85.157 | 99.001 | 98.941 |  nan  | 81.711 | 87.352 |\n",
      "\u001b[32m[09/26 18:06:50 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 18:06:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 85.157 | background | nan  |\n",
      "\u001b[32m[09/26 18:06:50 d2.engine.defaults]: \u001b[0mEvaluation results for test_data in csv format:\n",
      "\u001b[32m[09/26 18:06:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/26 18:06:50 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 18:06:50 d2.evaluation.testing]: \u001b[0mcopypaste: 90.3526,99.0010,98.9633,nan,90.4841,90.7166\n",
      "\u001b[32m[09/26 18:06:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/26 18:06:50 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 18:06:50 d2.evaluation.testing]: \u001b[0mcopypaste: 85.1571,99.0010,98.9415,nan,81.7109,87.3520\n",
      "\u001b[32m[09/26 18:06:50 d2.utils.events]: \u001b[0m eta: 6:06:16  iter: 5999  total_loss: 0.2618  loss_cls: 0.03628  loss_box_reg: 0.09063  loss_mask: 0.08608  loss_rpn_cls: 0.003731  loss_rpn_loc: 0.04264  total_val_loss: 0.2236  val_loss_cls: 0.03031  val_loss_box_reg: 0.06877  val_loss_mask: 0.08927  val_loss_rpn_cls: 0.00196  val_loss_rpn_loc: 0.02926    time: 1.6414  last_time: 1.5182  data_time: 0.0078  last_data_time: 0.0078   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:07:34 d2.utils.events]: \u001b[0m eta: 6:05:28  iter: 6019  total_loss: 0.3038  loss_cls: 0.04325  loss_box_reg: 0.1159  loss_mask: 0.09388  loss_rpn_cls: 0.004177  loss_rpn_loc: 0.04547  total_val_loss: 0.2285  val_loss_cls: 0.02971  val_loss_box_reg: 0.07296  val_loss_mask: 0.0882  val_loss_rpn_cls: 0.00252  val_loss_rpn_loc: 0.03313    time: 1.6411  last_time: 1.6863  data_time: 0.0074  last_data_time: 0.0070   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:08:19 d2.utils.events]: \u001b[0m eta: 6:04:31  iter: 6039  total_loss: 0.2715  loss_cls: 0.03936  loss_box_reg: 0.1  loss_mask: 0.08673  loss_rpn_cls: 0.003721  loss_rpn_loc: 0.04492  total_val_loss: 0.235  val_loss_cls: 0.03374  val_loss_box_reg: 0.07398  val_loss_mask: 0.08853  val_loss_rpn_cls: 0.002929  val_loss_rpn_loc: 0.03658    time: 1.6408  last_time: 1.5725  data_time: 0.0078  last_data_time: 0.0070   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:09:03 d2.utils.events]: \u001b[0m eta: 6:03:39  iter: 6059  total_loss: 0.251  loss_cls: 0.03653  loss_box_reg: 0.09145  loss_mask: 0.08633  loss_rpn_cls: 0.004151  loss_rpn_loc: 0.0369  total_val_loss: 0.2266  val_loss_cls: 0.03111  val_loss_box_reg: 0.07542  val_loss_mask: 0.08886  val_loss_rpn_cls: 0.003313  val_loss_rpn_loc: 0.03077    time: 1.6405  last_time: 1.6047  data_time: 0.0081  last_data_time: 0.0065   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:09:47 d2.utils.events]: \u001b[0m eta: 6:02:29  iter: 6079  total_loss: 0.2563  loss_cls: 0.03467  loss_box_reg: 0.0853  loss_mask: 0.08564  loss_rpn_cls: 0.004294  loss_rpn_loc: 0.039  total_val_loss: 0.2186  val_loss_cls: 0.03293  val_loss_box_reg: 0.07067  val_loss_mask: 0.08697  val_loss_rpn_cls: 0.00367  val_loss_rpn_loc: 0.03243    time: 1.6402  last_time: 1.5240  data_time: 0.0077  last_data_time: 0.0072   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:10:31 d2.utils.events]: \u001b[0m eta: 6:01:17  iter: 6099  total_loss: 0.2951  loss_cls: 0.04319  loss_box_reg: 0.1092  loss_mask: 0.0919  loss_rpn_cls: 0.005004  loss_rpn_loc: 0.04451  total_val_loss: 0.2355  val_loss_cls: 0.03333  val_loss_box_reg: 0.07225  val_loss_mask: 0.08801  val_loss_rpn_cls: 0.002623  val_loss_rpn_loc: 0.03437    time: 1.6399  last_time: 1.5235  data_time: 0.0076  last_data_time: 0.0072   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:11:16 d2.utils.events]: \u001b[0m eta: 6:00:38  iter: 6119  total_loss: 0.2669  loss_cls: 0.03679  loss_box_reg: 0.09139  loss_mask: 0.08182  loss_rpn_cls: 0.003862  loss_rpn_loc: 0.04592  total_val_loss: 0.2418  val_loss_cls: 0.03528  val_loss_box_reg: 0.07593  val_loss_mask: 0.09031  val_loss_rpn_cls: 0.002969  val_loss_rpn_loc: 0.03355    time: 1.6397  last_time: 1.5693  data_time: 0.0080  last_data_time: 0.0077   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:12:00 d2.utils.events]: \u001b[0m eta: 5:59:50  iter: 6139  total_loss: 0.2666  loss_cls: 0.04104  loss_box_reg: 0.09169  loss_mask: 0.08081  loss_rpn_cls: 0.005376  loss_rpn_loc: 0.04161  total_val_loss: 0.2187  val_loss_cls: 0.03493  val_loss_box_reg: 0.07371  val_loss_mask: 0.0839  val_loss_rpn_cls: 0.003666  val_loss_rpn_loc: 0.03238    time: 1.6395  last_time: 1.5462  data_time: 0.0079  last_data_time: 0.0092   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:12:44 d2.utils.events]: \u001b[0m eta: 5:58:56  iter: 6159  total_loss: 0.297  loss_cls: 0.04387  loss_box_reg: 0.1045  loss_mask: 0.08687  loss_rpn_cls: 0.004431  loss_rpn_loc: 0.0466  total_val_loss: 0.2178  val_loss_cls: 0.02997  val_loss_box_reg: 0.06642  val_loss_mask: 0.08646  val_loss_rpn_cls: 0.002723  val_loss_rpn_loc: 0.03    time: 1.6392  last_time: 1.4764  data_time: 0.0080  last_data_time: 0.0066   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:13:29 d2.utils.events]: \u001b[0m eta: 5:58:08  iter: 6179  total_loss: 0.2774  loss_cls: 0.04094  loss_box_reg: 0.09694  loss_mask: 0.08151  loss_rpn_cls: 0.004554  loss_rpn_loc: 0.04345  total_val_loss: 0.2335  val_loss_cls: 0.02887  val_loss_box_reg: 0.07725  val_loss_mask: 0.08603  val_loss_rpn_cls: 0.002929  val_loss_rpn_loc: 0.03372    time: 1.6389  last_time: 1.5778  data_time: 0.0072  last_data_time: 0.0078   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:14:13 d2.utils.events]: \u001b[0m eta: 5:57:24  iter: 6199  total_loss: 0.2631  loss_cls: 0.03534  loss_box_reg: 0.09068  loss_mask: 0.08958  loss_rpn_cls: 0.004758  loss_rpn_loc: 0.04139  total_val_loss: 0.2401  val_loss_cls: 0.03251  val_loss_box_reg: 0.07587  val_loss_mask: 0.08938  val_loss_rpn_cls: 0.003056  val_loss_rpn_loc: 0.03438    time: 1.6386  last_time: 1.5341  data_time: 0.0089  last_data_time: 0.0084   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:14:57 d2.utils.events]: \u001b[0m eta: 5:56:27  iter: 6219  total_loss: 0.2669  loss_cls: 0.03598  loss_box_reg: 0.09761  loss_mask: 0.07815  loss_rpn_cls: 0.004969  loss_rpn_loc: 0.04214  total_val_loss: 0.2231  val_loss_cls: 0.03453  val_loss_box_reg: 0.06768  val_loss_mask: 0.09086  val_loss_rpn_cls: 0.002852  val_loss_rpn_loc: 0.03192    time: 1.6383  last_time: 1.4475  data_time: 0.0079  last_data_time: 0.0089   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:15:40 d2.utils.events]: \u001b[0m eta: 5:55:37  iter: 6239  total_loss: 0.2619  loss_cls: 0.03502  loss_box_reg: 0.08855  loss_mask: 0.08381  loss_rpn_cls: 0.00451  loss_rpn_loc: 0.04191  total_val_loss: 0.2234  val_loss_cls: 0.02829  val_loss_box_reg: 0.06816  val_loss_mask: 0.08711  val_loss_rpn_cls: 0.00174  val_loss_rpn_loc: 0.02933    time: 1.6380  last_time: 1.4012  data_time: 0.0081  last_data_time: 0.0073   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:16:24 d2.utils.events]: \u001b[0m eta: 5:54:38  iter: 6259  total_loss: 0.2495  loss_cls: 0.03403  loss_box_reg: 0.08841  loss_mask: 0.08324  loss_rpn_cls: 0.003027  loss_rpn_loc: 0.03749  total_val_loss: 0.2349  val_loss_cls: 0.02876  val_loss_box_reg: 0.07686  val_loss_mask: 0.08408  val_loss_rpn_cls: 0.003235  val_loss_rpn_loc: 0.03463    time: 1.6377  last_time: 1.4671  data_time: 0.0075  last_data_time: 0.0070   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:17:08 d2.utils.events]: \u001b[0m eta: 5:53:56  iter: 6279  total_loss: 0.2676  loss_cls: 0.03614  loss_box_reg: 0.09153  loss_mask: 0.09004  loss_rpn_cls: 0.004441  loss_rpn_loc: 0.03936  total_val_loss: 0.2423  val_loss_cls: 0.03097  val_loss_box_reg: 0.07779  val_loss_mask: 0.08464  val_loss_rpn_cls: 0.002509  val_loss_rpn_loc: 0.03534    time: 1.6373  last_time: 1.4959  data_time: 0.0070  last_data_time: 0.0060   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:17:53 d2.utils.events]: \u001b[0m eta: 5:53:23  iter: 6299  total_loss: 0.3059  loss_cls: 0.0454  loss_box_reg: 0.1089  loss_mask: 0.09372  loss_rpn_cls: 0.005024  loss_rpn_loc: 0.04505  total_val_loss: 0.2364  val_loss_cls: 0.03453  val_loss_box_reg: 0.07729  val_loss_mask: 0.08251  val_loss_rpn_cls: 0.003031  val_loss_rpn_loc: 0.03368    time: 1.6372  last_time: 1.5627  data_time: 0.0077  last_data_time: 0.0070   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:18:38 d2.utils.events]: \u001b[0m eta: 5:52:38  iter: 6319  total_loss: 0.281  loss_cls: 0.03974  loss_box_reg: 0.09637  loss_mask: 0.08168  loss_rpn_cls: 0.006259  loss_rpn_loc: 0.04798  total_val_loss: 0.2569  val_loss_cls: 0.03497  val_loss_box_reg: 0.08316  val_loss_mask: 0.08669  val_loss_rpn_cls: 0.003473  val_loss_rpn_loc: 0.03827    time: 1.6370  last_time: 1.5903  data_time: 0.0081  last_data_time: 0.0083   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:19:22 d2.utils.events]: \u001b[0m eta: 5:51:48  iter: 6339  total_loss: 0.29  loss_cls: 0.04081  loss_box_reg: 0.1046  loss_mask: 0.08846  loss_rpn_cls: 0.007325  loss_rpn_loc: 0.04922  total_val_loss: 0.2408  val_loss_cls: 0.03272  val_loss_box_reg: 0.07543  val_loss_mask: 0.08895  val_loss_rpn_cls: 0.004114  val_loss_rpn_loc: 0.03746    time: 1.6367  last_time: 1.6288  data_time: 0.0087  last_data_time: 0.0068   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:20:07 d2.utils.events]: \u001b[0m eta: 5:51:17  iter: 6359  total_loss: 0.2786  loss_cls: 0.03686  loss_box_reg: 0.09912  loss_mask: 0.08693  loss_rpn_cls: 0.005129  loss_rpn_loc: 0.05423  total_val_loss: 0.2532  val_loss_cls: 0.03418  val_loss_box_reg: 0.08384  val_loss_mask: 0.08631  val_loss_rpn_cls: 0.003517  val_loss_rpn_loc: 0.03878    time: 1.6365  last_time: 1.4833  data_time: 0.0082  last_data_time: 0.0076   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:20:51 d2.utils.events]: \u001b[0m eta: 5:50:43  iter: 6379  total_loss: 0.2649  loss_cls: 0.03679  loss_box_reg: 0.09046  loss_mask: 0.08196  loss_rpn_cls: 0.006626  loss_rpn_loc: 0.04292  total_val_loss: 0.2142  val_loss_cls: 0.02957  val_loss_box_reg: 0.06684  val_loss_mask: 0.0882  val_loss_rpn_cls: 0.002513  val_loss_rpn_loc: 0.03212    time: 1.6363  last_time: 1.6274  data_time: 0.0075  last_data_time: 0.0081   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:21:38 d2.utils.events]: \u001b[0m eta: 5:50:18  iter: 6399  total_loss: 0.2864  loss_cls: 0.03988  loss_box_reg: 0.1052  loss_mask: 0.08546  loss_rpn_cls: 0.004486  loss_rpn_loc: 0.03766  total_val_loss: 0.245  val_loss_cls: 0.03534  val_loss_box_reg: 0.08559  val_loss_mask: 0.08244  val_loss_rpn_cls: 0.003209  val_loss_rpn_loc: 0.03549    time: 1.6362  last_time: 1.5365  data_time: 0.0075  last_data_time: 0.0088   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:22:35 d2.utils.events]: \u001b[0m eta: 5:50:03  iter: 6419  total_loss: 0.2552  loss_cls: 0.03986  loss_box_reg: 0.08648  loss_mask: 0.0813  loss_rpn_cls: 0.004456  loss_rpn_loc: 0.04059  total_val_loss: 0.2381  val_loss_cls: 0.03229  val_loss_box_reg: 0.07427  val_loss_mask: 0.07924  val_loss_rpn_cls: 0.002864  val_loss_rpn_loc: 0.03403    time: 1.6372  last_time: 1.8464  data_time: 0.0072  last_data_time: 0.0050   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:23:35 d2.utils.events]: \u001b[0m eta: 5:49:56  iter: 6439  total_loss: 0.2517  loss_cls: 0.03374  loss_box_reg: 0.0903  loss_mask: 0.08331  loss_rpn_cls: 0.003742  loss_rpn_loc: 0.03894  total_val_loss: 0.2294  val_loss_cls: 0.02978  val_loss_box_reg: 0.07677  val_loss_mask: 0.09161  val_loss_rpn_cls: 0.002535  val_loss_rpn_loc: 0.03198    time: 1.6388  last_time: 1.8900  data_time: 0.0079  last_data_time: 0.0065   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:24:33 d2.utils.events]: \u001b[0m eta: 5:49:58  iter: 6459  total_loss: 0.2735  loss_cls: 0.04311  loss_box_reg: 0.1031  loss_mask: 0.08247  loss_rpn_cls: 0.00332  loss_rpn_loc: 0.04448  total_val_loss: 0.2354  val_loss_cls: 0.03365  val_loss_box_reg: 0.0771  val_loss_mask: 0.08524  val_loss_rpn_cls: 0.003264  val_loss_rpn_loc: 0.03663    time: 1.6399  last_time: 2.0482  data_time: 0.0072  last_data_time: 0.0062   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:25:32 d2.utils.events]: \u001b[0m eta: 5:49:55  iter: 6479  total_loss: 0.2968  loss_cls: 0.04387  loss_box_reg: 0.1087  loss_mask: 0.0835  loss_rpn_cls: 0.005786  loss_rpn_loc: 0.04647  total_val_loss: 0.2296  val_loss_cls: 0.03654  val_loss_box_reg: 0.07241  val_loss_mask: 0.08329  val_loss_rpn_cls: 0.00231  val_loss_rpn_loc: 0.03482    time: 1.6411  last_time: 1.8959  data_time: 0.0082  last_data_time: 0.0062   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:26:29 d2.utils.events]: \u001b[0m eta: 5:49:50  iter: 6499  total_loss: 0.3065  loss_cls: 0.04112  loss_box_reg: 0.1029  loss_mask: 0.09035  loss_rpn_cls: 0.006299  loss_rpn_loc: 0.04534  total_val_loss: 0.2191  val_loss_cls: 0.03077  val_loss_box_reg: 0.06968  val_loss_mask: 0.08488  val_loss_rpn_cls: 0.002953  val_loss_rpn_loc: 0.03222    time: 1.6423  last_time: 2.1511  data_time: 0.0073  last_data_time: 0.0071   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:27:22 d2.utils.events]: \u001b[0m eta: 5:49:26  iter: 6519  total_loss: 0.2845  loss_cls: 0.03753  loss_box_reg: 0.1058  loss_mask: 0.09131  loss_rpn_cls: 0.006168  loss_rpn_loc: 0.04315  total_val_loss: 0.2634  val_loss_cls: 0.04177  val_loss_box_reg: 0.08643  val_loss_mask: 0.08925  val_loss_rpn_cls: 0.003476  val_loss_rpn_loc: 0.03638    time: 1.6431  last_time: 1.6359  data_time: 0.0077  last_data_time: 0.0061   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:28:19 d2.utils.events]: \u001b[0m eta: 5:49:25  iter: 6539  total_loss: 0.3073  loss_cls: 0.04588  loss_box_reg: 0.1094  loss_mask: 0.0849  loss_rpn_cls: 0.003962  loss_rpn_loc: 0.04413  total_val_loss: 0.243  val_loss_cls: 0.03661  val_loss_box_reg: 0.08367  val_loss_mask: 0.08772  val_loss_rpn_cls: 0.004454  val_loss_rpn_loc: 0.03721    time: 1.6442  last_time: 1.6105  data_time: 0.0075  last_data_time: 0.0086   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:29:15 d2.utils.events]: \u001b[0m eta: 5:49:49  iter: 6559  total_loss: 0.2824  loss_cls: 0.04292  loss_box_reg: 0.1004  loss_mask: 0.08339  loss_rpn_cls: 0.004942  loss_rpn_loc: 0.04294  total_val_loss: 0.2397  val_loss_cls: 0.03361  val_loss_box_reg: 0.0793  val_loss_mask: 0.08664  val_loss_rpn_cls: 0.002936  val_loss_rpn_loc: 0.0334    time: 1.6453  last_time: 2.0105  data_time: 0.0081  last_data_time: 0.0079   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:30:13 d2.utils.events]: \u001b[0m eta: 5:49:57  iter: 6579  total_loss: 0.2532  loss_cls: 0.0377  loss_box_reg: 0.09447  loss_mask: 0.08489  loss_rpn_cls: 0.004241  loss_rpn_loc: 0.03691  total_val_loss: 0.2143  val_loss_cls: 0.03145  val_loss_box_reg: 0.06648  val_loss_mask: 0.08351  val_loss_rpn_cls: 0.002433  val_loss_rpn_loc: 0.03281    time: 1.6467  last_time: 2.5294  data_time: 0.0074  last_data_time: 0.0055   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:31:12 d2.utils.events]: \u001b[0m eta: 5:49:53  iter: 6599  total_loss: 0.2438  loss_cls: 0.03466  loss_box_reg: 0.08679  loss_mask: 0.08082  loss_rpn_cls: 0.003859  loss_rpn_loc: 0.03832  total_val_loss: 0.2537  val_loss_cls: 0.03472  val_loss_box_reg: 0.08449  val_loss_mask: 0.08821  val_loss_rpn_cls: 0.003147  val_loss_rpn_loc: 0.03726    time: 1.6479  last_time: 2.5750  data_time: 0.0082  last_data_time: 0.0075   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:32:07 d2.utils.events]: \u001b[0m eta: 5:49:52  iter: 6619  total_loss: 0.252  loss_cls: 0.03808  loss_box_reg: 0.08967  loss_mask: 0.08394  loss_rpn_cls: 0.004637  loss_rpn_loc: 0.04332  total_val_loss: 0.215  val_loss_cls: 0.02632  val_loss_box_reg: 0.06895  val_loss_mask: 0.08452  val_loss_rpn_cls: 0.002373  val_loss_rpn_loc: 0.029    time: 1.6490  last_time: 2.2706  data_time: 0.0078  last_data_time: 0.0079   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:33:07 d2.utils.events]: \u001b[0m eta: 5:49:54  iter: 6639  total_loss: 0.272  loss_cls: 0.04111  loss_box_reg: 0.09316  loss_mask: 0.0843  loss_rpn_cls: 0.005342  loss_rpn_loc: 0.04291  total_val_loss: 0.2288  val_loss_cls: 0.03207  val_loss_box_reg: 0.07471  val_loss_mask: 0.08672  val_loss_rpn_cls: 0.00294  val_loss_rpn_loc: 0.03602    time: 1.6503  last_time: 1.9639  data_time: 0.0075  last_data_time: 0.0074   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:34:02 d2.utils.events]: \u001b[0m eta: 5:50:07  iter: 6659  total_loss: 0.2439  loss_cls: 0.03122  loss_box_reg: 0.08056  loss_mask: 0.08544  loss_rpn_cls: 0.004263  loss_rpn_loc: 0.03855  total_val_loss: 0.2302  val_loss_cls: 0.03086  val_loss_box_reg: 0.06975  val_loss_mask: 0.08419  val_loss_rpn_cls: 0.002684  val_loss_rpn_loc: 0.0309    time: 1.6510  last_time: 1.6917  data_time: 0.0080  last_data_time: 0.0086   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:34:49 d2.utils.events]: \u001b[0m eta: 5:50:09  iter: 6679  total_loss: 0.2522  loss_cls: 0.03587  loss_box_reg: 0.08262  loss_mask: 0.08738  loss_rpn_cls: 0.004549  loss_rpn_loc: 0.03778  total_val_loss: 0.2399  val_loss_cls: 0.03361  val_loss_box_reg: 0.07629  val_loss_mask: 0.08382  val_loss_rpn_cls: 0.002749  val_loss_rpn_loc: 0.03508    time: 1.6511  last_time: 1.5111  data_time: 0.0079  last_data_time: 0.0075   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:35:33 d2.utils.events]: \u001b[0m eta: 5:49:44  iter: 6699  total_loss: 0.2358  loss_cls: 0.03367  loss_box_reg: 0.08337  loss_mask: 0.08295  loss_rpn_cls: 0.004221  loss_rpn_loc: 0.03526  total_val_loss: 0.2258  val_loss_cls: 0.03129  val_loss_box_reg: 0.07756  val_loss_mask: 0.08582  val_loss_rpn_cls: 0.002713  val_loss_rpn_loc: 0.03227    time: 1.6507  last_time: 1.5775  data_time: 0.0077  last_data_time: 0.0110   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:36:17 d2.utils.events]: \u001b[0m eta: 5:49:34  iter: 6719  total_loss: 0.264  loss_cls: 0.03544  loss_box_reg: 0.08638  loss_mask: 0.08252  loss_rpn_cls: 0.004291  loss_rpn_loc: 0.0402  total_val_loss: 0.2315  val_loss_cls: 0.03724  val_loss_box_reg: 0.07678  val_loss_mask: 0.07916  val_loss_rpn_cls: 0.003235  val_loss_rpn_loc: 0.03458    time: 1.6505  last_time: 1.4942  data_time: 0.0071  last_data_time: 0.0065   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:37:01 d2.utils.events]: \u001b[0m eta: 5:48:56  iter: 6739  total_loss: 0.2722  loss_cls: 0.043  loss_box_reg: 0.09856  loss_mask: 0.08912  loss_rpn_cls: 0.004431  loss_rpn_loc: 0.04275  total_val_loss: 0.24  val_loss_cls: 0.03187  val_loss_box_reg: 0.0815  val_loss_mask: 0.08518  val_loss_rpn_cls: 0.002342  val_loss_rpn_loc: 0.03402    time: 1.6501  last_time: 1.6021  data_time: 0.0071  last_data_time: 0.0074   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:37:46 d2.utils.events]: \u001b[0m eta: 5:48:31  iter: 6759  total_loss: 0.2593  loss_cls: 0.03879  loss_box_reg: 0.09066  loss_mask: 0.08064  loss_rpn_cls: 0.003671  loss_rpn_loc: 0.03889  total_val_loss: 0.2073  val_loss_cls: 0.02847  val_loss_box_reg: 0.06472  val_loss_mask: 0.08568  val_loss_rpn_cls: 0.001837  val_loss_rpn_loc: 0.0311    time: 1.6499  last_time: 1.6239  data_time: 0.0073  last_data_time: 0.0061   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:38:29 d2.utils.events]: \u001b[0m eta: 5:47:59  iter: 6779  total_loss: 0.2438  loss_cls: 0.03627  loss_box_reg: 0.08328  loss_mask: 0.08395  loss_rpn_cls: 0.003634  loss_rpn_loc: 0.03846  total_val_loss: 0.2238  val_loss_cls: 0.02993  val_loss_box_reg: 0.07258  val_loss_mask: 0.08535  val_loss_rpn_cls: 0.002247  val_loss_rpn_loc: 0.0336    time: 1.6495  last_time: 1.5952  data_time: 0.0070  last_data_time: 0.0068   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:39:13 d2.utils.events]: \u001b[0m eta: 5:47:22  iter: 6799  total_loss: 0.2611  loss_cls: 0.03265  loss_box_reg: 0.08716  loss_mask: 0.08705  loss_rpn_cls: 0.004174  loss_rpn_loc: 0.04272  total_val_loss: 0.2433  val_loss_cls: 0.03473  val_loss_box_reg: 0.08311  val_loss_mask: 0.08325  val_loss_rpn_cls: 0.002734  val_loss_rpn_loc: 0.03245    time: 1.6491  last_time: 1.3757  data_time: 0.0072  last_data_time: 0.0068   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:39:57 d2.utils.events]: \u001b[0m eta: 5:46:57  iter: 6819  total_loss: 0.2543  loss_cls: 0.03161  loss_box_reg: 0.0894  loss_mask: 0.08266  loss_rpn_cls: 0.00354  loss_rpn_loc: 0.04471  total_val_loss: 0.2417  val_loss_cls: 0.03317  val_loss_box_reg: 0.07722  val_loss_mask: 0.08852  val_loss_rpn_cls: 0.002556  val_loss_rpn_loc: 0.0337    time: 1.6489  last_time: 1.4727  data_time: 0.0086  last_data_time: 0.0073   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:40:42 d2.utils.events]: \u001b[0m eta: 5:46:26  iter: 6839  total_loss: 0.2558  loss_cls: 0.03759  loss_box_reg: 0.08971  loss_mask: 0.08054  loss_rpn_cls: 0.005554  loss_rpn_loc: 0.04634  total_val_loss: 0.2294  val_loss_cls: 0.03245  val_loss_box_reg: 0.07534  val_loss_mask: 0.08269  val_loss_rpn_cls: 0.0031  val_loss_rpn_loc: 0.03221    time: 1.6486  last_time: 1.5823  data_time: 0.0074  last_data_time: 0.0072   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:41:27 d2.utils.events]: \u001b[0m eta: 5:46:01  iter: 6859  total_loss: 0.251  loss_cls: 0.0318  loss_box_reg: 0.08494  loss_mask: 0.08253  loss_rpn_cls: 0.003223  loss_rpn_loc: 0.03975  total_val_loss: 0.2268  val_loss_cls: 0.02876  val_loss_box_reg: 0.07663  val_loss_mask: 0.08742  val_loss_rpn_cls: 0.003379  val_loss_rpn_loc: 0.03129    time: 1.6485  last_time: 1.5743  data_time: 0.0079  last_data_time: 0.0078   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:42:13 d2.utils.events]: \u001b[0m eta: 5:45:51  iter: 6879  total_loss: 0.2949  loss_cls: 0.04078  loss_box_reg: 0.1115  loss_mask: 0.08624  loss_rpn_cls: 0.004735  loss_rpn_loc: 0.05155  total_val_loss: 0.2518  val_loss_cls: 0.0377  val_loss_box_reg: 0.0817  val_loss_mask: 0.08822  val_loss_rpn_cls: 0.002957  val_loss_rpn_loc: 0.03582    time: 1.6483  last_time: 1.6980  data_time: 0.0077  last_data_time: 0.0073   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:42:57 d2.utils.events]: \u001b[0m eta: 5:45:17  iter: 6899  total_loss: 0.2654  loss_cls: 0.04042  loss_box_reg: 0.09004  loss_mask: 0.08201  loss_rpn_cls: 0.005495  loss_rpn_loc: 0.04245  total_val_loss: 0.2363  val_loss_cls: 0.03338  val_loss_box_reg: 0.07685  val_loss_mask: 0.08471  val_loss_rpn_cls: 0.00306  val_loss_rpn_loc: 0.03394    time: 1.6480  last_time: 1.4993  data_time: 0.0078  last_data_time: 0.0066   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:43:41 d2.utils.events]: \u001b[0m eta: 5:44:44  iter: 6919  total_loss: 0.2323  loss_cls: 0.03417  loss_box_reg: 0.07884  loss_mask: 0.07955  loss_rpn_cls: 0.004066  loss_rpn_loc: 0.03796  total_val_loss: 0.2261  val_loss_cls: 0.03179  val_loss_box_reg: 0.0737  val_loss_mask: 0.08843  val_loss_rpn_cls: 0.002522  val_loss_rpn_loc: 0.03016    time: 1.6478  last_time: 1.4805  data_time: 0.0078  last_data_time: 0.0095   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:44:25 d2.utils.events]: \u001b[0m eta: 5:44:14  iter: 6939  total_loss: 0.226  loss_cls: 0.02929  loss_box_reg: 0.07605  loss_mask: 0.08061  loss_rpn_cls: 0.004337  loss_rpn_loc: 0.03598  total_val_loss: 0.2159  val_loss_cls: 0.02996  val_loss_box_reg: 0.07302  val_loss_mask: 0.08154  val_loss_rpn_cls: 0.002698  val_loss_rpn_loc: 0.03138    time: 1.6475  last_time: 1.5638  data_time: 0.0073  last_data_time: 0.0068   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:45:09 d2.utils.events]: \u001b[0m eta: 5:43:43  iter: 6959  total_loss: 0.2711  loss_cls: 0.04353  loss_box_reg: 0.09751  loss_mask: 0.08474  loss_rpn_cls: 0.004493  loss_rpn_loc: 0.04507  total_val_loss: 0.2037  val_loss_cls: 0.02717  val_loss_box_reg: 0.06644  val_loss_mask: 0.08168  val_loss_rpn_cls: 0.002292  val_loss_rpn_loc: 0.03058    time: 1.6472  last_time: 1.5324  data_time: 0.0077  last_data_time: 0.0089   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:45:53 d2.utils.events]: \u001b[0m eta: 5:43:14  iter: 6979  total_loss: 0.2596  loss_cls: 0.04153  loss_box_reg: 0.09184  loss_mask: 0.08908  loss_rpn_cls: 0.003202  loss_rpn_loc: 0.03959  total_val_loss: 0.2283  val_loss_cls: 0.03357  val_loss_box_reg: 0.07611  val_loss_mask: 0.08673  val_loss_rpn_cls: 0.003148  val_loss_rpn_loc: 0.03503    time: 1.6468  last_time: 1.5966  data_time: 0.0074  last_data_time: 0.0075   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:46:39 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\testing_images\\0_SideLane_addedversion_Testing_COCO.json\n",
      "\u001b[32m[09/26 18:46:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/26 18:46:39 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/26 18:46:39 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/26 18:46:39 d2.data.common]: \u001b[0mSerialized dataset takes 6.03 MiB\n",
      "\u001b[32m[09/26 18:46:39 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[09/26 18:46:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 566 batches\n",
      "\u001b[32m[09/26 18:46:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/566. Dataloading: 0.0004 s/iter. Inference: 0.0712 s/iter. Eval: 0.0064 s/iter. Total: 0.0780 s/iter. ETA=0:00:43\n",
      "\u001b[32m[09/26 18:46:48 d2.evaluation.evaluator]: \u001b[0mInference done 79/566. Dataloading: 0.0005 s/iter. Inference: 0.0712 s/iter. Eval: 0.0027 s/iter. Total: 0.0745 s/iter. ETA=0:00:36\n",
      "\u001b[32m[09/26 18:46:53 d2.evaluation.evaluator]: \u001b[0mInference done 144/566. Dataloading: 0.0006 s/iter. Inference: 0.0715 s/iter. Eval: 0.0038 s/iter. Total: 0.0758 s/iter. ETA=0:00:32\n",
      "\u001b[32m[09/26 18:46:58 d2.evaluation.evaluator]: \u001b[0mInference done 208/566. Dataloading: 0.0006 s/iter. Inference: 0.0723 s/iter. Eval: 0.0038 s/iter. Total: 0.0767 s/iter. ETA=0:00:27\n",
      "\u001b[32m[09/26 18:47:03 d2.evaluation.evaluator]: \u001b[0mInference done 272/566. Dataloading: 0.0006 s/iter. Inference: 0.0727 s/iter. Eval: 0.0038 s/iter. Total: 0.0771 s/iter. ETA=0:00:22\n",
      "\u001b[32m[09/26 18:47:08 d2.evaluation.evaluator]: \u001b[0mInference done 342/566. Dataloading: 0.0006 s/iter. Inference: 0.0721 s/iter. Eval: 0.0034 s/iter. Total: 0.0761 s/iter. ETA=0:00:17\n",
      "\u001b[32m[09/26 18:47:13 d2.evaluation.evaluator]: \u001b[0mInference done 410/566. Dataloading: 0.0006 s/iter. Inference: 0.0721 s/iter. Eval: 0.0030 s/iter. Total: 0.0758 s/iter. ETA=0:00:11\n",
      "\u001b[32m[09/26 18:47:18 d2.evaluation.evaluator]: \u001b[0mInference done 474/566. Dataloading: 0.0006 s/iter. Inference: 0.0722 s/iter. Eval: 0.0034 s/iter. Total: 0.0762 s/iter. ETA=0:00:07\n",
      "\u001b[32m[09/26 18:47:23 d2.evaluation.evaluator]: \u001b[0mInference done 538/566. Dataloading: 0.0006 s/iter. Inference: 0.0726 s/iter. Eval: 0.0034 s/iter. Total: 0.0766 s/iter. ETA=0:00:02\n",
      "\u001b[32m[09/26 18:47:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:43.560592 (0.077648 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 18:47:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:40 (0.072658 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 18:47:26 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/26 18:47:26 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\coco_instances_results.json\n",
      "\u001b[32m[09/26 18:47:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.24s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.913\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.908\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.919\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.194\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.922\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.936\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.921\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.946\n",
      "\u001b[32m[09/26 18:47:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 91.300 | 99.007 | 98.969 |  nan  | 90.769 | 91.896 |\n",
      "\u001b[32m[09/26 18:47:26 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 18:47:26 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 91.300 | background | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.42s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.852\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.980\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.818\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.876\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.873\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.887\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.855\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.908\n",
      "\u001b[32m[09/26 18:47:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 85.188 | 99.007 | 97.961 |  nan  | 81.755 | 87.644 |\n",
      "\u001b[32m[09/26 18:47:27 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 18:47:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 85.188 | background | nan  |\n",
      "\u001b[32m[09/26 18:47:27 d2.engine.defaults]: \u001b[0mEvaluation results for test_data in csv format:\n",
      "\u001b[32m[09/26 18:47:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/26 18:47:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 18:47:27 d2.evaluation.testing]: \u001b[0mcopypaste: 91.2997,99.0067,98.9694,nan,90.7692,91.8955\n",
      "\u001b[32m[09/26 18:47:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/26 18:47:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 18:47:27 d2.evaluation.testing]: \u001b[0mcopypaste: 85.1880,99.0067,97.9605,nan,81.7548,87.6439\n",
      "\u001b[32m[09/26 18:47:27 d2.utils.events]: \u001b[0m eta: 5:42:34  iter: 6999  total_loss: 0.2562  loss_cls: 0.03321  loss_box_reg: 0.08488  loss_mask: 0.08164  loss_rpn_cls: 0.004258  loss_rpn_loc: 0.04004  total_val_loss: 0.2389  val_loss_cls: 0.03421  val_loss_box_reg: 0.08256  val_loss_mask: 0.08792  val_loss_rpn_cls: 0.002897  val_loss_rpn_loc: 0.03516    time: 1.6464  last_time: 1.5098  data_time: 0.0077  last_data_time: 0.0067   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:48:11 d2.utils.events]: \u001b[0m eta: 5:41:56  iter: 7019  total_loss: 0.2492  loss_cls: 0.03069  loss_box_reg: 0.08152  loss_mask: 0.08695  loss_rpn_cls: 0.005119  loss_rpn_loc: 0.03853  total_val_loss: 0.232  val_loss_cls: 0.03179  val_loss_box_reg: 0.0747  val_loss_mask: 0.08472  val_loss_rpn_cls: 0.002816  val_loss_rpn_loc: 0.03223    time: 1.6461  last_time: 1.4863  data_time: 0.0077  last_data_time: 0.0085   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:48:55 d2.utils.events]: \u001b[0m eta: 5:41:07  iter: 7039  total_loss: 0.2556  loss_cls: 0.03331  loss_box_reg: 0.08459  loss_mask: 0.08911  loss_rpn_cls: 0.004366  loss_rpn_loc: 0.03747  total_val_loss: 0.2444  val_loss_cls: 0.03542  val_loss_box_reg: 0.08288  val_loss_mask: 0.08835  val_loss_rpn_cls: 0.002672  val_loss_rpn_loc: 0.03323    time: 1.6458  last_time: 1.5201  data_time: 0.0080  last_data_time: 0.0071   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:49:38 d2.utils.events]: \u001b[0m eta: 5:40:24  iter: 7059  total_loss: 0.2774  loss_cls: 0.04074  loss_box_reg: 0.1038  loss_mask: 0.08254  loss_rpn_cls: 0.005629  loss_rpn_loc: 0.04175  total_val_loss: 0.2159  val_loss_cls: 0.03085  val_loss_box_reg: 0.07178  val_loss_mask: 0.08864  val_loss_rpn_cls: 0.00227  val_loss_rpn_loc: 0.03054    time: 1.6454  last_time: 1.4604  data_time: 0.0074  last_data_time: 0.0073   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:50:22 d2.utils.events]: \u001b[0m eta: 5:39:51  iter: 7079  total_loss: 0.2685  loss_cls: 0.04111  loss_box_reg: 0.1015  loss_mask: 0.08495  loss_rpn_cls: 0.004792  loss_rpn_loc: 0.04325  total_val_loss: 0.2385  val_loss_cls: 0.03443  val_loss_box_reg: 0.08296  val_loss_mask: 0.08301  val_loss_rpn_cls: 0.002596  val_loss_rpn_loc: 0.03455    time: 1.6450  last_time: 1.4325  data_time: 0.0072  last_data_time: 0.0086   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:51:05 d2.utils.events]: \u001b[0m eta: 5:39:15  iter: 7099  total_loss: 0.2821  loss_cls: 0.03285  loss_box_reg: 0.09575  loss_mask: 0.09045  loss_rpn_cls: 0.004022  loss_rpn_loc: 0.04742  total_val_loss: 0.2314  val_loss_cls: 0.03071  val_loss_box_reg: 0.07406  val_loss_mask: 0.09023  val_loss_rpn_cls: 0.00326  val_loss_rpn_loc: 0.03602    time: 1.6447  last_time: 1.5822  data_time: 0.0073  last_data_time: 0.0070   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:51:49 d2.utils.events]: \u001b[0m eta: 5:38:26  iter: 7119  total_loss: 0.2551  loss_cls: 0.03539  loss_box_reg: 0.07933  loss_mask: 0.08265  loss_rpn_cls: 0.004606  loss_rpn_loc: 0.04485  total_val_loss: 0.2541  val_loss_cls: 0.03534  val_loss_box_reg: 0.08479  val_loss_mask: 0.08666  val_loss_rpn_cls: 0.003267  val_loss_rpn_loc: 0.03566    time: 1.6445  last_time: 1.4659  data_time: 0.0074  last_data_time: 0.0061   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:52:34 d2.utils.events]: \u001b[0m eta: 5:37:54  iter: 7139  total_loss: 0.2788  loss_cls: 0.04111  loss_box_reg: 0.09571  loss_mask: 0.08562  loss_rpn_cls: 0.005378  loss_rpn_loc: 0.04643  total_val_loss: 0.2399  val_loss_cls: 0.03675  val_loss_box_reg: 0.07903  val_loss_mask: 0.07979  val_loss_rpn_cls: 0.002278  val_loss_rpn_loc: 0.03803    time: 1.6442  last_time: 1.5019  data_time: 0.0073  last_data_time: 0.0064   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:53:18 d2.utils.events]: \u001b[0m eta: 5:37:16  iter: 7159  total_loss: 0.2656  loss_cls: 0.03875  loss_box_reg: 0.0931  loss_mask: 0.0831  loss_rpn_cls: 0.004249  loss_rpn_loc: 0.04479  total_val_loss: 0.2412  val_loss_cls: 0.03304  val_loss_box_reg: 0.07928  val_loss_mask: 0.09  val_loss_rpn_cls: 0.002917  val_loss_rpn_loc: 0.03502    time: 1.6439  last_time: 1.5506  data_time: 0.0073  last_data_time: 0.0072   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:54:01 d2.utils.events]: \u001b[0m eta: 5:36:31  iter: 7179  total_loss: 0.257  loss_cls: 0.03915  loss_box_reg: 0.08232  loss_mask: 0.08348  loss_rpn_cls: 0.003986  loss_rpn_loc: 0.03353  total_val_loss: 0.2207  val_loss_cls: 0.0294  val_loss_box_reg: 0.07132  val_loss_mask: 0.08626  val_loss_rpn_cls: 0.0024  val_loss_rpn_loc: 0.03245    time: 1.6436  last_time: 1.6693  data_time: 0.0075  last_data_time: 0.0060   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:54:46 d2.utils.events]: \u001b[0m eta: 5:35:48  iter: 7199  total_loss: 0.2606  loss_cls: 0.03769  loss_box_reg: 0.09412  loss_mask: 0.07988  loss_rpn_cls: 0.005288  loss_rpn_loc: 0.04437  total_val_loss: 0.2123  val_loss_cls: 0.02821  val_loss_box_reg: 0.06661  val_loss_mask: 0.08212  val_loss_rpn_cls: 0.002903  val_loss_rpn_loc: 0.03009    time: 1.6434  last_time: 1.6245  data_time: 0.0075  last_data_time: 0.0066   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:55:29 d2.utils.events]: \u001b[0m eta: 5:35:16  iter: 7219  total_loss: 0.2493  loss_cls: 0.03746  loss_box_reg: 0.08607  loss_mask: 0.08501  loss_rpn_cls: 0.004584  loss_rpn_loc: 0.03956  total_val_loss: 0.2395  val_loss_cls: 0.03428  val_loss_box_reg: 0.07682  val_loss_mask: 0.08325  val_loss_rpn_cls: 0.002809  val_loss_rpn_loc: 0.03408    time: 1.6430  last_time: 1.4478  data_time: 0.0077  last_data_time: 0.0054   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:56:13 d2.utils.events]: \u001b[0m eta: 5:34:39  iter: 7239  total_loss: 0.2479  loss_cls: 0.03711  loss_box_reg: 0.08992  loss_mask: 0.08704  loss_rpn_cls: 0.004389  loss_rpn_loc: 0.03686  total_val_loss: 0.2316  val_loss_cls: 0.034  val_loss_box_reg: 0.07383  val_loss_mask: 0.0889  val_loss_rpn_cls: 0.002418  val_loss_rpn_loc: 0.03028    time: 1.6428  last_time: 1.5788  data_time: 0.0072  last_data_time: 0.0067   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:56:57 d2.utils.events]: \u001b[0m eta: 5:33:50  iter: 7259  total_loss: 0.2383  loss_cls: 0.03339  loss_box_reg: 0.08607  loss_mask: 0.08378  loss_rpn_cls: 0.004132  loss_rpn_loc: 0.03787  total_val_loss: 0.2171  val_loss_cls: 0.02973  val_loss_box_reg: 0.07252  val_loss_mask: 0.08205  val_loss_rpn_cls: 0.003064  val_loss_rpn_loc: 0.03253    time: 1.6424  last_time: 1.6419  data_time: 0.0070  last_data_time: 0.0081   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:57:41 d2.utils.events]: \u001b[0m eta: 5:33:24  iter: 7279  total_loss: 0.254  loss_cls: 0.03515  loss_box_reg: 0.086  loss_mask: 0.08355  loss_rpn_cls: 0.004043  loss_rpn_loc: 0.04047  total_val_loss: 0.2404  val_loss_cls: 0.03215  val_loss_box_reg: 0.07653  val_loss_mask: 0.08824  val_loss_rpn_cls: 0.003049  val_loss_rpn_loc: 0.03568    time: 1.6422  last_time: 1.5755  data_time: 0.0073  last_data_time: 0.0065   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:58:25 d2.utils.events]: \u001b[0m eta: 5:32:33  iter: 7299  total_loss: 0.2565  loss_cls: 0.03358  loss_box_reg: 0.08783  loss_mask: 0.08157  loss_rpn_cls: 0.003505  loss_rpn_loc: 0.04187  total_val_loss: 0.2398  val_loss_cls: 0.03206  val_loss_box_reg: 0.07775  val_loss_mask: 0.08637  val_loss_rpn_cls: 0.002847  val_loss_rpn_loc: 0.03554    time: 1.6419  last_time: 1.6813  data_time: 0.0082  last_data_time: 0.0081   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:59:08 d2.utils.events]: \u001b[0m eta: 5:31:45  iter: 7319  total_loss: 0.2613  loss_cls: 0.03307  loss_box_reg: 0.09756  loss_mask: 0.08669  loss_rpn_cls: 0.003909  loss_rpn_loc: 0.04034  total_val_loss: 0.2579  val_loss_cls: 0.04007  val_loss_box_reg: 0.08589  val_loss_mask: 0.08877  val_loss_rpn_cls: 0.002246  val_loss_rpn_loc: 0.0336    time: 1.6416  last_time: 1.5886  data_time: 0.0076  last_data_time: 0.0086   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 18:59:52 d2.utils.events]: \u001b[0m eta: 5:31:02  iter: 7339  total_loss: 0.2786  loss_cls: 0.04446  loss_box_reg: 0.1032  loss_mask: 0.09234  loss_rpn_cls: 0.004329  loss_rpn_loc: 0.04419  total_val_loss: 0.2258  val_loss_cls: 0.03276  val_loss_box_reg: 0.07655  val_loss_mask: 0.08151  val_loss_rpn_cls: 0.002793  val_loss_rpn_loc: 0.03139    time: 1.6412  last_time: 1.4618  data_time: 0.0080  last_data_time: 0.0084   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:00:36 d2.utils.events]: \u001b[0m eta: 5:30:16  iter: 7359  total_loss: 0.2607  loss_cls: 0.03511  loss_box_reg: 0.09088  loss_mask: 0.08904  loss_rpn_cls: 0.004975  loss_rpn_loc: 0.03896  total_val_loss: 0.224  val_loss_cls: 0.03213  val_loss_box_reg: 0.07146  val_loss_mask: 0.08247  val_loss_rpn_cls: 0.00234  val_loss_rpn_loc: 0.03189    time: 1.6409  last_time: 1.5499  data_time: 0.0069  last_data_time: 0.0066   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:01:20 d2.utils.events]: \u001b[0m eta: 5:29:44  iter: 7379  total_loss: 0.2551  loss_cls: 0.03894  loss_box_reg: 0.08906  loss_mask: 0.08199  loss_rpn_cls: 0.004644  loss_rpn_loc: 0.0385  total_val_loss: 0.2154  val_loss_cls: 0.02962  val_loss_box_reg: 0.0762  val_loss_mask: 0.07823  val_loss_rpn_cls: 0.00239  val_loss_rpn_loc: 0.03081    time: 1.6407  last_time: 1.5870  data_time: 0.0071  last_data_time: 0.0085   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:02:04 d2.utils.events]: \u001b[0m eta: 5:29:03  iter: 7399  total_loss: 0.2917  loss_cls: 0.04088  loss_box_reg: 0.1013  loss_mask: 0.08777  loss_rpn_cls: 0.005704  loss_rpn_loc: 0.04551  total_val_loss: 0.2359  val_loss_cls: 0.03215  val_loss_box_reg: 0.0796  val_loss_mask: 0.08686  val_loss_rpn_cls: 0.002414  val_loss_rpn_loc: 0.03329    time: 1.6404  last_time: 1.5234  data_time: 0.0075  last_data_time: 0.0066   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:02:48 d2.utils.events]: \u001b[0m eta: 5:27:58  iter: 7419  total_loss: 0.2497  loss_cls: 0.03534  loss_box_reg: 0.08879  loss_mask: 0.08399  loss_rpn_cls: 0.003373  loss_rpn_loc: 0.04219  total_val_loss: 0.2433  val_loss_cls: 0.03421  val_loss_box_reg: 0.07801  val_loss_mask: 0.09116  val_loss_rpn_cls: 0.002784  val_loss_rpn_loc: 0.03396    time: 1.6401  last_time: 1.4535  data_time: 0.0082  last_data_time: 0.0085   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:03:32 d2.utils.events]: \u001b[0m eta: 5:27:04  iter: 7439  total_loss: 0.2624  loss_cls: 0.0384  loss_box_reg: 0.09304  loss_mask: 0.07837  loss_rpn_cls: 0.004639  loss_rpn_loc: 0.04319  total_val_loss: 0.2336  val_loss_cls: 0.0333  val_loss_box_reg: 0.07748  val_loss_mask: 0.08879  val_loss_rpn_cls: 0.002805  val_loss_rpn_loc: 0.03446    time: 1.6398  last_time: 1.5348  data_time: 0.0076  last_data_time: 0.0070   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:04:15 d2.utils.events]: \u001b[0m eta: 5:25:49  iter: 7459  total_loss: 0.2385  loss_cls: 0.03358  loss_box_reg: 0.08344  loss_mask: 0.08801  loss_rpn_cls: 0.004511  loss_rpn_loc: 0.04095  total_val_loss: 0.249  val_loss_cls: 0.03811  val_loss_box_reg: 0.08478  val_loss_mask: 0.08731  val_loss_rpn_cls: 0.003228  val_loss_rpn_loc: 0.03608    time: 1.6395  last_time: 1.4626  data_time: 0.0070  last_data_time: 0.0071   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:05:00 d2.utils.events]: \u001b[0m eta: 5:24:52  iter: 7479  total_loss: 0.2745  loss_cls: 0.04487  loss_box_reg: 0.09609  loss_mask: 0.08394  loss_rpn_cls: 0.004487  loss_rpn_loc: 0.04306  total_val_loss: 0.2325  val_loss_cls: 0.03118  val_loss_box_reg: 0.07777  val_loss_mask: 0.08589  val_loss_rpn_cls: 0.002587  val_loss_rpn_loc: 0.03449    time: 1.6393  last_time: 1.5281  data_time: 0.0071  last_data_time: 0.0065   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:05:47 d2.utils.events]: \u001b[0m eta: 5:23:52  iter: 7499  total_loss: 0.2475  loss_cls: 0.03426  loss_box_reg: 0.08457  loss_mask: 0.08309  loss_rpn_cls: 0.004452  loss_rpn_loc: 0.03715  total_val_loss: 0.2234  val_loss_cls: 0.0339  val_loss_box_reg: 0.07913  val_loss_mask: 0.08232  val_loss_rpn_cls: 0.002034  val_loss_rpn_loc: 0.03203    time: 1.6393  last_time: 2.1616  data_time: 0.0077  last_data_time: 0.0078   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:06:48 d2.utils.events]: \u001b[0m eta: 5:23:44  iter: 7519  total_loss: 0.2719  loss_cls: 0.03931  loss_box_reg: 0.09887  loss_mask: 0.08862  loss_rpn_cls: 0.004097  loss_rpn_loc: 0.04257  total_val_loss: 0.2314  val_loss_cls: 0.03114  val_loss_box_reg: 0.07635  val_loss_mask: 0.0872  val_loss_rpn_cls: 0.002567  val_loss_rpn_loc: 0.03178    time: 1.6407  last_time: 1.5707  data_time: 0.0079  last_data_time: 0.0074   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:07:48 d2.utils.events]: \u001b[0m eta: 5:23:13  iter: 7539  total_loss: 0.2548  loss_cls: 0.0392  loss_box_reg: 0.08995  loss_mask: 0.08319  loss_rpn_cls: 0.004054  loss_rpn_loc: 0.04208  total_val_loss: 0.218  val_loss_cls: 0.03318  val_loss_box_reg: 0.07084  val_loss_mask: 0.08526  val_loss_rpn_cls: 0.002251  val_loss_rpn_loc: 0.02916    time: 1.6418  last_time: 2.1946  data_time: 0.0074  last_data_time: 0.0079   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:08:45 d2.utils.events]: \u001b[0m eta: 5:22:33  iter: 7559  total_loss: 0.2563  loss_cls: 0.03611  loss_box_reg: 0.08316  loss_mask: 0.08998  loss_rpn_cls: 0.004315  loss_rpn_loc: 0.03818  total_val_loss: 0.2246  val_loss_cls: 0.03394  val_loss_box_reg: 0.07835  val_loss_mask: 0.08887  val_loss_rpn_cls: 0.003214  val_loss_rpn_loc: 0.03424    time: 1.6428  last_time: 1.5004  data_time: 0.0079  last_data_time: 0.0077   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:09:39 d2.utils.events]: \u001b[0m eta: 5:21:51  iter: 7579  total_loss: 0.2443  loss_cls: 0.03521  loss_box_reg: 0.07967  loss_mask: 0.08244  loss_rpn_cls: 0.004409  loss_rpn_loc: 0.04238  total_val_loss: 0.2278  val_loss_cls: 0.03488  val_loss_box_reg: 0.07308  val_loss_mask: 0.08457  val_loss_rpn_cls: 0.003239  val_loss_rpn_loc: 0.03326    time: 1.6434  last_time: 1.6327  data_time: 0.0113  last_data_time: 0.0080   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:10:24 d2.utils.events]: \u001b[0m eta: 5:21:10  iter: 7599  total_loss: 0.2732  loss_cls: 0.03691  loss_box_reg: 0.09683  loss_mask: 0.08032  loss_rpn_cls: 0.003436  loss_rpn_loc: 0.04354  total_val_loss: 0.264  val_loss_cls: 0.03394  val_loss_box_reg: 0.08876  val_loss_mask: 0.09036  val_loss_rpn_cls: 0.002284  val_loss_rpn_loc: 0.03729    time: 1.6432  last_time: 1.6101  data_time: 0.0081  last_data_time: 0.0103   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:11:08 d2.utils.events]: \u001b[0m eta: 5:20:15  iter: 7619  total_loss: 0.2788  loss_cls: 0.04095  loss_box_reg: 0.0983  loss_mask: 0.08524  loss_rpn_cls: 0.004374  loss_rpn_loc: 0.04716  total_val_loss: 0.2275  val_loss_cls: 0.03282  val_loss_box_reg: 0.07606  val_loss_mask: 0.0868  val_loss_rpn_cls: 0.002798  val_loss_rpn_loc: 0.03415    time: 1.6430  last_time: 1.4835  data_time: 0.0077  last_data_time: 0.0072   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:11:54 d2.utils.events]: \u001b[0m eta: 5:19:32  iter: 7639  total_loss: 0.2747  loss_cls: 0.04382  loss_box_reg: 0.1063  loss_mask: 0.07924  loss_rpn_cls: 0.00403  loss_rpn_loc: 0.04694  total_val_loss: 0.2259  val_loss_cls: 0.02948  val_loss_box_reg: 0.07471  val_loss_mask: 0.07887  val_loss_rpn_cls: 0.002358  val_loss_rpn_loc: 0.03677    time: 1.6429  last_time: 1.5265  data_time: 0.0103  last_data_time: 0.0089   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:12:42 d2.utils.events]: \u001b[0m eta: 5:18:57  iter: 7659  total_loss: 0.2745  loss_cls: 0.04219  loss_box_reg: 0.09399  loss_mask: 0.08281  loss_rpn_cls: 0.004136  loss_rpn_loc: 0.04534  total_val_loss: 0.2403  val_loss_cls: 0.03951  val_loss_box_reg: 0.08129  val_loss_mask: 0.08507  val_loss_rpn_cls: 0.002915  val_loss_rpn_loc: 0.03138    time: 1.6429  last_time: 1.6814  data_time: 0.0154  last_data_time: 0.0161   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:13:29 d2.utils.events]: \u001b[0m eta: 5:18:41  iter: 7679  total_loss: 0.2377  loss_cls: 0.03848  loss_box_reg: 0.08306  loss_mask: 0.08088  loss_rpn_cls: 0.005415  loss_rpn_loc: 0.03675  total_val_loss: 0.2263  val_loss_cls: 0.033  val_loss_box_reg: 0.07909  val_loss_mask: 0.0881  val_loss_rpn_cls: 0.00285  val_loss_rpn_loc: 0.03353    time: 1.6428  last_time: 1.6043  data_time: 0.0162  last_data_time: 0.0206   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:14:16 d2.utils.events]: \u001b[0m eta: 5:18:41  iter: 7699  total_loss: 0.2695  loss_cls: 0.0401  loss_box_reg: 0.09467  loss_mask: 0.08425  loss_rpn_cls: 0.004781  loss_rpn_loc: 0.04478  total_val_loss: 0.2367  val_loss_cls: 0.03105  val_loss_box_reg: 0.07463  val_loss_mask: 0.08674  val_loss_rpn_cls: 0.002329  val_loss_rpn_loc: 0.0312    time: 1.6428  last_time: 1.5790  data_time: 0.0166  last_data_time: 0.0140   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:15:04 d2.utils.events]: \u001b[0m eta: 5:18:31  iter: 7719  total_loss: 0.274  loss_cls: 0.04326  loss_box_reg: 0.09696  loss_mask: 0.08087  loss_rpn_cls: 0.003982  loss_rpn_loc: 0.04024  total_val_loss: 0.2381  val_loss_cls: 0.03407  val_loss_box_reg: 0.07545  val_loss_mask: 0.08453  val_loss_rpn_cls: 0.002789  val_loss_rpn_loc: 0.03207    time: 1.6428  last_time: 1.6723  data_time: 0.0176  last_data_time: 0.0187   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:15:51 d2.utils.events]: \u001b[0m eta: 5:18:17  iter: 7739  total_loss: 0.2632  loss_cls: 0.03571  loss_box_reg: 0.08463  loss_mask: 0.07872  loss_rpn_cls: 0.003151  loss_rpn_loc: 0.04415  total_val_loss: 0.2183  val_loss_cls: 0.02966  val_loss_box_reg: 0.07243  val_loss_mask: 0.0889  val_loss_rpn_cls: 0.002697  val_loss_rpn_loc: 0.03512    time: 1.6427  last_time: 1.6351  data_time: 0.0180  last_data_time: 0.0222   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:16:38 d2.utils.events]: \u001b[0m eta: 5:18:04  iter: 7759  total_loss: 0.2786  loss_cls: 0.04002  loss_box_reg: 0.1012  loss_mask: 0.08807  loss_rpn_cls: 0.003769  loss_rpn_loc: 0.046  total_val_loss: 0.25  val_loss_cls: 0.03368  val_loss_box_reg: 0.08455  val_loss_mask: 0.09001  val_loss_rpn_cls: 0.002864  val_loss_rpn_loc: 0.03743    time: 1.6426  last_time: 1.6187  data_time: 0.0173  last_data_time: 0.0216   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:17:26 d2.utils.events]: \u001b[0m eta: 5:18:08  iter: 7779  total_loss: 0.2606  loss_cls: 0.03594  loss_box_reg: 0.08811  loss_mask: 0.08616  loss_rpn_cls: 0.004494  loss_rpn_loc: 0.04386  total_val_loss: 0.2229  val_loss_cls: 0.02974  val_loss_box_reg: 0.07597  val_loss_mask: 0.08374  val_loss_rpn_cls: 0.002826  val_loss_rpn_loc: 0.03222    time: 1.6426  last_time: 1.7160  data_time: 0.0178  last_data_time: 0.0171   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:18:13 d2.utils.events]: \u001b[0m eta: 5:17:56  iter: 7799  total_loss: 0.267  loss_cls: 0.04057  loss_box_reg: 0.09341  loss_mask: 0.08726  loss_rpn_cls: 0.003656  loss_rpn_loc: 0.04078  total_val_loss: 0.2479  val_loss_cls: 0.03091  val_loss_box_reg: 0.08028  val_loss_mask: 0.08885  val_loss_rpn_cls: 0.002335  val_loss_rpn_loc: 0.03302    time: 1.6425  last_time: 1.5617  data_time: 0.0165  last_data_time: 0.0135   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:19:00 d2.utils.events]: \u001b[0m eta: 5:17:48  iter: 7819  total_loss: 0.2596  loss_cls: 0.03933  loss_box_reg: 0.08912  loss_mask: 0.08441  loss_rpn_cls: 0.004499  loss_rpn_loc: 0.0422  total_val_loss: 0.2517  val_loss_cls: 0.03469  val_loss_box_reg: 0.08867  val_loss_mask: 0.08419  val_loss_rpn_cls: 0.003123  val_loss_rpn_loc: 0.03992    time: 1.6425  last_time: 1.6445  data_time: 0.0163  last_data_time: 0.0169   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:19:47 d2.utils.events]: \u001b[0m eta: 5:17:21  iter: 7839  total_loss: 0.2806  loss_cls: 0.03626  loss_box_reg: 0.098  loss_mask: 0.08355  loss_rpn_cls: 0.00441  loss_rpn_loc: 0.04577  total_val_loss: 0.226  val_loss_cls: 0.03229  val_loss_box_reg: 0.07168  val_loss_mask: 0.08158  val_loss_rpn_cls: 0.002675  val_loss_rpn_loc: 0.03282    time: 1.6425  last_time: 1.5213  data_time: 0.0189  last_data_time: 0.0135   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:20:35 d2.utils.events]: \u001b[0m eta: 5:16:54  iter: 7859  total_loss: 0.2381  loss_cls: 0.03742  loss_box_reg: 0.08455  loss_mask: 0.08397  loss_rpn_cls: 0.003915  loss_rpn_loc: 0.03738  total_val_loss: 0.2364  val_loss_cls: 0.03314  val_loss_box_reg: 0.07497  val_loss_mask: 0.08424  val_loss_rpn_cls: 0.002881  val_loss_rpn_loc: 0.03416    time: 1.6424  last_time: 1.7118  data_time: 0.0162  last_data_time: 0.0130   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:21:22 d2.utils.events]: \u001b[0m eta: 5:16:26  iter: 7879  total_loss: 0.251  loss_cls: 0.03551  loss_box_reg: 0.08431  loss_mask: 0.08087  loss_rpn_cls: 0.003795  loss_rpn_loc: 0.04614  total_val_loss: 0.2275  val_loss_cls: 0.03238  val_loss_box_reg: 0.07451  val_loss_mask: 0.08529  val_loss_rpn_cls: 0.002955  val_loss_rpn_loc: 0.03367    time: 1.6424  last_time: 1.5389  data_time: 0.0140  last_data_time: 0.0110   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:22:10 d2.utils.events]: \u001b[0m eta: 5:16:24  iter: 7899  total_loss: 0.2663  loss_cls: 0.04015  loss_box_reg: 0.08914  loss_mask: 0.08734  loss_rpn_cls: 0.003967  loss_rpn_loc: 0.037  total_val_loss: 0.2337  val_loss_cls: 0.03524  val_loss_box_reg: 0.07493  val_loss_mask: 0.08866  val_loss_rpn_cls: 0.002544  val_loss_rpn_loc: 0.03344    time: 1.6424  last_time: 1.6923  data_time: 0.0177  last_data_time: 0.0148   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:22:57 d2.utils.events]: \u001b[0m eta: 5:16:31  iter: 7919  total_loss: 0.2609  loss_cls: 0.0398  loss_box_reg: 0.08667  loss_mask: 0.08216  loss_rpn_cls: 0.003885  loss_rpn_loc: 0.03659  total_val_loss: 0.2185  val_loss_cls: 0.02885  val_loss_box_reg: 0.07233  val_loss_mask: 0.08388  val_loss_rpn_cls: 0.003265  val_loss_rpn_loc: 0.03284    time: 1.6424  last_time: 1.5534  data_time: 0.0184  last_data_time: 0.0221   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:23:45 d2.utils.events]: \u001b[0m eta: 5:16:18  iter: 7939  total_loss: 0.2523  loss_cls: 0.03654  loss_box_reg: 0.08576  loss_mask: 0.08008  loss_rpn_cls: 0.002954  loss_rpn_loc: 0.03865  total_val_loss: 0.2191  val_loss_cls: 0.02815  val_loss_box_reg: 0.06937  val_loss_mask: 0.0823  val_loss_rpn_cls: 0.002264  val_loss_rpn_loc: 0.03137    time: 1.6424  last_time: 1.6878  data_time: 0.0158  last_data_time: 0.0177   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:24:32 d2.utils.events]: \u001b[0m eta: 5:16:10  iter: 7959  total_loss: 0.2295  loss_cls: 0.03005  loss_box_reg: 0.06842  loss_mask: 0.07857  loss_rpn_cls: 0.003422  loss_rpn_loc: 0.03868  total_val_loss: 0.2344  val_loss_cls: 0.03365  val_loss_box_reg: 0.07383  val_loss_mask: 0.08996  val_loss_rpn_cls: 0.002825  val_loss_rpn_loc: 0.03608    time: 1.6423  last_time: 1.6293  data_time: 0.0166  last_data_time: 0.0201   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:25:20 d2.utils.events]: \u001b[0m eta: 5:16:12  iter: 7979  total_loss: 0.2576  loss_cls: 0.04059  loss_box_reg: 0.0969  loss_mask: 0.0868  loss_rpn_cls: 0.004148  loss_rpn_loc: 0.03967  total_val_loss: 0.2342  val_loss_cls: 0.03311  val_loss_box_reg: 0.07612  val_loss_mask: 0.08323  val_loss_rpn_cls: 0.002767  val_loss_rpn_loc: 0.03261    time: 1.6423  last_time: 1.6409  data_time: 0.0164  last_data_time: 0.0143   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:26:09 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\testing_images\\0_SideLane_addedversion_Testing_COCO.json\n",
      "\u001b[32m[09/26 19:26:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/26 19:26:09 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/26 19:26:09 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/26 19:26:09 d2.data.common]: \u001b[0mSerialized dataset takes 6.03 MiB\n",
      "\u001b[32m[09/26 19:26:09 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[09/26 19:26:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 566 batches\n",
      "\u001b[32m[09/26 19:26:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/566. Dataloading: 0.0007 s/iter. Inference: 0.0763 s/iter. Eval: 0.0115 s/iter. Total: 0.0886 s/iter. ETA=0:00:49\n",
      "\u001b[32m[09/26 19:26:17 d2.evaluation.evaluator]: \u001b[0mInference done 72/566. Dataloading: 0.0010 s/iter. Inference: 0.0771 s/iter. Eval: 0.0054 s/iter. Total: 0.0835 s/iter. ETA=0:00:41\n",
      "\u001b[32m[09/26 19:26:22 d2.evaluation.evaluator]: \u001b[0mInference done 131/566. Dataloading: 0.0010 s/iter. Inference: 0.0768 s/iter. Eval: 0.0064 s/iter. Total: 0.0842 s/iter. ETA=0:00:36\n",
      "\u001b[32m[09/26 19:26:28 d2.evaluation.evaluator]: \u001b[0mInference done 190/566. Dataloading: 0.0010 s/iter. Inference: 0.0771 s/iter. Eval: 0.0066 s/iter. Total: 0.0848 s/iter. ETA=0:00:31\n",
      "\u001b[32m[09/26 19:26:33 d2.evaluation.evaluator]: \u001b[0mInference done 249/566. Dataloading: 0.0010 s/iter. Inference: 0.0776 s/iter. Eval: 0.0063 s/iter. Total: 0.0849 s/iter. ETA=0:00:26\n",
      "\u001b[32m[09/26 19:26:38 d2.evaluation.evaluator]: \u001b[0mInference done 308/566. Dataloading: 0.0010 s/iter. Inference: 0.0780 s/iter. Eval: 0.0061 s/iter. Total: 0.0851 s/iter. ETA=0:00:21\n",
      "\u001b[32m[09/26 19:26:43 d2.evaluation.evaluator]: \u001b[0mInference done 370/566. Dataloading: 0.0010 s/iter. Inference: 0.0777 s/iter. Eval: 0.0056 s/iter. Total: 0.0844 s/iter. ETA=0:00:16\n",
      "\u001b[32m[09/26 19:26:48 d2.evaluation.evaluator]: \u001b[0mInference done 434/566. Dataloading: 0.0010 s/iter. Inference: 0.0774 s/iter. Eval: 0.0052 s/iter. Total: 0.0836 s/iter. ETA=0:00:11\n",
      "\u001b[32m[09/26 19:26:53 d2.evaluation.evaluator]: \u001b[0mInference done 489/566. Dataloading: 0.0010 s/iter. Inference: 0.0776 s/iter. Eval: 0.0058 s/iter. Total: 0.0845 s/iter. ETA=0:00:06\n",
      "\u001b[32m[09/26 19:26:58 d2.evaluation.evaluator]: \u001b[0mInference done 547/566. Dataloading: 0.0010 s/iter. Inference: 0.0780 s/iter. Eval: 0.0057 s/iter. Total: 0.0848 s/iter. ETA=0:00:01\n",
      "\u001b[32m[09/26 19:27:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:48.150165 (0.085829 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 19:27:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:43 (0.077987 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 19:27:00 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/26 19:27:00 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\coco_instances_results.json\n",
      "\u001b[32m[09/26 19:27:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.44s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.909\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.913\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.909\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.921\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.935\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.926\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.941\n",
      "\u001b[32m[09/26 19:27:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 90.913 | 99.005 | 98.970 |  nan  | 91.326 | 90.885 |\n",
      "\u001b[32m[09/26 19:27:00 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 19:27:00 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 90.913 | background | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.63s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.856\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.823\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.876\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.877\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.890\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.861\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.909\n",
      "\u001b[32m[09/26 19:27:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 85.631 | 99.005 | 98.974 |  nan  | 82.264 | 87.609 |\n",
      "\u001b[32m[09/26 19:27:01 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 19:27:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 85.631 | background | nan  |\n",
      "\u001b[32m[09/26 19:27:01 d2.engine.defaults]: \u001b[0mEvaluation results for test_data in csv format:\n",
      "\u001b[32m[09/26 19:27:01 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/26 19:27:01 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 19:27:01 d2.evaluation.testing]: \u001b[0mcopypaste: 90.9133,99.0052,98.9702,nan,91.3261,90.8845\n",
      "\u001b[32m[09/26 19:27:01 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/26 19:27:01 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 19:27:01 d2.evaluation.testing]: \u001b[0mcopypaste: 85.6314,99.0052,98.9738,nan,82.2643,87.6094\n",
      "\u001b[32m[09/26 19:27:02 d2.utils.events]: \u001b[0m eta: 5:16:12  iter: 7999  total_loss: 0.2552  loss_cls: 0.03421  loss_box_reg: 0.09017  loss_mask: 0.08074  loss_rpn_cls: 0.003575  loss_rpn_loc: 0.03845  total_val_loss: 0.2483  val_loss_cls: 0.03531  val_loss_box_reg: 0.08265  val_loss_mask: 0.09382  val_loss_rpn_cls: 0.002543  val_loss_rpn_loc: 0.033    time: 1.6423  last_time: 1.6783  data_time: 0.0160  last_data_time: 0.0222   lr: 0.0025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:27:48 d2.utils.events]: \u001b[0m eta: 5:15:53  iter: 8019  total_loss: 0.2417  loss_cls: 0.03277  loss_box_reg: 0.08692  loss_mask: 0.07656  loss_rpn_cls: 0.00288  loss_rpn_loc: 0.03511  total_val_loss: 0.2143  val_loss_cls: 0.03122  val_loss_box_reg: 0.06972  val_loss_mask: 0.08326  val_loss_rpn_cls: 0.002156  val_loss_rpn_loc: 0.02797    time: 1.6421  last_time: 1.6474  data_time: 0.0185  last_data_time: 0.0176   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:28:35 d2.utils.events]: \u001b[0m eta: 5:16:02  iter: 8039  total_loss: 0.2467  loss_cls: 0.03411  loss_box_reg: 0.0821  loss_mask: 0.08143  loss_rpn_cls: 0.003441  loss_rpn_loc: 0.03454  total_val_loss: 0.2206  val_loss_cls: 0.03342  val_loss_box_reg: 0.07397  val_loss_mask: 0.07939  val_loss_rpn_cls: 0.002509  val_loss_rpn_loc: 0.02852    time: 1.6421  last_time: 1.6106  data_time: 0.0188  last_data_time: 0.0196   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:29:23 d2.utils.events]: \u001b[0m eta: 5:16:05  iter: 8059  total_loss: 0.2348  loss_cls: 0.03388  loss_box_reg: 0.0802  loss_mask: 0.08516  loss_rpn_cls: 0.002986  loss_rpn_loc: 0.03584  total_val_loss: 0.2176  val_loss_cls: 0.03315  val_loss_box_reg: 0.0692  val_loss_mask: 0.08622  val_loss_rpn_cls: 0.00235  val_loss_rpn_loc: 0.02525    time: 1.6421  last_time: 1.7343  data_time: 0.0171  last_data_time: 0.0154   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:30:10 d2.utils.events]: \u001b[0m eta: 5:16:01  iter: 8079  total_loss: 0.2491  loss_cls: 0.03798  loss_box_reg: 0.09537  loss_mask: 0.08442  loss_rpn_cls: 0.00448  loss_rpn_loc: 0.03405  total_val_loss: 0.2187  val_loss_cls: 0.02959  val_loss_box_reg: 0.07118  val_loss_mask: 0.08961  val_loss_rpn_cls: 0.002896  val_loss_rpn_loc: 0.0265    time: 1.6421  last_time: 1.6672  data_time: 0.0158  last_data_time: 0.0183   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:30:58 d2.utils.events]: \u001b[0m eta: 5:15:56  iter: 8099  total_loss: 0.2411  loss_cls: 0.03493  loss_box_reg: 0.09538  loss_mask: 0.0794  loss_rpn_cls: 0.004662  loss_rpn_loc: 0.03447  total_val_loss: 0.1972  val_loss_cls: 0.03027  val_loss_box_reg: 0.06273  val_loss_mask: 0.08002  val_loss_rpn_cls: 0.002136  val_loss_rpn_loc: 0.02573    time: 1.6421  last_time: 1.6566  data_time: 0.0158  last_data_time: 0.0144   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:31:45 d2.utils.events]: \u001b[0m eta: 5:15:46  iter: 8119  total_loss: 0.2308  loss_cls: 0.03444  loss_box_reg: 0.08075  loss_mask: 0.07801  loss_rpn_cls: 0.003088  loss_rpn_loc: 0.03193  total_val_loss: 0.2236  val_loss_cls: 0.03214  val_loss_box_reg: 0.07448  val_loss_mask: 0.08754  val_loss_rpn_cls: 0.002192  val_loss_rpn_loc: 0.02567    time: 1.6420  last_time: 1.5506  data_time: 0.0167  last_data_time: 0.0166   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:32:33 d2.utils.events]: \u001b[0m eta: 5:15:30  iter: 8139  total_loss: 0.2505  loss_cls: 0.03961  loss_box_reg: 0.09633  loss_mask: 0.07998  loss_rpn_cls: 0.004443  loss_rpn_loc: 0.03535  total_val_loss: 0.2145  val_loss_cls: 0.03213  val_loss_box_reg: 0.0705  val_loss_mask: 0.08057  val_loss_rpn_cls: 0.003198  val_loss_rpn_loc: 0.02461    time: 1.6420  last_time: 1.6900  data_time: 0.0163  last_data_time: 0.0171   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:33:20 d2.utils.events]: \u001b[0m eta: 5:15:12  iter: 8159  total_loss: 0.2387  loss_cls: 0.03353  loss_box_reg: 0.08532  loss_mask: 0.08109  loss_rpn_cls: 0.004184  loss_rpn_loc: 0.03299  total_val_loss: 0.2102  val_loss_cls: 0.03095  val_loss_box_reg: 0.06686  val_loss_mask: 0.08252  val_loss_rpn_cls: 0.00258  val_loss_rpn_loc: 0.02493    time: 1.6419  last_time: 1.5288  data_time: 0.0174  last_data_time: 0.0239   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:34:07 d2.utils.events]: \u001b[0m eta: 5:14:52  iter: 8179  total_loss: 0.2253  loss_cls: 0.03089  loss_box_reg: 0.07314  loss_mask: 0.07971  loss_rpn_cls: 0.003491  loss_rpn_loc: 0.02992  total_val_loss: 0.2124  val_loss_cls: 0.03029  val_loss_box_reg: 0.06842  val_loss_mask: 0.09021  val_loss_rpn_cls: 0.002455  val_loss_rpn_loc: 0.0245    time: 1.6419  last_time: 1.7436  data_time: 0.0170  last_data_time: 0.0218   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:34:55 d2.utils.events]: \u001b[0m eta: 5:14:51  iter: 8199  total_loss: 0.2275  loss_cls: 0.03064  loss_box_reg: 0.07898  loss_mask: 0.08337  loss_rpn_cls: 0.003055  loss_rpn_loc: 0.02928  total_val_loss: 0.2121  val_loss_cls: 0.02984  val_loss_box_reg: 0.06818  val_loss_mask: 0.08909  val_loss_rpn_cls: 0.002339  val_loss_rpn_loc: 0.02411    time: 1.6419  last_time: 1.6658  data_time: 0.0167  last_data_time: 0.0193   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:35:42 d2.utils.events]: \u001b[0m eta: 5:14:51  iter: 8219  total_loss: 0.2211  loss_cls: 0.03053  loss_box_reg: 0.07748  loss_mask: 0.07737  loss_rpn_cls: 0.003932  loss_rpn_loc: 0.03066  total_val_loss: 0.2269  val_loss_cls: 0.03337  val_loss_box_reg: 0.07145  val_loss_mask: 0.08839  val_loss_rpn_cls: 0.002536  val_loss_rpn_loc: 0.02568    time: 1.6418  last_time: 1.5172  data_time: 0.0156  last_data_time: 0.0162   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:36:29 d2.utils.events]: \u001b[0m eta: 5:14:34  iter: 8239  total_loss: 0.2339  loss_cls: 0.03669  loss_box_reg: 0.08094  loss_mask: 0.08386  loss_rpn_cls: 0.003302  loss_rpn_loc: 0.03165  total_val_loss: 0.2227  val_loss_cls: 0.0344  val_loss_box_reg: 0.07277  val_loss_mask: 0.08681  val_loss_rpn_cls: 0.002491  val_loss_rpn_loc: 0.02695    time: 1.6418  last_time: 1.6109  data_time: 0.0162  last_data_time: 0.0160   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:37:16 d2.utils.events]: \u001b[0m eta: 5:14:17  iter: 8259  total_loss: 0.2222  loss_cls: 0.03212  loss_box_reg: 0.07635  loss_mask: 0.0848  loss_rpn_cls: 0.004029  loss_rpn_loc: 0.02853  total_val_loss: 0.2066  val_loss_cls: 0.0299  val_loss_box_reg: 0.06744  val_loss_mask: 0.08104  val_loss_rpn_cls: 0.002142  val_loss_rpn_loc: 0.02381    time: 1.6417  last_time: 1.6077  data_time: 0.0159  last_data_time: 0.0134   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:38:03 d2.utils.events]: \u001b[0m eta: 5:14:05  iter: 8279  total_loss: 0.1961  loss_cls: 0.02611  loss_box_reg: 0.06213  loss_mask: 0.08186  loss_rpn_cls: 0.002499  loss_rpn_loc: 0.02616  total_val_loss: 0.1908  val_loss_cls: 0.02758  val_loss_box_reg: 0.05809  val_loss_mask: 0.0819  val_loss_rpn_cls: 0.002518  val_loss_rpn_loc: 0.02435    time: 1.6416  last_time: 1.6027  data_time: 0.0162  last_data_time: 0.0216   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:38:50 d2.utils.events]: \u001b[0m eta: 5:13:43  iter: 8299  total_loss: 0.2253  loss_cls: 0.03154  loss_box_reg: 0.07777  loss_mask: 0.07683  loss_rpn_cls: 0.00413  loss_rpn_loc: 0.03132  total_val_loss: 0.2189  val_loss_cls: 0.03309  val_loss_box_reg: 0.07102  val_loss_mask: 0.08368  val_loss_rpn_cls: 0.002507  val_loss_rpn_loc: 0.02466    time: 1.6415  last_time: 1.5029  data_time: 0.0174  last_data_time: 0.0109   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:39:38 d2.utils.events]: \u001b[0m eta: 5:13:28  iter: 8319  total_loss: 0.2531  loss_cls: 0.03914  loss_box_reg: 0.08162  loss_mask: 0.08281  loss_rpn_cls: 0.004368  loss_rpn_loc: 0.0337  total_val_loss: 0.2279  val_loss_cls: 0.03039  val_loss_box_reg: 0.07316  val_loss_mask: 0.09306  val_loss_rpn_cls: 0.001922  val_loss_rpn_loc: 0.02545    time: 1.6415  last_time: 1.4970  data_time: 0.0166  last_data_time: 0.0209   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:40:25 d2.utils.events]: \u001b[0m eta: 5:13:13  iter: 8339  total_loss: 0.2479  loss_cls: 0.0357  loss_box_reg: 0.09101  loss_mask: 0.07415  loss_rpn_cls: 0.00287  loss_rpn_loc: 0.03476  total_val_loss: 0.203  val_loss_cls: 0.02664  val_loss_box_reg: 0.0626  val_loss_mask: 0.08333  val_loss_rpn_cls: 0.001869  val_loss_rpn_loc: 0.02313    time: 1.6415  last_time: 1.7110  data_time: 0.0170  last_data_time: 0.0157   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:41:13 d2.utils.events]: \u001b[0m eta: 5:13:10  iter: 8359  total_loss: 0.217  loss_cls: 0.03054  loss_box_reg: 0.07086  loss_mask: 0.08512  loss_rpn_cls: 0.00336  loss_rpn_loc: 0.02909  total_val_loss: 0.2116  val_loss_cls: 0.027  val_loss_box_reg: 0.07031  val_loss_mask: 0.08667  val_loss_rpn_cls: 0.001939  val_loss_rpn_loc: 0.02547    time: 1.6415  last_time: 1.6211  data_time: 0.0164  last_data_time: 0.0189   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:42:00 d2.utils.events]: \u001b[0m eta: 5:12:53  iter: 8379  total_loss: 0.2405  loss_cls: 0.0348  loss_box_reg: 0.08304  loss_mask: 0.08074  loss_rpn_cls: 0.003705  loss_rpn_loc: 0.02803  total_val_loss: 0.2125  val_loss_cls: 0.03161  val_loss_box_reg: 0.07055  val_loss_mask: 0.08572  val_loss_rpn_cls: 0.001976  val_loss_rpn_loc: 0.02404    time: 1.6415  last_time: 1.6077  data_time: 0.0143  last_data_time: 0.0139   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:42:48 d2.utils.events]: \u001b[0m eta: 5:12:44  iter: 8399  total_loss: 0.242  loss_cls: 0.03578  loss_box_reg: 0.08625  loss_mask: 0.0807  loss_rpn_cls: 0.003462  loss_rpn_loc: 0.03336  total_val_loss: 0.2231  val_loss_cls: 0.03407  val_loss_box_reg: 0.0756  val_loss_mask: 0.08606  val_loss_rpn_cls: 0.001647  val_loss_rpn_loc: 0.02432    time: 1.6415  last_time: 1.5940  data_time: 0.0182  last_data_time: 0.0184   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:43:35 d2.utils.events]: \u001b[0m eta: 5:12:22  iter: 8419  total_loss: 0.2193  loss_cls: 0.02882  loss_box_reg: 0.07496  loss_mask: 0.07913  loss_rpn_cls: 0.00267  loss_rpn_loc: 0.0282  total_val_loss: 0.1932  val_loss_cls: 0.02603  val_loss_box_reg: 0.06237  val_loss_mask: 0.08124  val_loss_rpn_cls: 0.002228  val_loss_rpn_loc: 0.02206    time: 1.6415  last_time: 1.6842  data_time: 0.0181  last_data_time: 0.0156   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:44:23 d2.utils.events]: \u001b[0m eta: 5:12:17  iter: 8439  total_loss: 0.2387  loss_cls: 0.0343  loss_box_reg: 0.08643  loss_mask: 0.08653  loss_rpn_cls: 0.004473  loss_rpn_loc: 0.03342  total_val_loss: 0.2034  val_loss_cls: 0.02868  val_loss_box_reg: 0.06642  val_loss_mask: 0.08142  val_loss_rpn_cls: 0.001589  val_loss_rpn_loc: 0.02333    time: 1.6415  last_time: 1.5536  data_time: 0.0188  last_data_time: 0.0147   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:45:10 d2.utils.events]: \u001b[0m eta: 5:12:01  iter: 8459  total_loss: 0.2023  loss_cls: 0.03083  loss_box_reg: 0.0659  loss_mask: 0.08201  loss_rpn_cls: 0.003152  loss_rpn_loc: 0.02742  total_val_loss: 0.2075  val_loss_cls: 0.02757  val_loss_box_reg: 0.06656  val_loss_mask: 0.08302  val_loss_rpn_cls: 0.001916  val_loss_rpn_loc: 0.02331    time: 1.6414  last_time: 1.5683  data_time: 0.0183  last_data_time: 0.0204   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:45:57 d2.utils.events]: \u001b[0m eta: 5:11:41  iter: 8479  total_loss: 0.2353  loss_cls: 0.03294  loss_box_reg: 0.07857  loss_mask: 0.08215  loss_rpn_cls: 0.004395  loss_rpn_loc: 0.03287  total_val_loss: 0.1967  val_loss_cls: 0.02716  val_loss_box_reg: 0.0661  val_loss_mask: 0.08402  val_loss_rpn_cls: 0.001588  val_loss_rpn_loc: 0.02353    time: 1.6414  last_time: 1.7887  data_time: 0.0153  last_data_time: 0.0213   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:46:44 d2.utils.events]: \u001b[0m eta: 5:11:15  iter: 8499  total_loss: 0.2369  loss_cls: 0.03185  loss_box_reg: 0.08072  loss_mask: 0.09118  loss_rpn_cls: 0.002885  loss_rpn_loc: 0.03245  total_val_loss: 0.2138  val_loss_cls: 0.03058  val_loss_box_reg: 0.06462  val_loss_mask: 0.08682  val_loss_rpn_cls: 0.00303  val_loss_rpn_loc: 0.02214    time: 1.6413  last_time: 1.6182  data_time: 0.0165  last_data_time: 0.0151   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:47:31 d2.utils.events]: \u001b[0m eta: 5:10:23  iter: 8519  total_loss: 0.1965  loss_cls: 0.02715  loss_box_reg: 0.07236  loss_mask: 0.07045  loss_rpn_cls: 0.00397  loss_rpn_loc: 0.02755  total_val_loss: 0.2229  val_loss_cls: 0.03155  val_loss_box_reg: 0.07553  val_loss_mask: 0.08573  val_loss_rpn_cls: 0.00175  val_loss_rpn_loc: 0.026    time: 1.6413  last_time: 1.5803  data_time: 0.0141  last_data_time: 0.0107   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:48:18 d2.utils.events]: \u001b[0m eta: 5:09:30  iter: 8539  total_loss: 0.2022  loss_cls: 0.02686  loss_box_reg: 0.07145  loss_mask: 0.07892  loss_rpn_cls: 0.003288  loss_rpn_loc: 0.02779  total_val_loss: 0.2043  val_loss_cls: 0.03074  val_loss_box_reg: 0.06662  val_loss_mask: 0.0773  val_loss_rpn_cls: 0.002059  val_loss_rpn_loc: 0.0234    time: 1.6411  last_time: 1.5401  data_time: 0.0140  last_data_time: 0.0157   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:49:06 d2.utils.events]: \u001b[0m eta: 5:08:50  iter: 8559  total_loss: 0.2389  loss_cls: 0.02937  loss_box_reg: 0.07382  loss_mask: 0.07944  loss_rpn_cls: 0.002859  loss_rpn_loc: 0.03041  total_val_loss: 0.2063  val_loss_cls: 0.02702  val_loss_box_reg: 0.06803  val_loss_mask: 0.08671  val_loss_rpn_cls: 0.001609  val_loss_rpn_loc: 0.02624    time: 1.6412  last_time: 1.6402  data_time: 0.0148  last_data_time: 0.0168   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:49:53 d2.utils.events]: \u001b[0m eta: 5:08:15  iter: 8579  total_loss: 0.235  loss_cls: 0.03793  loss_box_reg: 0.08733  loss_mask: 0.07711  loss_rpn_cls: 0.004236  loss_rpn_loc: 0.03061  total_val_loss: 0.2053  val_loss_cls: 0.02731  val_loss_box_reg: 0.06949  val_loss_mask: 0.08775  val_loss_rpn_cls: 0.001718  val_loss_rpn_loc: 0.02483    time: 1.6412  last_time: 1.5053  data_time: 0.0134  last_data_time: 0.0131   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:50:40 d2.utils.events]: \u001b[0m eta: 5:07:53  iter: 8599  total_loss: 0.2293  loss_cls: 0.02992  loss_box_reg: 0.0755  loss_mask: 0.07981  loss_rpn_cls: 0.003152  loss_rpn_loc: 0.03018  total_val_loss: 0.2052  val_loss_cls: 0.02858  val_loss_box_reg: 0.06818  val_loss_mask: 0.08225  val_loss_rpn_cls: 0.002162  val_loss_rpn_loc: 0.02378    time: 1.6411  last_time: 1.7416  data_time: 0.0150  last_data_time: 0.0148   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:51:29 d2.utils.events]: \u001b[0m eta: 5:07:44  iter: 8619  total_loss: 0.2525  loss_cls: 0.03626  loss_box_reg: 0.09075  loss_mask: 0.08196  loss_rpn_cls: 0.003199  loss_rpn_loc: 0.03372  total_val_loss: 0.2252  val_loss_cls: 0.03514  val_loss_box_reg: 0.07499  val_loss_mask: 0.08718  val_loss_rpn_cls: 0.002273  val_loss_rpn_loc: 0.02759    time: 1.6412  last_time: 1.7730  data_time: 0.0155  last_data_time: 0.0108   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:52:16 d2.utils.events]: \u001b[0m eta: 5:07:21  iter: 8639  total_loss: 0.2219  loss_cls: 0.0308  loss_box_reg: 0.07562  loss_mask: 0.07654  loss_rpn_cls: 0.002502  loss_rpn_loc: 0.02803  total_val_loss: 0.2144  val_loss_cls: 0.02835  val_loss_box_reg: 0.07018  val_loss_mask: 0.08479  val_loss_rpn_cls: 0.001865  val_loss_rpn_loc: 0.0253    time: 1.6411  last_time: 1.6630  data_time: 0.0149  last_data_time: 0.0139   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:53:03 d2.utils.events]: \u001b[0m eta: 5:06:47  iter: 8659  total_loss: 0.2524  loss_cls: 0.03756  loss_box_reg: 0.08904  loss_mask: 0.08237  loss_rpn_cls: 0.003744  loss_rpn_loc: 0.03442  total_val_loss: 0.2038  val_loss_cls: 0.028  val_loss_box_reg: 0.06748  val_loss_mask: 0.08469  val_loss_rpn_cls: 0.002267  val_loss_rpn_loc: 0.02482    time: 1.6411  last_time: 1.6646  data_time: 0.0159  last_data_time: 0.0154   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:53:51 d2.utils.events]: \u001b[0m eta: 5:06:18  iter: 8679  total_loss: 0.2403  loss_cls: 0.03342  loss_box_reg: 0.08321  loss_mask: 0.08114  loss_rpn_cls: 0.003757  loss_rpn_loc: 0.03397  total_val_loss: 0.214  val_loss_cls: 0.03117  val_loss_box_reg: 0.06708  val_loss_mask: 0.08942  val_loss_rpn_cls: 0.001959  val_loss_rpn_loc: 0.02712    time: 1.6411  last_time: 1.5638  data_time: 0.0147  last_data_time: 0.0227   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:54:38 d2.utils.events]: \u001b[0m eta: 5:06:00  iter: 8699  total_loss: 0.2319  loss_cls: 0.03079  loss_box_reg: 0.07818  loss_mask: 0.08268  loss_rpn_cls: 0.003383  loss_rpn_loc: 0.03119  total_val_loss: 0.2113  val_loss_cls: 0.02973  val_loss_box_reg: 0.06704  val_loss_mask: 0.07929  val_loss_rpn_cls: 0.00164  val_loss_rpn_loc: 0.0247    time: 1.6411  last_time: 1.7970  data_time: 0.0144  last_data_time: 0.0105   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:55:25 d2.utils.events]: \u001b[0m eta: 5:05:12  iter: 8719  total_loss: 0.2145  loss_cls: 0.03383  loss_box_reg: 0.07761  loss_mask: 0.0805  loss_rpn_cls: 0.003093  loss_rpn_loc: 0.02758  total_val_loss: 0.2056  val_loss_cls: 0.03007  val_loss_box_reg: 0.06115  val_loss_mask: 0.08475  val_loss_rpn_cls: 0.002278  val_loss_rpn_loc: 0.02272    time: 1.6411  last_time: 1.6614  data_time: 0.0148  last_data_time: 0.0121   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:56:13 d2.utils.events]: \u001b[0m eta: 5:04:43  iter: 8739  total_loss: 0.2432  loss_cls: 0.03137  loss_box_reg: 0.07587  loss_mask: 0.07911  loss_rpn_cls: 0.003728  loss_rpn_loc: 0.03301  total_val_loss: 0.2055  val_loss_cls: 0.02727  val_loss_box_reg: 0.07001  val_loss_mask: 0.08397  val_loss_rpn_cls: 0.00166  val_loss_rpn_loc: 0.02397    time: 1.6410  last_time: 1.5786  data_time: 0.0146  last_data_time: 0.0155   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:57:00 d2.utils.events]: \u001b[0m eta: 5:04:11  iter: 8759  total_loss: 0.2233  loss_cls: 0.03205  loss_box_reg: 0.07534  loss_mask: 0.08331  loss_rpn_cls: 0.002374  loss_rpn_loc: 0.02539  total_val_loss: 0.2098  val_loss_cls: 0.0274  val_loss_box_reg: 0.06612  val_loss_mask: 0.08042  val_loss_rpn_cls: 0.001859  val_loss_rpn_loc: 0.02406    time: 1.6410  last_time: 1.5924  data_time: 0.0160  last_data_time: 0.0112   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:57:47 d2.utils.events]: \u001b[0m eta: 5:03:35  iter: 8779  total_loss: 0.2174  loss_cls: 0.03279  loss_box_reg: 0.07421  loss_mask: 0.08598  loss_rpn_cls: 0.00236  loss_rpn_loc: 0.03122  total_val_loss: 0.239  val_loss_cls: 0.03704  val_loss_box_reg: 0.07424  val_loss_mask: 0.08409  val_loss_rpn_cls: 0.001165  val_loss_rpn_loc: 0.02371    time: 1.6409  last_time: 1.5317  data_time: 0.0128  last_data_time: 0.0159   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:58:35 d2.utils.events]: \u001b[0m eta: 5:03:17  iter: 8799  total_loss: 0.2305  loss_cls: 0.03283  loss_box_reg: 0.07997  loss_mask: 0.08471  loss_rpn_cls: 0.002666  loss_rpn_loc: 0.03051  total_val_loss: 0.1984  val_loss_cls: 0.03057  val_loss_box_reg: 0.06577  val_loss_mask: 0.07482  val_loss_rpn_cls: 0.001686  val_loss_rpn_loc: 0.02251    time: 1.6409  last_time: 1.6919  data_time: 0.0157  last_data_time: 0.0158   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 19:59:22 d2.utils.events]: \u001b[0m eta: 5:02:43  iter: 8819  total_loss: 0.222  loss_cls: 0.03253  loss_box_reg: 0.07826  loss_mask: 0.07683  loss_rpn_cls: 0.003567  loss_rpn_loc: 0.02782  total_val_loss: 0.2138  val_loss_cls: 0.0317  val_loss_box_reg: 0.06418  val_loss_mask: 0.08794  val_loss_rpn_cls: 0.001403  val_loss_rpn_loc: 0.02428    time: 1.6408  last_time: 1.6706  data_time: 0.0147  last_data_time: 0.0207   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:00:09 d2.utils.events]: \u001b[0m eta: 5:02:10  iter: 8839  total_loss: 0.2198  loss_cls: 0.03386  loss_box_reg: 0.07469  loss_mask: 0.07743  loss_rpn_cls: 0.002824  loss_rpn_loc: 0.02915  total_val_loss: 0.207  val_loss_cls: 0.02904  val_loss_box_reg: 0.07016  val_loss_mask: 0.08516  val_loss_rpn_cls: 0.002527  val_loss_rpn_loc: 0.02505    time: 1.6408  last_time: 1.5898  data_time: 0.0138  last_data_time: 0.0142   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:00:55 d2.utils.events]: \u001b[0m eta: 5:01:24  iter: 8859  total_loss: 0.2183  loss_cls: 0.03101  loss_box_reg: 0.06999  loss_mask: 0.07608  loss_rpn_cls: 0.00266  loss_rpn_loc: 0.02837  total_val_loss: 0.2105  val_loss_cls: 0.03155  val_loss_box_reg: 0.07097  val_loss_mask: 0.08565  val_loss_rpn_cls: 0.001792  val_loss_rpn_loc: 0.0244    time: 1.6407  last_time: 1.5774  data_time: 0.0128  last_data_time: 0.0090   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:01:51 d2.utils.events]: \u001b[0m eta: 5:00:55  iter: 8879  total_loss: 0.2345  loss_cls: 0.03175  loss_box_reg: 0.08057  loss_mask: 0.08203  loss_rpn_cls: 0.002944  loss_rpn_loc: 0.03202  total_val_loss: 0.2041  val_loss_cls: 0.0286  val_loss_box_reg: 0.06126  val_loss_mask: 0.0861  val_loss_rpn_cls: 0.001495  val_loss_rpn_loc: 0.02289    time: 1.6413  last_time: 1.5658  data_time: 0.0091  last_data_time: 0.0119   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:02:48 d2.utils.events]: \u001b[0m eta: 5:00:42  iter: 8899  total_loss: 0.2283  loss_cls: 0.03172  loss_box_reg: 0.08131  loss_mask: 0.08454  loss_rpn_cls: 0.003198  loss_rpn_loc: 0.02859  total_val_loss: 0.1896  val_loss_cls: 0.02434  val_loss_box_reg: 0.05988  val_loss_mask: 0.0837  val_loss_rpn_cls: 0.001296  val_loss_rpn_loc: 0.02151    time: 1.6422  last_time: 1.9312  data_time: 0.0088  last_data_time: 0.0089   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:03:45 d2.utils.events]: \u001b[0m eta: 5:00:19  iter: 8919  total_loss: 0.2078  loss_cls: 0.02503  loss_box_reg: 0.06284  loss_mask: 0.07667  loss_rpn_cls: 0.002135  loss_rpn_loc: 0.02627  total_val_loss: 0.2181  val_loss_cls: 0.03328  val_loss_box_reg: 0.07263  val_loss_mask: 0.08261  val_loss_rpn_cls: 0.001969  val_loss_rpn_loc: 0.02643    time: 1.6429  last_time: 1.5655  data_time: 0.0076  last_data_time: 0.0065   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:04:45 d2.utils.events]: \u001b[0m eta: 4:59:55  iter: 8939  total_loss: 0.2438  loss_cls: 0.0331  loss_box_reg: 0.08454  loss_mask: 0.08487  loss_rpn_cls: 0.003191  loss_rpn_loc: 0.02913  total_val_loss: 0.2301  val_loss_cls: 0.03395  val_loss_box_reg: 0.07346  val_loss_mask: 0.09142  val_loss_rpn_cls: 0.002127  val_loss_rpn_loc: 0.0256    time: 1.6438  last_time: 2.0338  data_time: 0.0081  last_data_time: 0.0073   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:05:44 d2.utils.events]: \u001b[0m eta: 4:59:44  iter: 8959  total_loss: 0.225  loss_cls: 0.03027  loss_box_reg: 0.07644  loss_mask: 0.08196  loss_rpn_cls: 0.003327  loss_rpn_loc: 0.0358  total_val_loss: 0.2054  val_loss_cls: 0.02885  val_loss_box_reg: 0.06334  val_loss_mask: 0.07951  val_loss_rpn_cls: 0.001783  val_loss_rpn_loc: 0.02399    time: 1.6449  last_time: 2.1092  data_time: 0.0084  last_data_time: 0.0084   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:06:40 d2.utils.events]: \u001b[0m eta: 4:59:14  iter: 8979  total_loss: 0.2282  loss_cls: 0.03121  loss_box_reg: 0.07944  loss_mask: 0.08003  loss_rpn_cls: 0.00217  loss_rpn_loc: 0.03253  total_val_loss: 0.203  val_loss_cls: 0.0298  val_loss_box_reg: 0.06151  val_loss_mask: 0.08139  val_loss_rpn_cls: 0.001462  val_loss_rpn_loc: 0.02149    time: 1.6458  last_time: 1.5556  data_time: 0.0074  last_data_time: 0.0067   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:07:28 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\testing_images\\0_SideLane_addedversion_Testing_COCO.json\n",
      "\u001b[32m[09/26 20:07:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/26 20:07:28 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/26 20:07:28 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/26 20:07:28 d2.data.common]: \u001b[0mSerialized dataset takes 6.03 MiB\n",
      "\u001b[32m[09/26 20:07:28 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[09/26 20:07:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 566 batches\n",
      "\u001b[32m[09/26 20:07:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/566. Dataloading: 0.0004 s/iter. Inference: 0.0898 s/iter. Eval: 0.0073 s/iter. Total: 0.0976 s/iter. ETA=0:00:54\n",
      "\u001b[32m[09/26 20:07:37 d2.evaluation.evaluator]: \u001b[0mInference done 53/566. Dataloading: 0.0006 s/iter. Inference: 0.1127 s/iter. Eval: 0.0037 s/iter. Total: 0.1170 s/iter. ETA=0:01:00\n",
      "\u001b[32m[09/26 20:07:42 d2.evaluation.evaluator]: \u001b[0mInference done 98/566. Dataloading: 0.0006 s/iter. Inference: 0.1110 s/iter. Eval: 0.0031 s/iter. Total: 0.1148 s/iter. ETA=0:00:53\n",
      "\u001b[32m[09/26 20:07:47 d2.evaluation.evaluator]: \u001b[0mInference done 143/566. Dataloading: 0.0006 s/iter. Inference: 0.1096 s/iter. Eval: 0.0039 s/iter. Total: 0.1142 s/iter. ETA=0:00:48\n",
      "\u001b[32m[09/26 20:07:52 d2.evaluation.evaluator]: \u001b[0mInference done 189/566. Dataloading: 0.0007 s/iter. Inference: 0.1084 s/iter. Eval: 0.0040 s/iter. Total: 0.1131 s/iter. ETA=0:00:42\n",
      "\u001b[32m[09/26 20:07:57 d2.evaluation.evaluator]: \u001b[0mInference done 237/566. Dataloading: 0.0008 s/iter. Inference: 0.1061 s/iter. Eval: 0.0046 s/iter. Total: 0.1115 s/iter. ETA=0:00:36\n",
      "\u001b[32m[09/26 20:08:02 d2.evaluation.evaluator]: \u001b[0mInference done 277/566. Dataloading: 0.0008 s/iter. Inference: 0.1078 s/iter. Eval: 0.0049 s/iter. Total: 0.1136 s/iter. ETA=0:00:32\n",
      "\u001b[32m[09/26 20:08:07 d2.evaluation.evaluator]: \u001b[0mInference done 322/566. Dataloading: 0.0009 s/iter. Inference: 0.1077 s/iter. Eval: 0.0048 s/iter. Total: 0.1135 s/iter. ETA=0:00:27\n",
      "\u001b[32m[09/26 20:08:12 d2.evaluation.evaluator]: \u001b[0mInference done 368/566. Dataloading: 0.0009 s/iter. Inference: 0.1076 s/iter. Eval: 0.0046 s/iter. Total: 0.1132 s/iter. ETA=0:00:22\n",
      "\u001b[32m[09/26 20:08:17 d2.evaluation.evaluator]: \u001b[0mInference done 420/566. Dataloading: 0.0010 s/iter. Inference: 0.1057 s/iter. Eval: 0.0044 s/iter. Total: 0.1111 s/iter. ETA=0:00:16\n",
      "\u001b[32m[09/26 20:08:22 d2.evaluation.evaluator]: \u001b[0mInference done 464/566. Dataloading: 0.0010 s/iter. Inference: 0.1054 s/iter. Eval: 0.0052 s/iter. Total: 0.1116 s/iter. ETA=0:00:11\n",
      "\u001b[32m[09/26 20:08:28 d2.evaluation.evaluator]: \u001b[0mInference done 509/566. Dataloading: 0.0010 s/iter. Inference: 0.1054 s/iter. Eval: 0.0052 s/iter. Total: 0.1116 s/iter. ETA=0:00:06\n",
      "\u001b[32m[09/26 20:08:33 d2.evaluation.evaluator]: \u001b[0mInference done 551/566. Dataloading: 0.0010 s/iter. Inference: 0.1059 s/iter. Eval: 0.0053 s/iter. Total: 0.1123 s/iter. ETA=0:00:01\n",
      "\u001b[32m[09/26 20:08:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:03.173218 (0.112608 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 20:08:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:58 (0.105150 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 20:08:34 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/26 20:08:34 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\coco_instances_results.json\n",
      "\u001b[32m[09/26 20:08:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.53s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.932\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.933\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.934\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.935\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.950\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.941\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.956\n",
      "\u001b[32m[09/26 20:08:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 93.162 | 99.007 | 98.978 |  nan  | 93.323 | 93.358 |\n",
      "\u001b[32m[09/26 20:08:35 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 20:08:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 93.162 | background | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.72s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.859\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.829\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.881\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.879\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.893\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.864\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.912\n",
      "\u001b[32m[09/26 20:08:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 85.887 | 99.007 | 98.962 |  nan  | 82.913 | 88.055 |\n",
      "\u001b[32m[09/26 20:08:36 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 20:08:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 85.887 | background | nan  |\n",
      "\u001b[32m[09/26 20:08:36 d2.engine.defaults]: \u001b[0mEvaluation results for test_data in csv format:\n",
      "\u001b[32m[09/26 20:08:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/26 20:08:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 20:08:36 d2.evaluation.testing]: \u001b[0mcopypaste: 93.1621,99.0066,98.9780,nan,93.3234,93.3578\n",
      "\u001b[32m[09/26 20:08:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/26 20:08:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 20:08:36 d2.evaluation.testing]: \u001b[0mcopypaste: 85.8872,99.0066,98.9617,nan,82.9127,88.0546\n",
      "\u001b[32m[09/26 20:08:37 d2.utils.events]: \u001b[0m eta: 4:58:37  iter: 8999  total_loss: 0.2348  loss_cls: 0.03431  loss_box_reg: 0.07756  loss_mask: 0.08131  loss_rpn_cls: 0.002113  loss_rpn_loc: 0.0288  total_val_loss: 0.1732  val_loss_cls: 0.02247  val_loss_box_reg: 0.05178  val_loss_mask: 0.07991  val_loss_rpn_cls: 0.001431  val_loss_rpn_loc: 0.02102    time: 1.6458  last_time: 2.2789  data_time: 0.0076  last_data_time: 0.0083   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:09:42 d2.utils.events]: \u001b[0m eta: 4:58:28  iter: 9019  total_loss: 0.2358  loss_cls: 0.0322  loss_box_reg: 0.07953  loss_mask: 0.08033  loss_rpn_cls: 0.00361  loss_rpn_loc: 0.03199  total_val_loss: 0.2101  val_loss_cls: 0.0289  val_loss_box_reg: 0.06923  val_loss_mask: 0.08231  val_loss_rpn_cls: 0.001242  val_loss_rpn_loc: 0.02621    time: 1.6472  last_time: 2.0951  data_time: 0.0139  last_data_time: 0.0114   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:10:37 d2.utils.events]: \u001b[0m eta: 4:58:19  iter: 9039  total_loss: 0.2324  loss_cls: 0.03138  loss_box_reg: 0.08245  loss_mask: 0.07674  loss_rpn_cls: 0.003077  loss_rpn_loc: 0.03399  total_val_loss: 0.2135  val_loss_cls: 0.03206  val_loss_box_reg: 0.07117  val_loss_mask: 0.08763  val_loss_rpn_cls: 0.001937  val_loss_rpn_loc: 0.02359    time: 1.6477  last_time: 1.7537  data_time: 0.0175  last_data_time: 0.0185   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:11:24 d2.utils.events]: \u001b[0m eta: 4:57:23  iter: 9059  total_loss: 0.2426  loss_cls: 0.03361  loss_box_reg: 0.08698  loss_mask: 0.0833  loss_rpn_cls: 0.003021  loss_rpn_loc: 0.03436  total_val_loss: 0.2081  val_loss_cls: 0.02639  val_loss_box_reg: 0.06535  val_loss_mask: 0.08946  val_loss_rpn_cls: 0.002367  val_loss_rpn_loc: 0.0236    time: 1.6476  last_time: 1.7326  data_time: 0.0149  last_data_time: 0.0161   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:12:10 d2.utils.events]: \u001b[0m eta: 4:56:50  iter: 9079  total_loss: 0.2058  loss_cls: 0.02699  loss_box_reg: 0.06291  loss_mask: 0.07535  loss_rpn_cls: 0.002662  loss_rpn_loc: 0.02894  total_val_loss: 0.2234  val_loss_cls: 0.03333  val_loss_box_reg: 0.07165  val_loss_mask: 0.08491  val_loss_rpn_cls: 0.002055  val_loss_rpn_loc: 0.02619    time: 1.6475  last_time: 1.6741  data_time: 0.0149  last_data_time: 0.0193   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:12:57 d2.utils.events]: \u001b[0m eta: 4:56:11  iter: 9099  total_loss: 0.2122  loss_cls: 0.03021  loss_box_reg: 0.07083  loss_mask: 0.07459  loss_rpn_cls: 0.003739  loss_rpn_loc: 0.02972  total_val_loss: 0.2061  val_loss_cls: 0.02881  val_loss_box_reg: 0.07204  val_loss_mask: 0.08011  val_loss_rpn_cls: 0.001204  val_loss_rpn_loc: 0.02401    time: 1.6474  last_time: 1.7193  data_time: 0.0167  last_data_time: 0.0173   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:13:43 d2.utils.events]: \u001b[0m eta: 4:55:36  iter: 9119  total_loss: 0.2187  loss_cls: 0.03171  loss_box_reg: 0.0756  loss_mask: 0.07817  loss_rpn_cls: 0.001876  loss_rpn_loc: 0.02714  total_val_loss: 0.2061  val_loss_cls: 0.02927  val_loss_box_reg: 0.06467  val_loss_mask: 0.08512  val_loss_rpn_cls: 0.001824  val_loss_rpn_loc: 0.02216    time: 1.6473  last_time: 1.5781  data_time: 0.0152  last_data_time: 0.0087   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:14:29 d2.utils.events]: \u001b[0m eta: 4:54:52  iter: 9139  total_loss: 0.2292  loss_cls: 0.03209  loss_box_reg: 0.07559  loss_mask: 0.0818  loss_rpn_cls: 0.004026  loss_rpn_loc: 0.0303  total_val_loss: 0.2091  val_loss_cls: 0.02943  val_loss_box_reg: 0.07007  val_loss_mask: 0.08578  val_loss_rpn_cls: 0.001437  val_loss_rpn_loc: 0.02612    time: 1.6472  last_time: 1.5411  data_time: 0.0118  last_data_time: 0.0134   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:15:16 d2.utils.events]: \u001b[0m eta: 4:54:16  iter: 9159  total_loss: 0.2318  loss_cls: 0.03348  loss_box_reg: 0.08046  loss_mask: 0.08153  loss_rpn_cls: 0.00345  loss_rpn_loc: 0.02907  total_val_loss: 0.1948  val_loss_cls: 0.0277  val_loss_box_reg: 0.0651  val_loss_mask: 0.07691  val_loss_rpn_cls: 0.00108  val_loss_rpn_loc: 0.02389    time: 1.6470  last_time: 1.6879  data_time: 0.0147  last_data_time: 0.0183   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:16:02 d2.utils.events]: \u001b[0m eta: 4:53:27  iter: 9179  total_loss: 0.2052  loss_cls: 0.02737  loss_box_reg: 0.06786  loss_mask: 0.08145  loss_rpn_cls: 0.001856  loss_rpn_loc: 0.02615  total_val_loss: 0.1874  val_loss_cls: 0.02263  val_loss_box_reg: 0.06215  val_loss_mask: 0.08497  val_loss_rpn_cls: 0.001864  val_loss_rpn_loc: 0.02306    time: 1.6469  last_time: 1.7904  data_time: 0.0142  last_data_time: 0.0176   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:16:48 d2.utils.events]: \u001b[0m eta: 4:52:34  iter: 9199  total_loss: 0.2196  loss_cls: 0.03027  loss_box_reg: 0.07115  loss_mask: 0.07824  loss_rpn_cls: 0.002843  loss_rpn_loc: 0.0318  total_val_loss: 0.2026  val_loss_cls: 0.03264  val_loss_box_reg: 0.069  val_loss_mask: 0.0836  val_loss_rpn_cls: 0.001702  val_loss_rpn_loc: 0.02582    time: 1.6467  last_time: 1.5880  data_time: 0.0129  last_data_time: 0.0112   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:17:34 d2.utils.events]: \u001b[0m eta: 4:51:58  iter: 9219  total_loss: 0.2325  loss_cls: 0.03187  loss_box_reg: 0.07845  loss_mask: 0.08614  loss_rpn_cls: 0.003053  loss_rpn_loc: 0.02883  total_val_loss: 0.2184  val_loss_cls: 0.03267  val_loss_box_reg: 0.07552  val_loss_mask: 0.08585  val_loss_rpn_cls: 0.00127  val_loss_rpn_loc: 0.02529    time: 1.6466  last_time: 1.5833  data_time: 0.0116  last_data_time: 0.0115   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:18:21 d2.utils.events]: \u001b[0m eta: 4:51:29  iter: 9239  total_loss: 0.2374  loss_cls: 0.03393  loss_box_reg: 0.07882  loss_mask: 0.08184  loss_rpn_cls: 0.002388  loss_rpn_loc: 0.03482  total_val_loss: 0.2068  val_loss_cls: 0.02354  val_loss_box_reg: 0.0607  val_loss_mask: 0.08832  val_loss_rpn_cls: 0.001847  val_loss_rpn_loc: 0.02135    time: 1.6465  last_time: 1.5884  data_time: 0.0107  last_data_time: 0.0099   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:19:07 d2.utils.events]: \u001b[0m eta: 4:50:53  iter: 9259  total_loss: 0.2027  loss_cls: 0.02608  loss_box_reg: 0.0674  loss_mask: 0.07651  loss_rpn_cls: 0.002096  loss_rpn_loc: 0.02568  total_val_loss: 0.2077  val_loss_cls: 0.02909  val_loss_box_reg: 0.06747  val_loss_mask: 0.08199  val_loss_rpn_cls: 0.001629  val_loss_rpn_loc: 0.02503    time: 1.6464  last_time: 1.5903  data_time: 0.0112  last_data_time: 0.0107   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:19:52 d2.utils.events]: \u001b[0m eta: 4:50:12  iter: 9279  total_loss: 0.2277  loss_cls: 0.02928  loss_box_reg: 0.07826  loss_mask: 0.08115  loss_rpn_cls: 0.002485  loss_rpn_loc: 0.02753  total_val_loss: 0.2058  val_loss_cls: 0.02944  val_loss_box_reg: 0.06418  val_loss_mask: 0.08708  val_loss_rpn_cls: 0.001453  val_loss_rpn_loc: 0.02265    time: 1.6462  last_time: 1.6104  data_time: 0.0107  last_data_time: 0.0094   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:20:36 d2.utils.events]: \u001b[0m eta: 4:49:33  iter: 9299  total_loss: 0.2215  loss_cls: 0.03102  loss_box_reg: 0.07349  loss_mask: 0.08228  loss_rpn_cls: 0.003523  loss_rpn_loc: 0.0307  total_val_loss: 0.1874  val_loss_cls: 0.02692  val_loss_box_reg: 0.06159  val_loss_mask: 0.08339  val_loss_rpn_cls: 0.001551  val_loss_rpn_loc: 0.0234    time: 1.6460  last_time: 1.5451  data_time: 0.0083  last_data_time: 0.0095   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:21:20 d2.utils.events]: \u001b[0m eta: 4:48:44  iter: 9319  total_loss: 0.2091  loss_cls: 0.02905  loss_box_reg: 0.07266  loss_mask: 0.08033  loss_rpn_cls: 0.002253  loss_rpn_loc: 0.02739  total_val_loss: 0.2007  val_loss_cls: 0.02778  val_loss_box_reg: 0.0609  val_loss_mask: 0.08375  val_loss_rpn_cls: 0.001327  val_loss_rpn_loc: 0.02191    time: 1.6457  last_time: 1.6091  data_time: 0.0075  last_data_time: 0.0066   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:22:04 d2.utils.events]: \u001b[0m eta: 4:47:50  iter: 9339  total_loss: 0.2127  loss_cls: 0.02632  loss_box_reg: 0.0666  loss_mask: 0.08144  loss_rpn_cls: 0.00171  loss_rpn_loc: 0.02475  total_val_loss: 0.2212  val_loss_cls: 0.03195  val_loss_box_reg: 0.06976  val_loss_mask: 0.08626  val_loss_rpn_cls: 0.001599  val_loss_rpn_loc: 0.02386    time: 1.6455  last_time: 1.4691  data_time: 0.0079  last_data_time: 0.0105   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:22:48 d2.utils.events]: \u001b[0m eta: 4:46:45  iter: 9359  total_loss: 0.2304  loss_cls: 0.02855  loss_box_reg: 0.08351  loss_mask: 0.08276  loss_rpn_cls: 0.00249  loss_rpn_loc: 0.03208  total_val_loss: 0.2037  val_loss_cls: 0.02871  val_loss_box_reg: 0.0677  val_loss_mask: 0.07896  val_loss_rpn_cls: 0.001639  val_loss_rpn_loc: 0.02585    time: 1.6453  last_time: 1.6735  data_time: 0.0081  last_data_time: 0.0066   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:23:32 d2.utils.events]: \u001b[0m eta: 4:45:53  iter: 9379  total_loss: 0.21  loss_cls: 0.02536  loss_box_reg: 0.06635  loss_mask: 0.08026  loss_rpn_cls: 0.001704  loss_rpn_loc: 0.02739  total_val_loss: 0.2091  val_loss_cls: 0.02777  val_loss_box_reg: 0.06397  val_loss_mask: 0.09379  val_loss_rpn_cls: 0.001492  val_loss_rpn_loc: 0.02419    time: 1.6451  last_time: 1.5935  data_time: 0.0076  last_data_time: 0.0070   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:24:16 d2.utils.events]: \u001b[0m eta: 4:45:03  iter: 9399  total_loss: 0.2185  loss_cls: 0.03068  loss_box_reg: 0.07189  loss_mask: 0.08105  loss_rpn_cls: 0.002471  loss_rpn_loc: 0.03019  total_val_loss: 0.2026  val_loss_cls: 0.02696  val_loss_box_reg: 0.06517  val_loss_mask: 0.08436  val_loss_rpn_cls: 0.001732  val_loss_rpn_loc: 0.02418    time: 1.6448  last_time: 1.4983  data_time: 0.0069  last_data_time: 0.0064   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:25:00 d2.utils.events]: \u001b[0m eta: 4:44:11  iter: 9419  total_loss: 0.2286  loss_cls: 0.03143  loss_box_reg: 0.07899  loss_mask: 0.08017  loss_rpn_cls: 0.003061  loss_rpn_loc: 0.03018  total_val_loss: 0.1921  val_loss_cls: 0.02724  val_loss_box_reg: 0.06337  val_loss_mask: 0.08043  val_loss_rpn_cls: 0.001417  val_loss_rpn_loc: 0.02275    time: 1.6446  last_time: 1.5043  data_time: 0.0079  last_data_time: 0.0080   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:25:43 d2.utils.events]: \u001b[0m eta: 4:43:08  iter: 9439  total_loss: 0.2198  loss_cls: 0.02912  loss_box_reg: 0.0727  loss_mask: 0.07932  loss_rpn_cls: 0.003024  loss_rpn_loc: 0.02549  total_val_loss: 0.2059  val_loss_cls: 0.02976  val_loss_box_reg: 0.06845  val_loss_mask: 0.08867  val_loss_rpn_cls: 0.001644  val_loss_rpn_loc: 0.02464    time: 1.6444  last_time: 1.4801  data_time: 0.0079  last_data_time: 0.0078   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:26:27 d2.utils.events]: \u001b[0m eta: 4:42:25  iter: 9459  total_loss: 0.2004  loss_cls: 0.02913  loss_box_reg: 0.06724  loss_mask: 0.07348  loss_rpn_cls: 0.003043  loss_rpn_loc: 0.02754  total_val_loss: 0.2018  val_loss_cls: 0.02866  val_loss_box_reg: 0.06207  val_loss_mask: 0.08064  val_loss_rpn_cls: 0.001281  val_loss_rpn_loc: 0.02148    time: 1.6441  last_time: 1.5370  data_time: 0.0072  last_data_time: 0.0074   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:27:11 d2.utils.events]: \u001b[0m eta: 4:41:33  iter: 9479  total_loss: 0.2422  loss_cls: 0.03317  loss_box_reg: 0.0796  loss_mask: 0.07953  loss_rpn_cls: 0.003683  loss_rpn_loc: 0.03267  total_val_loss: 0.2016  val_loss_cls: 0.02961  val_loss_box_reg: 0.0625  val_loss_mask: 0.08123  val_loss_rpn_cls: 0.002069  val_loss_rpn_loc: 0.02316    time: 1.6439  last_time: 1.4828  data_time: 0.0079  last_data_time: 0.0063   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:27:55 d2.utils.events]: \u001b[0m eta: 4:40:35  iter: 9499  total_loss: 0.2386  loss_cls: 0.03374  loss_box_reg: 0.07853  loss_mask: 0.07774  loss_rpn_cls: 0.002855  loss_rpn_loc: 0.03079  total_val_loss: 0.2165  val_loss_cls: 0.03084  val_loss_box_reg: 0.0689  val_loss_mask: 0.08534  val_loss_rpn_cls: 0.001381  val_loss_rpn_loc: 0.02441    time: 1.6437  last_time: 1.4435  data_time: 0.0077  last_data_time: 0.0074   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:28:39 d2.utils.events]: \u001b[0m eta: 4:39:51  iter: 9519  total_loss: 0.2204  loss_cls: 0.02918  loss_box_reg: 0.07476  loss_mask: 0.07979  loss_rpn_cls: 0.001916  loss_rpn_loc: 0.03247  total_val_loss: 0.2163  val_loss_cls: 0.03093  val_loss_box_reg: 0.06917  val_loss_mask: 0.08468  val_loss_rpn_cls: 0.002147  val_loss_rpn_loc: 0.02491    time: 1.6435  last_time: 1.5241  data_time: 0.0075  last_data_time: 0.0059   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:29:23 d2.utils.events]: \u001b[0m eta: 4:38:58  iter: 9539  total_loss: 0.2318  loss_cls: 0.03159  loss_box_reg: 0.07813  loss_mask: 0.07771  loss_rpn_cls: 0.003131  loss_rpn_loc: 0.03233  total_val_loss: 0.2019  val_loss_cls: 0.03011  val_loss_box_reg: 0.06546  val_loss_mask: 0.08416  val_loss_rpn_cls: 0.001075  val_loss_rpn_loc: 0.0247    time: 1.6433  last_time: 1.5341  data_time: 0.0076  last_data_time: 0.0085   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:30:07 d2.utils.events]: \u001b[0m eta: 4:38:00  iter: 9559  total_loss: 0.2094  loss_cls: 0.03007  loss_box_reg: 0.07661  loss_mask: 0.07908  loss_rpn_cls: 0.0026  loss_rpn_loc: 0.02742  total_val_loss: 0.1841  val_loss_cls: 0.0264  val_loss_box_reg: 0.05429  val_loss_mask: 0.08269  val_loss_rpn_cls: 0.001915  val_loss_rpn_loc: 0.0206    time: 1.6431  last_time: 1.4755  data_time: 0.0072  last_data_time: 0.0076   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:30:51 d2.utils.events]: \u001b[0m eta: 4:37:01  iter: 9579  total_loss: 0.2271  loss_cls: 0.03266  loss_box_reg: 0.0796  loss_mask: 0.07966  loss_rpn_cls: 0.002369  loss_rpn_loc: 0.031  total_val_loss: 0.2162  val_loss_cls: 0.03041  val_loss_box_reg: 0.06733  val_loss_mask: 0.08792  val_loss_rpn_cls: 0.00171  val_loss_rpn_loc: 0.02318    time: 1.6429  last_time: 1.5670  data_time: 0.0071  last_data_time: 0.0068   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:31:35 d2.utils.events]: \u001b[0m eta: 4:36:11  iter: 9599  total_loss: 0.2014  loss_cls: 0.02764  loss_box_reg: 0.06315  loss_mask: 0.07387  loss_rpn_cls: 0.002377  loss_rpn_loc: 0.02877  total_val_loss: 0.2096  val_loss_cls: 0.02853  val_loss_box_reg: 0.06646  val_loss_mask: 0.08248  val_loss_rpn_cls: 0.001367  val_loss_rpn_loc: 0.02303    time: 1.6426  last_time: 1.5845  data_time: 0.0071  last_data_time: 0.0070   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:32:18 d2.utils.events]: \u001b[0m eta: 4:34:57  iter: 9619  total_loss: 0.2401  loss_cls: 0.03255  loss_box_reg: 0.08619  loss_mask: 0.08069  loss_rpn_cls: 0.003297  loss_rpn_loc: 0.03072  total_val_loss: 0.2119  val_loss_cls: 0.03078  val_loss_box_reg: 0.07177  val_loss_mask: 0.08313  val_loss_rpn_cls: 0.001381  val_loss_rpn_loc: 0.02458    time: 1.6424  last_time: 1.5317  data_time: 0.0076  last_data_time: 0.0075   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:33:02 d2.utils.events]: \u001b[0m eta: 4:34:11  iter: 9639  total_loss: 0.2238  loss_cls: 0.02953  loss_box_reg: 0.07319  loss_mask: 0.07966  loss_rpn_cls: 0.003639  loss_rpn_loc: 0.03316  total_val_loss: 0.2003  val_loss_cls: 0.0273  val_loss_box_reg: 0.05899  val_loss_mask: 0.08585  val_loss_rpn_cls: 0.001321  val_loss_rpn_loc: 0.02039    time: 1.6422  last_time: 1.6374  data_time: 0.0078  last_data_time: 0.0085   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:33:46 d2.utils.events]: \u001b[0m eta: 4:33:22  iter: 9659  total_loss: 0.2186  loss_cls: 0.0309  loss_box_reg: 0.07573  loss_mask: 0.08276  loss_rpn_cls: 0.002626  loss_rpn_loc: 0.02963  total_val_loss: 0.204  val_loss_cls: 0.03033  val_loss_box_reg: 0.06646  val_loss_mask: 0.08373  val_loss_rpn_cls: 0.002018  val_loss_rpn_loc: 0.02251    time: 1.6420  last_time: 1.5336  data_time: 0.0077  last_data_time: 0.0078   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:34:30 d2.utils.events]: \u001b[0m eta: 4:32:20  iter: 9679  total_loss: 0.2123  loss_cls: 0.02756  loss_box_reg: 0.07178  loss_mask: 0.08232  loss_rpn_cls: 0.002033  loss_rpn_loc: 0.02717  total_val_loss: 0.2042  val_loss_cls: 0.029  val_loss_box_reg: 0.0663  val_loss_mask: 0.08555  val_loss_rpn_cls: 0.001184  val_loss_rpn_loc: 0.02179    time: 1.6418  last_time: 1.5981  data_time: 0.0078  last_data_time: 0.0089   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:35:14 d2.utils.events]: \u001b[0m eta: 4:31:22  iter: 9699  total_loss: 0.2043  loss_cls: 0.02528  loss_box_reg: 0.06604  loss_mask: 0.07504  loss_rpn_cls: 0.002471  loss_rpn_loc: 0.0268  total_val_loss: 0.2058  val_loss_cls: 0.02696  val_loss_box_reg: 0.06458  val_loss_mask: 0.08222  val_loss_rpn_cls: 0.001452  val_loss_rpn_loc: 0.02517    time: 1.6416  last_time: 1.6139  data_time: 0.0073  last_data_time: 0.0065   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:35:58 d2.utils.events]: \u001b[0m eta: 4:30:32  iter: 9719  total_loss: 0.2306  loss_cls: 0.03278  loss_box_reg: 0.07377  loss_mask: 0.0834  loss_rpn_cls: 0.003004  loss_rpn_loc: 0.02956  total_val_loss: 0.2047  val_loss_cls: 0.02704  val_loss_box_reg: 0.06427  val_loss_mask: 0.08235  val_loss_rpn_cls: 0.001167  val_loss_rpn_loc: 0.02219    time: 1.6414  last_time: 1.6109  data_time: 0.0075  last_data_time: 0.0065   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:36:41 d2.utils.events]: \u001b[0m eta: 4:29:31  iter: 9739  total_loss: 0.2287  loss_cls: 0.03273  loss_box_reg: 0.08128  loss_mask: 0.07835  loss_rpn_cls: 0.002541  loss_rpn_loc: 0.03386  total_val_loss: 0.2028  val_loss_cls: 0.02705  val_loss_box_reg: 0.06564  val_loss_mask: 0.08005  val_loss_rpn_cls: 0.001518  val_loss_rpn_loc: 0.02404    time: 1.6412  last_time: 1.4616  data_time: 0.0081  last_data_time: 0.0065   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:37:25 d2.utils.events]: \u001b[0m eta: 4:28:35  iter: 9759  total_loss: 0.2414  loss_cls: 0.0305  loss_box_reg: 0.08174  loss_mask: 0.08345  loss_rpn_cls: 0.002595  loss_rpn_loc: 0.03317  total_val_loss: 0.2231  val_loss_cls: 0.03305  val_loss_box_reg: 0.07342  val_loss_mask: 0.0845  val_loss_rpn_cls: 0.001581  val_loss_rpn_loc: 0.02553    time: 1.6409  last_time: 1.6443  data_time: 0.0071  last_data_time: 0.0075   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:38:09 d2.utils.events]: \u001b[0m eta: 4:27:45  iter: 9779  total_loss: 0.2098  loss_cls: 0.03283  loss_box_reg: 0.06385  loss_mask: 0.08101  loss_rpn_cls: 0.002832  loss_rpn_loc: 0.02853  total_val_loss: 0.2093  val_loss_cls: 0.03261  val_loss_box_reg: 0.06967  val_loss_mask: 0.08321  val_loss_rpn_cls: 0.001884  val_loss_rpn_loc: 0.02519    time: 1.6407  last_time: 1.4822  data_time: 0.0065  last_data_time: 0.0059   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:38:53 d2.utils.events]: \u001b[0m eta: 4:26:33  iter: 9799  total_loss: 0.2219  loss_cls: 0.02976  loss_box_reg: 0.07373  loss_mask: 0.08118  loss_rpn_cls: 0.002022  loss_rpn_loc: 0.02806  total_val_loss: 0.2109  val_loss_cls: 0.02882  val_loss_box_reg: 0.06324  val_loss_mask: 0.08145  val_loss_rpn_cls: 0.001413  val_loss_rpn_loc: 0.02233    time: 1.6405  last_time: 1.3760  data_time: 0.0072  last_data_time: 0.0083   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:39:37 d2.utils.events]: \u001b[0m eta: 4:25:53  iter: 9819  total_loss: 0.2345  loss_cls: 0.03071  loss_box_reg: 0.08706  loss_mask: 0.07787  loss_rpn_cls: 0.002179  loss_rpn_loc: 0.02966  total_val_loss: 0.1983  val_loss_cls: 0.02747  val_loss_box_reg: 0.06701  val_loss_mask: 0.08232  val_loss_rpn_cls: 0.001066  val_loss_rpn_loc: 0.02365    time: 1.6403  last_time: 1.4786  data_time: 0.0080  last_data_time: 0.0096   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:40:21 d2.utils.events]: \u001b[0m eta: 4:24:55  iter: 9839  total_loss: 0.2155  loss_cls: 0.03034  loss_box_reg: 0.07074  loss_mask: 0.08044  loss_rpn_cls: 0.002753  loss_rpn_loc: 0.02773  total_val_loss: 0.2061  val_loss_cls: 0.0309  val_loss_box_reg: 0.06735  val_loss_mask: 0.08066  val_loss_rpn_cls: 0.001516  val_loss_rpn_loc: 0.02443    time: 1.6401  last_time: 1.5401  data_time: 0.0073  last_data_time: 0.0075   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:41:05 d2.utils.events]: \u001b[0m eta: 4:24:09  iter: 9859  total_loss: 0.2189  loss_cls: 0.03087  loss_box_reg: 0.07699  loss_mask: 0.08084  loss_rpn_cls: 0.003204  loss_rpn_loc: 0.03319  total_val_loss: 0.2025  val_loss_cls: 0.02708  val_loss_box_reg: 0.06791  val_loss_mask: 0.08678  val_loss_rpn_cls: 0.0012  val_loss_rpn_loc: 0.02259    time: 1.6399  last_time: 1.6441  data_time: 0.0074  last_data_time: 0.0074   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:41:48 d2.utils.events]: \u001b[0m eta: 4:23:24  iter: 9879  total_loss: 0.2099  loss_cls: 0.02939  loss_box_reg: 0.0735  loss_mask: 0.07667  loss_rpn_cls: 0.003507  loss_rpn_loc: 0.03088  total_val_loss: 0.2061  val_loss_cls: 0.02899  val_loss_box_reg: 0.06881  val_loss_mask: 0.08592  val_loss_rpn_cls: 0.001055  val_loss_rpn_loc: 0.02553    time: 1.6396  last_time: 1.4588  data_time: 0.0073  last_data_time: 0.0068   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:42:32 d2.utils.events]: \u001b[0m eta: 4:22:05  iter: 9899  total_loss: 0.228  loss_cls: 0.0274  loss_box_reg: 0.08  loss_mask: 0.08193  loss_rpn_cls: 0.001456  loss_rpn_loc: 0.02804  total_val_loss: 0.199  val_loss_cls: 0.03115  val_loss_box_reg: 0.06593  val_loss_mask: 0.08424  val_loss_rpn_cls: 0.001266  val_loss_rpn_loc: 0.02276    time: 1.6394  last_time: 1.5145  data_time: 0.0071  last_data_time: 0.0061   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:43:16 d2.utils.events]: \u001b[0m eta: 4:21:20  iter: 9919  total_loss: 0.1972  loss_cls: 0.02738  loss_box_reg: 0.05995  loss_mask: 0.07792  loss_rpn_cls: 0.002751  loss_rpn_loc: 0.02487  total_val_loss: 0.1852  val_loss_cls: 0.02376  val_loss_box_reg: 0.05881  val_loss_mask: 0.07966  val_loss_rpn_cls: 0.001167  val_loss_rpn_loc: 0.02045    time: 1.6392  last_time: 1.6539  data_time: 0.0078  last_data_time: 0.0090   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:44:00 d2.utils.events]: \u001b[0m eta: 4:20:38  iter: 9939  total_loss: 0.237  loss_cls: 0.04016  loss_box_reg: 0.08508  loss_mask: 0.079  loss_rpn_cls: 0.001683  loss_rpn_loc: 0.03502  total_val_loss: 0.2067  val_loss_cls: 0.03001  val_loss_box_reg: 0.06869  val_loss_mask: 0.08523  val_loss_rpn_cls: 0.001264  val_loss_rpn_loc: 0.02266    time: 1.6391  last_time: 1.6205  data_time: 0.0078  last_data_time: 0.0107   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:44:44 d2.utils.events]: \u001b[0m eta: 4:19:54  iter: 9959  total_loss: 0.2246  loss_cls: 0.03337  loss_box_reg: 0.07562  loss_mask: 0.08051  loss_rpn_cls: 0.002284  loss_rpn_loc: 0.02984  total_val_loss: 0.2225  val_loss_cls: 0.03167  val_loss_box_reg: 0.06951  val_loss_mask: 0.08434  val_loss_rpn_cls: 0.001441  val_loss_rpn_loc: 0.02688    time: 1.6389  last_time: 1.5375  data_time: 0.0077  last_data_time: 0.0077   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:45:34 d2.utils.events]: \u001b[0m eta: 4:19:16  iter: 9979  total_loss: 0.216  loss_cls: 0.02609  loss_box_reg: 0.07077  loss_mask: 0.08234  loss_rpn_cls: 0.002281  loss_rpn_loc: 0.02837  total_val_loss: 0.2034  val_loss_cls: 0.02814  val_loss_box_reg: 0.06635  val_loss_mask: 0.08344  val_loss_rpn_cls: 0.001268  val_loss_rpn_loc: 0.02417    time: 1.6391  last_time: 2.0423  data_time: 0.0079  last_data_time: 0.0083   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:46:44 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\testing_images\\0_SideLane_addedversion_Testing_COCO.json\n",
      "\u001b[32m[09/26 20:46:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/26 20:46:44 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/26 20:46:44 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/26 20:46:44 d2.data.common]: \u001b[0mSerialized dataset takes 6.03 MiB\n",
      "\u001b[32m[09/26 20:46:44 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[09/26 20:46:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 566 batches\n",
      "\u001b[32m[09/26 20:46:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/566. Dataloading: 0.0005 s/iter. Inference: 0.1261 s/iter. Eval: 0.0067 s/iter. Total: 0.1333 s/iter. ETA=0:01:13\n",
      "\u001b[32m[09/26 20:46:53 d2.evaluation.evaluator]: \u001b[0mInference done 49/566. Dataloading: 0.0006 s/iter. Inference: 0.1291 s/iter. Eval: 0.0036 s/iter. Total: 0.1334 s/iter. ETA=0:01:08\n",
      "\u001b[32m[09/26 20:46:58 d2.evaluation.evaluator]: \u001b[0mInference done 94/566. Dataloading: 0.0006 s/iter. Inference: 0.1199 s/iter. Eval: 0.0027 s/iter. Total: 0.1233 s/iter. ETA=0:00:58\n",
      "\u001b[32m[09/26 20:47:03 d2.evaluation.evaluator]: \u001b[0mInference done 141/566. Dataloading: 0.0006 s/iter. Inference: 0.1135 s/iter. Eval: 0.0036 s/iter. Total: 0.1178 s/iter. ETA=0:00:50\n",
      "\u001b[32m[09/26 20:47:08 d2.evaluation.evaluator]: \u001b[0mInference done 189/566. Dataloading: 0.0006 s/iter. Inference: 0.1101 s/iter. Eval: 0.0037 s/iter. Total: 0.1145 s/iter. ETA=0:00:43\n",
      "\u001b[32m[09/26 20:47:13 d2.evaluation.evaluator]: \u001b[0mInference done 235/566. Dataloading: 0.0006 s/iter. Inference: 0.1094 s/iter. Eval: 0.0036 s/iter. Total: 0.1137 s/iter. ETA=0:00:37\n",
      "\u001b[32m[09/26 20:47:18 d2.evaluation.evaluator]: \u001b[0mInference done 280/566. Dataloading: 0.0006 s/iter. Inference: 0.1096 s/iter. Eval: 0.0036 s/iter. Total: 0.1138 s/iter. ETA=0:00:32\n",
      "\u001b[32m[09/26 20:47:23 d2.evaluation.evaluator]: \u001b[0mInference done 327/566. Dataloading: 0.0006 s/iter. Inference: 0.1088 s/iter. Eval: 0.0033 s/iter. Total: 0.1128 s/iter. ETA=0:00:26\n",
      "\u001b[32m[09/26 20:47:28 d2.evaluation.evaluator]: \u001b[0mInference done 375/566. Dataloading: 0.0006 s/iter. Inference: 0.1081 s/iter. Eval: 0.0031 s/iter. Total: 0.1119 s/iter. ETA=0:00:21\n",
      "\u001b[32m[09/26 20:47:33 d2.evaluation.evaluator]: \u001b[0mInference done 424/566. Dataloading: 0.0006 s/iter. Inference: 0.1072 s/iter. Eval: 0.0029 s/iter. Total: 0.1108 s/iter. ETA=0:00:15\n",
      "\u001b[32m[09/26 20:47:38 d2.evaluation.evaluator]: \u001b[0mInference done 465/566. Dataloading: 0.0007 s/iter. Inference: 0.1079 s/iter. Eval: 0.0033 s/iter. Total: 0.1119 s/iter. ETA=0:00:11\n",
      "\u001b[32m[09/26 20:47:43 d2.evaluation.evaluator]: \u001b[0mInference done 510/566. Dataloading: 0.0007 s/iter. Inference: 0.1079 s/iter. Eval: 0.0033 s/iter. Total: 0.1119 s/iter. ETA=0:00:06\n",
      "\u001b[32m[09/26 20:47:48 d2.evaluation.evaluator]: \u001b[0mInference done 552/566. Dataloading: 0.0007 s/iter. Inference: 0.1085 s/iter. Eval: 0.0033 s/iter. Total: 0.1125 s/iter. ETA=0:00:01\n",
      "\u001b[32m[09/26 20:47:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:03.636784 (0.113435 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 20:47:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:00 (0.108442 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 20:47:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/26 20:47:50 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\coco_instances_results.json\n",
      "\u001b[32m[09/26 20:47:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.32s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.931\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.928\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.934\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.194\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.936\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.951\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.939\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.958\n",
      "\u001b[32m[09/26 20:47:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 93.076 | 99.008 | 98.993 |  nan  | 92.803 | 93.392 |\n",
      "\u001b[32m[09/26 20:47:51 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 20:47:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 93.076 | background | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.40s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.859\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.826\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.880\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.880\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.894\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.865\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.913\n",
      "\u001b[32m[09/26 20:47:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 85.867 | 99.008 | 98.957 |  nan  | 82.629 | 87.964 |\n",
      "\u001b[32m[09/26 20:47:51 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 20:47:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 85.867 | background | nan  |\n",
      "\u001b[32m[09/26 20:47:51 d2.engine.defaults]: \u001b[0mEvaluation results for test_data in csv format:\n",
      "\u001b[32m[09/26 20:47:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/26 20:47:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 20:47:51 d2.evaluation.testing]: \u001b[0mcopypaste: 93.0760,99.0076,98.9932,nan,92.8029,93.3918\n",
      "\u001b[32m[09/26 20:47:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/26 20:47:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 20:47:51 d2.evaluation.testing]: \u001b[0mcopypaste: 85.8669,99.0076,98.9573,nan,82.6287,87.9645\n",
      "\u001b[32m[09/26 20:47:52 d2.utils.events]: \u001b[0m eta: 4:18:57  iter: 9999  total_loss: 0.2183  loss_cls: 0.03361  loss_box_reg: 0.07714  loss_mask: 0.07712  loss_rpn_cls: 0.0027  loss_rpn_loc: 0.03259  total_val_loss: 0.1986  val_loss_cls: 0.02481  val_loss_box_reg: 0.0591  val_loss_mask: 0.08067  val_loss_rpn_cls: 0.0008214  val_loss_rpn_loc: 0.0201    time: 1.6407  last_time: 2.4855  data_time: 0.0077  last_data_time: 0.0062   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:48:51 d2.utils.events]: \u001b[0m eta: 4:18:23  iter: 10019  total_loss: 0.2148  loss_cls: 0.03015  loss_box_reg: 0.07308  loss_mask: 0.08509  loss_rpn_cls: 0.002198  loss_rpn_loc: 0.02864  total_val_loss: 0.2072  val_loss_cls: 0.02673  val_loss_box_reg: 0.06938  val_loss_mask: 0.0819  val_loss_rpn_cls: 0.00136  val_loss_rpn_loc: 0.02503    time: 1.6415  last_time: 1.4963  data_time: 0.0077  last_data_time: 0.0075   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:49:35 d2.utils.events]: \u001b[0m eta: 4:17:41  iter: 10039  total_loss: 0.2106  loss_cls: 0.02846  loss_box_reg: 0.06847  loss_mask: 0.08047  loss_rpn_cls: 0.002389  loss_rpn_loc: 0.02823  total_val_loss: 0.2076  val_loss_cls: 0.03071  val_loss_box_reg: 0.06928  val_loss_mask: 0.08818  val_loss_rpn_cls: 0.00141  val_loss_rpn_loc: 0.02371    time: 1.6413  last_time: 1.5013  data_time: 0.0076  last_data_time: 0.0075   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:50:18 d2.utils.events]: \u001b[0m eta: 4:16:48  iter: 10059  total_loss: 0.2258  loss_cls: 0.03254  loss_box_reg: 0.07471  loss_mask: 0.08006  loss_rpn_cls: 0.001655  loss_rpn_loc: 0.03258  total_val_loss: 0.2218  val_loss_cls: 0.02896  val_loss_box_reg: 0.07397  val_loss_mask: 0.08503  val_loss_rpn_cls: 0.001715  val_loss_rpn_loc: 0.02761    time: 1.6411  last_time: 1.5215  data_time: 0.0077  last_data_time: 0.0072   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:51:02 d2.utils.events]: \u001b[0m eta: 4:16:05  iter: 10079  total_loss: 0.2125  loss_cls: 0.02984  loss_box_reg: 0.0732  loss_mask: 0.07678  loss_rpn_cls: 0.002  loss_rpn_loc: 0.02894  total_val_loss: 0.1949  val_loss_cls: 0.02511  val_loss_box_reg: 0.06397  val_loss_mask: 0.08612  val_loss_rpn_cls: 0.001507  val_loss_rpn_loc: 0.02086    time: 1.6409  last_time: 1.6277  data_time: 0.0075  last_data_time: 0.0064   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:51:45 d2.utils.events]: \u001b[0m eta: 4:15:14  iter: 10099  total_loss: 0.2175  loss_cls: 0.03161  loss_box_reg: 0.06904  loss_mask: 0.08336  loss_rpn_cls: 0.002384  loss_rpn_loc: 0.02592  total_val_loss: 0.2447  val_loss_cls: 0.03575  val_loss_box_reg: 0.07371  val_loss_mask: 0.08838  val_loss_rpn_cls: 0.001363  val_loss_rpn_loc: 0.02447    time: 1.6406  last_time: 1.5758  data_time: 0.0074  last_data_time: 0.0080   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:52:29 d2.utils.events]: \u001b[0m eta: 4:14:38  iter: 10119  total_loss: 0.2552  loss_cls: 0.03699  loss_box_reg: 0.08568  loss_mask: 0.07346  loss_rpn_cls: 0.003044  loss_rpn_loc: 0.03375  total_val_loss: 0.1988  val_loss_cls: 0.0287  val_loss_box_reg: 0.06057  val_loss_mask: 0.07625  val_loss_rpn_cls: 0.001509  val_loss_rpn_loc: 0.0243    time: 1.6404  last_time: 1.5407  data_time: 0.0073  last_data_time: 0.0061   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:53:13 d2.utils.events]: \u001b[0m eta: 4:14:03  iter: 10139  total_loss: 0.2369  loss_cls: 0.0319  loss_box_reg: 0.0785  loss_mask: 0.07927  loss_rpn_cls: 0.002964  loss_rpn_loc: 0.03167  total_val_loss: 0.1926  val_loss_cls: 0.02658  val_loss_box_reg: 0.06076  val_loss_mask: 0.08243  val_loss_rpn_cls: 0.001432  val_loss_rpn_loc: 0.02389    time: 1.6402  last_time: 1.5545  data_time: 0.0076  last_data_time: 0.0080   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:53:56 d2.utils.events]: \u001b[0m eta: 4:13:20  iter: 10159  total_loss: 0.2062  loss_cls: 0.02317  loss_box_reg: 0.06005  loss_mask: 0.0794  loss_rpn_cls: 0.003623  loss_rpn_loc: 0.02838  total_val_loss: 0.2031  val_loss_cls: 0.02971  val_loss_box_reg: 0.06651  val_loss_mask: 0.08334  val_loss_rpn_cls: 0.001233  val_loss_rpn_loc: 0.02462    time: 1.6400  last_time: 1.5264  data_time: 0.0073  last_data_time: 0.0077   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:54:40 d2.utils.events]: \u001b[0m eta: 4:12:44  iter: 10179  total_loss: 0.2054  loss_cls: 0.03  loss_box_reg: 0.06984  loss_mask: 0.0747  loss_rpn_cls: 0.001897  loss_rpn_loc: 0.02744  total_val_loss: 0.2115  val_loss_cls: 0.03052  val_loss_box_reg: 0.06751  val_loss_mask: 0.08368  val_loss_rpn_cls: 0.001712  val_loss_rpn_loc: 0.02424    time: 1.6398  last_time: 1.5531  data_time: 0.0073  last_data_time: 0.0069   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:55:24 d2.utils.events]: \u001b[0m eta: 4:12:06  iter: 10199  total_loss: 0.2097  loss_cls: 0.02867  loss_box_reg: 0.07202  loss_mask: 0.0772  loss_rpn_cls: 0.002086  loss_rpn_loc: 0.02851  total_val_loss: 0.1972  val_loss_cls: 0.02896  val_loss_box_reg: 0.06319  val_loss_mask: 0.0806  val_loss_rpn_cls: 0.0008995  val_loss_rpn_loc: 0.02455    time: 1.6396  last_time: 1.6501  data_time: 0.0072  last_data_time: 0.0083   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:56:09 d2.utils.events]: \u001b[0m eta: 4:11:33  iter: 10219  total_loss: 0.2181  loss_cls: 0.03114  loss_box_reg: 0.07435  loss_mask: 0.08225  loss_rpn_cls: 0.003256  loss_rpn_loc: 0.02974  total_val_loss: 0.209  val_loss_cls: 0.0314  val_loss_box_reg: 0.06969  val_loss_mask: 0.08881  val_loss_rpn_cls: 0.00124  val_loss_rpn_loc: 0.0224    time: 1.6395  last_time: 1.5303  data_time: 0.0075  last_data_time: 0.0067   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:56:52 d2.utils.events]: \u001b[0m eta: 4:10:46  iter: 10239  total_loss: 0.2149  loss_cls: 0.02923  loss_box_reg: 0.06987  loss_mask: 0.07851  loss_rpn_cls: 0.002138  loss_rpn_loc: 0.03319  total_val_loss: 0.1956  val_loss_cls: 0.02745  val_loss_box_reg: 0.06422  val_loss_mask: 0.07695  val_loss_rpn_cls: 0.001377  val_loss_rpn_loc: 0.02386    time: 1.6392  last_time: 1.5833  data_time: 0.0071  last_data_time: 0.0067   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:57:37 d2.utils.events]: \u001b[0m eta: 4:10:13  iter: 10259  total_loss: 0.2126  loss_cls: 0.02807  loss_box_reg: 0.06559  loss_mask: 0.08035  loss_rpn_cls: 0.00272  loss_rpn_loc: 0.02953  total_val_loss: 0.2141  val_loss_cls: 0.02899  val_loss_box_reg: 0.0696  val_loss_mask: 0.08478  val_loss_rpn_cls: 0.001439  val_loss_rpn_loc: 0.02423    time: 1.6391  last_time: 1.6727  data_time: 0.0075  last_data_time: 0.0095   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:58:21 d2.utils.events]: \u001b[0m eta: 4:09:45  iter: 10279  total_loss: 0.2219  loss_cls: 0.03344  loss_box_reg: 0.07169  loss_mask: 0.07912  loss_rpn_cls: 0.002202  loss_rpn_loc: 0.0298  total_val_loss: 0.1976  val_loss_cls: 0.02777  val_loss_box_reg: 0.06478  val_loss_mask: 0.08486  val_loss_rpn_cls: 0.001253  val_loss_rpn_loc: 0.02257    time: 1.6389  last_time: 1.4493  data_time: 0.0078  last_data_time: 0.0067   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 20:59:11 d2.utils.events]: \u001b[0m eta: 4:09:14  iter: 10299  total_loss: 0.2121  loss_cls: 0.02988  loss_box_reg: 0.07311  loss_mask: 0.08034  loss_rpn_cls: 0.002652  loss_rpn_loc: 0.02951  total_val_loss: 0.2205  val_loss_cls: 0.03472  val_loss_box_reg: 0.07723  val_loss_mask: 0.08056  val_loss_rpn_cls: 0.001476  val_loss_rpn_loc: 0.02669    time: 1.6392  last_time: 2.5069  data_time: 0.0072  last_data_time: 0.0074   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:00:16 d2.utils.events]: \u001b[0m eta: 4:09:04  iter: 10319  total_loss: 0.2124  loss_cls: 0.03068  loss_box_reg: 0.07353  loss_mask: 0.07863  loss_rpn_cls: 0.002242  loss_rpn_loc: 0.02796  total_val_loss: 0.2006  val_loss_cls: 0.02854  val_loss_box_reg: 0.05934  val_loss_mask: 0.08322  val_loss_rpn_cls: 0.0007847  val_loss_rpn_loc: 0.02021    time: 1.6403  last_time: 1.8017  data_time: 0.0075  last_data_time: 0.0062   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:01:11 d2.utils.events]: \u001b[0m eta: 4:08:39  iter: 10339  total_loss: 0.2348  loss_cls: 0.03285  loss_box_reg: 0.0838  loss_mask: 0.08496  loss_rpn_cls: 0.003136  loss_rpn_loc: 0.03374  total_val_loss: 0.1825  val_loss_cls: 0.02674  val_loss_box_reg: 0.05582  val_loss_mask: 0.07804  val_loss_rpn_cls: 0.001064  val_loss_rpn_loc: 0.02242    time: 1.6410  last_time: 1.5440  data_time: 0.0069  last_data_time: 0.0076   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:01:55 d2.utils.events]: \u001b[0m eta: 4:08:06  iter: 10359  total_loss: 0.2227  loss_cls: 0.03087  loss_box_reg: 0.07344  loss_mask: 0.07871  loss_rpn_cls: 0.002971  loss_rpn_loc: 0.02967  total_val_loss: 0.2122  val_loss_cls: 0.0289  val_loss_box_reg: 0.06606  val_loss_mask: 0.08841  val_loss_rpn_cls: 0.001117  val_loss_rpn_loc: 0.0227    time: 1.6407  last_time: 1.5406  data_time: 0.0076  last_data_time: 0.0078   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:02:39 d2.utils.events]: \u001b[0m eta: 4:07:38  iter: 10379  total_loss: 0.2162  loss_cls: 0.02885  loss_box_reg: 0.07043  loss_mask: 0.08096  loss_rpn_cls: 0.002051  loss_rpn_loc: 0.0262  total_val_loss: 0.211  val_loss_cls: 0.03024  val_loss_box_reg: 0.06945  val_loss_mask: 0.08279  val_loss_rpn_cls: 0.001814  val_loss_rpn_loc: 0.02454    time: 1.6406  last_time: 1.4665  data_time: 0.0080  last_data_time: 0.0079   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:03:23 d2.utils.events]: \u001b[0m eta: 4:07:10  iter: 10399  total_loss: 0.2406  loss_cls: 0.03859  loss_box_reg: 0.08119  loss_mask: 0.07697  loss_rpn_cls: 0.00279  loss_rpn_loc: 0.04041  total_val_loss: 0.207  val_loss_cls: 0.02682  val_loss_box_reg: 0.06933  val_loss_mask: 0.08364  val_loss_rpn_cls: 0.001916  val_loss_rpn_loc: 0.02436    time: 1.6404  last_time: 1.5628  data_time: 0.0077  last_data_time: 0.0063   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:04:07 d2.utils.events]: \u001b[0m eta: 4:06:41  iter: 10419  total_loss: 0.2136  loss_cls: 0.02769  loss_box_reg: 0.07074  loss_mask: 0.08203  loss_rpn_cls: 0.002688  loss_rpn_loc: 0.02497  total_val_loss: 0.2145  val_loss_cls: 0.02941  val_loss_box_reg: 0.07122  val_loss_mask: 0.08127  val_loss_rpn_cls: 0.001536  val_loss_rpn_loc: 0.02567    time: 1.6402  last_time: 1.5744  data_time: 0.0073  last_data_time: 0.0074   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:04:50 d2.utils.events]: \u001b[0m eta: 4:06:13  iter: 10439  total_loss: 0.1961  loss_cls: 0.0223  loss_box_reg: 0.0623  loss_mask: 0.07929  loss_rpn_cls: 0.002037  loss_rpn_loc: 0.02816  total_val_loss: 0.2005  val_loss_cls: 0.03167  val_loss_box_reg: 0.05896  val_loss_mask: 0.08651  val_loss_rpn_cls: 0.0007042  val_loss_rpn_loc: 0.02059    time: 1.6400  last_time: 1.4513  data_time: 0.0073  last_data_time: 0.0069   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:05:34 d2.utils.events]: \u001b[0m eta: 4:05:41  iter: 10459  total_loss: 0.2131  loss_cls: 0.02878  loss_box_reg: 0.07278  loss_mask: 0.0778  loss_rpn_cls: 0.002494  loss_rpn_loc: 0.02655  total_val_loss: 0.2123  val_loss_cls: 0.02741  val_loss_box_reg: 0.06643  val_loss_mask: 0.08464  val_loss_rpn_cls: 0.001851  val_loss_rpn_loc: 0.02293    time: 1.6398  last_time: 1.4948  data_time: 0.0072  last_data_time: 0.0059   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:06:19 d2.utils.events]: \u001b[0m eta: 4:05:13  iter: 10479  total_loss: 0.2038  loss_cls: 0.0265  loss_box_reg: 0.06817  loss_mask: 0.07808  loss_rpn_cls: 0.002442  loss_rpn_loc: 0.02967  total_val_loss: 0.2053  val_loss_cls: 0.02695  val_loss_box_reg: 0.0673  val_loss_mask: 0.08398  val_loss_rpn_cls: 0.001508  val_loss_rpn_loc: 0.02315    time: 1.6396  last_time: 1.5660  data_time: 0.0076  last_data_time: 0.0093   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:07:03 d2.utils.events]: \u001b[0m eta: 4:04:51  iter: 10499  total_loss: 0.2266  loss_cls: 0.02766  loss_box_reg: 0.07234  loss_mask: 0.07877  loss_rpn_cls: 0.002363  loss_rpn_loc: 0.02947  total_val_loss: 0.2126  val_loss_cls: 0.02971  val_loss_box_reg: 0.07167  val_loss_mask: 0.08608  val_loss_rpn_cls: 0.001853  val_loss_rpn_loc: 0.02424    time: 1.6394  last_time: 1.4560  data_time: 0.0081  last_data_time: 0.0082   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:07:46 d2.utils.events]: \u001b[0m eta: 4:04:11  iter: 10519  total_loss: 0.2353  loss_cls: 0.03104  loss_box_reg: 0.07923  loss_mask: 0.08188  loss_rpn_cls: 0.002436  loss_rpn_loc: 0.0323  total_val_loss: 0.2063  val_loss_cls: 0.02698  val_loss_box_reg: 0.06502  val_loss_mask: 0.08132  val_loss_rpn_cls: 0.001473  val_loss_rpn_loc: 0.02255    time: 1.6392  last_time: 1.5175  data_time: 0.0073  last_data_time: 0.0068   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:08:30 d2.utils.events]: \u001b[0m eta: 4:03:39  iter: 10539  total_loss: 0.2126  loss_cls: 0.03116  loss_box_reg: 0.07247  loss_mask: 0.08137  loss_rpn_cls: 0.003307  loss_rpn_loc: 0.02658  total_val_loss: 0.1945  val_loss_cls: 0.02525  val_loss_box_reg: 0.06586  val_loss_mask: 0.08283  val_loss_rpn_cls: 0.001403  val_loss_rpn_loc: 0.0246    time: 1.6390  last_time: 1.5398  data_time: 0.0072  last_data_time: 0.0080   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:09:14 d2.utils.events]: \u001b[0m eta: 4:02:58  iter: 10559  total_loss: 0.224  loss_cls: 0.03018  loss_box_reg: 0.07423  loss_mask: 0.07547  loss_rpn_cls: 0.002165  loss_rpn_loc: 0.02848  total_val_loss: 0.2074  val_loss_cls: 0.03154  val_loss_box_reg: 0.06912  val_loss_mask: 0.08234  val_loss_rpn_cls: 0.001328  val_loss_rpn_loc: 0.02282    time: 1.6388  last_time: 1.5032  data_time: 0.0074  last_data_time: 0.0064   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:09:58 d2.utils.events]: \u001b[0m eta: 4:02:24  iter: 10579  total_loss: 0.2167  loss_cls: 0.03059  loss_box_reg: 0.07566  loss_mask: 0.08384  loss_rpn_cls: 0.003133  loss_rpn_loc: 0.0282  total_val_loss: 0.2259  val_loss_cls: 0.03177  val_loss_box_reg: 0.0798  val_loss_mask: 0.08651  val_loss_rpn_cls: 0.00154  val_loss_rpn_loc: 0.02743    time: 1.6387  last_time: 1.4776  data_time: 0.0081  last_data_time: 0.0064   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:10:43 d2.utils.events]: \u001b[0m eta: 4:01:57  iter: 10599  total_loss: 0.2312  loss_cls: 0.03005  loss_box_reg: 0.08024  loss_mask: 0.07786  loss_rpn_cls: 0.002314  loss_rpn_loc: 0.03197  total_val_loss: 0.194  val_loss_cls: 0.02724  val_loss_box_reg: 0.06091  val_loss_mask: 0.08058  val_loss_rpn_cls: 0.001308  val_loss_rpn_loc: 0.02114    time: 1.6385  last_time: 1.5219  data_time: 0.0072  last_data_time: 0.0065   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:11:27 d2.utils.events]: \u001b[0m eta: 4:01:35  iter: 10619  total_loss: 0.2395  loss_cls: 0.03062  loss_box_reg: 0.0806  loss_mask: 0.08434  loss_rpn_cls: 0.002366  loss_rpn_loc: 0.03314  total_val_loss: 0.1999  val_loss_cls: 0.02688  val_loss_box_reg: 0.06122  val_loss_mask: 0.08304  val_loss_rpn_cls: 0.001491  val_loss_rpn_loc: 0.02171    time: 1.6384  last_time: 1.3650  data_time: 0.0074  last_data_time: 0.0059   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:12:10 d2.utils.events]: \u001b[0m eta: 4:00:57  iter: 10639  total_loss: 0.2182  loss_cls: 0.03015  loss_box_reg: 0.07634  loss_mask: 0.08024  loss_rpn_cls: 0.002532  loss_rpn_loc: 0.03015  total_val_loss: 0.1998  val_loss_cls: 0.02773  val_loss_box_reg: 0.06681  val_loss_mask: 0.08017  val_loss_rpn_cls: 0.001235  val_loss_rpn_loc: 0.02447    time: 1.6381  last_time: 1.4749  data_time: 0.0072  last_data_time: 0.0072   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:12:54 d2.utils.events]: \u001b[0m eta: 4:00:22  iter: 10659  total_loss: 0.1929  loss_cls: 0.02617  loss_box_reg: 0.06386  loss_mask: 0.07456  loss_rpn_cls: 0.002947  loss_rpn_loc: 0.02628  total_val_loss: 0.1858  val_loss_cls: 0.02704  val_loss_box_reg: 0.05959  val_loss_mask: 0.08252  val_loss_rpn_cls: 0.00129  val_loss_rpn_loc: 0.0223    time: 1.6379  last_time: 1.4898  data_time: 0.0074  last_data_time: 0.0084   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:13:39 d2.utils.events]: \u001b[0m eta: 3:59:57  iter: 10679  total_loss: 0.2262  loss_cls: 0.02907  loss_box_reg: 0.07152  loss_mask: 0.08013  loss_rpn_cls: 0.002527  loss_rpn_loc: 0.03056  total_val_loss: 0.2223  val_loss_cls: 0.0325  val_loss_box_reg: 0.07431  val_loss_mask: 0.09141  val_loss_rpn_cls: 0.001226  val_loss_rpn_loc: 0.02604    time: 1.6378  last_time: 1.6049  data_time: 0.0072  last_data_time: 0.0065   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:14:23 d2.utils.events]: \u001b[0m eta: 3:59:21  iter: 10699  total_loss: 0.2198  loss_cls: 0.03018  loss_box_reg: 0.07636  loss_mask: 0.07782  loss_rpn_cls: 0.002142  loss_rpn_loc: 0.02665  total_val_loss: 0.2202  val_loss_cls: 0.02965  val_loss_box_reg: 0.07207  val_loss_mask: 0.08545  val_loss_rpn_cls: 0.001181  val_loss_rpn_loc: 0.02698    time: 1.6376  last_time: 1.6058  data_time: 0.0073  last_data_time: 0.0065   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:15:07 d2.utils.events]: \u001b[0m eta: 3:58:49  iter: 10719  total_loss: 0.2071  loss_cls: 0.0257  loss_box_reg: 0.06576  loss_mask: 0.07941  loss_rpn_cls: 0.001484  loss_rpn_loc: 0.02548  total_val_loss: 0.211  val_loss_cls: 0.03098  val_loss_box_reg: 0.07042  val_loss_mask: 0.08632  val_loss_rpn_cls: 0.001349  val_loss_rpn_loc: 0.02303    time: 1.6374  last_time: 1.5674  data_time: 0.0071  last_data_time: 0.0058   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:15:50 d2.utils.events]: \u001b[0m eta: 3:58:13  iter: 10739  total_loss: 0.2068  loss_cls: 0.02884  loss_box_reg: 0.06996  loss_mask: 0.07482  loss_rpn_cls: 0.001476  loss_rpn_loc: 0.0272  total_val_loss: 0.1872  val_loss_cls: 0.02761  val_loss_box_reg: 0.05794  val_loss_mask: 0.08663  val_loss_rpn_cls: 0.001583  val_loss_rpn_loc: 0.02085    time: 1.6372  last_time: 1.5014  data_time: 0.0074  last_data_time: 0.0061   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:16:34 d2.utils.events]: \u001b[0m eta: 3:57:42  iter: 10759  total_loss: 0.1961  loss_cls: 0.02487  loss_box_reg: 0.06428  loss_mask: 0.07635  loss_rpn_cls: 0.002887  loss_rpn_loc: 0.02809  total_val_loss: 0.2061  val_loss_cls: 0.03029  val_loss_box_reg: 0.06784  val_loss_mask: 0.08468  val_loss_rpn_cls: 0.001265  val_loss_rpn_loc: 0.02411    time: 1.6370  last_time: 1.5785  data_time: 0.0073  last_data_time: 0.0072   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:17:17 d2.utils.events]: \u001b[0m eta: 3:57:06  iter: 10779  total_loss: 0.219  loss_cls: 0.02661  loss_box_reg: 0.0652  loss_mask: 0.08089  loss_rpn_cls: 0.001813  loss_rpn_loc: 0.02858  total_val_loss: 0.2113  val_loss_cls: 0.02889  val_loss_box_reg: 0.0671  val_loss_mask: 0.08783  val_loss_rpn_cls: 0.001224  val_loss_rpn_loc: 0.02433    time: 1.6368  last_time: 1.5143  data_time: 0.0071  last_data_time: 0.0059   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:18:02 d2.utils.events]: \u001b[0m eta: 3:56:46  iter: 10799  total_loss: 0.2215  loss_cls: 0.02999  loss_box_reg: 0.07843  loss_mask: 0.08264  loss_rpn_cls: 0.003171  loss_rpn_loc: 0.02956  total_val_loss: 0.2094  val_loss_cls: 0.0287  val_loss_box_reg: 0.06914  val_loss_mask: 0.08309  val_loss_rpn_cls: 0.00154  val_loss_rpn_loc: 0.02515    time: 1.6367  last_time: 1.7481  data_time: 0.0079  last_data_time: 0.0084   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:18:45 d2.utils.events]: \u001b[0m eta: 3:56:13  iter: 10819  total_loss: 0.2075  loss_cls: 0.02756  loss_box_reg: 0.06448  loss_mask: 0.08167  loss_rpn_cls: 0.001728  loss_rpn_loc: 0.02605  total_val_loss: 0.2055  val_loss_cls: 0.0304  val_loss_box_reg: 0.0663  val_loss_mask: 0.08026  val_loss_rpn_cls: 0.001109  val_loss_rpn_loc: 0.02329    time: 1.6365  last_time: 1.5345  data_time: 0.0072  last_data_time: 0.0072   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:19:29 d2.utils.events]: \u001b[0m eta: 3:55:43  iter: 10839  total_loss: 0.2172  loss_cls: 0.02976  loss_box_reg: 0.07288  loss_mask: 0.08087  loss_rpn_cls: 0.002361  loss_rpn_loc: 0.02802  total_val_loss: 0.179  val_loss_cls: 0.0237  val_loss_box_reg: 0.05766  val_loss_mask: 0.08125  val_loss_rpn_cls: 0.001278  val_loss_rpn_loc: 0.02062    time: 1.6363  last_time: 1.4498  data_time: 0.0068  last_data_time: 0.0059   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:20:13 d2.utils.events]: \u001b[0m eta: 3:55:12  iter: 10859  total_loss: 0.216  loss_cls: 0.02894  loss_box_reg: 0.07231  loss_mask: 0.08099  loss_rpn_cls: 0.001447  loss_rpn_loc: 0.02697  total_val_loss: 0.2089  val_loss_cls: 0.02902  val_loss_box_reg: 0.06132  val_loss_mask: 0.08523  val_loss_rpn_cls: 0.001371  val_loss_rpn_loc: 0.02202    time: 1.6361  last_time: 1.4458  data_time: 0.0074  last_data_time: 0.0055   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:20:56 d2.utils.events]: \u001b[0m eta: 3:54:47  iter: 10879  total_loss: 0.2246  loss_cls: 0.03149  loss_box_reg: 0.07449  loss_mask: 0.08147  loss_rpn_cls: 0.003716  loss_rpn_loc: 0.02674  total_val_loss: 0.2069  val_loss_cls: 0.03029  val_loss_box_reg: 0.07288  val_loss_mask: 0.08332  val_loss_rpn_cls: 0.001226  val_loss_rpn_loc: 0.02436    time: 1.6359  last_time: 1.4677  data_time: 0.0075  last_data_time: 0.0068   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:21:40 d2.utils.events]: \u001b[0m eta: 3:54:22  iter: 10899  total_loss: 0.1999  loss_cls: 0.0279  loss_box_reg: 0.0684  loss_mask: 0.07506  loss_rpn_cls: 0.002437  loss_rpn_loc: 0.02757  total_val_loss: 0.2087  val_loss_cls: 0.03015  val_loss_box_reg: 0.06695  val_loss_mask: 0.08327  val_loss_rpn_cls: 0.001947  val_loss_rpn_loc: 0.02367    time: 1.6357  last_time: 1.5402  data_time: 0.0076  last_data_time: 0.0111   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:22:24 d2.utils.events]: \u001b[0m eta: 3:53:49  iter: 10919  total_loss: 0.2115  loss_cls: 0.02869  loss_box_reg: 0.06991  loss_mask: 0.07979  loss_rpn_cls: 0.001898  loss_rpn_loc: 0.0293  total_val_loss: 0.1995  val_loss_cls: 0.02697  val_loss_box_reg: 0.05864  val_loss_mask: 0.07832  val_loss_rpn_cls: 0.001794  val_loss_rpn_loc: 0.02285    time: 1.6355  last_time: 1.6308  data_time: 0.0080  last_data_time: 0.0089   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:23:07 d2.utils.events]: \u001b[0m eta: 3:53:03  iter: 10939  total_loss: 0.1939  loss_cls: 0.02599  loss_box_reg: 0.06304  loss_mask: 0.08013  loss_rpn_cls: 0.001753  loss_rpn_loc: 0.02528  total_val_loss: 0.1993  val_loss_cls: 0.02637  val_loss_box_reg: 0.06198  val_loss_mask: 0.09111  val_loss_rpn_cls: 0.0009632  val_loss_rpn_loc: 0.02455    time: 1.6353  last_time: 1.5530  data_time: 0.0078  last_data_time: 0.0063   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:23:52 d2.utils.events]: \u001b[0m eta: 3:52:40  iter: 10959  total_loss: 0.2132  loss_cls: 0.03314  loss_box_reg: 0.0702  loss_mask: 0.07928  loss_rpn_cls: 0.002062  loss_rpn_loc: 0.02944  total_val_loss: 0.212  val_loss_cls: 0.0278  val_loss_box_reg: 0.06625  val_loss_mask: 0.08454  val_loss_rpn_cls: 0.0008971  val_loss_rpn_loc: 0.02344    time: 1.6352  last_time: 1.5978  data_time: 0.0071  last_data_time: 0.0061   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:24:35 d2.utils.events]: \u001b[0m eta: 3:51:54  iter: 10979  total_loss: 0.2023  loss_cls: 0.02461  loss_box_reg: 0.06405  loss_mask: 0.08148  loss_rpn_cls: 0.001695  loss_rpn_loc: 0.02549  total_val_loss: 0.2103  val_loss_cls: 0.02799  val_loss_box_reg: 0.0661  val_loss_mask: 0.08597  val_loss_rpn_cls: 0.001114  val_loss_rpn_loc: 0.02452    time: 1.6349  last_time: 1.5187  data_time: 0.0076  last_data_time: 0.0077   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:25:21 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\testing_images\\0_SideLane_addedversion_Testing_COCO.json\n",
      "\u001b[32m[09/26 21:25:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/26 21:25:21 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/26 21:25:21 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/26 21:25:21 d2.data.common]: \u001b[0mSerialized dataset takes 6.03 MiB\n",
      "\u001b[32m[09/26 21:25:21 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[09/26 21:25:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 566 batches\n",
      "\u001b[32m[09/26 21:25:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/566. Dataloading: 0.0004 s/iter. Inference: 0.0711 s/iter. Eval: 0.0064 s/iter. Total: 0.0779 s/iter. ETA=0:00:43\n",
      "\u001b[32m[09/26 21:25:30 d2.evaluation.evaluator]: \u001b[0mInference done 77/566. Dataloading: 0.0006 s/iter. Inference: 0.0727 s/iter. Eval: 0.0028 s/iter. Total: 0.0761 s/iter. ETA=0:00:37\n",
      "\u001b[32m[09/26 21:25:35 d2.evaluation.evaluator]: \u001b[0mInference done 142/566. Dataloading: 0.0006 s/iter. Inference: 0.0726 s/iter. Eval: 0.0036 s/iter. Total: 0.0769 s/iter. ETA=0:00:32\n",
      "\u001b[32m[09/26 21:25:40 d2.evaluation.evaluator]: \u001b[0mInference done 205/566. Dataloading: 0.0006 s/iter. Inference: 0.0737 s/iter. Eval: 0.0037 s/iter. Total: 0.0780 s/iter. ETA=0:00:28\n",
      "\u001b[32m[09/26 21:25:45 d2.evaluation.evaluator]: \u001b[0mInference done 269/566. Dataloading: 0.0006 s/iter. Inference: 0.0738 s/iter. Eval: 0.0037 s/iter. Total: 0.0782 s/iter. ETA=0:00:23\n",
      "\u001b[32m[09/26 21:25:50 d2.evaluation.evaluator]: \u001b[0mInference done 338/566. Dataloading: 0.0006 s/iter. Inference: 0.0733 s/iter. Eval: 0.0033 s/iter. Total: 0.0772 s/iter. ETA=0:00:17\n",
      "\u001b[32m[09/26 21:25:55 d2.evaluation.evaluator]: \u001b[0mInference done 405/566. Dataloading: 0.0006 s/iter. Inference: 0.0733 s/iter. Eval: 0.0030 s/iter. Total: 0.0769 s/iter. ETA=0:00:12\n",
      "\u001b[32m[09/26 21:26:00 d2.evaluation.evaluator]: \u001b[0mInference done 469/566. Dataloading: 0.0006 s/iter. Inference: 0.0733 s/iter. Eval: 0.0032 s/iter. Total: 0.0772 s/iter. ETA=0:00:07\n",
      "\u001b[32m[09/26 21:26:05 d2.evaluation.evaluator]: \u001b[0mInference done 532/566. Dataloading: 0.0006 s/iter. Inference: 0.0736 s/iter. Eval: 0.0032 s/iter. Total: 0.0775 s/iter. ETA=0:00:02\n",
      "\u001b[32m[09/26 21:26:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:43.996247 (0.078425 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 21:26:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.073737 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 21:26:08 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/26 21:26:08 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\coco_instances_results.json\n",
      "\u001b[32m[09/26 21:26:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.21s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.931\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.926\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.934\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.194\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.936\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.951\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.940\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.958\n",
      "\u001b[32m[09/26 21:26:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 93.148 | 99.008 | 98.993 |  nan  | 92.572 | 93.440 |\n",
      "\u001b[32m[09/26 21:26:08 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 21:26:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 93.148 | background | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.31s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.859\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.827\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.880\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.881\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.895\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.865\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.914\n",
      "\u001b[32m[09/26 21:26:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 85.877 | 99.008 | 98.951 |  nan  | 82.715 | 87.970 |\n",
      "\u001b[32m[09/26 21:26:09 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 21:26:09 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 85.877 | background | nan  |\n",
      "\u001b[32m[09/26 21:26:09 d2.engine.defaults]: \u001b[0mEvaluation results for test_data in csv format:\n",
      "\u001b[32m[09/26 21:26:09 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/26 21:26:09 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 21:26:09 d2.evaluation.testing]: \u001b[0mcopypaste: 93.1483,99.0076,98.9931,nan,92.5716,93.4402\n",
      "\u001b[32m[09/26 21:26:09 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/26 21:26:09 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 21:26:09 d2.evaluation.testing]: \u001b[0mcopypaste: 85.8774,99.0076,98.9513,nan,82.7153,87.9699\n",
      "\u001b[32m[09/26 21:26:09 d2.utils.events]: \u001b[0m eta: 3:51:10  iter: 10999  total_loss: 0.2274  loss_cls: 0.03619  loss_box_reg: 0.08409  loss_mask: 0.0756  loss_rpn_cls: 0.002384  loss_rpn_loc: 0.03014  total_val_loss: 0.2106  val_loss_cls: 0.02998  val_loss_box_reg: 0.07185  val_loss_mask: 0.08518  val_loss_rpn_cls: 0.001147  val_loss_rpn_loc: 0.02357    time: 1.6348  last_time: 1.4552  data_time: 0.0077  last_data_time: 0.0075   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:26:54 d2.utils.events]: \u001b[0m eta: 3:50:34  iter: 11019  total_loss: 0.2059  loss_cls: 0.02597  loss_box_reg: 0.07034  loss_mask: 0.08365  loss_rpn_cls: 0.001863  loss_rpn_loc: 0.02537  total_val_loss: 0.1892  val_loss_cls: 0.02555  val_loss_box_reg: 0.05985  val_loss_mask: 0.08631  val_loss_rpn_cls: 0.001065  val_loss_rpn_loc: 0.02205    time: 1.6347  last_time: 1.4301  data_time: 0.0074  last_data_time: 0.0061   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:27:38 d2.utils.events]: \u001b[0m eta: 3:50:04  iter: 11039  total_loss: 0.2386  loss_cls: 0.03015  loss_box_reg: 0.08412  loss_mask: 0.08424  loss_rpn_cls: 0.00301  loss_rpn_loc: 0.02934  total_val_loss: 0.2083  val_loss_cls: 0.02745  val_loss_box_reg: 0.07006  val_loss_mask: 0.08358  val_loss_rpn_cls: 0.001295  val_loss_rpn_loc: 0.02361    time: 1.6345  last_time: 1.5336  data_time: 0.0074  last_data_time: 0.0069   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:28:21 d2.utils.events]: \u001b[0m eta: 3:49:33  iter: 11059  total_loss: 0.23  loss_cls: 0.03289  loss_box_reg: 0.07835  loss_mask: 0.08092  loss_rpn_cls: 0.002378  loss_rpn_loc: 0.03198  total_val_loss: 0.2174  val_loss_cls: 0.03253  val_loss_box_reg: 0.07288  val_loss_mask: 0.0879  val_loss_rpn_cls: 0.001467  val_loss_rpn_loc: 0.02385    time: 1.6343  last_time: 1.4837  data_time: 0.0073  last_data_time: 0.0072   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:29:05 d2.utils.events]: \u001b[0m eta: 3:49:02  iter: 11079  total_loss: 0.2224  loss_cls: 0.03206  loss_box_reg: 0.07673  loss_mask: 0.08409  loss_rpn_cls: 0.002104  loss_rpn_loc: 0.0286  total_val_loss: 0.1969  val_loss_cls: 0.0269  val_loss_box_reg: 0.06302  val_loss_mask: 0.08201  val_loss_rpn_cls: 0.0009132  val_loss_rpn_loc: 0.02359    time: 1.6341  last_time: 1.5626  data_time: 0.0075  last_data_time: 0.0069   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:29:49 d2.utils.events]: \u001b[0m eta: 3:48:34  iter: 11099  total_loss: 0.2405  loss_cls: 0.03232  loss_box_reg: 0.0829  loss_mask: 0.08392  loss_rpn_cls: 0.002582  loss_rpn_loc: 0.03166  total_val_loss: 0.1974  val_loss_cls: 0.02695  val_loss_box_reg: 0.06416  val_loss_mask: 0.0844  val_loss_rpn_cls: 0.0008598  val_loss_rpn_loc: 0.02183    time: 1.6340  last_time: 1.4858  data_time: 0.0076  last_data_time: 0.0063   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:30:33 d2.utils.events]: \u001b[0m eta: 3:48:00  iter: 11119  total_loss: 0.2136  loss_cls: 0.02651  loss_box_reg: 0.06487  loss_mask: 0.07896  loss_rpn_cls: 0.002286  loss_rpn_loc: 0.02639  total_val_loss: 0.2106  val_loss_cls: 0.02872  val_loss_box_reg: 0.06898  val_loss_mask: 0.0828  val_loss_rpn_cls: 0.001262  val_loss_rpn_loc: 0.02597    time: 1.6338  last_time: 1.5587  data_time: 0.0072  last_data_time: 0.0067   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:31:18 d2.utils.events]: \u001b[0m eta: 3:47:36  iter: 11139  total_loss: 0.2357  loss_cls: 0.03182  loss_box_reg: 0.0787  loss_mask: 0.07924  loss_rpn_cls: 0.001931  loss_rpn_loc: 0.03218  total_val_loss: 0.2259  val_loss_cls: 0.03084  val_loss_box_reg: 0.07149  val_loss_mask: 0.09148  val_loss_rpn_cls: 0.001216  val_loss_rpn_loc: 0.02401    time: 1.6337  last_time: 1.6579  data_time: 0.0069  last_data_time: 0.0057   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:32:02 d2.utils.events]: \u001b[0m eta: 3:47:17  iter: 11159  total_loss: 0.2091  loss_cls: 0.02614  loss_box_reg: 0.06979  loss_mask: 0.07873  loss_rpn_cls: 0.002133  loss_rpn_loc: 0.0236  total_val_loss: 0.1951  val_loss_cls: 0.02787  val_loss_box_reg: 0.06329  val_loss_mask: 0.0774  val_loss_rpn_cls: 0.001098  val_loss_rpn_loc: 0.02266    time: 1.6336  last_time: 1.5873  data_time: 0.0073  last_data_time: 0.0105   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:32:45 d2.utils.events]: \u001b[0m eta: 3:46:43  iter: 11179  total_loss: 0.2241  loss_cls: 0.0298  loss_box_reg: 0.07223  loss_mask: 0.08093  loss_rpn_cls: 0.002137  loss_rpn_loc: 0.03249  total_val_loss: 0.1814  val_loss_cls: 0.02307  val_loss_box_reg: 0.05715  val_loss_mask: 0.07803  val_loss_rpn_cls: 0.0009702  val_loss_rpn_loc: 0.02109    time: 1.6334  last_time: 1.5682  data_time: 0.0075  last_data_time: 0.0068   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:33:29 d2.utils.events]: \u001b[0m eta: 3:46:07  iter: 11199  total_loss: 0.2272  loss_cls: 0.02966  loss_box_reg: 0.07466  loss_mask: 0.08469  loss_rpn_cls: 0.002263  loss_rpn_loc: 0.02775  total_val_loss: 0.2036  val_loss_cls: 0.02907  val_loss_box_reg: 0.06389  val_loss_mask: 0.08171  val_loss_rpn_cls: 0.001077  val_loss_rpn_loc: 0.02336    time: 1.6332  last_time: 1.5213  data_time: 0.0077  last_data_time: 0.0063   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:34:14 d2.utils.events]: \u001b[0m eta: 3:45:36  iter: 11219  total_loss: 0.2249  loss_cls: 0.03127  loss_box_reg: 0.07802  loss_mask: 0.07719  loss_rpn_cls: 0.002715  loss_rpn_loc: 0.02687  total_val_loss: 0.2132  val_loss_cls: 0.02911  val_loss_box_reg: 0.06638  val_loss_mask: 0.08949  val_loss_rpn_cls: 0.0009968  val_loss_rpn_loc: 0.02247    time: 1.6331  last_time: 1.5004  data_time: 0.0082  last_data_time: 0.0073   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:35:08 d2.utils.events]: \u001b[0m eta: 3:45:13  iter: 11239  total_loss: 0.1957  loss_cls: 0.02594  loss_box_reg: 0.06244  loss_mask: 0.07438  loss_rpn_cls: 0.001658  loss_rpn_loc: 0.02435  total_val_loss: 0.2004  val_loss_cls: 0.0301  val_loss_box_reg: 0.06516  val_loss_mask: 0.08497  val_loss_rpn_cls: 0.001392  val_loss_rpn_loc: 0.02315    time: 1.6335  last_time: 2.4178  data_time: 0.0078  last_data_time: 0.0075   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:36:15 d2.utils.events]: \u001b[0m eta: 3:45:02  iter: 11259  total_loss: 0.2152  loss_cls: 0.02882  loss_box_reg: 0.07309  loss_mask: 0.08311  loss_rpn_cls: 0.003533  loss_rpn_loc: 0.02989  total_val_loss: 0.2153  val_loss_cls: 0.02983  val_loss_box_reg: 0.07095  val_loss_mask: 0.087  val_loss_rpn_cls: 0.001385  val_loss_rpn_loc: 0.02507    time: 1.6347  last_time: 2.7055  data_time: 0.0076  last_data_time: 0.0074   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:37:18 d2.utils.events]: \u001b[0m eta: 3:44:47  iter: 11279  total_loss: 0.2205  loss_cls: 0.02877  loss_box_reg: 0.07174  loss_mask: 0.08103  loss_rpn_cls: 0.001908  loss_rpn_loc: 0.03251  total_val_loss: 0.2008  val_loss_cls: 0.0267  val_loss_box_reg: 0.05912  val_loss_mask: 0.08616  val_loss_rpn_cls: 0.001193  val_loss_rpn_loc: 0.02096    time: 1.6358  last_time: 2.3107  data_time: 0.0078  last_data_time: 0.0083   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:38:22 d2.utils.events]: \u001b[0m eta: 3:44:39  iter: 11299  total_loss: 0.1943  loss_cls: 0.0256  loss_box_reg: 0.06377  loss_mask: 0.0778  loss_rpn_cls: 0.00224  loss_rpn_loc: 0.02774  total_val_loss: 0.2289  val_loss_cls: 0.03104  val_loss_box_reg: 0.07418  val_loss_mask: 0.08884  val_loss_rpn_cls: 0.001162  val_loss_rpn_loc: 0.02433    time: 1.6369  last_time: 2.1375  data_time: 0.0075  last_data_time: 0.0067   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:39:31 d2.utils.events]: \u001b[0m eta: 3:44:08  iter: 11319  total_loss: 0.2149  loss_cls: 0.02622  loss_box_reg: 0.06622  loss_mask: 0.08064  loss_rpn_cls: 0.00215  loss_rpn_loc: 0.03049  total_val_loss: 0.1991  val_loss_cls: 0.0271  val_loss_box_reg: 0.06406  val_loss_mask: 0.07244  val_loss_rpn_cls: 0.000952  val_loss_rpn_loc: 0.02327    time: 1.6383  last_time: 2.1986  data_time: 0.0072  last_data_time: 0.0063   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:40:20 d2.utils.events]: \u001b[0m eta: 3:43:32  iter: 11339  total_loss: 0.2179  loss_cls: 0.03204  loss_box_reg: 0.07261  loss_mask: 0.07829  loss_rpn_cls: 0.002267  loss_rpn_loc: 0.0274  total_val_loss: 0.2178  val_loss_cls: 0.0314  val_loss_box_reg: 0.07033  val_loss_mask: 0.08415  val_loss_rpn_cls: 0.001207  val_loss_rpn_loc: 0.02585    time: 1.6385  last_time: 1.5836  data_time: 0.0076  last_data_time: 0.0067   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:41:02 d2.utils.events]: \u001b[0m eta: 3:42:50  iter: 11359  total_loss: 0.2144  loss_cls: 0.03027  loss_box_reg: 0.07095  loss_mask: 0.0809  loss_rpn_cls: 0.001951  loss_rpn_loc: 0.02474  total_val_loss: 0.2036  val_loss_cls: 0.02756  val_loss_box_reg: 0.0636  val_loss_mask: 0.0817  val_loss_rpn_cls: 0.001013  val_loss_rpn_loc: 0.02481    time: 1.6382  last_time: 1.4756  data_time: 0.0076  last_data_time: 0.0101   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:41:45 d2.utils.events]: \u001b[0m eta: 3:41:56  iter: 11379  total_loss: 0.2398  loss_cls: 0.03356  loss_box_reg: 0.08439  loss_mask: 0.08279  loss_rpn_cls: 0.003322  loss_rpn_loc: 0.03642  total_val_loss: 0.2088  val_loss_cls: 0.02936  val_loss_box_reg: 0.06724  val_loss_mask: 0.08256  val_loss_rpn_cls: 0.001954  val_loss_rpn_loc: 0.02223    time: 1.6380  last_time: 1.5169  data_time: 0.0074  last_data_time: 0.0090   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:42:28 d2.utils.events]: \u001b[0m eta: 3:41:18  iter: 11399  total_loss: 0.2101  loss_cls: 0.02631  loss_box_reg: 0.06645  loss_mask: 0.08235  loss_rpn_cls: 0.00323  loss_rpn_loc: 0.03159  total_val_loss: 0.192  val_loss_cls: 0.02454  val_loss_box_reg: 0.0645  val_loss_mask: 0.07992  val_loss_rpn_cls: 0.001063  val_loss_rpn_loc: 0.02217    time: 1.6378  last_time: 1.5953  data_time: 0.0071  last_data_time: 0.0062   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:43:12 d2.utils.events]: \u001b[0m eta: 3:40:29  iter: 11419  total_loss: 0.2144  loss_cls: 0.03114  loss_box_reg: 0.07663  loss_mask: 0.07735  loss_rpn_cls: 0.002911  loss_rpn_loc: 0.02947  total_val_loss: 0.1995  val_loss_cls: 0.03022  val_loss_box_reg: 0.06259  val_loss_mask: 0.08346  val_loss_rpn_cls: 0.0009884  val_loss_rpn_loc: 0.02206    time: 1.6376  last_time: 1.5412  data_time: 0.0070  last_data_time: 0.0071   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:43:54 d2.utils.events]: \u001b[0m eta: 3:39:55  iter: 11439  total_loss: 0.2151  loss_cls: 0.03016  loss_box_reg: 0.07239  loss_mask: 0.07751  loss_rpn_cls: 0.00238  loss_rpn_loc: 0.02959  total_val_loss: 0.1913  val_loss_cls: 0.02401  val_loss_box_reg: 0.05904  val_loss_mask: 0.08287  val_loss_rpn_cls: 0.001209  val_loss_rpn_loc: 0.02112    time: 1.6373  last_time: 1.5464  data_time: 0.0076  last_data_time: 0.0075   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:44:41 d2.utils.events]: \u001b[0m eta: 3:39:25  iter: 11459  total_loss: 0.223  loss_cls: 0.0302  loss_box_reg: 0.0786  loss_mask: 0.08631  loss_rpn_cls: 0.002097  loss_rpn_loc: 0.03057  total_val_loss: 0.2229  val_loss_cls: 0.03257  val_loss_box_reg: 0.0747  val_loss_mask: 0.08588  val_loss_rpn_cls: 0.001163  val_loss_rpn_loc: 0.02476    time: 1.6373  last_time: 1.9842  data_time: 0.0075  last_data_time: 0.0074   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:45:43 d2.utils.events]: \u001b[0m eta: 3:39:10  iter: 11479  total_loss: 0.1987  loss_cls: 0.02565  loss_box_reg: 0.06446  loss_mask: 0.07397  loss_rpn_cls: 0.002111  loss_rpn_loc: 0.02733  total_val_loss: 0.191  val_loss_cls: 0.02553  val_loss_box_reg: 0.06026  val_loss_mask: 0.08122  val_loss_rpn_cls: 0.0009757  val_loss_rpn_loc: 0.02282    time: 1.6382  last_time: 2.2986  data_time: 0.0076  last_data_time: 0.0078   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:46:46 d2.utils.events]: \u001b[0m eta: 3:38:57  iter: 11499  total_loss: 0.213  loss_cls: 0.02708  loss_box_reg: 0.07285  loss_mask: 0.08246  loss_rpn_cls: 0.001527  loss_rpn_loc: 0.02424  total_val_loss: 0.2092  val_loss_cls: 0.0309  val_loss_box_reg: 0.06777  val_loss_mask: 0.08064  val_loss_rpn_cls: 0.001617  val_loss_rpn_loc: 0.02414    time: 1.6391  last_time: 2.3467  data_time: 0.0078  last_data_time: 0.0074   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:47:53 d2.utils.events]: \u001b[0m eta: 3:39:01  iter: 11519  total_loss: 0.2264  loss_cls: 0.03235  loss_box_reg: 0.07383  loss_mask: 0.08326  loss_rpn_cls: 0.002189  loss_rpn_loc: 0.03214  total_val_loss: 0.2154  val_loss_cls: 0.03091  val_loss_box_reg: 0.06879  val_loss_mask: 0.0889  val_loss_rpn_cls: 0.001811  val_loss_rpn_loc: 0.0233    time: 1.6404  last_time: 2.3494  data_time: 0.0079  last_data_time: 0.0067   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:48:56 d2.utils.events]: \u001b[0m eta: 3:38:49  iter: 11539  total_loss: 0.225  loss_cls: 0.03083  loss_box_reg: 0.07745  loss_mask: 0.08227  loss_rpn_cls: 0.002615  loss_rpn_loc: 0.03039  total_val_loss: 0.194  val_loss_cls: 0.0248  val_loss_box_reg: 0.06104  val_loss_mask: 0.08324  val_loss_rpn_cls: 0.0008042  val_loss_rpn_loc: 0.02092    time: 1.6414  last_time: 1.4639  data_time: 0.0073  last_data_time: 0.0072   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:49:40 d2.utils.events]: \u001b[0m eta: 3:38:18  iter: 11559  total_loss: 0.228  loss_cls: 0.03333  loss_box_reg: 0.07793  loss_mask: 0.08105  loss_rpn_cls: 0.00236  loss_rpn_loc: 0.03198  total_val_loss: 0.1992  val_loss_cls: 0.02597  val_loss_box_reg: 0.06246  val_loss_mask: 0.08724  val_loss_rpn_cls: 0.0009097  val_loss_rpn_loc: 0.02242    time: 1.6413  last_time: 1.4582  data_time: 0.0073  last_data_time: 0.0059   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:50:24 d2.utils.events]: \u001b[0m eta: 3:37:46  iter: 11579  total_loss: 0.1957  loss_cls: 0.02898  loss_box_reg: 0.06467  loss_mask: 0.08086  loss_rpn_cls: 0.001691  loss_rpn_loc: 0.02777  total_val_loss: 0.1957  val_loss_cls: 0.02573  val_loss_box_reg: 0.06148  val_loss_mask: 0.08453  val_loss_rpn_cls: 0.0009253  val_loss_rpn_loc: 0.0221    time: 1.6411  last_time: 1.5056  data_time: 0.0073  last_data_time: 0.0058   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:51:08 d2.utils.events]: \u001b[0m eta: 3:37:15  iter: 11599  total_loss: 0.1946  loss_cls: 0.02348  loss_box_reg: 0.06515  loss_mask: 0.07602  loss_rpn_cls: 0.001628  loss_rpn_loc: 0.02747  total_val_loss: 0.2284  val_loss_cls: 0.03504  val_loss_box_reg: 0.07448  val_loss_mask: 0.08727  val_loss_rpn_cls: 0.001686  val_loss_rpn_loc: 0.02482    time: 1.6409  last_time: 1.5097  data_time: 0.0081  last_data_time: 0.0069   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:51:52 d2.utils.events]: \u001b[0m eta: 3:36:44  iter: 11619  total_loss: 0.2026  loss_cls: 0.02648  loss_box_reg: 0.06328  loss_mask: 0.0844  loss_rpn_cls: 0.002785  loss_rpn_loc: 0.02518  total_val_loss: 0.2002  val_loss_cls: 0.02585  val_loss_box_reg: 0.06138  val_loss_mask: 0.08685  val_loss_rpn_cls: 0.001961  val_loss_rpn_loc: 0.02164    time: 1.6408  last_time: 1.6061  data_time: 0.0076  last_data_time: 0.0071   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:52:36 d2.utils.events]: \u001b[0m eta: 3:36:15  iter: 11639  total_loss: 0.2224  loss_cls: 0.03086  loss_box_reg: 0.07509  loss_mask: 0.08192  loss_rpn_cls: 0.00234  loss_rpn_loc: 0.02996  total_val_loss: 0.2083  val_loss_cls: 0.03201  val_loss_box_reg: 0.06911  val_loss_mask: 0.08451  val_loss_rpn_cls: 0.001856  val_loss_rpn_loc: 0.02549    time: 1.6406  last_time: 1.4659  data_time: 0.0071  last_data_time: 0.0081   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:53:20 d2.utils.events]: \u001b[0m eta: 3:35:44  iter: 11659  total_loss: 0.2312  loss_cls: 0.03007  loss_box_reg: 0.07783  loss_mask: 0.08705  loss_rpn_cls: 0.001395  loss_rpn_loc: 0.03216  total_val_loss: 0.2022  val_loss_cls: 0.02717  val_loss_box_reg: 0.06388  val_loss_mask: 0.08002  val_loss_rpn_cls: 0.001699  val_loss_rpn_loc: 0.02198    time: 1.6404  last_time: 1.4580  data_time: 0.0077  last_data_time: 0.0061   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:54:05 d2.utils.events]: \u001b[0m eta: 3:35:12  iter: 11679  total_loss: 0.2031  loss_cls: 0.02595  loss_box_reg: 0.07165  loss_mask: 0.07641  loss_rpn_cls: 0.001542  loss_rpn_loc: 0.02987  total_val_loss: 0.208  val_loss_cls: 0.03215  val_loss_box_reg: 0.06746  val_loss_mask: 0.07913  val_loss_rpn_cls: 0.001111  val_loss_rpn_loc: 0.02223    time: 1.6403  last_time: 1.4923  data_time: 0.0077  last_data_time: 0.0064   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:54:48 d2.utils.events]: \u001b[0m eta: 3:34:41  iter: 11699  total_loss: 0.19  loss_cls: 0.02298  loss_box_reg: 0.05957  loss_mask: 0.08139  loss_rpn_cls: 0.001302  loss_rpn_loc: 0.02234  total_val_loss: 0.2196  val_loss_cls: 0.0315  val_loss_box_reg: 0.07193  val_loss_mask: 0.08437  val_loss_rpn_cls: 0.001412  val_loss_rpn_loc: 0.02512    time: 1.6401  last_time: 1.5252  data_time: 0.0073  last_data_time: 0.0077   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:55:33 d2.utils.events]: \u001b[0m eta: 3:34:11  iter: 11719  total_loss: 0.2051  loss_cls: 0.02378  loss_box_reg: 0.06587  loss_mask: 0.08036  loss_rpn_cls: 0.001671  loss_rpn_loc: 0.02903  total_val_loss: 0.2095  val_loss_cls: 0.0293  val_loss_box_reg: 0.06975  val_loss_mask: 0.08342  val_loss_rpn_cls: 0.00104  val_loss_rpn_loc: 0.02467    time: 1.6400  last_time: 1.5480  data_time: 0.0076  last_data_time: 0.0073   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:56:17 d2.utils.events]: \u001b[0m eta: 3:33:49  iter: 11739  total_loss: 0.2193  loss_cls: 0.0286  loss_box_reg: 0.07396  loss_mask: 0.07715  loss_rpn_cls: 0.002275  loss_rpn_loc: 0.03098  total_val_loss: 0.1993  val_loss_cls: 0.02794  val_loss_box_reg: 0.06261  val_loss_mask: 0.08253  val_loss_rpn_cls: 0.001232  val_loss_rpn_loc: 0.02269    time: 1.6399  last_time: 1.5682  data_time: 0.0076  last_data_time: 0.0065   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:57:02 d2.utils.events]: \u001b[0m eta: 3:33:25  iter: 11759  total_loss: 0.2364  loss_cls: 0.03085  loss_box_reg: 0.07517  loss_mask: 0.08095  loss_rpn_cls: 0.001676  loss_rpn_loc: 0.02726  total_val_loss: 0.2051  val_loss_cls: 0.02962  val_loss_box_reg: 0.06703  val_loss_mask: 0.08545  val_loss_rpn_cls: 0.0009269  val_loss_rpn_loc: 0.02325    time: 1.6397  last_time: 1.7942  data_time: 0.0080  last_data_time: 0.0075   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:57:46 d2.utils.events]: \u001b[0m eta: 3:32:52  iter: 11779  total_loss: 0.2198  loss_cls: 0.02737  loss_box_reg: 0.07523  loss_mask: 0.08177  loss_rpn_cls: 0.001781  loss_rpn_loc: 0.0312  total_val_loss: 0.2077  val_loss_cls: 0.03111  val_loss_box_reg: 0.06703  val_loss_mask: 0.08156  val_loss_rpn_cls: 0.00169  val_loss_rpn_loc: 0.02534    time: 1.6395  last_time: 1.5797  data_time: 0.0073  last_data_time: 0.0066   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:58:29 d2.utils.events]: \u001b[0m eta: 3:32:20  iter: 11799  total_loss: 0.2138  loss_cls: 0.02832  loss_box_reg: 0.07342  loss_mask: 0.08229  loss_rpn_cls: 0.001827  loss_rpn_loc: 0.02634  total_val_loss: 0.2014  val_loss_cls: 0.02811  val_loss_box_reg: 0.0674  val_loss_mask: 0.08916  val_loss_rpn_cls: 0.0008089  val_loss_rpn_loc: 0.02226    time: 1.6394  last_time: 1.4767  data_time: 0.0070  last_data_time: 0.0070   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:59:13 d2.utils.events]: \u001b[0m eta: 3:31:52  iter: 11819  total_loss: 0.2184  loss_cls: 0.02592  loss_box_reg: 0.06922  loss_mask: 0.08093  loss_rpn_cls: 0.003044  loss_rpn_loc: 0.02771  total_val_loss: 0.1884  val_loss_cls: 0.02439  val_loss_box_reg: 0.06066  val_loss_mask: 0.07967  val_loss_rpn_cls: 0.0009784  val_loss_rpn_loc: 0.02208    time: 1.6392  last_time: 1.6077  data_time: 0.0079  last_data_time: 0.0100   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 21:59:56 d2.utils.events]: \u001b[0m eta: 3:31:22  iter: 11839  total_loss: 0.1982  loss_cls: 0.02825  loss_box_reg: 0.06497  loss_mask: 0.07707  loss_rpn_cls: 0.00271  loss_rpn_loc: 0.03014  total_val_loss: 0.1875  val_loss_cls: 0.02597  val_loss_box_reg: 0.06296  val_loss_mask: 0.07724  val_loss_rpn_cls: 0.001051  val_loss_rpn_loc: 0.02309    time: 1.6390  last_time: 1.5497  data_time: 0.0074  last_data_time: 0.0069   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 22:00:40 d2.utils.events]: \u001b[0m eta: 3:30:52  iter: 11859  total_loss: 0.2229  loss_cls: 0.03058  loss_box_reg: 0.07708  loss_mask: 0.07739  loss_rpn_cls: 0.00322  loss_rpn_loc: 0.0285  total_val_loss: 0.2122  val_loss_cls: 0.02645  val_loss_box_reg: 0.06625  val_loss_mask: 0.08272  val_loss_rpn_cls: 0.0009517  val_loss_rpn_loc: 0.02193    time: 1.6389  last_time: 1.5714  data_time: 0.0076  last_data_time: 0.0073   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 22:01:24 d2.utils.events]: \u001b[0m eta: 3:30:15  iter: 11879  total_loss: 0.2073  loss_cls: 0.02875  loss_box_reg: 0.07423  loss_mask: 0.08019  loss_rpn_cls: 0.002537  loss_rpn_loc: 0.02771  total_val_loss: 0.213  val_loss_cls: 0.0287  val_loss_box_reg: 0.06931  val_loss_mask: 0.08694  val_loss_rpn_cls: 0.00117  val_loss_rpn_loc: 0.02511    time: 1.6387  last_time: 1.5980  data_time: 0.0078  last_data_time: 0.0101   lr: 0.00025  max_mem: 15219M\n",
      "\u001b[32m[09/26 22:02:09 d2.utils.events]: \u001b[0m eta: 3:29:47  iter: 11899  total_loss: 0.2442  loss_cls: 0.02995  loss_box_reg: 0.08159  loss_mask: 0.08484  loss_rpn_cls: 0.001895  loss_rpn_loc: 0.03698  total_val_loss: 0.1945  val_loss_cls: 0.02494  val_loss_box_reg: 0.05689  val_loss_mask: 0.08495  val_loss_rpn_cls: 0.001019  val_loss_rpn_loc: 0.02286    time: 1.6386  last_time: 1.5267  data_time: 0.0073  last_data_time: 0.0085   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:02:53 d2.utils.events]: \u001b[0m eta: 3:29:16  iter: 11919  total_loss: 0.214  loss_cls: 0.03188  loss_box_reg: 0.07567  loss_mask: 0.0827  loss_rpn_cls: 0.001419  loss_rpn_loc: 0.03052  total_val_loss: 0.1976  val_loss_cls: 0.02627  val_loss_box_reg: 0.06511  val_loss_mask: 0.08194  val_loss_rpn_cls: 0.001587  val_loss_rpn_loc: 0.0242    time: 1.6384  last_time: 1.5617  data_time: 0.0076  last_data_time: 0.0080   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:03:36 d2.utils.events]: \u001b[0m eta: 3:28:57  iter: 11939  total_loss: 0.2249  loss_cls: 0.03094  loss_box_reg: 0.07546  loss_mask: 0.08449  loss_rpn_cls: 0.002909  loss_rpn_loc: 0.02891  total_val_loss: 0.2211  val_loss_cls: 0.03138  val_loss_box_reg: 0.07025  val_loss_mask: 0.08576  val_loss_rpn_cls: 0.001123  val_loss_rpn_loc: 0.02291    time: 1.6382  last_time: 1.5561  data_time: 0.0074  last_data_time: 0.0088   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:04:20 d2.utils.events]: \u001b[0m eta: 3:28:13  iter: 11959  total_loss: 0.2084  loss_cls: 0.02818  loss_box_reg: 0.06536  loss_mask: 0.07808  loss_rpn_cls: 0.001413  loss_rpn_loc: 0.02545  total_val_loss: 0.2059  val_loss_cls: 0.03031  val_loss_box_reg: 0.0677  val_loss_mask: 0.08097  val_loss_rpn_cls: 0.0008579  val_loss_rpn_loc: 0.02384    time: 1.6380  last_time: 1.5792  data_time: 0.0075  last_data_time: 0.0063   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:05:04 d2.utils.events]: \u001b[0m eta: 3:27:46  iter: 11979  total_loss: 0.1929  loss_cls: 0.02364  loss_box_reg: 0.06209  loss_mask: 0.07775  loss_rpn_cls: 0.001538  loss_rpn_loc: 0.0232  total_val_loss: 0.2015  val_loss_cls: 0.02448  val_loss_box_reg: 0.06267  val_loss_mask: 0.08869  val_loss_rpn_cls: 0.001689  val_loss_rpn_loc: 0.02244    time: 1.6379  last_time: 1.4499  data_time: 0.0069  last_data_time: 0.0061   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:05:48 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\testing_images\\0_SideLane_addedversion_Testing_COCO.json\n",
      "\u001b[32m[09/26 22:05:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/26 22:05:48 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/26 22:05:48 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/26 22:05:48 d2.data.common]: \u001b[0mSerialized dataset takes 6.03 MiB\n",
      "\u001b[32m[09/26 22:05:48 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[09/26 22:05:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 566 batches\n",
      "\u001b[32m[09/26 22:05:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/566. Dataloading: 0.0004 s/iter. Inference: 0.0728 s/iter. Eval: 0.0064 s/iter. Total: 0.0796 s/iter. ETA=0:00:44\n",
      "\u001b[32m[09/26 22:05:56 d2.evaluation.evaluator]: \u001b[0mInference done 76/566. Dataloading: 0.0006 s/iter. Inference: 0.0746 s/iter. Eval: 0.0029 s/iter. Total: 0.0781 s/iter. ETA=0:00:38\n",
      "\u001b[32m[09/26 22:06:01 d2.evaluation.evaluator]: \u001b[0mInference done 140/566. Dataloading: 0.0006 s/iter. Inference: 0.0742 s/iter. Eval: 0.0037 s/iter. Total: 0.0786 s/iter. ETA=0:00:33\n",
      "\u001b[32m[09/26 22:06:07 d2.evaluation.evaluator]: \u001b[0mInference done 204/566. Dataloading: 0.0006 s/iter. Inference: 0.0742 s/iter. Eval: 0.0038 s/iter. Total: 0.0788 s/iter. ETA=0:00:28\n",
      "\u001b[32m[09/26 22:06:12 d2.evaluation.evaluator]: \u001b[0mInference done 269/566. Dataloading: 0.0006 s/iter. Inference: 0.0741 s/iter. Eval: 0.0038 s/iter. Total: 0.0786 s/iter. ETA=0:00:23\n",
      "\u001b[32m[09/26 22:06:17 d2.evaluation.evaluator]: \u001b[0mInference done 337/566. Dataloading: 0.0006 s/iter. Inference: 0.0735 s/iter. Eval: 0.0034 s/iter. Total: 0.0776 s/iter. ETA=0:00:17\n",
      "\u001b[32m[09/26 22:06:22 d2.evaluation.evaluator]: \u001b[0mInference done 403/566. Dataloading: 0.0006 s/iter. Inference: 0.0736 s/iter. Eval: 0.0031 s/iter. Total: 0.0774 s/iter. ETA=0:00:12\n",
      "\u001b[32m[09/26 22:06:27 d2.evaluation.evaluator]: \u001b[0mInference done 466/566. Dataloading: 0.0006 s/iter. Inference: 0.0737 s/iter. Eval: 0.0034 s/iter. Total: 0.0778 s/iter. ETA=0:00:07\n",
      "\u001b[32m[09/26 22:06:32 d2.evaluation.evaluator]: \u001b[0mInference done 530/566. Dataloading: 0.0006 s/iter. Inference: 0.0739 s/iter. Eval: 0.0034 s/iter. Total: 0.0780 s/iter. ETA=0:00:02\n",
      "\u001b[32m[09/26 22:06:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:44.251921 (0.078880 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 22:06:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.074057 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 22:06:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/26 22:06:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\coco_instances_results.json\n",
      "\u001b[32m[09/26 22:06:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.22s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.933\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.928\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.936\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.936\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.951\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.941\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.957\n",
      "\u001b[32m[09/26 22:06:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 93.291 | 99.005 | 98.989 |  nan  | 92.844 | 93.585 |\n",
      "\u001b[32m[09/26 22:06:35 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 22:06:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 93.291 | background | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.33s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.860\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.827\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.882\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.880\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.894\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.865\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.912\n",
      "\u001b[32m[09/26 22:06:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 86.043 | 99.005 | 98.958 |  nan  | 82.720 | 88.162 |\n",
      "\u001b[32m[09/26 22:06:36 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 22:06:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 86.043 | background | nan  |\n",
      "\u001b[32m[09/26 22:06:36 d2.engine.defaults]: \u001b[0mEvaluation results for test_data in csv format:\n",
      "\u001b[32m[09/26 22:06:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/26 22:06:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 22:06:36 d2.evaluation.testing]: \u001b[0mcopypaste: 93.2913,99.0052,98.9892,nan,92.8441,93.5853\n",
      "\u001b[32m[09/26 22:06:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/26 22:06:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 22:06:36 d2.evaluation.testing]: \u001b[0mcopypaste: 86.0426,99.0052,98.9582,nan,82.7196,88.1621\n",
      "\u001b[32m[09/26 22:06:36 d2.utils.events]: \u001b[0m eta: 3:27:14  iter: 11999  total_loss: 0.2132  loss_cls: 0.02846  loss_box_reg: 0.06882  loss_mask: 0.07823  loss_rpn_cls: 0.002076  loss_rpn_loc: 0.02556  total_val_loss: 0.1829  val_loss_cls: 0.02193  val_loss_box_reg: 0.05464  val_loss_mask: 0.07668  val_loss_rpn_cls: 0.001179  val_loss_rpn_loc: 0.02116    time: 1.6377  last_time: 1.6328  data_time: 0.0078  last_data_time: 0.0091   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:07:20 d2.utils.events]: \u001b[0m eta: 3:26:31  iter: 12019  total_loss: 0.2025  loss_cls: 0.03026  loss_box_reg: 0.06934  loss_mask: 0.07786  loss_rpn_cls: 0.001943  loss_rpn_loc: 0.02429  total_val_loss: 0.2097  val_loss_cls: 0.03206  val_loss_box_reg: 0.06638  val_loss_mask: 0.08054  val_loss_rpn_cls: 0.001588  val_loss_rpn_loc: 0.02541    time: 1.6375  last_time: 1.5929  data_time: 0.0071  last_data_time: 0.0076   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:08:04 d2.utils.events]: \u001b[0m eta: 3:25:59  iter: 12039  total_loss: 0.2342  loss_cls: 0.03332  loss_box_reg: 0.08139  loss_mask: 0.08321  loss_rpn_cls: 0.002432  loss_rpn_loc: 0.02961  total_val_loss: 0.2051  val_loss_cls: 0.03014  val_loss_box_reg: 0.06964  val_loss_mask: 0.088  val_loss_rpn_cls: 0.001195  val_loss_rpn_loc: 0.02421    time: 1.6373  last_time: 1.5064  data_time: 0.0072  last_data_time: 0.0082   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:08:47 d2.utils.events]: \u001b[0m eta: 3:25:31  iter: 12059  total_loss: 0.2368  loss_cls: 0.03046  loss_box_reg: 0.08077  loss_mask: 0.08642  loss_rpn_cls: 0.002625  loss_rpn_loc: 0.03157  total_val_loss: 0.1991  val_loss_cls: 0.0269  val_loss_box_reg: 0.05747  val_loss_mask: 0.08287  val_loss_rpn_cls: 0.0008551  val_loss_rpn_loc: 0.02215    time: 1.6372  last_time: 1.4558  data_time: 0.0081  last_data_time: 0.0091   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:09:32 d2.utils.events]: \u001b[0m eta: 3:25:04  iter: 12079  total_loss: 0.228  loss_cls: 0.03128  loss_box_reg: 0.0754  loss_mask: 0.07828  loss_rpn_cls: 0.001947  loss_rpn_loc: 0.0306  total_val_loss: 0.2071  val_loss_cls: 0.02729  val_loss_box_reg: 0.06941  val_loss_mask: 0.08049  val_loss_rpn_cls: 0.001017  val_loss_rpn_loc: 0.02384    time: 1.6370  last_time: 1.5062  data_time: 0.0069  last_data_time: 0.0060   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:10:16 d2.utils.events]: \u001b[0m eta: 3:24:33  iter: 12099  total_loss: 0.2129  loss_cls: 0.02898  loss_box_reg: 0.06721  loss_mask: 0.08139  loss_rpn_cls: 0.001846  loss_rpn_loc: 0.02851  total_val_loss: 0.21  val_loss_cls: 0.02732  val_loss_box_reg: 0.06696  val_loss_mask: 0.08608  val_loss_rpn_cls: 0.001799  val_loss_rpn_loc: 0.0246    time: 1.6369  last_time: 1.4906  data_time: 0.0072  last_data_time: 0.0058   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:11:00 d2.utils.events]: \u001b[0m eta: 3:23:56  iter: 12119  total_loss: 0.2048  loss_cls: 0.02698  loss_box_reg: 0.0729  loss_mask: 0.07834  loss_rpn_cls: 0.001716  loss_rpn_loc: 0.02904  total_val_loss: 0.1941  val_loss_cls: 0.02678  val_loss_box_reg: 0.06187  val_loss_mask: 0.0789  val_loss_rpn_cls: 0.001805  val_loss_rpn_loc: 0.02266    time: 1.6367  last_time: 1.5864  data_time: 0.0072  last_data_time: 0.0075   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:11:43 d2.utils.events]: \u001b[0m eta: 3:23:25  iter: 12139  total_loss: 0.2318  loss_cls: 0.03182  loss_box_reg: 0.07893  loss_mask: 0.08123  loss_rpn_cls: 0.003124  loss_rpn_loc: 0.02845  total_val_loss: 0.2144  val_loss_cls: 0.03234  val_loss_box_reg: 0.06616  val_loss_mask: 0.0825  val_loss_rpn_cls: 0.001107  val_loss_rpn_loc: 0.02471    time: 1.6365  last_time: 1.5381  data_time: 0.0071  last_data_time: 0.0084   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:12:28 d2.utils.events]: \u001b[0m eta: 3:22:56  iter: 12159  total_loss: 0.2316  loss_cls: 0.02877  loss_box_reg: 0.07813  loss_mask: 0.08666  loss_rpn_cls: 0.002493  loss_rpn_loc: 0.02916  total_val_loss: 0.1976  val_loss_cls: 0.02677  val_loss_box_reg: 0.06376  val_loss_mask: 0.08236  val_loss_rpn_cls: 0.001083  val_loss_rpn_loc: 0.02316    time: 1.6364  last_time: 1.5118  data_time: 0.0077  last_data_time: 0.0065   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:13:13 d2.utils.events]: \u001b[0m eta: 3:22:31  iter: 12179  total_loss: 0.2207  loss_cls: 0.03066  loss_box_reg: 0.06701  loss_mask: 0.07783  loss_rpn_cls: 0.001479  loss_rpn_loc: 0.02563  total_val_loss: 0.2147  val_loss_cls: 0.03382  val_loss_box_reg: 0.07031  val_loss_mask: 0.08357  val_loss_rpn_cls: 0.0009994  val_loss_rpn_loc: 0.02483    time: 1.6363  last_time: 1.6447  data_time: 0.0078  last_data_time: 0.0070   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:13:58 d2.utils.events]: \u001b[0m eta: 3:21:59  iter: 12199  total_loss: 0.2004  loss_cls: 0.02702  loss_box_reg: 0.06794  loss_mask: 0.07829  loss_rpn_cls: 0.001809  loss_rpn_loc: 0.02811  total_val_loss: 0.2043  val_loss_cls: 0.02977  val_loss_box_reg: 0.06709  val_loss_mask: 0.08259  val_loss_rpn_cls: 0.001543  val_loss_rpn_loc: 0.02157    time: 1.6362  last_time: 1.5710  data_time: 0.0076  last_data_time: 0.0066   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:14:43 d2.utils.events]: \u001b[0m eta: 3:21:27  iter: 12219  total_loss: 0.2052  loss_cls: 0.02924  loss_box_reg: 0.07106  loss_mask: 0.07751  loss_rpn_cls: 0.00262  loss_rpn_loc: 0.02774  total_val_loss: 0.1882  val_loss_cls: 0.02464  val_loss_box_reg: 0.05861  val_loss_mask: 0.08678  val_loss_rpn_cls: 0.0009307  val_loss_rpn_loc: 0.02201    time: 1.6361  last_time: 1.5891  data_time: 0.0074  last_data_time: 0.0065   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:15:27 d2.utils.events]: \u001b[0m eta: 3:20:52  iter: 12239  total_loss: 0.2228  loss_cls: 0.02855  loss_box_reg: 0.0766  loss_mask: 0.07877  loss_rpn_cls: 0.00299  loss_rpn_loc: 0.02924  total_val_loss: 0.1975  val_loss_cls: 0.02618  val_loss_box_reg: 0.0651  val_loss_mask: 0.08226  val_loss_rpn_cls: 0.001328  val_loss_rpn_loc: 0.02085    time: 1.6359  last_time: 1.4672  data_time: 0.0075  last_data_time: 0.0061   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:16:12 d2.utils.events]: \u001b[0m eta: 3:20:11  iter: 12259  total_loss: 0.2235  loss_cls: 0.02957  loss_box_reg: 0.07553  loss_mask: 0.08108  loss_rpn_cls: 0.001794  loss_rpn_loc: 0.02998  total_val_loss: 0.1965  val_loss_cls: 0.02846  val_loss_box_reg: 0.06156  val_loss_mask: 0.08294  val_loss_rpn_cls: 0.001209  val_loss_rpn_loc: 0.02234    time: 1.6359  last_time: 1.5857  data_time: 0.0079  last_data_time: 0.0093   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:16:56 d2.utils.events]: \u001b[0m eta: 3:19:29  iter: 12279  total_loss: 0.2119  loss_cls: 0.02857  loss_box_reg: 0.06783  loss_mask: 0.07727  loss_rpn_cls: 0.002546  loss_rpn_loc: 0.02957  total_val_loss: 0.2002  val_loss_cls: 0.02747  val_loss_box_reg: 0.06947  val_loss_mask: 0.08108  val_loss_rpn_cls: 0.00122  val_loss_rpn_loc: 0.02308    time: 1.6357  last_time: 1.5978  data_time: 0.0073  last_data_time: 0.0084   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:17:40 d2.utils.events]: \u001b[0m eta: 3:18:42  iter: 12299  total_loss: 0.2277  loss_cls: 0.02929  loss_box_reg: 0.07751  loss_mask: 0.08298  loss_rpn_cls: 0.002037  loss_rpn_loc: 0.02755  total_val_loss: 0.2005  val_loss_cls: 0.02754  val_loss_box_reg: 0.06813  val_loss_mask: 0.08347  val_loss_rpn_cls: 0.001509  val_loss_rpn_loc: 0.02316    time: 1.6355  last_time: 1.5505  data_time: 0.0074  last_data_time: 0.0065   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:18:24 d2.utils.events]: \u001b[0m eta: 3:17:51  iter: 12319  total_loss: 0.2067  loss_cls: 0.02449  loss_box_reg: 0.06553  loss_mask: 0.07914  loss_rpn_cls: 0.001328  loss_rpn_loc: 0.02845  total_val_loss: 0.1903  val_loss_cls: 0.02824  val_loss_box_reg: 0.06402  val_loss_mask: 0.0838  val_loss_rpn_cls: 0.001122  val_loss_rpn_loc: 0.02275    time: 1.6354  last_time: 1.5040  data_time: 0.0079  last_data_time: 0.0061   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:19:08 d2.utils.events]: \u001b[0m eta: 3:17:20  iter: 12339  total_loss: 0.2255  loss_cls: 0.02805  loss_box_reg: 0.07085  loss_mask: 0.08399  loss_rpn_cls: 0.002181  loss_rpn_loc: 0.03224  total_val_loss: 0.216  val_loss_cls: 0.02716  val_loss_box_reg: 0.07452  val_loss_mask: 0.08511  val_loss_rpn_cls: 0.001044  val_loss_rpn_loc: 0.02512    time: 1.6352  last_time: 1.6579  data_time: 0.0080  last_data_time: 0.0090   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:19:52 d2.utils.events]: \u001b[0m eta: 3:16:52  iter: 12359  total_loss: 0.2119  loss_cls: 0.02852  loss_box_reg: 0.07171  loss_mask: 0.07579  loss_rpn_cls: 0.002036  loss_rpn_loc: 0.02835  total_val_loss: 0.2041  val_loss_cls: 0.0267  val_loss_box_reg: 0.06257  val_loss_mask: 0.08067  val_loss_rpn_cls: 0.0007344  val_loss_rpn_loc: 0.02268    time: 1.6350  last_time: 1.5373  data_time: 0.0076  last_data_time: 0.0073   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:20:36 d2.utils.events]: \u001b[0m eta: 3:16:37  iter: 12379  total_loss: 0.2238  loss_cls: 0.02991  loss_box_reg: 0.07668  loss_mask: 0.08421  loss_rpn_cls: 0.002274  loss_rpn_loc: 0.03171  total_val_loss: 0.2066  val_loss_cls: 0.03079  val_loss_box_reg: 0.06681  val_loss_mask: 0.0811  val_loss_rpn_cls: 0.001112  val_loss_rpn_loc: 0.0235    time: 1.6349  last_time: 1.6460  data_time: 0.0074  last_data_time: 0.0065   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:21:20 d2.utils.events]: \u001b[0m eta: 3:16:10  iter: 12399  total_loss: 0.1957  loss_cls: 0.02801  loss_box_reg: 0.06722  loss_mask: 0.07894  loss_rpn_cls: 0.002934  loss_rpn_loc: 0.02688  total_val_loss: 0.1878  val_loss_cls: 0.0258  val_loss_box_reg: 0.06013  val_loss_mask: 0.08235  val_loss_rpn_cls: 0.000862  val_loss_rpn_loc: 0.02296    time: 1.6348  last_time: 1.6146  data_time: 0.0073  last_data_time: 0.0070   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:22:04 d2.utils.events]: \u001b[0m eta: 3:15:42  iter: 12419  total_loss: 0.2291  loss_cls: 0.03052  loss_box_reg: 0.07657  loss_mask: 0.07929  loss_rpn_cls: 0.002637  loss_rpn_loc: 0.03336  total_val_loss: 0.1933  val_loss_cls: 0.02691  val_loss_box_reg: 0.06383  val_loss_mask: 0.08459  val_loss_rpn_cls: 0.001167  val_loss_rpn_loc: 0.02343    time: 1.6346  last_time: 1.5587  data_time: 0.0071  last_data_time: 0.0071   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:22:48 d2.utils.events]: \u001b[0m eta: 3:15:15  iter: 12439  total_loss: 0.2082  loss_cls: 0.02874  loss_box_reg: 0.06998  loss_mask: 0.07975  loss_rpn_cls: 0.002123  loss_rpn_loc: 0.02709  total_val_loss: 0.2081  val_loss_cls: 0.02607  val_loss_box_reg: 0.07053  val_loss_mask: 0.08311  val_loss_rpn_cls: 0.001195  val_loss_rpn_loc: 0.02534    time: 1.6345  last_time: 1.5195  data_time: 0.0082  last_data_time: 0.0078   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:23:32 d2.utils.events]: \u001b[0m eta: 3:14:44  iter: 12459  total_loss: 0.2344  loss_cls: 0.03204  loss_box_reg: 0.07627  loss_mask: 0.08349  loss_rpn_cls: 0.003044  loss_rpn_loc: 0.0327  total_val_loss: 0.2063  val_loss_cls: 0.02869  val_loss_box_reg: 0.06427  val_loss_mask: 0.08509  val_loss_rpn_cls: 0.001687  val_loss_rpn_loc: 0.02412    time: 1.6344  last_time: 1.5445  data_time: 0.0077  last_data_time: 0.0087   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:24:16 d2.utils.events]: \u001b[0m eta: 3:14:02  iter: 12479  total_loss: 0.204  loss_cls: 0.0292  loss_box_reg: 0.06546  loss_mask: 0.07624  loss_rpn_cls: 0.001667  loss_rpn_loc: 0.02522  total_val_loss: 0.2076  val_loss_cls: 0.03199  val_loss_box_reg: 0.06417  val_loss_mask: 0.08419  val_loss_rpn_cls: 0.0011  val_loss_rpn_loc: 0.02197    time: 1.6342  last_time: 1.4198  data_time: 0.0076  last_data_time: 0.0058   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:24:59 d2.utils.events]: \u001b[0m eta: 3:13:14  iter: 12499  total_loss: 0.21  loss_cls: 0.03108  loss_box_reg: 0.06854  loss_mask: 0.07794  loss_rpn_cls: 0.002182  loss_rpn_loc: 0.02793  total_val_loss: 0.2059  val_loss_cls: 0.02492  val_loss_box_reg: 0.06022  val_loss_mask: 0.08159  val_loss_rpn_cls: 0.0008643  val_loss_rpn_loc: 0.02227    time: 1.6340  last_time: 1.5748  data_time: 0.0082  last_data_time: 0.0060   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:25:43 d2.utils.events]: \u001b[0m eta: 3:12:28  iter: 12519  total_loss: 0.2048  loss_cls: 0.0275  loss_box_reg: 0.06663  loss_mask: 0.08238  loss_rpn_cls: 0.00196  loss_rpn_loc: 0.02434  total_val_loss: 0.2001  val_loss_cls: 0.0285  val_loss_box_reg: 0.06765  val_loss_mask: 0.08231  val_loss_rpn_cls: 0.001034  val_loss_rpn_loc: 0.02296    time: 1.6339  last_time: 1.4350  data_time: 0.0087  last_data_time: 0.0096   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:26:27 d2.utils.events]: \u001b[0m eta: 3:11:48  iter: 12539  total_loss: 0.2069  loss_cls: 0.02942  loss_box_reg: 0.06874  loss_mask: 0.07925  loss_rpn_cls: 0.00249  loss_rpn_loc: 0.02698  total_val_loss: 0.1848  val_loss_cls: 0.02803  val_loss_box_reg: 0.05994  val_loss_mask: 0.07813  val_loss_rpn_cls: 0.001399  val_loss_rpn_loc: 0.02089    time: 1.6337  last_time: 1.4643  data_time: 0.0075  last_data_time: 0.0053   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:27:11 d2.utils.events]: \u001b[0m eta: 3:11:16  iter: 12559  total_loss: 0.2067  loss_cls: 0.02618  loss_box_reg: 0.0674  loss_mask: 0.08542  loss_rpn_cls: 0.002898  loss_rpn_loc: 0.02605  total_val_loss: 0.2064  val_loss_cls: 0.02996  val_loss_box_reg: 0.06578  val_loss_mask: 0.08439  val_loss_rpn_cls: 0.001398  val_loss_rpn_loc: 0.02428    time: 1.6335  last_time: 1.5012  data_time: 0.0077  last_data_time: 0.0068   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:27:54 d2.utils.events]: \u001b[0m eta: 3:10:45  iter: 12579  total_loss: 0.2073  loss_cls: 0.03011  loss_box_reg: 0.0621  loss_mask: 0.08172  loss_rpn_cls: 0.001879  loss_rpn_loc: 0.026  total_val_loss: 0.2156  val_loss_cls: 0.02821  val_loss_box_reg: 0.06858  val_loss_mask: 0.09207  val_loss_rpn_cls: 0.0008105  val_loss_rpn_loc: 0.0234    time: 1.6333  last_time: 1.4117  data_time: 0.0069  last_data_time: 0.0080   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:28:37 d2.utils.events]: \u001b[0m eta: 3:09:54  iter: 12599  total_loss: 0.2242  loss_cls: 0.03044  loss_box_reg: 0.07356  loss_mask: 0.08001  loss_rpn_cls: 0.001312  loss_rpn_loc: 0.02868  total_val_loss: 0.2072  val_loss_cls: 0.02846  val_loss_box_reg: 0.065  val_loss_mask: 0.08879  val_loss_rpn_cls: 0.001357  val_loss_rpn_loc: 0.02371    time: 1.6332  last_time: 1.5147  data_time: 0.0070  last_data_time: 0.0072   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:29:21 d2.utils.events]: \u001b[0m eta: 3:09:12  iter: 12619  total_loss: 0.2152  loss_cls: 0.03007  loss_box_reg: 0.07409  loss_mask: 0.07914  loss_rpn_cls: 0.001943  loss_rpn_loc: 0.02812  total_val_loss: 0.2066  val_loss_cls: 0.02985  val_loss_box_reg: 0.06927  val_loss_mask: 0.08295  val_loss_rpn_cls: 0.001011  val_loss_rpn_loc: 0.02407    time: 1.6330  last_time: 1.5502  data_time: 0.0074  last_data_time: 0.0083   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:30:05 d2.utils.events]: \u001b[0m eta: 3:08:48  iter: 12639  total_loss: 0.2329  loss_cls: 0.03229  loss_box_reg: 0.08257  loss_mask: 0.07938  loss_rpn_cls: 0.003387  loss_rpn_loc: 0.03259  total_val_loss: 0.2102  val_loss_cls: 0.02776  val_loss_box_reg: 0.06735  val_loss_mask: 0.08028  val_loss_rpn_cls: 0.0007792  val_loss_rpn_loc: 0.0241    time: 1.6329  last_time: 1.4440  data_time: 0.0077  last_data_time: 0.0070   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:30:48 d2.utils.events]: \u001b[0m eta: 3:08:05  iter: 12659  total_loss: 0.2191  loss_cls: 0.02791  loss_box_reg: 0.07441  loss_mask: 0.0791  loss_rpn_cls: 0.001822  loss_rpn_loc: 0.02638  total_val_loss: 0.1915  val_loss_cls: 0.02603  val_loss_box_reg: 0.05856  val_loss_mask: 0.08068  val_loss_rpn_cls: 0.0008148  val_loss_rpn_loc: 0.0225    time: 1.6327  last_time: 1.4504  data_time: 0.0074  last_data_time: 0.0089   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:31:31 d2.utils.events]: \u001b[0m eta: 3:07:37  iter: 12679  total_loss: 0.23  loss_cls: 0.03035  loss_box_reg: 0.08324  loss_mask: 0.08401  loss_rpn_cls: 0.003314  loss_rpn_loc: 0.03136  total_val_loss: 0.2141  val_loss_cls: 0.02956  val_loss_box_reg: 0.06647  val_loss_mask: 0.08509  val_loss_rpn_cls: 0.00122  val_loss_rpn_loc: 0.02488    time: 1.6325  last_time: 1.5973  data_time: 0.0077  last_data_time: 0.0061   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:32:15 d2.utils.events]: \u001b[0m eta: 3:07:09  iter: 12699  total_loss: 0.2357  loss_cls: 0.03065  loss_box_reg: 0.08271  loss_mask: 0.07853  loss_rpn_cls: 0.002931  loss_rpn_loc: 0.03128  total_val_loss: 0.1833  val_loss_cls: 0.02235  val_loss_box_reg: 0.05531  val_loss_mask: 0.08383  val_loss_rpn_cls: 0.0008011  val_loss_rpn_loc: 0.01853    time: 1.6323  last_time: 1.5494  data_time: 0.0076  last_data_time: 0.0082   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:32:59 d2.utils.events]: \u001b[0m eta: 3:06:35  iter: 12719  total_loss: 0.2223  loss_cls: 0.03171  loss_box_reg: 0.07742  loss_mask: 0.08046  loss_rpn_cls: 0.002332  loss_rpn_loc: 0.03029  total_val_loss: 0.2074  val_loss_cls: 0.02857  val_loss_box_reg: 0.06627  val_loss_mask: 0.08579  val_loss_rpn_cls: 0.001385  val_loss_rpn_loc: 0.02306    time: 1.6322  last_time: 1.5851  data_time: 0.0074  last_data_time: 0.0093   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:33:43 d2.utils.events]: \u001b[0m eta: 3:06:01  iter: 12739  total_loss: 0.2302  loss_cls: 0.03156  loss_box_reg: 0.07364  loss_mask: 0.07191  loss_rpn_cls: 0.002641  loss_rpn_loc: 0.02847  total_val_loss: 0.202  val_loss_cls: 0.02642  val_loss_box_reg: 0.06659  val_loss_mask: 0.08481  val_loss_rpn_cls: 0.0007958  val_loss_rpn_loc: 0.0237    time: 1.6321  last_time: 1.5160  data_time: 0.0078  last_data_time: 0.0071   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:34:27 d2.utils.events]: \u001b[0m eta: 3:05:31  iter: 12759  total_loss: 0.2191  loss_cls: 0.03199  loss_box_reg: 0.07173  loss_mask: 0.07742  loss_rpn_cls: 0.002147  loss_rpn_loc: 0.02815  total_val_loss: 0.2071  val_loss_cls: 0.02717  val_loss_box_reg: 0.06654  val_loss_mask: 0.08095  val_loss_rpn_cls: 0.001031  val_loss_rpn_loc: 0.02338    time: 1.6319  last_time: 1.5770  data_time: 0.0073  last_data_time: 0.0078   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:35:11 d2.utils.events]: \u001b[0m eta: 3:05:00  iter: 12779  total_loss: 0.2151  loss_cls: 0.0296  loss_box_reg: 0.06823  loss_mask: 0.0804  loss_rpn_cls: 0.001858  loss_rpn_loc: 0.02903  total_val_loss: 0.1882  val_loss_cls: 0.02426  val_loss_box_reg: 0.05859  val_loss_mask: 0.08247  val_loss_rpn_cls: 0.001137  val_loss_rpn_loc: 0.02096    time: 1.6318  last_time: 1.4883  data_time: 0.0068  last_data_time: 0.0084   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:35:54 d2.utils.events]: \u001b[0m eta: 3:04:29  iter: 12799  total_loss: 0.2082  loss_cls: 0.02943  loss_box_reg: 0.06862  loss_mask: 0.08159  loss_rpn_cls: 0.002848  loss_rpn_loc: 0.03242  total_val_loss: 0.1962  val_loss_cls: 0.02649  val_loss_box_reg: 0.06328  val_loss_mask: 0.08302  val_loss_rpn_cls: 0.001277  val_loss_rpn_loc: 0.02355    time: 1.6316  last_time: 1.5698  data_time: 0.0072  last_data_time: 0.0082   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:36:38 d2.utils.events]: \u001b[0m eta: 3:03:59  iter: 12819  total_loss: 0.209  loss_cls: 0.02962  loss_box_reg: 0.07343  loss_mask: 0.07796  loss_rpn_cls: 0.002419  loss_rpn_loc: 0.03337  total_val_loss: 0.2258  val_loss_cls: 0.03194  val_loss_box_reg: 0.07252  val_loss_mask: 0.08665  val_loss_rpn_cls: 0.001365  val_loss_rpn_loc: 0.02764    time: 1.6315  last_time: 1.4990  data_time: 0.0072  last_data_time: 0.0054   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:37:23 d2.utils.events]: \u001b[0m eta: 3:03:33  iter: 12839  total_loss: 0.2339  loss_cls: 0.03185  loss_box_reg: 0.07668  loss_mask: 0.08253  loss_rpn_cls: 0.00186  loss_rpn_loc: 0.03017  total_val_loss: 0.1885  val_loss_cls: 0.025  val_loss_box_reg: 0.06167  val_loss_mask: 0.08142  val_loss_rpn_cls: 0.001254  val_loss_rpn_loc: 0.02161    time: 1.6314  last_time: 1.6093  data_time: 0.0072  last_data_time: 0.0064   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:38:07 d2.utils.events]: \u001b[0m eta: 3:02:58  iter: 12859  total_loss: 0.2027  loss_cls: 0.02586  loss_box_reg: 0.0654  loss_mask: 0.08085  loss_rpn_cls: 0.002013  loss_rpn_loc: 0.02492  total_val_loss: 0.2046  val_loss_cls: 0.03169  val_loss_box_reg: 0.06255  val_loss_mask: 0.08556  val_loss_rpn_cls: 0.001301  val_loss_rpn_loc: 0.02358    time: 1.6312  last_time: 1.5175  data_time: 0.0073  last_data_time: 0.0086   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:38:50 d2.utils.events]: \u001b[0m eta: 3:02:29  iter: 12879  total_loss: 0.2119  loss_cls: 0.027  loss_box_reg: 0.07229  loss_mask: 0.08431  loss_rpn_cls: 0.00177  loss_rpn_loc: 0.02537  total_val_loss: 0.1868  val_loss_cls: 0.02261  val_loss_box_reg: 0.06025  val_loss_mask: 0.082  val_loss_rpn_cls: 0.001035  val_loss_rpn_loc: 0.02194    time: 1.6311  last_time: 1.4699  data_time: 0.0072  last_data_time: 0.0087   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:39:34 d2.utils.events]: \u001b[0m eta: 3:01:53  iter: 12899  total_loss: 0.1947  loss_cls: 0.0261  loss_box_reg: 0.06472  loss_mask: 0.07562  loss_rpn_cls: 0.00126  loss_rpn_loc: 0.02737  total_val_loss: 0.1993  val_loss_cls: 0.02934  val_loss_box_reg: 0.06766  val_loss_mask: 0.08307  val_loss_rpn_cls: 0.001135  val_loss_rpn_loc: 0.02485    time: 1.6309  last_time: 1.5957  data_time: 0.0077  last_data_time: 0.0077   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:40:17 d2.utils.events]: \u001b[0m eta: 3:01:19  iter: 12919  total_loss: 0.2313  loss_cls: 0.03275  loss_box_reg: 0.07077  loss_mask: 0.08139  loss_rpn_cls: 0.001891  loss_rpn_loc: 0.02954  total_val_loss: 0.2003  val_loss_cls: 0.02767  val_loss_box_reg: 0.06659  val_loss_mask: 0.07891  val_loss_rpn_cls: 0.001225  val_loss_rpn_loc: 0.02491    time: 1.6307  last_time: 1.4362  data_time: 0.0074  last_data_time: 0.0067   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:41:02 d2.utils.events]: \u001b[0m eta: 3:00:52  iter: 12939  total_loss: 0.2046  loss_cls: 0.02731  loss_box_reg: 0.07026  loss_mask: 0.07895  loss_rpn_cls: 0.001808  loss_rpn_loc: 0.02893  total_val_loss: 0.206  val_loss_cls: 0.03152  val_loss_box_reg: 0.06311  val_loss_mask: 0.08317  val_loss_rpn_cls: 0.001303  val_loss_rpn_loc: 0.02196    time: 1.6306  last_time: 1.6005  data_time: 0.0069  last_data_time: 0.0066   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:41:46 d2.utils.events]: \u001b[0m eta: 3:00:22  iter: 12959  total_loss: 0.205  loss_cls: 0.02856  loss_box_reg: 0.06658  loss_mask: 0.07998  loss_rpn_cls: 0.001449  loss_rpn_loc: 0.02534  total_val_loss: 0.1899  val_loss_cls: 0.02558  val_loss_box_reg: 0.06188  val_loss_mask: 0.08092  val_loss_rpn_cls: 0.0008897  val_loss_rpn_loc: 0.02227    time: 1.6305  last_time: 1.5561  data_time: 0.0072  last_data_time: 0.0063   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:42:30 d2.utils.events]: \u001b[0m eta: 2:59:54  iter: 12979  total_loss: 0.2091  loss_cls: 0.0297  loss_box_reg: 0.06794  loss_mask: 0.07866  loss_rpn_cls: 0.00277  loss_rpn_loc: 0.02786  total_val_loss: 0.2162  val_loss_cls: 0.02894  val_loss_box_reg: 0.06981  val_loss_mask: 0.0832  val_loss_rpn_cls: 0.001507  val_loss_rpn_loc: 0.02313    time: 1.6304  last_time: 1.3284  data_time: 0.0078  last_data_time: 0.0058   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:43:14 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\testing_images\\0_SideLane_addedversion_Testing_COCO.json\n",
      "\u001b[32m[09/26 22:43:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/26 22:43:14 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/26 22:43:14 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/26 22:43:14 d2.data.common]: \u001b[0mSerialized dataset takes 6.03 MiB\n",
      "\u001b[32m[09/26 22:43:14 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[09/26 22:43:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 566 batches\n",
      "\u001b[32m[09/26 22:43:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/566. Dataloading: 0.0004 s/iter. Inference: 0.0708 s/iter. Eval: 0.0065 s/iter. Total: 0.0777 s/iter. ETA=0:00:43\n",
      "\u001b[32m[09/26 22:43:23 d2.evaluation.evaluator]: \u001b[0mInference done 77/566. Dataloading: 0.0006 s/iter. Inference: 0.0726 s/iter. Eval: 0.0028 s/iter. Total: 0.0760 s/iter. ETA=0:00:37\n",
      "\u001b[32m[09/26 22:43:28 d2.evaluation.evaluator]: \u001b[0mInference done 142/566. Dataloading: 0.0006 s/iter. Inference: 0.0725 s/iter. Eval: 0.0037 s/iter. Total: 0.0767 s/iter. ETA=0:00:32\n",
      "\u001b[32m[09/26 22:43:33 d2.evaluation.evaluator]: \u001b[0mInference done 205/566. Dataloading: 0.0006 s/iter. Inference: 0.0735 s/iter. Eval: 0.0038 s/iter. Total: 0.0779 s/iter. ETA=0:00:28\n",
      "\u001b[32m[09/26 22:43:38 d2.evaluation.evaluator]: \u001b[0mInference done 269/566. Dataloading: 0.0006 s/iter. Inference: 0.0736 s/iter. Eval: 0.0038 s/iter. Total: 0.0780 s/iter. ETA=0:00:23\n",
      "\u001b[32m[09/26 22:43:43 d2.evaluation.evaluator]: \u001b[0mInference done 337/566. Dataloading: 0.0006 s/iter. Inference: 0.0733 s/iter. Eval: 0.0034 s/iter. Total: 0.0773 s/iter. ETA=0:00:17\n",
      "\u001b[32m[09/26 22:43:48 d2.evaluation.evaluator]: \u001b[0mInference done 403/566. Dataloading: 0.0006 s/iter. Inference: 0.0734 s/iter. Eval: 0.0030 s/iter. Total: 0.0771 s/iter. ETA=0:00:12\n",
      "\u001b[32m[09/26 22:43:53 d2.evaluation.evaluator]: \u001b[0mInference done 467/566. Dataloading: 0.0006 s/iter. Inference: 0.0733 s/iter. Eval: 0.0033 s/iter. Total: 0.0773 s/iter. ETA=0:00:07\n",
      "\u001b[32m[09/26 22:43:58 d2.evaluation.evaluator]: \u001b[0mInference done 530/566. Dataloading: 0.0006 s/iter. Inference: 0.0736 s/iter. Eval: 0.0033 s/iter. Total: 0.0775 s/iter. ETA=0:00:02\n",
      "\u001b[32m[09/26 22:44:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:44.149378 (0.078698 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 22:44:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:41 (0.073867 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 22:44:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/26 22:44:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\coco_instances_results.json\n",
      "\u001b[32m[09/26 22:44:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.23s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.932\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.926\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.934\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.936\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.950\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.940\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.957\n",
      "\u001b[32m[09/26 22:44:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 93.180 | 99.009 | 98.991 |  nan  | 92.649 | 93.440 |\n",
      "\u001b[32m[09/26 22:44:02 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 22:44:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 93.180 | background | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.36s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.860\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.827\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.880\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.880\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.894\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.865\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.912\n",
      "\u001b[32m[09/26 22:44:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 85.974 | 99.009 | 98.956 |  nan  | 82.716 | 87.971 |\n",
      "\u001b[32m[09/26 22:44:02 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 22:44:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 85.974 | background | nan  |\n",
      "\u001b[32m[09/26 22:44:02 d2.engine.defaults]: \u001b[0mEvaluation results for test_data in csv format:\n",
      "\u001b[32m[09/26 22:44:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/26 22:44:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 22:44:02 d2.evaluation.testing]: \u001b[0mcopypaste: 93.1799,99.0085,98.9908,nan,92.6490,93.4397\n",
      "\u001b[32m[09/26 22:44:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/26 22:44:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 22:44:02 d2.evaluation.testing]: \u001b[0mcopypaste: 85.9741,99.0085,98.9564,nan,82.7160,87.9709\n",
      "\u001b[32m[09/26 22:44:03 d2.utils.events]: \u001b[0m eta: 2:59:20  iter: 12999  total_loss: 0.2117  loss_cls: 0.02955  loss_box_reg: 0.07206  loss_mask: 0.07944  loss_rpn_cls: 0.002413  loss_rpn_loc: 0.02994  total_val_loss: 0.1945  val_loss_cls: 0.0276  val_loss_box_reg: 0.06241  val_loss_mask: 0.08463  val_loss_rpn_cls: 0.001237  val_loss_rpn_loc: 0.0229    time: 1.6302  last_time: 1.6469  data_time: 0.0068  last_data_time: 0.0096   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:44:47 d2.utils.events]: \u001b[0m eta: 2:58:52  iter: 13019  total_loss: 0.2075  loss_cls: 0.02882  loss_box_reg: 0.07739  loss_mask: 0.07768  loss_rpn_cls: 0.001741  loss_rpn_loc: 0.03047  total_val_loss: 0.1925  val_loss_cls: 0.02517  val_loss_box_reg: 0.05926  val_loss_mask: 0.08537  val_loss_rpn_cls: 0.0009859  val_loss_rpn_loc: 0.02154    time: 1.6301  last_time: 1.4527  data_time: 0.0076  last_data_time: 0.0065   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:45:31 d2.utils.events]: \u001b[0m eta: 2:58:24  iter: 13039  total_loss: 0.2182  loss_cls: 0.03141  loss_box_reg: 0.06865  loss_mask: 0.08028  loss_rpn_cls: 0.001715  loss_rpn_loc: 0.02605  total_val_loss: 0.2086  val_loss_cls: 0.02918  val_loss_box_reg: 0.06944  val_loss_mask: 0.08247  val_loss_rpn_cls: 0.0008449  val_loss_rpn_loc: 0.02539    time: 1.6299  last_time: 1.5612  data_time: 0.0076  last_data_time: 0.0068   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:46:15 d2.utils.events]: \u001b[0m eta: 2:57:53  iter: 13059  total_loss: 0.2208  loss_cls: 0.02632  loss_box_reg: 0.06972  loss_mask: 0.0781  loss_rpn_cls: 0.001828  loss_rpn_loc: 0.03092  total_val_loss: 0.189  val_loss_cls: 0.02517  val_loss_box_reg: 0.06022  val_loss_mask: 0.08522  val_loss_rpn_cls: 0.001159  val_loss_rpn_loc: 0.02162    time: 1.6298  last_time: 1.4519  data_time: 0.0076  last_data_time: 0.0068   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:46:58 d2.utils.events]: \u001b[0m eta: 2:57:19  iter: 13079  total_loss: 0.2085  loss_cls: 0.02907  loss_box_reg: 0.06686  loss_mask: 0.07684  loss_rpn_cls: 0.002422  loss_rpn_loc: 0.02895  total_val_loss: 0.2011  val_loss_cls: 0.0286  val_loss_box_reg: 0.0609  val_loss_mask: 0.08427  val_loss_rpn_cls: 0.001112  val_loss_rpn_loc: 0.0224    time: 1.6296  last_time: 1.4968  data_time: 0.0070  last_data_time: 0.0066   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:47:42 d2.utils.events]: \u001b[0m eta: 2:56:50  iter: 13099  total_loss: 0.2232  loss_cls: 0.03221  loss_box_reg: 0.07954  loss_mask: 0.08159  loss_rpn_cls: 0.001994  loss_rpn_loc: 0.03241  total_val_loss: 0.2254  val_loss_cls: 0.03579  val_loss_box_reg: 0.0765  val_loss_mask: 0.08027  val_loss_rpn_cls: 0.001372  val_loss_rpn_loc: 0.02611    time: 1.6295  last_time: 1.4421  data_time: 0.0078  last_data_time: 0.0061   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:48:26 d2.utils.events]: \u001b[0m eta: 2:56:19  iter: 13119  total_loss: 0.2349  loss_cls: 0.03195  loss_box_reg: 0.08093  loss_mask: 0.08515  loss_rpn_cls: 0.002794  loss_rpn_loc: 0.03091  total_val_loss: 0.2033  val_loss_cls: 0.02946  val_loss_box_reg: 0.06378  val_loss_mask: 0.08128  val_loss_rpn_cls: 0.00103  val_loss_rpn_loc: 0.02213    time: 1.6294  last_time: 1.5344  data_time: 0.0076  last_data_time: 0.0067   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:49:10 d2.utils.events]: \u001b[0m eta: 2:55:48  iter: 13139  total_loss: 0.2048  loss_cls: 0.02555  loss_box_reg: 0.06549  loss_mask: 0.07707  loss_rpn_cls: 0.001889  loss_rpn_loc: 0.02856  total_val_loss: 0.2097  val_loss_cls: 0.03079  val_loss_box_reg: 0.06766  val_loss_mask: 0.08932  val_loss_rpn_cls: 0.0008454  val_loss_rpn_loc: 0.02324    time: 1.6292  last_time: 1.4115  data_time: 0.0071  last_data_time: 0.0063   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:49:54 d2.utils.events]: \u001b[0m eta: 2:55:16  iter: 13159  total_loss: 0.2497  loss_cls: 0.03562  loss_box_reg: 0.08793  loss_mask: 0.08422  loss_rpn_cls: 0.002628  loss_rpn_loc: 0.03662  total_val_loss: 0.1998  val_loss_cls: 0.02347  val_loss_box_reg: 0.06055  val_loss_mask: 0.07941  val_loss_rpn_cls: 0.001239  val_loss_rpn_loc: 0.02362    time: 1.6291  last_time: 1.4486  data_time: 0.0070  last_data_time: 0.0065   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:50:37 d2.utils.events]: \u001b[0m eta: 2:54:39  iter: 13179  total_loss: 0.1845  loss_cls: 0.02673  loss_box_reg: 0.05751  loss_mask: 0.08364  loss_rpn_cls: 0.002024  loss_rpn_loc: 0.02473  total_val_loss: 0.1949  val_loss_cls: 0.02844  val_loss_box_reg: 0.0613  val_loss_mask: 0.08356  val_loss_rpn_cls: 0.0009876  val_loss_rpn_loc: 0.02279    time: 1.6289  last_time: 1.5000  data_time: 0.0078  last_data_time: 0.0083   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:51:21 d2.utils.events]: \u001b[0m eta: 2:54:13  iter: 13199  total_loss: 0.1918  loss_cls: 0.02471  loss_box_reg: 0.06527  loss_mask: 0.07339  loss_rpn_cls: 0.001563  loss_rpn_loc: 0.02693  total_val_loss: 0.2045  val_loss_cls: 0.027  val_loss_box_reg: 0.06704  val_loss_mask: 0.08376  val_loss_rpn_cls: 0.001286  val_loss_rpn_loc: 0.02292    time: 1.6288  last_time: 1.5359  data_time: 0.0072  last_data_time: 0.0068   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:52:05 d2.utils.events]: \u001b[0m eta: 2:53:42  iter: 13219  total_loss: 0.2068  loss_cls: 0.02705  loss_box_reg: 0.06418  loss_mask: 0.08409  loss_rpn_cls: 0.002112  loss_rpn_loc: 0.02542  total_val_loss: 0.2029  val_loss_cls: 0.02834  val_loss_box_reg: 0.06471  val_loss_mask: 0.08249  val_loss_rpn_cls: 0.0009301  val_loss_rpn_loc: 0.02293    time: 1.6287  last_time: 1.6720  data_time: 0.0071  last_data_time: 0.0079   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:52:49 d2.utils.events]: \u001b[0m eta: 2:53:11  iter: 13239  total_loss: 0.2019  loss_cls: 0.02862  loss_box_reg: 0.06311  loss_mask: 0.07903  loss_rpn_cls: 0.002083  loss_rpn_loc: 0.02582  total_val_loss: 0.2099  val_loss_cls: 0.03041  val_loss_box_reg: 0.06363  val_loss_mask: 0.08625  val_loss_rpn_cls: 0.0008857  val_loss_rpn_loc: 0.02237    time: 1.6285  last_time: 1.5640  data_time: 0.0070  last_data_time: 0.0068   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:53:32 d2.utils.events]: \u001b[0m eta: 2:52:33  iter: 13259  total_loss: 0.2203  loss_cls: 0.02723  loss_box_reg: 0.0778  loss_mask: 0.08492  loss_rpn_cls: 0.001739  loss_rpn_loc: 0.03116  total_val_loss: 0.2002  val_loss_cls: 0.02651  val_loss_box_reg: 0.06117  val_loss_mask: 0.08661  val_loss_rpn_cls: 0.001014  val_loss_rpn_loc: 0.02195    time: 1.6284  last_time: 1.6183  data_time: 0.0079  last_data_time: 0.0062   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:54:17 d2.utils.events]: \u001b[0m eta: 2:52:08  iter: 13279  total_loss: 0.2345  loss_cls: 0.03187  loss_box_reg: 0.07753  loss_mask: 0.07822  loss_rpn_cls: 0.002974  loss_rpn_loc: 0.03173  total_val_loss: 0.2079  val_loss_cls: 0.03081  val_loss_box_reg: 0.06809  val_loss_mask: 0.08557  val_loss_rpn_cls: 0.001546  val_loss_rpn_loc: 0.02423    time: 1.6283  last_time: 1.7874  data_time: 0.0074  last_data_time: 0.0063   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:55:01 d2.utils.events]: \u001b[0m eta: 2:51:35  iter: 13299  total_loss: 0.2165  loss_cls: 0.02903  loss_box_reg: 0.07657  loss_mask: 0.07637  loss_rpn_cls: 0.001901  loss_rpn_loc: 0.02973  total_val_loss: 0.2182  val_loss_cls: 0.03175  val_loss_box_reg: 0.07158  val_loss_mask: 0.08897  val_loss_rpn_cls: 0.001315  val_loss_rpn_loc: 0.02564    time: 1.6282  last_time: 1.7168  data_time: 0.0075  last_data_time: 0.0082   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:55:45 d2.utils.events]: \u001b[0m eta: 2:51:05  iter: 13319  total_loss: 0.2111  loss_cls: 0.02825  loss_box_reg: 0.06473  loss_mask: 0.07589  loss_rpn_cls: 0.002403  loss_rpn_loc: 0.02937  total_val_loss: 0.2022  val_loss_cls: 0.02757  val_loss_box_reg: 0.06753  val_loss_mask: 0.08112  val_loss_rpn_cls: 0.001532  val_loss_rpn_loc: 0.02273    time: 1.6280  last_time: 1.6536  data_time: 0.0076  last_data_time: 0.0092   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:56:28 d2.utils.events]: \u001b[0m eta: 2:50:33  iter: 13339  total_loss: 0.219  loss_cls: 0.02739  loss_box_reg: 0.07093  loss_mask: 0.07993  loss_rpn_cls: 0.001341  loss_rpn_loc: 0.02662  total_val_loss: 0.2049  val_loss_cls: 0.03123  val_loss_box_reg: 0.06923  val_loss_mask: 0.0826  val_loss_rpn_cls: 0.001152  val_loss_rpn_loc: 0.02371    time: 1.6279  last_time: 1.4894  data_time: 0.0074  last_data_time: 0.0064   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:57:11 d2.utils.events]: \u001b[0m eta: 2:49:54  iter: 13359  total_loss: 0.2034  loss_cls: 0.0279  loss_box_reg: 0.06564  loss_mask: 0.08219  loss_rpn_cls: 0.001815  loss_rpn_loc: 0.0262  total_val_loss: 0.2027  val_loss_cls: 0.02698  val_loss_box_reg: 0.06196  val_loss_mask: 0.08578  val_loss_rpn_cls: 0.001562  val_loss_rpn_loc: 0.0218    time: 1.6277  last_time: 1.4242  data_time: 0.0073  last_data_time: 0.0052   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:57:54 d2.utils.events]: \u001b[0m eta: 2:49:14  iter: 13379  total_loss: 0.224  loss_cls: 0.02836  loss_box_reg: 0.07209  loss_mask: 0.08571  loss_rpn_cls: 0.0025  loss_rpn_loc: 0.03209  total_val_loss: 0.192  val_loss_cls: 0.02296  val_loss_box_reg: 0.058  val_loss_mask: 0.08126  val_loss_rpn_cls: 0.001297  val_loss_rpn_loc: 0.02252    time: 1.6275  last_time: 1.5469  data_time: 0.0070  last_data_time: 0.0080   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:58:36 d2.utils.events]: \u001b[0m eta: 2:48:38  iter: 13399  total_loss: 0.1976  loss_cls: 0.02958  loss_box_reg: 0.06674  loss_mask: 0.08013  loss_rpn_cls: 0.001593  loss_rpn_loc: 0.02804  total_val_loss: 0.1991  val_loss_cls: 0.02728  val_loss_box_reg: 0.06297  val_loss_mask: 0.08255  val_loss_rpn_cls: 0.001445  val_loss_rpn_loc: 0.02291    time: 1.6273  last_time: 1.5636  data_time: 0.0080  last_data_time: 0.0073   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 22:59:19 d2.utils.events]: \u001b[0m eta: 2:48:05  iter: 13419  total_loss: 0.2242  loss_cls: 0.03049  loss_box_reg: 0.07874  loss_mask: 0.07915  loss_rpn_cls: 0.002074  loss_rpn_loc: 0.0282  total_val_loss: 0.2045  val_loss_cls: 0.02749  val_loss_box_reg: 0.06507  val_loss_mask: 0.08317  val_loss_rpn_cls: 0.001411  val_loss_rpn_loc: 0.02149    time: 1.6271  last_time: 1.5737  data_time: 0.0074  last_data_time: 0.0086   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:00:02 d2.utils.events]: \u001b[0m eta: 2:47:28  iter: 13439  total_loss: 0.2083  loss_cls: 0.03172  loss_box_reg: 0.07259  loss_mask: 0.07955  loss_rpn_cls: 0.001699  loss_rpn_loc: 0.02838  total_val_loss: 0.2119  val_loss_cls: 0.02834  val_loss_box_reg: 0.06581  val_loss_mask: 0.08773  val_loss_rpn_cls: 0.001081  val_loss_rpn_loc: 0.02389    time: 1.6269  last_time: 1.5132  data_time: 0.0080  last_data_time: 0.0084   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:00:45 d2.utils.events]: \u001b[0m eta: 2:46:50  iter: 13459  total_loss: 0.2239  loss_cls: 0.02949  loss_box_reg: 0.07821  loss_mask: 0.07711  loss_rpn_cls: 0.002447  loss_rpn_loc: 0.02947  total_val_loss: 0.2095  val_loss_cls: 0.02989  val_loss_box_reg: 0.06708  val_loss_mask: 0.08789  val_loss_rpn_cls: 0.001285  val_loss_rpn_loc: 0.02525    time: 1.6267  last_time: 1.4510  data_time: 0.0082  last_data_time: 0.0065   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:01:27 d2.utils.events]: \u001b[0m eta: 2:46:17  iter: 13479  total_loss: 0.1879  loss_cls: 0.02336  loss_box_reg: 0.06253  loss_mask: 0.07964  loss_rpn_cls: 0.001497  loss_rpn_loc: 0.02244  total_val_loss: 0.2101  val_loss_cls: 0.02674  val_loss_box_reg: 0.06748  val_loss_mask: 0.08908  val_loss_rpn_cls: 0.001212  val_loss_rpn_loc: 0.0237    time: 1.6265  last_time: 1.5141  data_time: 0.0079  last_data_time: 0.0083   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:02:10 d2.utils.events]: \u001b[0m eta: 2:45:49  iter: 13499  total_loss: 0.2075  loss_cls: 0.0259  loss_box_reg: 0.06641  loss_mask: 0.08246  loss_rpn_cls: 0.001696  loss_rpn_loc: 0.02778  total_val_loss: 0.1845  val_loss_cls: 0.02727  val_loss_box_reg: 0.0592  val_loss_mask: 0.07545  val_loss_rpn_cls: 0.0007461  val_loss_rpn_loc: 0.02148    time: 1.6263  last_time: 1.4477  data_time: 0.0084  last_data_time: 0.0062   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:02:52 d2.utils.events]: \u001b[0m eta: 2:45:12  iter: 13519  total_loss: 0.221  loss_cls: 0.02831  loss_box_reg: 0.07163  loss_mask: 0.07888  loss_rpn_cls: 0.002054  loss_rpn_loc: 0.02856  total_val_loss: 0.2041  val_loss_cls: 0.0245  val_loss_box_reg: 0.05759  val_loss_mask: 0.08026  val_loss_rpn_cls: 0.001832  val_loss_rpn_loc: 0.02201    time: 1.6261  last_time: 1.4586  data_time: 0.0073  last_data_time: 0.0079   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:03:34 d2.utils.events]: \u001b[0m eta: 2:44:38  iter: 13539  total_loss: 0.2275  loss_cls: 0.02912  loss_box_reg: 0.07134  loss_mask: 0.08239  loss_rpn_cls: 0.002393  loss_rpn_loc: 0.02883  total_val_loss: 0.1908  val_loss_cls: 0.02584  val_loss_box_reg: 0.05947  val_loss_mask: 0.08353  val_loss_rpn_cls: 0.001267  val_loss_rpn_loc: 0.02226    time: 1.6259  last_time: 1.4941  data_time: 0.0069  last_data_time: 0.0067   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:04:17 d2.utils.events]: \u001b[0m eta: 2:44:04  iter: 13559  total_loss: 0.2168  loss_cls: 0.03201  loss_box_reg: 0.06957  loss_mask: 0.07815  loss_rpn_cls: 0.002451  loss_rpn_loc: 0.03211  total_val_loss: 0.2174  val_loss_cls: 0.0298  val_loss_box_reg: 0.06545  val_loss_mask: 0.08189  val_loss_rpn_cls: 0.0009772  val_loss_rpn_loc: 0.02449    time: 1.6257  last_time: 1.5224  data_time: 0.0069  last_data_time: 0.0099   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:04:59 d2.utils.events]: \u001b[0m eta: 2:43:29  iter: 13579  total_loss: 0.2225  loss_cls: 0.0317  loss_box_reg: 0.07639  loss_mask: 0.07757  loss_rpn_cls: 0.003138  loss_rpn_loc: 0.03378  total_val_loss: 0.193  val_loss_cls: 0.02714  val_loss_box_reg: 0.06461  val_loss_mask: 0.08502  val_loss_rpn_cls: 0.001089  val_loss_rpn_loc: 0.02479    time: 1.6255  last_time: 1.4484  data_time: 0.0072  last_data_time: 0.0087   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:05:41 d2.utils.events]: \u001b[0m eta: 2:42:56  iter: 13599  total_loss: 0.2168  loss_cls: 0.03095  loss_box_reg: 0.07492  loss_mask: 0.0801  loss_rpn_cls: 0.002437  loss_rpn_loc: 0.02653  total_val_loss: 0.2005  val_loss_cls: 0.03001  val_loss_box_reg: 0.06696  val_loss_mask: 0.08146  val_loss_rpn_cls: 0.00132  val_loss_rpn_loc: 0.02374    time: 1.6253  last_time: 1.4981  data_time: 0.0073  last_data_time: 0.0059   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:06:24 d2.utils.events]: \u001b[0m eta: 2:42:19  iter: 13619  total_loss: 0.2165  loss_cls: 0.02873  loss_box_reg: 0.06698  loss_mask: 0.0792  loss_rpn_cls: 0.002141  loss_rpn_loc: 0.02577  total_val_loss: 0.2127  val_loss_cls: 0.02729  val_loss_box_reg: 0.06966  val_loss_mask: 0.08103  val_loss_rpn_cls: 0.002394  val_loss_rpn_loc: 0.02511    time: 1.6251  last_time: 1.5232  data_time: 0.0077  last_data_time: 0.0066   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:07:06 d2.utils.events]: \u001b[0m eta: 2:41:34  iter: 13639  total_loss: 0.2046  loss_cls: 0.02579  loss_box_reg: 0.06837  loss_mask: 0.07799  loss_rpn_cls: 0.001561  loss_rpn_loc: 0.02538  total_val_loss: 0.2057  val_loss_cls: 0.02563  val_loss_box_reg: 0.0618  val_loss_mask: 0.08064  val_loss_rpn_cls: 0.0007543  val_loss_rpn_loc: 0.02323    time: 1.6249  last_time: 1.5063  data_time: 0.0065  last_data_time: 0.0063   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:07:48 d2.utils.events]: \u001b[0m eta: 2:40:53  iter: 13659  total_loss: 0.2016  loss_cls: 0.03019  loss_box_reg: 0.07172  loss_mask: 0.07656  loss_rpn_cls: 0.00159  loss_rpn_loc: 0.02669  total_val_loss: 0.1772  val_loss_cls: 0.02337  val_loss_box_reg: 0.05713  val_loss_mask: 0.08153  val_loss_rpn_cls: 0.000642  val_loss_rpn_loc: 0.02059    time: 1.6246  last_time: 1.4484  data_time: 0.0070  last_data_time: 0.0076   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:08:30 d2.utils.events]: \u001b[0m eta: 2:40:17  iter: 13679  total_loss: 0.2104  loss_cls: 0.0295  loss_box_reg: 0.07025  loss_mask: 0.08429  loss_rpn_cls: 0.001572  loss_rpn_loc: 0.02649  total_val_loss: 0.1947  val_loss_cls: 0.02742  val_loss_box_reg: 0.06347  val_loss_mask: 0.08923  val_loss_rpn_cls: 0.00103  val_loss_rpn_loc: 0.02086    time: 1.6244  last_time: 1.3930  data_time: 0.0069  last_data_time: 0.0060   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:09:13 d2.utils.events]: \u001b[0m eta: 2:39:42  iter: 13699  total_loss: 0.2297  loss_cls: 0.03163  loss_box_reg: 0.0756  loss_mask: 0.08203  loss_rpn_cls: 0.00232  loss_rpn_loc: 0.03012  total_val_loss: 0.2087  val_loss_cls: 0.02957  val_loss_box_reg: 0.06593  val_loss_mask: 0.0812  val_loss_rpn_cls: 0.000959  val_loss_rpn_loc: 0.02477    time: 1.6242  last_time: 1.5539  data_time: 0.0076  last_data_time: 0.0066   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:09:56 d2.utils.events]: \u001b[0m eta: 2:38:50  iter: 13719  total_loss: 0.2402  loss_cls: 0.03374  loss_box_reg: 0.07064  loss_mask: 0.07491  loss_rpn_cls: 0.002864  loss_rpn_loc: 0.0345  total_val_loss: 0.2132  val_loss_cls: 0.03175  val_loss_box_reg: 0.0686  val_loss_mask: 0.08266  val_loss_rpn_cls: 0.0007319  val_loss_rpn_loc: 0.02446    time: 1.6240  last_time: 1.4399  data_time: 0.0078  last_data_time: 0.0080   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:10:38 d2.utils.events]: \u001b[0m eta: 2:37:57  iter: 13739  total_loss: 0.2301  loss_cls: 0.03435  loss_box_reg: 0.082  loss_mask: 0.08288  loss_rpn_cls: 0.002111  loss_rpn_loc: 0.03132  total_val_loss: 0.1846  val_loss_cls: 0.02649  val_loss_box_reg: 0.06699  val_loss_mask: 0.08236  val_loss_rpn_cls: 0.001052  val_loss_rpn_loc: 0.02321    time: 1.6238  last_time: 1.4708  data_time: 0.0071  last_data_time: 0.0075   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:11:20 d2.utils.events]: \u001b[0m eta: 2:37:17  iter: 13759  total_loss: 0.198  loss_cls: 0.02852  loss_box_reg: 0.06549  loss_mask: 0.07747  loss_rpn_cls: 0.001931  loss_rpn_loc: 0.02448  total_val_loss: 0.2015  val_loss_cls: 0.02876  val_loss_box_reg: 0.06698  val_loss_mask: 0.08462  val_loss_rpn_cls: 0.001095  val_loss_rpn_loc: 0.02149    time: 1.6236  last_time: 1.4546  data_time: 0.0071  last_data_time: 0.0087   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:12:02 d2.utils.events]: \u001b[0m eta: 2:36:40  iter: 13779  total_loss: 0.1992  loss_cls: 0.02701  loss_box_reg: 0.06378  loss_mask: 0.07983  loss_rpn_cls: 0.00231  loss_rpn_loc: 0.0282  total_val_loss: 0.1845  val_loss_cls: 0.02493  val_loss_box_reg: 0.06199  val_loss_mask: 0.07932  val_loss_rpn_cls: 0.001633  val_loss_rpn_loc: 0.0234    time: 1.6234  last_time: 1.4957  data_time: 0.0073  last_data_time: 0.0062   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:12:44 d2.utils.events]: \u001b[0m eta: 2:36:00  iter: 13799  total_loss: 0.2124  loss_cls: 0.0275  loss_box_reg: 0.06693  loss_mask: 0.08625  loss_rpn_cls: 0.001948  loss_rpn_loc: 0.03221  total_val_loss: 0.2054  val_loss_cls: 0.0287  val_loss_box_reg: 0.06716  val_loss_mask: 0.0847  val_loss_rpn_cls: 0.000772  val_loss_rpn_loc: 0.023    time: 1.6231  last_time: 1.4563  data_time: 0.0074  last_data_time: 0.0108   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:13:26 d2.utils.events]: \u001b[0m eta: 2:35:24  iter: 13819  total_loss: 0.1993  loss_cls: 0.02757  loss_box_reg: 0.06496  loss_mask: 0.07565  loss_rpn_cls: 0.003044  loss_rpn_loc: 0.03004  total_val_loss: 0.2125  val_loss_cls: 0.0301  val_loss_box_reg: 0.06884  val_loss_mask: 0.08321  val_loss_rpn_cls: 0.0007484  val_loss_rpn_loc: 0.0251    time: 1.6229  last_time: 1.4864  data_time: 0.0072  last_data_time: 0.0060   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:14:09 d2.utils.events]: \u001b[0m eta: 2:34:53  iter: 13839  total_loss: 0.2302  loss_cls: 0.02924  loss_box_reg: 0.07619  loss_mask: 0.08075  loss_rpn_cls: 0.002083  loss_rpn_loc: 0.03211  total_val_loss: 0.2121  val_loss_cls: 0.02995  val_loss_box_reg: 0.07039  val_loss_mask: 0.08404  val_loss_rpn_cls: 0.002151  val_loss_rpn_loc: 0.02338    time: 1.6228  last_time: 1.5271  data_time: 0.0069  last_data_time: 0.0059   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:14:52 d2.utils.events]: \u001b[0m eta: 2:34:12  iter: 13859  total_loss: 0.2151  loss_cls: 0.02862  loss_box_reg: 0.06785  loss_mask: 0.08655  loss_rpn_cls: 0.002111  loss_rpn_loc: 0.02634  total_val_loss: 0.2055  val_loss_cls: 0.02768  val_loss_box_reg: 0.06398  val_loss_mask: 0.0848  val_loss_rpn_cls: 0.001442  val_loss_rpn_loc: 0.02373    time: 1.6226  last_time: 1.4793  data_time: 0.0074  last_data_time: 0.0079   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:15:34 d2.utils.events]: \u001b[0m eta: 2:33:36  iter: 13879  total_loss: 0.206  loss_cls: 0.02626  loss_box_reg: 0.06527  loss_mask: 0.07915  loss_rpn_cls: 0.002011  loss_rpn_loc: 0.02907  total_val_loss: 0.209  val_loss_cls: 0.02834  val_loss_box_reg: 0.06571  val_loss_mask: 0.08632  val_loss_rpn_cls: 0.001182  val_loss_rpn_loc: 0.02314    time: 1.6224  last_time: 1.6275  data_time: 0.0070  last_data_time: 0.0071   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:16:16 d2.utils.events]: \u001b[0m eta: 2:33:01  iter: 13899  total_loss: 0.1926  loss_cls: 0.02518  loss_box_reg: 0.06674  loss_mask: 0.07831  loss_rpn_cls: 0.001996  loss_rpn_loc: 0.02815  total_val_loss: 0.1854  val_loss_cls: 0.02383  val_loss_box_reg: 0.05945  val_loss_mask: 0.08278  val_loss_rpn_cls: 0.0005403  val_loss_rpn_loc: 0.02138    time: 1.6222  last_time: 1.4236  data_time: 0.0069  last_data_time: 0.0078   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:16:59 d2.utils.events]: \u001b[0m eta: 2:32:31  iter: 13919  total_loss: 0.2183  loss_cls: 0.03011  loss_box_reg: 0.07322  loss_mask: 0.08256  loss_rpn_cls: 0.002014  loss_rpn_loc: 0.0324  total_val_loss: 0.2039  val_loss_cls: 0.0256  val_loss_box_reg: 0.05923  val_loss_mask: 0.09059  val_loss_rpn_cls: 0.001017  val_loss_rpn_loc: 0.02169    time: 1.6220  last_time: 1.5908  data_time: 0.0066  last_data_time: 0.0066   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:17:41 d2.utils.events]: \u001b[0m eta: 2:31:43  iter: 13939  total_loss: 0.2117  loss_cls: 0.0277  loss_box_reg: 0.07042  loss_mask: 0.08278  loss_rpn_cls: 0.001454  loss_rpn_loc: 0.0264  total_val_loss: 0.2043  val_loss_cls: 0.02957  val_loss_box_reg: 0.06983  val_loss_mask: 0.08244  val_loss_rpn_cls: 0.0009326  val_loss_rpn_loc: 0.02361    time: 1.6218  last_time: 1.4231  data_time: 0.0065  last_data_time: 0.0060   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:18:23 d2.utils.events]: \u001b[0m eta: 2:31:11  iter: 13959  total_loss: 0.2375  loss_cls: 0.03373  loss_box_reg: 0.07909  loss_mask: 0.07887  loss_rpn_cls: 0.00217  loss_rpn_loc: 0.03278  total_val_loss: 0.198  val_loss_cls: 0.02587  val_loss_box_reg: 0.06669  val_loss_mask: 0.07965  val_loss_rpn_cls: 0.001367  val_loss_rpn_loc: 0.0229    time: 1.6216  last_time: 1.4316  data_time: 0.0068  last_data_time: 0.0064   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:19:06 d2.utils.events]: \u001b[0m eta: 2:30:30  iter: 13979  total_loss: 0.1854  loss_cls: 0.02644  loss_box_reg: 0.06017  loss_mask: 0.0799  loss_rpn_cls: 0.001861  loss_rpn_loc: 0.02796  total_val_loss: 0.1927  val_loss_cls: 0.02967  val_loss_box_reg: 0.06304  val_loss_mask: 0.08325  val_loss_rpn_cls: 0.00127  val_loss_rpn_loc: 0.02209    time: 1.6214  last_time: 1.3819  data_time: 0.0068  last_data_time: 0.0066   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:19:49 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\testing_images\\0_SideLane_addedversion_Testing_COCO.json\n",
      "\u001b[32m[09/26 23:19:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/26 23:19:49 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/26 23:19:49 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/26 23:19:49 d2.data.common]: \u001b[0mSerialized dataset takes 6.03 MiB\n",
      "\u001b[32m[09/26 23:19:49 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[09/26 23:19:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 566 batches\n",
      "\u001b[32m[09/26 23:19:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/566. Dataloading: 0.0004 s/iter. Inference: 0.0705 s/iter. Eval: 0.0066 s/iter. Total: 0.0775 s/iter. ETA=0:00:43\n",
      "\u001b[32m[09/26 23:20:01 d2.evaluation.evaluator]: \u001b[0mInference done 79/566. Dataloading: 0.0006 s/iter. Inference: 0.0710 s/iter. Eval: 0.0028 s/iter. Total: 0.0743 s/iter. ETA=0:00:36\n",
      "\u001b[32m[09/26 23:20:06 d2.evaluation.evaluator]: \u001b[0mInference done 146/566. Dataloading: 0.0006 s/iter. Inference: 0.0704 s/iter. Eval: 0.0037 s/iter. Total: 0.0746 s/iter. ETA=0:00:31\n",
      "\u001b[32m[09/26 23:20:11 d2.evaluation.evaluator]: \u001b[0mInference done 212/566. Dataloading: 0.0006 s/iter. Inference: 0.0709 s/iter. Eval: 0.0036 s/iter. Total: 0.0751 s/iter. ETA=0:00:26\n",
      "\u001b[32m[09/26 23:20:16 d2.evaluation.evaluator]: \u001b[0mInference done 279/566. Dataloading: 0.0006 s/iter. Inference: 0.0711 s/iter. Eval: 0.0035 s/iter. Total: 0.0752 s/iter. ETA=0:00:21\n",
      "\u001b[32m[09/26 23:20:21 d2.evaluation.evaluator]: \u001b[0mInference done 349/566. Dataloading: 0.0006 s/iter. Inference: 0.0707 s/iter. Eval: 0.0032 s/iter. Total: 0.0745 s/iter. ETA=0:00:16\n",
      "\u001b[32m[09/26 23:20:26 d2.evaluation.evaluator]: \u001b[0mInference done 419/566. Dataloading: 0.0006 s/iter. Inference: 0.0706 s/iter. Eval: 0.0029 s/iter. Total: 0.0741 s/iter. ETA=0:00:10\n",
      "\u001b[32m[09/26 23:20:31 d2.evaluation.evaluator]: \u001b[0mInference done 483/566. Dataloading: 0.0006 s/iter. Inference: 0.0708 s/iter. Eval: 0.0033 s/iter. Total: 0.0747 s/iter. ETA=0:00:06\n",
      "\u001b[32m[09/26 23:20:36 d2.evaluation.evaluator]: \u001b[0mInference done 548/566. Dataloading: 0.0006 s/iter. Inference: 0.0713 s/iter. Eval: 0.0032 s/iter. Total: 0.0751 s/iter. ETA=0:00:01\n",
      "\u001b[32m[09/26 23:20:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:42.620063 (0.075972 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 23:20:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.071293 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 23:20:38 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/26 23:20:38 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\coco_instances_results.json\n",
      "\u001b[32m[09/26 23:20:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.22s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.932\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.928\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.935\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.937\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.951\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.940\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.958\n",
      "\u001b[32m[09/26 23:20:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 93.246 | 99.009 | 98.998 |  nan  | 92.840 | 93.513 |\n",
      "\u001b[32m[09/26 23:20:38 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 23:20:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 93.246 | background | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.34s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.860\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.828\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.881\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.881\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.895\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.866\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.914\n",
      "\u001b[32m[09/26 23:20:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 86.022 | 99.009 | 98.957 |  nan  | 82.786 | 88.146 |\n",
      "\u001b[32m[09/26 23:20:39 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 23:20:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 86.022 | background | nan  |\n",
      "\u001b[32m[09/26 23:20:39 d2.engine.defaults]: \u001b[0mEvaluation results for test_data in csv format:\n",
      "\u001b[32m[09/26 23:20:39 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/26 23:20:39 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 23:20:39 d2.evaluation.testing]: \u001b[0mcopypaste: 93.2463,99.0085,98.9976,nan,92.8403,93.5134\n",
      "\u001b[32m[09/26 23:20:39 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/26 23:20:39 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 23:20:39 d2.evaluation.testing]: \u001b[0mcopypaste: 86.0222,99.0085,98.9575,nan,82.7856,88.1455\n",
      "\u001b[32m[09/26 23:20:39 d2.utils.events]: \u001b[0m eta: 2:29:58  iter: 13999  total_loss: 0.2163  loss_cls: 0.03136  loss_box_reg: 0.0738  loss_mask: 0.07738  loss_rpn_cls: 0.002138  loss_rpn_loc: 0.02962  total_val_loss: 0.2071  val_loss_cls: 0.02704  val_loss_box_reg: 0.0685  val_loss_mask: 0.0837  val_loss_rpn_cls: 0.0009398  val_loss_rpn_loc: 0.02515    time: 1.6211  last_time: 1.5491  data_time: 0.0067  last_data_time: 0.0068   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:21:21 d2.utils.events]: \u001b[0m eta: 2:29:23  iter: 14019  total_loss: 0.2305  loss_cls: 0.03503  loss_box_reg: 0.07628  loss_mask: 0.07558  loss_rpn_cls: 0.00227  loss_rpn_loc: 0.0285  total_val_loss: 0.2023  val_loss_cls: 0.02886  val_loss_box_reg: 0.062  val_loss_mask: 0.08856  val_loss_rpn_cls: 0.0008601  val_loss_rpn_loc: 0.02199    time: 1.6209  last_time: 1.4795  data_time: 0.0066  last_data_time: 0.0060   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:22:04 d2.utils.events]: \u001b[0m eta: 2:28:46  iter: 14039  total_loss: 0.2091  loss_cls: 0.03052  loss_box_reg: 0.07083  loss_mask: 0.08168  loss_rpn_cls: 0.002333  loss_rpn_loc: 0.02913  total_val_loss: 0.2063  val_loss_cls: 0.02829  val_loss_box_reg: 0.06477  val_loss_mask: 0.0858  val_loss_rpn_cls: 0.001028  val_loss_rpn_loc: 0.02243    time: 1.6207  last_time: 1.4450  data_time: 0.0068  last_data_time: 0.0059   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:22:46 d2.utils.events]: \u001b[0m eta: 2:28:10  iter: 14059  total_loss: 0.2143  loss_cls: 0.03162  loss_box_reg: 0.06725  loss_mask: 0.07719  loss_rpn_cls: 0.00196  loss_rpn_loc: 0.03195  total_val_loss: 0.1936  val_loss_cls: 0.02594  val_loss_box_reg: 0.06504  val_loss_mask: 0.08046  val_loss_rpn_cls: 0.0008401  val_loss_rpn_loc: 0.02268    time: 1.6205  last_time: 1.3857  data_time: 0.0069  last_data_time: 0.0065   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:23:29 d2.utils.events]: \u001b[0m eta: 2:27:36  iter: 14079  total_loss: 0.2002  loss_cls: 0.02577  loss_box_reg: 0.0577  loss_mask: 0.08555  loss_rpn_cls: 0.002297  loss_rpn_loc: 0.02838  total_val_loss: 0.1934  val_loss_cls: 0.02577  val_loss_box_reg: 0.06225  val_loss_mask: 0.08352  val_loss_rpn_cls: 0.000793  val_loss_rpn_loc: 0.0251    time: 1.6203  last_time: 1.4545  data_time: 0.0066  last_data_time: 0.0063   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:24:11 d2.utils.events]: \u001b[0m eta: 2:27:02  iter: 14099  total_loss: 0.188  loss_cls: 0.02443  loss_box_reg: 0.06209  loss_mask: 0.07648  loss_rpn_cls: 0.001695  loss_rpn_loc: 0.02364  total_val_loss: 0.2162  val_loss_cls: 0.02652  val_loss_box_reg: 0.06565  val_loss_mask: 0.08952  val_loss_rpn_cls: 0.000881  val_loss_rpn_loc: 0.02212    time: 1.6201  last_time: 1.4902  data_time: 0.0068  last_data_time: 0.0077   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:24:53 d2.utils.events]: \u001b[0m eta: 2:26:27  iter: 14119  total_loss: 0.2253  loss_cls: 0.03345  loss_box_reg: 0.07783  loss_mask: 0.08273  loss_rpn_cls: 0.001982  loss_rpn_loc: 0.02871  total_val_loss: 0.1799  val_loss_cls: 0.02348  val_loss_box_reg: 0.05495  val_loss_mask: 0.07835  val_loss_rpn_cls: 0.001088  val_loss_rpn_loc: 0.02172    time: 1.6199  last_time: 1.5580  data_time: 0.0068  last_data_time: 0.0073   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:25:36 d2.utils.events]: \u001b[0m eta: 2:25:50  iter: 14139  total_loss: 0.233  loss_cls: 0.02959  loss_box_reg: 0.07148  loss_mask: 0.07913  loss_rpn_cls: 0.002413  loss_rpn_loc: 0.03086  total_val_loss: 0.2098  val_loss_cls: 0.03098  val_loss_box_reg: 0.0693  val_loss_mask: 0.08034  val_loss_rpn_cls: 0.001119  val_loss_rpn_loc: 0.02501    time: 1.6197  last_time: 1.5467  data_time: 0.0070  last_data_time: 0.0064   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:26:18 d2.utils.events]: \u001b[0m eta: 2:25:14  iter: 14159  total_loss: 0.1969  loss_cls: 0.02405  loss_box_reg: 0.06194  loss_mask: 0.08273  loss_rpn_cls: 0.001753  loss_rpn_loc: 0.02431  total_val_loss: 0.213  val_loss_cls: 0.03043  val_loss_box_reg: 0.07387  val_loss_mask: 0.08094  val_loss_rpn_cls: 0.0009627  val_loss_rpn_loc: 0.02572    time: 1.6195  last_time: 1.4625  data_time: 0.0072  last_data_time: 0.0055   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:27:01 d2.utils.events]: \u001b[0m eta: 2:24:42  iter: 14179  total_loss: 0.2196  loss_cls: 0.02699  loss_box_reg: 0.07228  loss_mask: 0.07934  loss_rpn_cls: 0.003051  loss_rpn_loc: 0.02965  total_val_loss: 0.1947  val_loss_cls: 0.02535  val_loss_box_reg: 0.06042  val_loss_mask: 0.08308  val_loss_rpn_cls: 0.001363  val_loss_rpn_loc: 0.02362    time: 1.6193  last_time: 1.4436  data_time: 0.0076  last_data_time: 0.0076   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:27:44 d2.utils.events]: \u001b[0m eta: 2:24:02  iter: 14199  total_loss: 0.2129  loss_cls: 0.02959  loss_box_reg: 0.06778  loss_mask: 0.08174  loss_rpn_cls: 0.002573  loss_rpn_loc: 0.03071  total_val_loss: 0.2125  val_loss_cls: 0.02541  val_loss_box_reg: 0.06681  val_loss_mask: 0.08327  val_loss_rpn_cls: 0.0009263  val_loss_rpn_loc: 0.02349    time: 1.6191  last_time: 1.5099  data_time: 0.0080  last_data_time: 0.0078   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:28:26 d2.utils.events]: \u001b[0m eta: 2:23:25  iter: 14219  total_loss: 0.1958  loss_cls: 0.02548  loss_box_reg: 0.06123  loss_mask: 0.08183  loss_rpn_cls: 0.001954  loss_rpn_loc: 0.0244  total_val_loss: 0.2038  val_loss_cls: 0.02943  val_loss_box_reg: 0.06625  val_loss_mask: 0.08454  val_loss_rpn_cls: 0.00115  val_loss_rpn_loc: 0.02335    time: 1.6189  last_time: 1.5262  data_time: 0.0074  last_data_time: 0.0083   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:29:09 d2.utils.events]: \u001b[0m eta: 2:22:51  iter: 14239  total_loss: 0.2246  loss_cls: 0.02984  loss_box_reg: 0.07638  loss_mask: 0.08163  loss_rpn_cls: 0.001999  loss_rpn_loc: 0.03121  total_val_loss: 0.1967  val_loss_cls: 0.02678  val_loss_box_reg: 0.05895  val_loss_mask: 0.08176  val_loss_rpn_cls: 0.0008362  val_loss_rpn_loc: 0.02073    time: 1.6188  last_time: 1.4830  data_time: 0.0078  last_data_time: 0.0075   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:29:51 d2.utils.events]: \u001b[0m eta: 2:22:16  iter: 14259  total_loss: 0.2044  loss_cls: 0.02755  loss_box_reg: 0.06744  loss_mask: 0.07801  loss_rpn_cls: 0.001969  loss_rpn_loc: 0.02578  total_val_loss: 0.2127  val_loss_cls: 0.02931  val_loss_box_reg: 0.06857  val_loss_mask: 0.08518  val_loss_rpn_cls: 0.001061  val_loss_rpn_loc: 0.02382    time: 1.6186  last_time: 1.4478  data_time: 0.0074  last_data_time: 0.0091   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:30:34 d2.utils.events]: \u001b[0m eta: 2:21:34  iter: 14279  total_loss: 0.2267  loss_cls: 0.03387  loss_box_reg: 0.08474  loss_mask: 0.07611  loss_rpn_cls: 0.0024  loss_rpn_loc: 0.03416  total_val_loss: 0.2118  val_loss_cls: 0.02943  val_loss_box_reg: 0.07175  val_loss_mask: 0.08401  val_loss_rpn_cls: 0.001244  val_loss_rpn_loc: 0.02487    time: 1.6184  last_time: 1.4821  data_time: 0.0081  last_data_time: 0.0071   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:31:16 d2.utils.events]: \u001b[0m eta: 2:20:55  iter: 14299  total_loss: 0.2144  loss_cls: 0.02913  loss_box_reg: 0.07313  loss_mask: 0.07665  loss_rpn_cls: 0.002711  loss_rpn_loc: 0.02754  total_val_loss: 0.2008  val_loss_cls: 0.02892  val_loss_box_reg: 0.06153  val_loss_mask: 0.08256  val_loss_rpn_cls: 0.0008451  val_loss_rpn_loc: 0.02179    time: 1.6182  last_time: 1.4815  data_time: 0.0080  last_data_time: 0.0060   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:31:59 d2.utils.events]: \u001b[0m eta: 2:20:21  iter: 14319  total_loss: 0.2043  loss_cls: 0.0272  loss_box_reg: 0.06584  loss_mask: 0.07932  loss_rpn_cls: 0.001633  loss_rpn_loc: 0.02679  total_val_loss: 0.1943  val_loss_cls: 0.02655  val_loss_box_reg: 0.064  val_loss_mask: 0.0826  val_loss_rpn_cls: 0.0009116  val_loss_rpn_loc: 0.02201    time: 1.6180  last_time: 1.5105  data_time: 0.0083  last_data_time: 0.0087   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:32:41 d2.utils.events]: \u001b[0m eta: 2:19:48  iter: 14339  total_loss: 0.2207  loss_cls: 0.03305  loss_box_reg: 0.07454  loss_mask: 0.07979  loss_rpn_cls: 0.001726  loss_rpn_loc: 0.02769  total_val_loss: 0.2024  val_loss_cls: 0.02516  val_loss_box_reg: 0.06668  val_loss_mask: 0.08149  val_loss_rpn_cls: 0.00165  val_loss_rpn_loc: 0.02347    time: 1.6179  last_time: 1.4236  data_time: 0.0077  last_data_time: 0.0072   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:33:24 d2.utils.events]: \u001b[0m eta: 2:19:19  iter: 14359  total_loss: 0.2265  loss_cls: 0.03193  loss_box_reg: 0.07722  loss_mask: 0.0816  loss_rpn_cls: 0.002425  loss_rpn_loc: 0.0266  total_val_loss: 0.2037  val_loss_cls: 0.02779  val_loss_box_reg: 0.0638  val_loss_mask: 0.08781  val_loss_rpn_cls: 0.0006532  val_loss_rpn_loc: 0.02446    time: 1.6177  last_time: 1.5100  data_time: 0.0075  last_data_time: 0.0079   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:34:07 d2.utils.events]: \u001b[0m eta: 2:18:47  iter: 14379  total_loss: 0.2133  loss_cls: 0.02861  loss_box_reg: 0.07108  loss_mask: 0.0829  loss_rpn_cls: 0.002168  loss_rpn_loc: 0.027  total_val_loss: 0.1972  val_loss_cls: 0.02467  val_loss_box_reg: 0.05739  val_loss_mask: 0.08638  val_loss_rpn_cls: 0.001358  val_loss_rpn_loc: 0.02094    time: 1.6175  last_time: 1.5779  data_time: 0.0077  last_data_time: 0.0063   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:34:49 d2.utils.events]: \u001b[0m eta: 2:18:16  iter: 14399  total_loss: 0.2019  loss_cls: 0.02711  loss_box_reg: 0.07107  loss_mask: 0.07869  loss_rpn_cls: 0.002613  loss_rpn_loc: 0.02502  total_val_loss: 0.2032  val_loss_cls: 0.02805  val_loss_box_reg: 0.06263  val_loss_mask: 0.08072  val_loss_rpn_cls: 0.0015  val_loss_rpn_loc: 0.02298    time: 1.6173  last_time: 1.3845  data_time: 0.0080  last_data_time: 0.0081   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:35:32 d2.utils.events]: \u001b[0m eta: 2:17:47  iter: 14419  total_loss: 0.1969  loss_cls: 0.02585  loss_box_reg: 0.06207  loss_mask: 0.06921  loss_rpn_cls: 0.001209  loss_rpn_loc: 0.02165  total_val_loss: 0.1955  val_loss_cls: 0.02634  val_loss_box_reg: 0.06134  val_loss_mask: 0.08068  val_loss_rpn_cls: 0.000686  val_loss_rpn_loc: 0.02181    time: 1.6171  last_time: 1.3725  data_time: 0.0076  last_data_time: 0.0070   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:36:14 d2.utils.events]: \u001b[0m eta: 2:17:17  iter: 14439  total_loss: 0.2154  loss_cls: 0.02868  loss_box_reg: 0.07437  loss_mask: 0.08033  loss_rpn_cls: 0.002771  loss_rpn_loc: 0.02951  total_val_loss: 0.2099  val_loss_cls: 0.02808  val_loss_box_reg: 0.06667  val_loss_mask: 0.08476  val_loss_rpn_cls: 0.001585  val_loss_rpn_loc: 0.02606    time: 1.6170  last_time: 1.5214  data_time: 0.0076  last_data_time: 0.0076   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:36:57 d2.utils.events]: \u001b[0m eta: 2:16:46  iter: 14459  total_loss: 0.2156  loss_cls: 0.02672  loss_box_reg: 0.07506  loss_mask: 0.0832  loss_rpn_cls: 0.00209  loss_rpn_loc: 0.02685  total_val_loss: 0.1987  val_loss_cls: 0.03005  val_loss_box_reg: 0.06692  val_loss_mask: 0.08402  val_loss_rpn_cls: 0.0009912  val_loss_rpn_loc: 0.02421    time: 1.6168  last_time: 1.4386  data_time: 0.0073  last_data_time: 0.0074   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:37:39 d2.utils.events]: \u001b[0m eta: 2:16:16  iter: 14479  total_loss: 0.2001  loss_cls: 0.02785  loss_box_reg: 0.06346  loss_mask: 0.07647  loss_rpn_cls: 0.001497  loss_rpn_loc: 0.02458  total_val_loss: 0.2229  val_loss_cls: 0.03077  val_loss_box_reg: 0.07425  val_loss_mask: 0.08602  val_loss_rpn_cls: 0.001307  val_loss_rpn_loc: 0.02585    time: 1.6166  last_time: 1.4416  data_time: 0.0076  last_data_time: 0.0075   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:38:21 d2.utils.events]: \u001b[0m eta: 2:15:46  iter: 14499  total_loss: 0.188  loss_cls: 0.02433  loss_box_reg: 0.05978  loss_mask: 0.07737  loss_rpn_cls: 0.002118  loss_rpn_loc: 0.02486  total_val_loss: 0.1892  val_loss_cls: 0.02438  val_loss_box_reg: 0.05985  val_loss_mask: 0.08674  val_loss_rpn_cls: 0.0008559  val_loss_rpn_loc: 0.02189    time: 1.6164  last_time: 1.4360  data_time: 0.0076  last_data_time: 0.0062   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:39:04 d2.utils.events]: \u001b[0m eta: 2:15:16  iter: 14519  total_loss: 0.2183  loss_cls: 0.03208  loss_box_reg: 0.07786  loss_mask: 0.07585  loss_rpn_cls: 0.001786  loss_rpn_loc: 0.02767  total_val_loss: 0.1906  val_loss_cls: 0.02719  val_loss_box_reg: 0.06048  val_loss_mask: 0.08745  val_loss_rpn_cls: 0.00073  val_loss_rpn_loc: 0.0218    time: 1.6162  last_time: 1.5140  data_time: 0.0075  last_data_time: 0.0063   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:39:47 d2.utils.events]: \u001b[0m eta: 2:14:47  iter: 14539  total_loss: 0.2149  loss_cls: 0.02758  loss_box_reg: 0.07461  loss_mask: 0.08146  loss_rpn_cls: 0.002325  loss_rpn_loc: 0.02837  total_val_loss: 0.1953  val_loss_cls: 0.02972  val_loss_box_reg: 0.06369  val_loss_mask: 0.08558  val_loss_rpn_cls: 0.0009494  val_loss_rpn_loc: 0.02411    time: 1.6160  last_time: 1.3972  data_time: 0.0077  last_data_time: 0.0062   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:40:29 d2.utils.events]: \u001b[0m eta: 2:14:14  iter: 14559  total_loss: 0.2099  loss_cls: 0.02674  loss_box_reg: 0.06555  loss_mask: 0.07996  loss_rpn_cls: 0.001741  loss_rpn_loc: 0.02772  total_val_loss: 0.1975  val_loss_cls: 0.02916  val_loss_box_reg: 0.06115  val_loss_mask: 0.08247  val_loss_rpn_cls: 0.001036  val_loss_rpn_loc: 0.02272    time: 1.6159  last_time: 1.4630  data_time: 0.0074  last_data_time: 0.0070   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:41:12 d2.utils.events]: \u001b[0m eta: 2:13:44  iter: 14579  total_loss: 0.2029  loss_cls: 0.02709  loss_box_reg: 0.06731  loss_mask: 0.0816  loss_rpn_cls: 0.00183  loss_rpn_loc: 0.02729  total_val_loss: 0.2066  val_loss_cls: 0.02655  val_loss_box_reg: 0.06393  val_loss_mask: 0.08542  val_loss_rpn_cls: 0.001861  val_loss_rpn_loc: 0.02495    time: 1.6157  last_time: 1.5705  data_time: 0.0078  last_data_time: 0.0071   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:41:54 d2.utils.events]: \u001b[0m eta: 2:13:17  iter: 14599  total_loss: 0.2202  loss_cls: 0.02849  loss_box_reg: 0.07491  loss_mask: 0.0842  loss_rpn_cls: 0.001937  loss_rpn_loc: 0.02934  total_val_loss: 0.1941  val_loss_cls: 0.02483  val_loss_box_reg: 0.06226  val_loss_mask: 0.08066  val_loss_rpn_cls: 0.0008667  val_loss_rpn_loc: 0.02399    time: 1.6155  last_time: 1.3939  data_time: 0.0080  last_data_time: 0.0102   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:42:37 d2.utils.events]: \u001b[0m eta: 2:12:44  iter: 14619  total_loss: 0.2144  loss_cls: 0.02983  loss_box_reg: 0.07312  loss_mask: 0.08072  loss_rpn_cls: 0.001974  loss_rpn_loc: 0.02791  total_val_loss: 0.2243  val_loss_cls: 0.03521  val_loss_box_reg: 0.07693  val_loss_mask: 0.08718  val_loss_rpn_cls: 0.0009779  val_loss_rpn_loc: 0.02431    time: 1.6154  last_time: 1.5789  data_time: 0.0083  last_data_time: 0.0088   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:43:20 d2.utils.events]: \u001b[0m eta: 2:12:15  iter: 14639  total_loss: 0.2114  loss_cls: 0.02695  loss_box_reg: 0.0711  loss_mask: 0.08105  loss_rpn_cls: 0.002593  loss_rpn_loc: 0.03116  total_val_loss: 0.1783  val_loss_cls: 0.0228  val_loss_box_reg: 0.05473  val_loss_mask: 0.07918  val_loss_rpn_cls: 0.0008161  val_loss_rpn_loc: 0.0199    time: 1.6152  last_time: 1.4590  data_time: 0.0077  last_data_time: 0.0067   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:44:03 d2.utils.events]: \u001b[0m eta: 2:11:50  iter: 14659  total_loss: 0.2135  loss_cls: 0.02903  loss_box_reg: 0.07048  loss_mask: 0.08441  loss_rpn_cls: 0.001992  loss_rpn_loc: 0.02846  total_val_loss: 0.1992  val_loss_cls: 0.0253  val_loss_box_reg: 0.06302  val_loss_mask: 0.08709  val_loss_rpn_cls: 0.0008999  val_loss_rpn_loc: 0.02329    time: 1.6151  last_time: 1.4906  data_time: 0.0078  last_data_time: 0.0074   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:44:45 d2.utils.events]: \u001b[0m eta: 2:11:20  iter: 14679  total_loss: 0.2203  loss_cls: 0.03157  loss_box_reg: 0.07061  loss_mask: 0.07993  loss_rpn_cls: 0.002422  loss_rpn_loc: 0.03215  total_val_loss: 0.2038  val_loss_cls: 0.02788  val_loss_box_reg: 0.06346  val_loss_mask: 0.08249  val_loss_rpn_cls: 0.0009447  val_loss_rpn_loc: 0.02126    time: 1.6149  last_time: 1.5052  data_time: 0.0073  last_data_time: 0.0066   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:45:27 d2.utils.events]: \u001b[0m eta: 2:10:50  iter: 14699  total_loss: 0.2321  loss_cls: 0.0334  loss_box_reg: 0.0716  loss_mask: 0.07634  loss_rpn_cls: 0.002328  loss_rpn_loc: 0.03212  total_val_loss: 0.2082  val_loss_cls: 0.02912  val_loss_box_reg: 0.06721  val_loss_mask: 0.08139  val_loss_rpn_cls: 0.0008654  val_loss_rpn_loc: 0.02302    time: 1.6147  last_time: 1.4892  data_time: 0.0074  last_data_time: 0.0089   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:46:10 d2.utils.events]: \u001b[0m eta: 2:10:20  iter: 14719  total_loss: 0.2205  loss_cls: 0.02698  loss_box_reg: 0.07436  loss_mask: 0.07983  loss_rpn_cls: 0.002908  loss_rpn_loc: 0.02779  total_val_loss: 0.2102  val_loss_cls: 0.02472  val_loss_box_reg: 0.06326  val_loss_mask: 0.08083  val_loss_rpn_cls: 0.001196  val_loss_rpn_loc: 0.02418    time: 1.6145  last_time: 1.5680  data_time: 0.0075  last_data_time: 0.0086   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:46:53 d2.utils.events]: \u001b[0m eta: 2:09:51  iter: 14739  total_loss: 0.2204  loss_cls: 0.02817  loss_box_reg: 0.07343  loss_mask: 0.08338  loss_rpn_cls: 0.001469  loss_rpn_loc: 0.02979  total_val_loss: 0.1975  val_loss_cls: 0.0255  val_loss_box_reg: 0.06053  val_loss_mask: 0.08491  val_loss_rpn_cls: 0.001254  val_loss_rpn_loc: 0.02443    time: 1.6144  last_time: 1.4732  data_time: 0.0076  last_data_time: 0.0066   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:47:35 d2.utils.events]: \u001b[0m eta: 2:09:23  iter: 14759  total_loss: 0.2023  loss_cls: 0.02734  loss_box_reg: 0.06533  loss_mask: 0.07737  loss_rpn_cls: 0.002555  loss_rpn_loc: 0.0255  total_val_loss: 0.2154  val_loss_cls: 0.02912  val_loss_box_reg: 0.07278  val_loss_mask: 0.08601  val_loss_rpn_cls: 0.001115  val_loss_rpn_loc: 0.02487    time: 1.6142  last_time: 1.4179  data_time: 0.0075  last_data_time: 0.0073   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:48:18 d2.utils.events]: \u001b[0m eta: 2:08:55  iter: 14779  total_loss: 0.2035  loss_cls: 0.0293  loss_box_reg: 0.06633  loss_mask: 0.07773  loss_rpn_cls: 0.002788  loss_rpn_loc: 0.03015  total_val_loss: 0.1976  val_loss_cls: 0.0256  val_loss_box_reg: 0.06612  val_loss_mask: 0.08795  val_loss_rpn_cls: 0.0006942  val_loss_rpn_loc: 0.02167    time: 1.6140  last_time: 1.3952  data_time: 0.0073  last_data_time: 0.0061   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:49:00 d2.utils.events]: \u001b[0m eta: 2:08:26  iter: 14799  total_loss: 0.1969  loss_cls: 0.03  loss_box_reg: 0.06542  loss_mask: 0.07585  loss_rpn_cls: 0.001801  loss_rpn_loc: 0.02893  total_val_loss: 0.1809  val_loss_cls: 0.02238  val_loss_box_reg: 0.05255  val_loss_mask: 0.07866  val_loss_rpn_cls: 0.0008411  val_loss_rpn_loc: 0.02206    time: 1.6139  last_time: 1.5574  data_time: 0.0078  last_data_time: 0.0064   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:49:43 d2.utils.events]: \u001b[0m eta: 2:07:57  iter: 14819  total_loss: 0.2317  loss_cls: 0.02984  loss_box_reg: 0.07709  loss_mask: 0.08401  loss_rpn_cls: 0.002812  loss_rpn_loc: 0.03081  total_val_loss: 0.2101  val_loss_cls: 0.02555  val_loss_box_reg: 0.0578  val_loss_mask: 0.08757  val_loss_rpn_cls: 0.00147  val_loss_rpn_loc: 0.02419    time: 1.6137  last_time: 1.4272  data_time: 0.0073  last_data_time: 0.0109   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:50:25 d2.utils.events]: \u001b[0m eta: 2:07:25  iter: 14839  total_loss: 0.199  loss_cls: 0.02541  loss_box_reg: 0.06709  loss_mask: 0.07889  loss_rpn_cls: 0.001293  loss_rpn_loc: 0.02808  total_val_loss: 0.215  val_loss_cls: 0.03353  val_loss_box_reg: 0.07255  val_loss_mask: 0.0812  val_loss_rpn_cls: 0.0008106  val_loss_rpn_loc: 0.02509    time: 1.6135  last_time: 1.5429  data_time: 0.0081  last_data_time: 0.0069   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:51:08 d2.utils.events]: \u001b[0m eta: 2:06:55  iter: 14859  total_loss: 0.2068  loss_cls: 0.02483  loss_box_reg: 0.06734  loss_mask: 0.07889  loss_rpn_cls: 0.002123  loss_rpn_loc: 0.02799  total_val_loss: 0.1872  val_loss_cls: 0.02577  val_loss_box_reg: 0.06248  val_loss_mask: 0.08386  val_loss_rpn_cls: 0.001062  val_loss_rpn_loc: 0.02209    time: 1.6134  last_time: 1.4620  data_time: 0.0078  last_data_time: 0.0095   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:51:51 d2.utils.events]: \u001b[0m eta: 2:06:26  iter: 14879  total_loss: 0.2299  loss_cls: 0.03449  loss_box_reg: 0.07999  loss_mask: 0.08034  loss_rpn_cls: 0.001711  loss_rpn_loc: 0.03226  total_val_loss: 0.1908  val_loss_cls: 0.02522  val_loss_box_reg: 0.05955  val_loss_mask: 0.08619  val_loss_rpn_cls: 0.0007649  val_loss_rpn_loc: 0.02332    time: 1.6132  last_time: 1.4566  data_time: 0.0079  last_data_time: 0.0106   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:52:33 d2.utils.events]: \u001b[0m eta: 2:05:58  iter: 14899  total_loss: 0.2317  loss_cls: 0.02924  loss_box_reg: 0.07407  loss_mask: 0.08614  loss_rpn_cls: 0.001801  loss_rpn_loc: 0.02881  total_val_loss: 0.2044  val_loss_cls: 0.02702  val_loss_box_reg: 0.06259  val_loss_mask: 0.081  val_loss_rpn_cls: 0.00108  val_loss_rpn_loc: 0.02391    time: 1.6130  last_time: 1.4940  data_time: 0.0077  last_data_time: 0.0102   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:53:15 d2.utils.events]: \u001b[0m eta: 2:05:26  iter: 14919  total_loss: 0.2107  loss_cls: 0.02949  loss_box_reg: 0.06797  loss_mask: 0.07703  loss_rpn_cls: 0.001958  loss_rpn_loc: 0.0265  total_val_loss: 0.2049  val_loss_cls: 0.03238  val_loss_box_reg: 0.072  val_loss_mask: 0.08631  val_loss_rpn_cls: 0.001146  val_loss_rpn_loc: 0.02384    time: 1.6129  last_time: 1.4193  data_time: 0.0074  last_data_time: 0.0088   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:53:58 d2.utils.events]: \u001b[0m eta: 2:04:59  iter: 14939  total_loss: 0.2165  loss_cls: 0.02967  loss_box_reg: 0.07438  loss_mask: 0.08244  loss_rpn_cls: 0.001797  loss_rpn_loc: 0.02824  total_val_loss: 0.1794  val_loss_cls: 0.02324  val_loss_box_reg: 0.05535  val_loss_mask: 0.07783  val_loss_rpn_cls: 0.0006187  val_loss_rpn_loc: 0.01878    time: 1.6127  last_time: 1.4945  data_time: 0.0080  last_data_time: 0.0067   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:54:40 d2.utils.events]: \u001b[0m eta: 2:04:28  iter: 14959  total_loss: 0.2112  loss_cls: 0.02749  loss_box_reg: 0.06823  loss_mask: 0.08492  loss_rpn_cls: 0.002422  loss_rpn_loc: 0.02685  total_val_loss: 0.2296  val_loss_cls: 0.03526  val_loss_box_reg: 0.07721  val_loss_mask: 0.08983  val_loss_rpn_cls: 0.001391  val_loss_rpn_loc: 0.02597    time: 1.6125  last_time: 1.4619  data_time: 0.0083  last_data_time: 0.0062   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:55:23 d2.utils.events]: \u001b[0m eta: 2:04:03  iter: 14979  total_loss: 0.2071  loss_cls: 0.02512  loss_box_reg: 0.06973  loss_mask: 0.0754  loss_rpn_cls: 0.002051  loss_rpn_loc: 0.02684  total_val_loss: 0.2062  val_loss_cls: 0.02677  val_loss_box_reg: 0.06711  val_loss_mask: 0.08831  val_loss_rpn_cls: 0.001276  val_loss_rpn_loc: 0.02371    time: 1.6124  last_time: 1.5245  data_time: 0.0080  last_data_time: 0.0070   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:56:09 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\testing_images\\0_SideLane_addedversion_Testing_COCO.json\n",
      "\u001b[32m[09/26 23:56:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/26 23:56:09 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/26 23:56:09 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/26 23:56:09 d2.data.common]: \u001b[0mSerialized dataset takes 6.03 MiB\n",
      "\u001b[32m[09/26 23:56:09 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[09/26 23:56:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 566 batches\n",
      "\u001b[32m[09/26 23:56:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/566. Dataloading: 0.0003 s/iter. Inference: 0.0698 s/iter. Eval: 0.0063 s/iter. Total: 0.0765 s/iter. ETA=0:00:42\n",
      "\u001b[32m[09/26 23:56:18 d2.evaluation.evaluator]: \u001b[0mInference done 80/566. Dataloading: 0.0005 s/iter. Inference: 0.0699 s/iter. Eval: 0.0027 s/iter. Total: 0.0732 s/iter. ETA=0:00:35\n",
      "\u001b[32m[09/26 23:56:23 d2.evaluation.evaluator]: \u001b[0mInference done 147/566. Dataloading: 0.0005 s/iter. Inference: 0.0699 s/iter. Eval: 0.0037 s/iter. Total: 0.0742 s/iter. ETA=0:00:31\n",
      "\u001b[32m[09/26 23:56:28 d2.evaluation.evaluator]: \u001b[0mInference done 213/566. Dataloading: 0.0006 s/iter. Inference: 0.0706 s/iter. Eval: 0.0036 s/iter. Total: 0.0748 s/iter. ETA=0:00:26\n",
      "\u001b[32m[09/26 23:56:33 d2.evaluation.evaluator]: \u001b[0mInference done 280/566. Dataloading: 0.0006 s/iter. Inference: 0.0709 s/iter. Eval: 0.0035 s/iter. Total: 0.0750 s/iter. ETA=0:00:21\n",
      "\u001b[32m[09/26 23:56:38 d2.evaluation.evaluator]: \u001b[0mInference done 350/566. Dataloading: 0.0006 s/iter. Inference: 0.0705 s/iter. Eval: 0.0032 s/iter. Total: 0.0743 s/iter. ETA=0:00:16\n",
      "\u001b[32m[09/26 23:56:43 d2.evaluation.evaluator]: \u001b[0mInference done 419/566. Dataloading: 0.0006 s/iter. Inference: 0.0705 s/iter. Eval: 0.0029 s/iter. Total: 0.0740 s/iter. ETA=0:00:10\n",
      "\u001b[32m[09/26 23:56:48 d2.evaluation.evaluator]: \u001b[0mInference done 482/566. Dataloading: 0.0006 s/iter. Inference: 0.0709 s/iter. Eval: 0.0033 s/iter. Total: 0.0748 s/iter. ETA=0:00:06\n",
      "\u001b[32m[09/26 23:56:53 d2.evaluation.evaluator]: \u001b[0mInference done 547/566. Dataloading: 0.0006 s/iter. Inference: 0.0713 s/iter. Eval: 0.0033 s/iter. Total: 0.0751 s/iter. ETA=0:00:01\n",
      "\u001b[32m[09/26 23:56:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:42.632877 (0.075994 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 23:56:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:40 (0.071301 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/26 23:56:55 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/26 23:56:55 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\coco_instances_results.json\n",
      "\u001b[32m[09/26 23:56:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.21s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.934\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.929\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.937\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.937\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.952\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.942\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.958\n",
      "\u001b[32m[09/26 23:56:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 93.400 | 99.006 | 98.993 |  nan  | 92.859 | 93.685 |\n",
      "\u001b[32m[09/26 23:56:55 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 23:56:55 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 93.400 | background | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.39s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.859\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.827\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.880\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.880\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.894\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.865\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.912\n",
      "\u001b[32m[09/26 23:56:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 85.898 | 99.006 | 98.952 |  nan  | 82.739 | 87.998 |\n",
      "\u001b[32m[09/26 23:56:56 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/26 23:56:56 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 85.898 | background | nan  |\n",
      "\u001b[32m[09/26 23:56:56 d2.engine.defaults]: \u001b[0mEvaluation results for test_data in csv format:\n",
      "\u001b[32m[09/26 23:56:56 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/26 23:56:56 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 23:56:56 d2.evaluation.testing]: \u001b[0mcopypaste: 93.3999,99.0057,98.9932,nan,92.8590,93.6848\n",
      "\u001b[32m[09/26 23:56:56 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/26 23:56:56 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/26 23:56:56 d2.evaluation.testing]: \u001b[0mcopypaste: 85.8984,99.0057,98.9517,nan,82.7390,87.9975\n",
      "\u001b[32m[09/26 23:56:57 d2.utils.events]: \u001b[0m eta: 2:03:36  iter: 14999  total_loss: 0.2444  loss_cls: 0.03293  loss_box_reg: 0.08585  loss_mask: 0.08127  loss_rpn_cls: 0.002313  loss_rpn_loc: 0.03542  total_val_loss: 0.1999  val_loss_cls: 0.02816  val_loss_box_reg: 0.06483  val_loss_mask: 0.08104  val_loss_rpn_cls: 0.002094  val_loss_rpn_loc: 0.02406    time: 1.6123  last_time: 1.4529  data_time: 0.0079  last_data_time: 0.0072   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:57:39 d2.utils.events]: \u001b[0m eta: 2:03:10  iter: 15019  total_loss: 0.2123  loss_cls: 0.03028  loss_box_reg: 0.06696  loss_mask: 0.07369  loss_rpn_cls: 0.001707  loss_rpn_loc: 0.03001  total_val_loss: 0.2048  val_loss_cls: 0.02839  val_loss_box_reg: 0.06483  val_loss_mask: 0.08356  val_loss_rpn_cls: 0.001234  val_loss_rpn_loc: 0.02293    time: 1.6121  last_time: 1.4410  data_time: 0.0079  last_data_time: 0.0068   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:58:22 d2.utils.events]: \u001b[0m eta: 2:02:45  iter: 15039  total_loss: 0.2182  loss_cls: 0.02989  loss_box_reg: 0.07217  loss_mask: 0.079  loss_rpn_cls: 0.003107  loss_rpn_loc: 0.02648  total_val_loss: 0.1956  val_loss_cls: 0.0265  val_loss_box_reg: 0.0621  val_loss_mask: 0.08179  val_loss_rpn_cls: 0.001207  val_loss_rpn_loc: 0.02296    time: 1.6119  last_time: 1.5238  data_time: 0.0074  last_data_time: 0.0073   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:59:04 d2.utils.events]: \u001b[0m eta: 2:02:14  iter: 15059  total_loss: 0.1887  loss_cls: 0.02464  loss_box_reg: 0.06176  loss_mask: 0.08014  loss_rpn_cls: 0.001506  loss_rpn_loc: 0.02313  total_val_loss: 0.221  val_loss_cls: 0.03231  val_loss_box_reg: 0.07141  val_loss_mask: 0.08054  val_loss_rpn_cls: 0.000892  val_loss_rpn_loc: 0.02512    time: 1.6118  last_time: 1.5791  data_time: 0.0078  last_data_time: 0.0064   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/26 23:59:46 d2.utils.events]: \u001b[0m eta: 2:01:47  iter: 15079  total_loss: 0.2137  loss_cls: 0.0266  loss_box_reg: 0.06979  loss_mask: 0.08238  loss_rpn_cls: 0.002039  loss_rpn_loc: 0.03222  total_val_loss: 0.2125  val_loss_cls: 0.02704  val_loss_box_reg: 0.07207  val_loss_mask: 0.08704  val_loss_rpn_cls: 0.001373  val_loss_rpn_loc: 0.0257    time: 1.6116  last_time: 1.4666  data_time: 0.0075  last_data_time: 0.0081   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:00:29 d2.utils.events]: \u001b[0m eta: 2:01:17  iter: 15099  total_loss: 0.2028  loss_cls: 0.02782  loss_box_reg: 0.06344  loss_mask: 0.07812  loss_rpn_cls: 0.001411  loss_rpn_loc: 0.0259  total_val_loss: 0.1981  val_loss_cls: 0.03025  val_loss_box_reg: 0.06743  val_loss_mask: 0.08007  val_loss_rpn_cls: 0.0008535  val_loss_rpn_loc: 0.02227    time: 1.6114  last_time: 1.4843  data_time: 0.0076  last_data_time: 0.0067   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:01:12 d2.utils.events]: \u001b[0m eta: 2:00:53  iter: 15119  total_loss: 0.2234  loss_cls: 0.02726  loss_box_reg: 0.07468  loss_mask: 0.07658  loss_rpn_cls: 0.002253  loss_rpn_loc: 0.03134  total_val_loss: 0.1852  val_loss_cls: 0.02394  val_loss_box_reg: 0.0596  val_loss_mask: 0.07771  val_loss_rpn_cls: 0.0007507  val_loss_rpn_loc: 0.02021    time: 1.6113  last_time: 1.5420  data_time: 0.0081  last_data_time: 0.0066   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:01:54 d2.utils.events]: \u001b[0m eta: 2:00:23  iter: 15139  total_loss: 0.2151  loss_cls: 0.02771  loss_box_reg: 0.07307  loss_mask: 0.08132  loss_rpn_cls: 0.002109  loss_rpn_loc: 0.02856  total_val_loss: 0.2059  val_loss_cls: 0.02638  val_loss_box_reg: 0.06197  val_loss_mask: 0.08604  val_loss_rpn_cls: 0.0007646  val_loss_rpn_loc: 0.02262    time: 1.6111  last_time: 1.4435  data_time: 0.0081  last_data_time: 0.0079   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:02:37 d2.utils.events]: \u001b[0m eta: 1:59:56  iter: 15159  total_loss: 0.202  loss_cls: 0.02521  loss_box_reg: 0.06702  loss_mask: 0.07772  loss_rpn_cls: 0.002156  loss_rpn_loc: 0.02493  total_val_loss: 0.1974  val_loss_cls: 0.0244  val_loss_box_reg: 0.06303  val_loss_mask: 0.08237  val_loss_rpn_cls: 0.001333  val_loss_rpn_loc: 0.02246    time: 1.6110  last_time: 1.4319  data_time: 0.0071  last_data_time: 0.0060   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:03:19 d2.utils.events]: \u001b[0m eta: 1:59:26  iter: 15179  total_loss: 0.2258  loss_cls: 0.03111  loss_box_reg: 0.07716  loss_mask: 0.08139  loss_rpn_cls: 0.00146  loss_rpn_loc: 0.03035  total_val_loss: 0.2117  val_loss_cls: 0.02599  val_loss_box_reg: 0.06818  val_loss_mask: 0.08188  val_loss_rpn_cls: 0.001323  val_loss_rpn_loc: 0.02606    time: 1.6108  last_time: 1.4695  data_time: 0.0076  last_data_time: 0.0067   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:04:02 d2.utils.events]: \u001b[0m eta: 1:58:56  iter: 15199  total_loss: 0.2329  loss_cls: 0.03038  loss_box_reg: 0.08052  loss_mask: 0.0828  loss_rpn_cls: 0.003189  loss_rpn_loc: 0.03128  total_val_loss: 0.184  val_loss_cls: 0.02455  val_loss_box_reg: 0.05739  val_loss_mask: 0.07978  val_loss_rpn_cls: 0.001557  val_loss_rpn_loc: 0.02201    time: 1.6106  last_time: 1.4970  data_time: 0.0080  last_data_time: 0.0123   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:04:44 d2.utils.events]: \u001b[0m eta: 1:58:28  iter: 15219  total_loss: 0.2131  loss_cls: 0.02799  loss_box_reg: 0.07044  loss_mask: 0.07423  loss_rpn_cls: 0.001571  loss_rpn_loc: 0.02905  total_val_loss: 0.1938  val_loss_cls: 0.02605  val_loss_box_reg: 0.06817  val_loss_mask: 0.0825  val_loss_rpn_cls: 0.0008508  val_loss_rpn_loc: 0.02408    time: 1.6105  last_time: 1.3664  data_time: 0.0077  last_data_time: 0.0075   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:05:26 d2.utils.events]: \u001b[0m eta: 1:58:00  iter: 15239  total_loss: 0.2133  loss_cls: 0.02846  loss_box_reg: 0.07287  loss_mask: 0.08057  loss_rpn_cls: 0.002866  loss_rpn_loc: 0.02988  total_val_loss: 0.1913  val_loss_cls: 0.02534  val_loss_box_reg: 0.05763  val_loss_mask: 0.08386  val_loss_rpn_cls: 0.001566  val_loss_rpn_loc: 0.02086    time: 1.6103  last_time: 1.5287  data_time: 0.0075  last_data_time: 0.0102   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:06:09 d2.utils.events]: \u001b[0m eta: 1:57:30  iter: 15259  total_loss: 0.1859  loss_cls: 0.02391  loss_box_reg: 0.05949  loss_mask: 0.07492  loss_rpn_cls: 0.001298  loss_rpn_loc: 0.02403  total_val_loss: 0.2283  val_loss_cls: 0.03419  val_loss_box_reg: 0.07509  val_loss_mask: 0.08501  val_loss_rpn_cls: 0.001376  val_loss_rpn_loc: 0.02559    time: 1.6101  last_time: 1.5283  data_time: 0.0078  last_data_time: 0.0084   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:06:51 d2.utils.events]: \u001b[0m eta: 1:57:01  iter: 15279  total_loss: 0.2101  loss_cls: 0.02813  loss_box_reg: 0.07333  loss_mask: 0.08414  loss_rpn_cls: 0.001501  loss_rpn_loc: 0.02757  total_val_loss: 0.2044  val_loss_cls: 0.02814  val_loss_box_reg: 0.06872  val_loss_mask: 0.08112  val_loss_rpn_cls: 0.001222  val_loss_rpn_loc: 0.02264    time: 1.6100  last_time: 1.4852  data_time: 0.0077  last_data_time: 0.0090   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:07:33 d2.utils.events]: \u001b[0m eta: 1:56:31  iter: 15299  total_loss: 0.2163  loss_cls: 0.02955  loss_box_reg: 0.07302  loss_mask: 0.07876  loss_rpn_cls: 0.002003  loss_rpn_loc: 0.02945  total_val_loss: 0.1929  val_loss_cls: 0.02668  val_loss_box_reg: 0.06237  val_loss_mask: 0.08236  val_loss_rpn_cls: 0.000898  val_loss_rpn_loc: 0.02297    time: 1.6098  last_time: 1.4917  data_time: 0.0072  last_data_time: 0.0079   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:08:16 d2.utils.events]: \u001b[0m eta: 1:56:01  iter: 15319  total_loss: 0.2176  loss_cls: 0.02909  loss_box_reg: 0.06984  loss_mask: 0.08389  loss_rpn_cls: 0.001982  loss_rpn_loc: 0.02843  total_val_loss: 0.2101  val_loss_cls: 0.03125  val_loss_box_reg: 0.06751  val_loss_mask: 0.08546  val_loss_rpn_cls: 0.001336  val_loss_rpn_loc: 0.02341    time: 1.6096  last_time: 1.5003  data_time: 0.0077  last_data_time: 0.0092   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:08:58 d2.utils.events]: \u001b[0m eta: 1:55:32  iter: 15339  total_loss: 0.1949  loss_cls: 0.02572  loss_box_reg: 0.06507  loss_mask: 0.07618  loss_rpn_cls: 0.001682  loss_rpn_loc: 0.0251  total_val_loss: 0.208  val_loss_cls: 0.0323  val_loss_box_reg: 0.06989  val_loss_mask: 0.08281  val_loss_rpn_cls: 0.0009304  val_loss_rpn_loc: 0.02128    time: 1.6095  last_time: 1.4817  data_time: 0.0074  last_data_time: 0.0069   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:09:41 d2.utils.events]: \u001b[0m eta: 1:55:02  iter: 15359  total_loss: 0.2133  loss_cls: 0.02906  loss_box_reg: 0.06905  loss_mask: 0.08238  loss_rpn_cls: 0.001858  loss_rpn_loc: 0.02943  total_val_loss: 0.2165  val_loss_cls: 0.03171  val_loss_box_reg: 0.06753  val_loss_mask: 0.08942  val_loss_rpn_cls: 0.0007756  val_loss_rpn_loc: 0.02441    time: 1.6094  last_time: 1.5389  data_time: 0.0075  last_data_time: 0.0068   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:10:24 d2.utils.events]: \u001b[0m eta: 1:54:33  iter: 15379  total_loss: 0.2226  loss_cls: 0.02868  loss_box_reg: 0.07333  loss_mask: 0.08045  loss_rpn_cls: 0.002612  loss_rpn_loc: 0.03256  total_val_loss: 0.1997  val_loss_cls: 0.02769  val_loss_box_reg: 0.06248  val_loss_mask: 0.07974  val_loss_rpn_cls: 0.001628  val_loss_rpn_loc: 0.02371    time: 1.6092  last_time: 1.4679  data_time: 0.0079  last_data_time: 0.0071   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:11:06 d2.utils.events]: \u001b[0m eta: 1:54:03  iter: 15399  total_loss: 0.2017  loss_cls: 0.02679  loss_box_reg: 0.06351  loss_mask: 0.08261  loss_rpn_cls: 0.001904  loss_rpn_loc: 0.02648  total_val_loss: 0.2146  val_loss_cls: 0.03244  val_loss_box_reg: 0.0681  val_loss_mask: 0.085  val_loss_rpn_cls: 0.000869  val_loss_rpn_loc: 0.02448    time: 1.6090  last_time: 1.4797  data_time: 0.0080  last_data_time: 0.0078   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:11:48 d2.utils.events]: \u001b[0m eta: 1:53:34  iter: 15419  total_loss: 0.2403  loss_cls: 0.03457  loss_box_reg: 0.08403  loss_mask: 0.08372  loss_rpn_cls: 0.00226  loss_rpn_loc: 0.03131  total_val_loss: 0.2028  val_loss_cls: 0.02401  val_loss_box_reg: 0.06285  val_loss_mask: 0.09004  val_loss_rpn_cls: 0.0006879  val_loss_rpn_loc: 0.01961    time: 1.6089  last_time: 1.5563  data_time: 0.0084  last_data_time: 0.0070   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:12:31 d2.utils.events]: \u001b[0m eta: 1:53:07  iter: 15439  total_loss: 0.2101  loss_cls: 0.02603  loss_box_reg: 0.06503  loss_mask: 0.07915  loss_rpn_cls: 0.002077  loss_rpn_loc: 0.02596  total_val_loss: 0.1926  val_loss_cls: 0.02465  val_loss_box_reg: 0.0603  val_loss_mask: 0.08279  val_loss_rpn_cls: 0.0008757  val_loss_rpn_loc: 0.02216    time: 1.6087  last_time: 1.6042  data_time: 0.0082  last_data_time: 0.0082   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:13:14 d2.utils.events]: \u001b[0m eta: 1:52:38  iter: 15459  total_loss: 0.2202  loss_cls: 0.02774  loss_box_reg: 0.0702  loss_mask: 0.077  loss_rpn_cls: 0.002339  loss_rpn_loc: 0.02991  total_val_loss: 0.2056  val_loss_cls: 0.02845  val_loss_box_reg: 0.06633  val_loss_mask: 0.0844  val_loss_rpn_cls: 0.001195  val_loss_rpn_loc: 0.02351    time: 1.6086  last_time: 1.4173  data_time: 0.0083  last_data_time: 0.0061   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:13:57 d2.utils.events]: \u001b[0m eta: 1:52:15  iter: 15479  total_loss: 0.2014  loss_cls: 0.02861  loss_box_reg: 0.06684  loss_mask: 0.07811  loss_rpn_cls: 0.001697  loss_rpn_loc: 0.02593  total_val_loss: 0.203  val_loss_cls: 0.02707  val_loss_box_reg: 0.06743  val_loss_mask: 0.08378  val_loss_rpn_cls: 0.0006085  val_loss_rpn_loc: 0.02321    time: 1.6085  last_time: 1.5259  data_time: 0.0079  last_data_time: 0.0066   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:14:40 d2.utils.events]: \u001b[0m eta: 1:51:43  iter: 15499  total_loss: 0.2031  loss_cls: 0.02761  loss_box_reg: 0.06634  loss_mask: 0.07491  loss_rpn_cls: 0.001676  loss_rpn_loc: 0.02841  total_val_loss: 0.198  val_loss_cls: 0.0259  val_loss_box_reg: 0.06369  val_loss_mask: 0.08296  val_loss_rpn_cls: 0.0009408  val_loss_rpn_loc: 0.02288    time: 1.6083  last_time: 1.4699  data_time: 0.0074  last_data_time: 0.0056   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:15:22 d2.utils.events]: \u001b[0m eta: 1:51:13  iter: 15519  total_loss: 0.2144  loss_cls: 0.03155  loss_box_reg: 0.07803  loss_mask: 0.07893  loss_rpn_cls: 0.002024  loss_rpn_loc: 0.02905  total_val_loss: 0.1983  val_loss_cls: 0.02812  val_loss_box_reg: 0.06497  val_loss_mask: 0.08193  val_loss_rpn_cls: 0.0006599  val_loss_rpn_loc: 0.02316    time: 1.6082  last_time: 1.4617  data_time: 0.0077  last_data_time: 0.0055   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:16:05 d2.utils.events]: \u001b[0m eta: 1:50:47  iter: 15539  total_loss: 0.2183  loss_cls: 0.02808  loss_box_reg: 0.07246  loss_mask: 0.08329  loss_rpn_cls: 0.001824  loss_rpn_loc: 0.02859  total_val_loss: 0.2192  val_loss_cls: 0.03164  val_loss_box_reg: 0.07345  val_loss_mask: 0.09048  val_loss_rpn_cls: 0.0007725  val_loss_rpn_loc: 0.02375    time: 1.6080  last_time: 1.5285  data_time: 0.0078  last_data_time: 0.0081   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:16:48 d2.utils.events]: \u001b[0m eta: 1:50:19  iter: 15559  total_loss: 0.2193  loss_cls: 0.02676  loss_box_reg: 0.07454  loss_mask: 0.07945  loss_rpn_cls: 0.001313  loss_rpn_loc: 0.02857  total_val_loss: 0.1937  val_loss_cls: 0.02482  val_loss_box_reg: 0.06327  val_loss_mask: 0.07717  val_loss_rpn_cls: 0.0007998  val_loss_rpn_loc: 0.02323    time: 1.6079  last_time: 1.5044  data_time: 0.0078  last_data_time: 0.0105   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:17:31 d2.utils.events]: \u001b[0m eta: 1:49:48  iter: 15579  total_loss: 0.204  loss_cls: 0.02682  loss_box_reg: 0.06521  loss_mask: 0.08314  loss_rpn_cls: 0.001915  loss_rpn_loc: 0.02678  total_val_loss: 0.2028  val_loss_cls: 0.03069  val_loss_box_reg: 0.06359  val_loss_mask: 0.08414  val_loss_rpn_cls: 0.0008797  val_loss_rpn_loc: 0.02268    time: 1.6078  last_time: 1.4688  data_time: 0.0079  last_data_time: 0.0062   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:18:14 d2.utils.events]: \u001b[0m eta: 1:49:20  iter: 15599  total_loss: 0.2042  loss_cls: 0.02807  loss_box_reg: 0.07073  loss_mask: 0.07784  loss_rpn_cls: 0.002192  loss_rpn_loc: 0.03046  total_val_loss: 0.2132  val_loss_cls: 0.03058  val_loss_box_reg: 0.07212  val_loss_mask: 0.08481  val_loss_rpn_cls: 0.001121  val_loss_rpn_loc: 0.02566    time: 1.6077  last_time: 1.4614  data_time: 0.0076  last_data_time: 0.0085   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:18:56 d2.utils.events]: \u001b[0m eta: 1:48:50  iter: 15619  total_loss: 0.1972  loss_cls: 0.02704  loss_box_reg: 0.06324  loss_mask: 0.07508  loss_rpn_cls: 0.002239  loss_rpn_loc: 0.02491  total_val_loss: 0.2019  val_loss_cls: 0.02662  val_loss_box_reg: 0.06331  val_loss_mask: 0.08526  val_loss_rpn_cls: 0.0006808  val_loss_rpn_loc: 0.02073    time: 1.6075  last_time: 1.4305  data_time: 0.0074  last_data_time: 0.0085   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:19:38 d2.utils.events]: \u001b[0m eta: 1:48:19  iter: 15639  total_loss: 0.2042  loss_cls: 0.0279  loss_box_reg: 0.07037  loss_mask: 0.08167  loss_rpn_cls: 0.001598  loss_rpn_loc: 0.02775  total_val_loss: 0.2091  val_loss_cls: 0.02944  val_loss_box_reg: 0.06971  val_loss_mask: 0.08103  val_loss_rpn_cls: 0.001274  val_loss_rpn_loc: 0.02396    time: 1.6073  last_time: 1.4466  data_time: 0.0075  last_data_time: 0.0063   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:20:21 d2.utils.events]: \u001b[0m eta: 1:47:48  iter: 15659  total_loss: 0.2155  loss_cls: 0.03051  loss_box_reg: 0.07536  loss_mask: 0.08095  loss_rpn_cls: 0.001878  loss_rpn_loc: 0.02794  total_val_loss: 0.2165  val_loss_cls: 0.03191  val_loss_box_reg: 0.07488  val_loss_mask: 0.07873  val_loss_rpn_cls: 0.000855  val_loss_rpn_loc: 0.02526    time: 1.6072  last_time: 1.4566  data_time: 0.0082  last_data_time: 0.0114   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:21:03 d2.utils.events]: \u001b[0m eta: 1:47:19  iter: 15679  total_loss: 0.2081  loss_cls: 0.02709  loss_box_reg: 0.07008  loss_mask: 0.08173  loss_rpn_cls: 0.00161  loss_rpn_loc: 0.02836  total_val_loss: 0.2071  val_loss_cls: 0.02785  val_loss_box_reg: 0.06401  val_loss_mask: 0.08507  val_loss_rpn_cls: 0.001016  val_loss_rpn_loc: 0.02314    time: 1.6070  last_time: 1.4119  data_time: 0.0076  last_data_time: 0.0093   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:21:46 d2.utils.events]: \u001b[0m eta: 1:46:51  iter: 15699  total_loss: 0.2085  loss_cls: 0.02567  loss_box_reg: 0.06939  loss_mask: 0.08286  loss_rpn_cls: 0.002533  loss_rpn_loc: 0.02983  total_val_loss: 0.2105  val_loss_cls: 0.03095  val_loss_box_reg: 0.0702  val_loss_mask: 0.0833  val_loss_rpn_cls: 0.0009456  val_loss_rpn_loc: 0.02427    time: 1.6069  last_time: 1.5772  data_time: 0.0080  last_data_time: 0.0081   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:22:29 d2.utils.events]: \u001b[0m eta: 1:46:20  iter: 15719  total_loss: 0.2122  loss_cls: 0.02842  loss_box_reg: 0.06698  loss_mask: 0.07441  loss_rpn_cls: 0.001259  loss_rpn_loc: 0.0277  total_val_loss: 0.208  val_loss_cls: 0.02918  val_loss_box_reg: 0.06539  val_loss_mask: 0.0865  val_loss_rpn_cls: 0.0007503  val_loss_rpn_loc: 0.02324    time: 1.6067  last_time: 1.5882  data_time: 0.0076  last_data_time: 0.0061   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:23:11 d2.utils.events]: \u001b[0m eta: 1:45:50  iter: 15739  total_loss: 0.2297  loss_cls: 0.02892  loss_box_reg: 0.07421  loss_mask: 0.08502  loss_rpn_cls: 0.001491  loss_rpn_loc: 0.02809  total_val_loss: 0.2077  val_loss_cls: 0.02654  val_loss_box_reg: 0.06782  val_loss_mask: 0.0838  val_loss_rpn_cls: 0.001226  val_loss_rpn_loc: 0.02404    time: 1.6066  last_time: 1.5175  data_time: 0.0077  last_data_time: 0.0073   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:23:54 d2.utils.events]: \u001b[0m eta: 1:45:19  iter: 15759  total_loss: 0.221  loss_cls: 0.02934  loss_box_reg: 0.07126  loss_mask: 0.07962  loss_rpn_cls: 0.002347  loss_rpn_loc: 0.02836  total_val_loss: 0.1871  val_loss_cls: 0.02828  val_loss_box_reg: 0.05991  val_loss_mask: 0.08145  val_loss_rpn_cls: 0.0007045  val_loss_rpn_loc: 0.02184    time: 1.6065  last_time: 1.4416  data_time: 0.0076  last_data_time: 0.0082   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:24:36 d2.utils.events]: \u001b[0m eta: 1:44:50  iter: 15779  total_loss: 0.1989  loss_cls: 0.02817  loss_box_reg: 0.06193  loss_mask: 0.0776  loss_rpn_cls: 0.001812  loss_rpn_loc: 0.02437  total_val_loss: 0.1914  val_loss_cls: 0.02462  val_loss_box_reg: 0.06204  val_loss_mask: 0.08079  val_loss_rpn_cls: 0.001007  val_loss_rpn_loc: 0.02194    time: 1.6063  last_time: 1.5487  data_time: 0.0073  last_data_time: 0.0071   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:25:18 d2.utils.events]: \u001b[0m eta: 1:44:20  iter: 15799  total_loss: 0.2183  loss_cls: 0.02778  loss_box_reg: 0.0703  loss_mask: 0.08152  loss_rpn_cls: 0.001569  loss_rpn_loc: 0.02928  total_val_loss: 0.1871  val_loss_cls: 0.02509  val_loss_box_reg: 0.05713  val_loss_mask: 0.08637  val_loss_rpn_cls: 0.001018  val_loss_rpn_loc: 0.0211    time: 1.6061  last_time: 1.4264  data_time: 0.0078  last_data_time: 0.0071   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:26:01 d2.utils.events]: \u001b[0m eta: 1:43:51  iter: 15819  total_loss: 0.1957  loss_cls: 0.02815  loss_box_reg: 0.06095  loss_mask: 0.07832  loss_rpn_cls: 0.002507  loss_rpn_loc: 0.02504  total_val_loss: 0.2188  val_loss_cls: 0.02804  val_loss_box_reg: 0.06867  val_loss_mask: 0.08616  val_loss_rpn_cls: 0.001471  val_loss_rpn_loc: 0.02451    time: 1.6060  last_time: 1.5680  data_time: 0.0072  last_data_time: 0.0064   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:26:43 d2.utils.events]: \u001b[0m eta: 1:43:21  iter: 15839  total_loss: 0.2243  loss_cls: 0.03153  loss_box_reg: 0.07438  loss_mask: 0.07658  loss_rpn_cls: 0.002214  loss_rpn_loc: 0.02804  total_val_loss: 0.2008  val_loss_cls: 0.02716  val_loss_box_reg: 0.06765  val_loss_mask: 0.07975  val_loss_rpn_cls: 0.001597  val_loss_rpn_loc: 0.02477    time: 1.6059  last_time: 1.5767  data_time: 0.0075  last_data_time: 0.0067   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:27:25 d2.utils.events]: \u001b[0m eta: 1:42:50  iter: 15859  total_loss: 0.1973  loss_cls: 0.02665  loss_box_reg: 0.06166  loss_mask: 0.08045  loss_rpn_cls: 0.001685  loss_rpn_loc: 0.02624  total_val_loss: 0.2019  val_loss_cls: 0.02675  val_loss_box_reg: 0.06287  val_loss_mask: 0.08351  val_loss_rpn_cls: 0.001035  val_loss_rpn_loc: 0.02305    time: 1.6057  last_time: 1.4288  data_time: 0.0077  last_data_time: 0.0070   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:28:08 d2.utils.events]: \u001b[0m eta: 1:42:23  iter: 15879  total_loss: 0.2095  loss_cls: 0.02855  loss_box_reg: 0.06348  loss_mask: 0.0822  loss_rpn_cls: 0.001643  loss_rpn_loc: 0.02556  total_val_loss: 0.2026  val_loss_cls: 0.02853  val_loss_box_reg: 0.06643  val_loss_mask: 0.08696  val_loss_rpn_cls: 0.0008879  val_loss_rpn_loc: 0.02433    time: 1.6056  last_time: 1.5493  data_time: 0.0070  last_data_time: 0.0087   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:28:51 d2.utils.events]: \u001b[0m eta: 1:41:55  iter: 15899  total_loss: 0.2061  loss_cls: 0.02778  loss_box_reg: 0.0767  loss_mask: 0.07768  loss_rpn_cls: 0.002958  loss_rpn_loc: 0.02615  total_val_loss: 0.2005  val_loss_cls: 0.02908  val_loss_box_reg: 0.067  val_loss_mask: 0.07883  val_loss_rpn_cls: 0.0007642  val_loss_rpn_loc: 0.02306    time: 1.6054  last_time: 1.4646  data_time: 0.0075  last_data_time: 0.0066   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:29:33 d2.utils.events]: \u001b[0m eta: 1:41:23  iter: 15919  total_loss: 0.2048  loss_cls: 0.02813  loss_box_reg: 0.06726  loss_mask: 0.08072  loss_rpn_cls: 0.001963  loss_rpn_loc: 0.02367  total_val_loss: 0.2182  val_loss_cls: 0.03012  val_loss_box_reg: 0.0669  val_loss_mask: 0.08567  val_loss_rpn_cls: 0.0009211  val_loss_rpn_loc: 0.02438    time: 1.6052  last_time: 1.5430  data_time: 0.0071  last_data_time: 0.0117   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:30:15 d2.utils.events]: \u001b[0m eta: 1:40:52  iter: 15939  total_loss: 0.2092  loss_cls: 0.02581  loss_box_reg: 0.06637  loss_mask: 0.07658  loss_rpn_cls: 0.001074  loss_rpn_loc: 0.02432  total_val_loss: 0.1985  val_loss_cls: 0.02881  val_loss_box_reg: 0.06155  val_loss_mask: 0.08378  val_loss_rpn_cls: 0.0007525  val_loss_rpn_loc: 0.02012    time: 1.6051  last_time: 1.4949  data_time: 0.0068  last_data_time: 0.0068   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:30:58 d2.utils.events]: \u001b[0m eta: 1:40:26  iter: 15959  total_loss: 0.2157  loss_cls: 0.02914  loss_box_reg: 0.07326  loss_mask: 0.08108  loss_rpn_cls: 0.001918  loss_rpn_loc: 0.03007  total_val_loss: 0.2003  val_loss_cls: 0.02737  val_loss_box_reg: 0.06909  val_loss_mask: 0.08328  val_loss_rpn_cls: 0.0009291  val_loss_rpn_loc: 0.02232    time: 1.6050  last_time: 1.4842  data_time: 0.0079  last_data_time: 0.0069   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:31:41 d2.utils.events]: \u001b[0m eta: 1:40:00  iter: 15979  total_loss: 0.2254  loss_cls: 0.03159  loss_box_reg: 0.07757  loss_mask: 0.08218  loss_rpn_cls: 0.001806  loss_rpn_loc: 0.03052  total_val_loss: 0.1836  val_loss_cls: 0.02502  val_loss_box_reg: 0.0579  val_loss_mask: 0.08111  val_loss_rpn_cls: 0.0008475  val_loss_rpn_loc: 0.02198    time: 1.6048  last_time: 1.4920  data_time: 0.0080  last_data_time: 0.0071   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:32:25 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\testing_images\\0_SideLane_addedversion_Testing_COCO.json\n",
      "\u001b[32m[09/27 00:32:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/27 00:32:25 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/27 00:32:25 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/27 00:32:25 d2.data.common]: \u001b[0mSerialized dataset takes 6.03 MiB\n",
      "\u001b[32m[09/27 00:32:25 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[09/27 00:32:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 566 batches\n",
      "\u001b[32m[09/27 00:32:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/566. Dataloading: 0.0004 s/iter. Inference: 0.0707 s/iter. Eval: 0.0065 s/iter. Total: 0.0776 s/iter. ETA=0:00:43\n",
      "\u001b[32m[09/27 00:32:34 d2.evaluation.evaluator]: \u001b[0mInference done 80/566. Dataloading: 0.0006 s/iter. Inference: 0.0699 s/iter. Eval: 0.0027 s/iter. Total: 0.0732 s/iter. ETA=0:00:35\n",
      "\u001b[32m[09/27 00:32:39 d2.evaluation.evaluator]: \u001b[0mInference done 147/566. Dataloading: 0.0006 s/iter. Inference: 0.0701 s/iter. Eval: 0.0037 s/iter. Total: 0.0744 s/iter. ETA=0:00:31\n",
      "\u001b[32m[09/27 00:32:44 d2.evaluation.evaluator]: \u001b[0mInference done 213/566. Dataloading: 0.0006 s/iter. Inference: 0.0710 s/iter. Eval: 0.0036 s/iter. Total: 0.0752 s/iter. ETA=0:00:26\n",
      "\u001b[32m[09/27 00:32:49 d2.evaluation.evaluator]: \u001b[0mInference done 280/566. Dataloading: 0.0006 s/iter. Inference: 0.0711 s/iter. Eval: 0.0035 s/iter. Total: 0.0753 s/iter. ETA=0:00:21\n",
      "\u001b[32m[09/27 00:32:54 d2.evaluation.evaluator]: \u001b[0mInference done 350/566. Dataloading: 0.0006 s/iter. Inference: 0.0707 s/iter. Eval: 0.0032 s/iter. Total: 0.0745 s/iter. ETA=0:00:16\n",
      "\u001b[32m[09/27 00:32:59 d2.evaluation.evaluator]: \u001b[0mInference done 419/566. Dataloading: 0.0006 s/iter. Inference: 0.0706 s/iter. Eval: 0.0029 s/iter. Total: 0.0742 s/iter. ETA=0:00:10\n",
      "\u001b[32m[09/27 00:33:04 d2.evaluation.evaluator]: \u001b[0mInference done 483/566. Dataloading: 0.0006 s/iter. Inference: 0.0709 s/iter. Eval: 0.0033 s/iter. Total: 0.0748 s/iter. ETA=0:00:06\n",
      "\u001b[32m[09/27 00:33:09 d2.evaluation.evaluator]: \u001b[0mInference done 549/566. Dataloading: 0.0006 s/iter. Inference: 0.0712 s/iter. Eval: 0.0032 s/iter. Total: 0.0751 s/iter. ETA=0:00:01\n",
      "\u001b[32m[09/27 00:33:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:42.566474 (0.075876 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/27 00:33:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.071142 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/27 00:33:11 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/27 00:33:11 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\coco_instances_results.json\n",
      "\u001b[32m[09/27 00:33:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.23s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.932\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.928\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.936\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.937\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.951\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.940\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.958\n",
      "\u001b[32m[09/27 00:33:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 93.248 | 99.008 | 98.995 |  nan  | 92.819 | 93.610 |\n",
      "\u001b[32m[09/27 00:33:11 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/27 00:33:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 93.248 | background | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.41s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.860\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.828\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.881\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.182\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.881\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.895\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.866\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.913\n",
      "\u001b[32m[09/27 00:33:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 86.035 | 99.008 | 98.956 |  nan  | 82.780 | 88.126 |\n",
      "\u001b[32m[09/27 00:33:12 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/27 00:33:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 86.035 | background | nan  |\n",
      "\u001b[32m[09/27 00:33:12 d2.engine.defaults]: \u001b[0mEvaluation results for test_data in csv format:\n",
      "\u001b[32m[09/27 00:33:12 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/27 00:33:12 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/27 00:33:12 d2.evaluation.testing]: \u001b[0mcopypaste: 93.2480,99.0076,98.9955,nan,92.8190,93.6100\n",
      "\u001b[32m[09/27 00:33:12 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/27 00:33:12 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/27 00:33:12 d2.evaluation.testing]: \u001b[0mcopypaste: 86.0346,99.0076,98.9561,nan,82.7800,88.1261\n",
      "\u001b[32m[09/27 00:33:12 d2.utils.events]: \u001b[0m eta: 1:39:26  iter: 15999  total_loss: 0.219  loss_cls: 0.02908  loss_box_reg: 0.07419  loss_mask: 0.08428  loss_rpn_cls: 0.002115  loss_rpn_loc: 0.02998  total_val_loss: 0.2087  val_loss_cls: 0.03113  val_loss_box_reg: 0.06547  val_loss_mask: 0.08959  val_loss_rpn_cls: 0.001121  val_loss_rpn_loc: 0.02351    time: 1.6047  last_time: 1.4570  data_time: 0.0075  last_data_time: 0.0060   lr: 0.00025  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:33:55 d2.utils.events]: \u001b[0m eta: 1:38:57  iter: 16019  total_loss: 0.229  loss_cls: 0.03077  loss_box_reg: 0.07543  loss_mask: 0.07776  loss_rpn_cls: 0.001323  loss_rpn_loc: 0.03075  total_val_loss: 0.1995  val_loss_cls: 0.02895  val_loss_box_reg: 0.06202  val_loss_mask: 0.08028  val_loss_rpn_cls: 0.001003  val_loss_rpn_loc: 0.02048    time: 1.6046  last_time: 1.4800  data_time: 0.0077  last_data_time: 0.0066   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:34:38 d2.utils.events]: \u001b[0m eta: 1:38:26  iter: 16039  total_loss: 0.2128  loss_cls: 0.02945  loss_box_reg: 0.07286  loss_mask: 0.07637  loss_rpn_cls: 0.001989  loss_rpn_loc: 0.02807  total_val_loss: 0.2082  val_loss_cls: 0.02878  val_loss_box_reg: 0.06885  val_loss_mask: 0.08163  val_loss_rpn_cls: 0.0008457  val_loss_rpn_loc: 0.02363    time: 1.6044  last_time: 1.5431  data_time: 0.0078  last_data_time: 0.0083   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:35:21 d2.utils.events]: \u001b[0m eta: 1:37:58  iter: 16059  total_loss: 0.1938  loss_cls: 0.02434  loss_box_reg: 0.06112  loss_mask: 0.07474  loss_rpn_cls: 0.002053  loss_rpn_loc: 0.02494  total_val_loss: 0.2007  val_loss_cls: 0.03145  val_loss_box_reg: 0.06382  val_loss_mask: 0.08029  val_loss_rpn_cls: 0.0007517  val_loss_rpn_loc: 0.02221    time: 1.6043  last_time: 1.5651  data_time: 0.0079  last_data_time: 0.0066   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:36:04 d2.utils.events]: \u001b[0m eta: 1:37:32  iter: 16079  total_loss: 0.2199  loss_cls: 0.03437  loss_box_reg: 0.07753  loss_mask: 0.08272  loss_rpn_cls: 0.001691  loss_rpn_loc: 0.02932  total_val_loss: 0.1887  val_loss_cls: 0.02712  val_loss_box_reg: 0.06209  val_loss_mask: 0.08255  val_loss_rpn_cls: 0.001036  val_loss_rpn_loc: 0.02235    time: 1.6042  last_time: 1.5715  data_time: 0.0075  last_data_time: 0.0057   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:36:47 d2.utils.events]: \u001b[0m eta: 1:37:03  iter: 16099  total_loss: 0.192  loss_cls: 0.0269  loss_box_reg: 0.06234  loss_mask: 0.07252  loss_rpn_cls: 0.001435  loss_rpn_loc: 0.02289  total_val_loss: 0.2076  val_loss_cls: 0.02492  val_loss_box_reg: 0.06421  val_loss_mask: 0.08123  val_loss_rpn_cls: 0.0008286  val_loss_rpn_loc: 0.02256    time: 1.6041  last_time: 1.4093  data_time: 0.0079  last_data_time: 0.0084   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:37:29 d2.utils.events]: \u001b[0m eta: 1:36:28  iter: 16119  total_loss: 0.1958  loss_cls: 0.02541  loss_box_reg: 0.06726  loss_mask: 0.07696  loss_rpn_cls: 0.001501  loss_rpn_loc: 0.02745  total_val_loss: 0.1867  val_loss_cls: 0.02291  val_loss_box_reg: 0.05717  val_loss_mask: 0.08775  val_loss_rpn_cls: 0.001264  val_loss_rpn_loc: 0.02015    time: 1.6039  last_time: 1.4409  data_time: 0.0077  last_data_time: 0.0074   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:38:11 d2.utils.events]: \u001b[0m eta: 1:35:57  iter: 16139  total_loss: 0.1887  loss_cls: 0.02555  loss_box_reg: 0.06092  loss_mask: 0.07459  loss_rpn_cls: 0.001391  loss_rpn_loc: 0.02551  total_val_loss: 0.2018  val_loss_cls: 0.02795  val_loss_box_reg: 0.06705  val_loss_mask: 0.08375  val_loss_rpn_cls: 0.0009114  val_loss_rpn_loc: 0.02233    time: 1.6038  last_time: 1.5914  data_time: 0.0077  last_data_time: 0.0083   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:38:54 d2.utils.events]: \u001b[0m eta: 1:35:28  iter: 16159  total_loss: 0.2345  loss_cls: 0.03338  loss_box_reg: 0.07553  loss_mask: 0.07945  loss_rpn_cls: 0.00141  loss_rpn_loc: 0.02647  total_val_loss: 0.2049  val_loss_cls: 0.0267  val_loss_box_reg: 0.0671  val_loss_mask: 0.0878  val_loss_rpn_cls: 0.001313  val_loss_rpn_loc: 0.0222    time: 1.6037  last_time: 1.4942  data_time: 0.0075  last_data_time: 0.0069   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:39:37 d2.utils.events]: \u001b[0m eta: 1:34:59  iter: 16179  total_loss: 0.2025  loss_cls: 0.02788  loss_box_reg: 0.06901  loss_mask: 0.07428  loss_rpn_cls: 0.001459  loss_rpn_loc: 0.02666  total_val_loss: 0.187  val_loss_cls: 0.02463  val_loss_box_reg: 0.06001  val_loss_mask: 0.08101  val_loss_rpn_cls: 0.0007212  val_loss_rpn_loc: 0.02143    time: 1.6035  last_time: 1.4682  data_time: 0.0078  last_data_time: 0.0084   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:40:19 d2.utils.events]: \u001b[0m eta: 1:34:28  iter: 16199  total_loss: 0.2041  loss_cls: 0.02951  loss_box_reg: 0.07296  loss_mask: 0.0757  loss_rpn_cls: 0.001981  loss_rpn_loc: 0.02748  total_val_loss: 0.2078  val_loss_cls: 0.03245  val_loss_box_reg: 0.07016  val_loss_mask: 0.08055  val_loss_rpn_cls: 0.0008228  val_loss_rpn_loc: 0.02383    time: 1.6034  last_time: 1.4287  data_time: 0.0075  last_data_time: 0.0062   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:41:02 d2.utils.events]: \u001b[0m eta: 1:33:59  iter: 16219  total_loss: 0.2076  loss_cls: 0.02965  loss_box_reg: 0.06837  loss_mask: 0.07723  loss_rpn_cls: 0.002588  loss_rpn_loc: 0.0281  total_val_loss: 0.1911  val_loss_cls: 0.02606  val_loss_box_reg: 0.06017  val_loss_mask: 0.08201  val_loss_rpn_cls: 0.001112  val_loss_rpn_loc: 0.02139    time: 1.6033  last_time: 1.4595  data_time: 0.0072  last_data_time: 0.0067   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:41:44 d2.utils.events]: \u001b[0m eta: 1:33:28  iter: 16239  total_loss: 0.2062  loss_cls: 0.02901  loss_box_reg: 0.06555  loss_mask: 0.08647  loss_rpn_cls: 0.001414  loss_rpn_loc: 0.02517  total_val_loss: 0.1986  val_loss_cls: 0.03053  val_loss_box_reg: 0.06413  val_loss_mask: 0.07925  val_loss_rpn_cls: 0.001558  val_loss_rpn_loc: 0.02238    time: 1.6031  last_time: 1.5386  data_time: 0.0074  last_data_time: 0.0075   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:42:27 d2.utils.events]: \u001b[0m eta: 1:32:58  iter: 16259  total_loss: 0.2082  loss_cls: 0.03026  loss_box_reg: 0.07168  loss_mask: 0.07977  loss_rpn_cls: 0.001763  loss_rpn_loc: 0.026  total_val_loss: 0.2155  val_loss_cls: 0.02858  val_loss_box_reg: 0.07301  val_loss_mask: 0.08304  val_loss_rpn_cls: 0.001113  val_loss_rpn_loc: 0.02412    time: 1.6030  last_time: 1.4587  data_time: 0.0081  last_data_time: 0.0067   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:43:09 d2.utils.events]: \u001b[0m eta: 1:32:28  iter: 16279  total_loss: 0.2016  loss_cls: 0.02726  loss_box_reg: 0.06645  loss_mask: 0.08285  loss_rpn_cls: 0.002231  loss_rpn_loc: 0.02433  total_val_loss: 0.2073  val_loss_cls: 0.03001  val_loss_box_reg: 0.06513  val_loss_mask: 0.08761  val_loss_rpn_cls: 0.001172  val_loss_rpn_loc: 0.02055    time: 1.6028  last_time: 1.5986  data_time: 0.0081  last_data_time: 0.0089   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:43:52 d2.utils.events]: \u001b[0m eta: 1:32:00  iter: 16299  total_loss: 0.2212  loss_cls: 0.03124  loss_box_reg: 0.06907  loss_mask: 0.08001  loss_rpn_cls: 0.001932  loss_rpn_loc: 0.02697  total_val_loss: 0.2087  val_loss_cls: 0.02769  val_loss_box_reg: 0.06747  val_loss_mask: 0.0831  val_loss_rpn_cls: 0.001292  val_loss_rpn_loc: 0.02297    time: 1.6027  last_time: 1.5487  data_time: 0.0081  last_data_time: 0.0080   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:44:35 d2.utils.events]: \u001b[0m eta: 1:31:31  iter: 16319  total_loss: 0.2177  loss_cls: 0.0301  loss_box_reg: 0.06896  loss_mask: 0.07826  loss_rpn_cls: 0.002007  loss_rpn_loc: 0.02732  total_val_loss: 0.1921  val_loss_cls: 0.02312  val_loss_box_reg: 0.06135  val_loss_mask: 0.08194  val_loss_rpn_cls: 0.001077  val_loss_rpn_loc: 0.02236    time: 1.6026  last_time: 1.5876  data_time: 0.0076  last_data_time: 0.0093   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:45:18 d2.utils.events]: \u001b[0m eta: 1:31:02  iter: 16339  total_loss: 0.1963  loss_cls: 0.0258  loss_box_reg: 0.06513  loss_mask: 0.07645  loss_rpn_cls: 0.001019  loss_rpn_loc: 0.02538  total_val_loss: 0.1964  val_loss_cls: 0.03057  val_loss_box_reg: 0.06233  val_loss_mask: 0.08307  val_loss_rpn_cls: 0.001216  val_loss_rpn_loc: 0.02057    time: 1.6025  last_time: 1.5036  data_time: 0.0075  last_data_time: 0.0073   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:46:00 d2.utils.events]: \u001b[0m eta: 1:30:30  iter: 16359  total_loss: 0.2068  loss_cls: 0.0285  loss_box_reg: 0.06604  loss_mask: 0.08252  loss_rpn_cls: 0.002465  loss_rpn_loc: 0.0299  total_val_loss: 0.2057  val_loss_cls: 0.03293  val_loss_box_reg: 0.06883  val_loss_mask: 0.08293  val_loss_rpn_cls: 0.0009343  val_loss_rpn_loc: 0.02399    time: 1.6023  last_time: 1.5136  data_time: 0.0078  last_data_time: 0.0083   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:46:42 d2.utils.events]: \u001b[0m eta: 1:30:00  iter: 16379  total_loss: 0.2074  loss_cls: 0.02961  loss_box_reg: 0.06635  loss_mask: 0.08139  loss_rpn_cls: 0.002186  loss_rpn_loc: 0.02715  total_val_loss: 0.2108  val_loss_cls: 0.0296  val_loss_box_reg: 0.07571  val_loss_mask: 0.08051  val_loss_rpn_cls: 0.001646  val_loss_rpn_loc: 0.02309    time: 1.6022  last_time: 1.4761  data_time: 0.0075  last_data_time: 0.0081   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:47:24 d2.utils.events]: \u001b[0m eta: 1:29:31  iter: 16399  total_loss: 0.1966  loss_cls: 0.02539  loss_box_reg: 0.06393  loss_mask: 0.07972  loss_rpn_cls: 0.001801  loss_rpn_loc: 0.02478  total_val_loss: 0.1943  val_loss_cls: 0.02495  val_loss_box_reg: 0.05936  val_loss_mask: 0.08074  val_loss_rpn_cls: 0.0008158  val_loss_rpn_loc: 0.0208    time: 1.6020  last_time: 1.4323  data_time: 0.0072  last_data_time: 0.0070   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:48:07 d2.utils.events]: \u001b[0m eta: 1:29:01  iter: 16419  total_loss: 0.1957  loss_cls: 0.02696  loss_box_reg: 0.06652  loss_mask: 0.08151  loss_rpn_cls: 0.001389  loss_rpn_loc: 0.02606  total_val_loss: 0.2063  val_loss_cls: 0.02811  val_loss_box_reg: 0.06687  val_loss_mask: 0.08433  val_loss_rpn_cls: 0.001409  val_loss_rpn_loc: 0.02366    time: 1.6019  last_time: 1.5875  data_time: 0.0075  last_data_time: 0.0060   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:48:49 d2.utils.events]: \u001b[0m eta: 1:28:30  iter: 16439  total_loss: 0.1866  loss_cls: 0.02297  loss_box_reg: 0.05991  loss_mask: 0.0781  loss_rpn_cls: 0.002079  loss_rpn_loc: 0.02265  total_val_loss: 0.2054  val_loss_cls: 0.03025  val_loss_box_reg: 0.0735  val_loss_mask: 0.08922  val_loss_rpn_cls: 0.001561  val_loss_rpn_loc: 0.02504    time: 1.6017  last_time: 1.6264  data_time: 0.0076  last_data_time: 0.0095   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:49:32 d2.utils.events]: \u001b[0m eta: 1:28:00  iter: 16459  total_loss: 0.195  loss_cls: 0.02442  loss_box_reg: 0.06577  loss_mask: 0.07445  loss_rpn_cls: 0.0008002  loss_rpn_loc: 0.02353  total_val_loss: 0.1983  val_loss_cls: 0.0266  val_loss_box_reg: 0.0692  val_loss_mask: 0.08439  val_loss_rpn_cls: 0.001182  val_loss_rpn_loc: 0.02318    time: 1.6016  last_time: 1.3922  data_time: 0.0073  last_data_time: 0.0079   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:50:14 d2.utils.events]: \u001b[0m eta: 1:27:29  iter: 16479  total_loss: 0.2058  loss_cls: 0.02714  loss_box_reg: 0.0692  loss_mask: 0.08293  loss_rpn_cls: 0.001964  loss_rpn_loc: 0.02517  total_val_loss: 0.191  val_loss_cls: 0.02837  val_loss_box_reg: 0.06353  val_loss_mask: 0.07949  val_loss_rpn_cls: 0.001156  val_loss_rpn_loc: 0.02104    time: 1.6015  last_time: 1.4645  data_time: 0.0079  last_data_time: 0.0096   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:50:57 d2.utils.events]: \u001b[0m eta: 1:27:00  iter: 16499  total_loss: 0.21  loss_cls: 0.02686  loss_box_reg: 0.06952  loss_mask: 0.077  loss_rpn_cls: 0.001631  loss_rpn_loc: 0.0269  total_val_loss: 0.2117  val_loss_cls: 0.03321  val_loss_box_reg: 0.07203  val_loss_mask: 0.08283  val_loss_rpn_cls: 0.001465  val_loss_rpn_loc: 0.0249    time: 1.6013  last_time: 1.4771  data_time: 0.0075  last_data_time: 0.0059   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:51:39 d2.utils.events]: \u001b[0m eta: 1:26:28  iter: 16519  total_loss: 0.2044  loss_cls: 0.02595  loss_box_reg: 0.06706  loss_mask: 0.07724  loss_rpn_cls: 0.002556  loss_rpn_loc: 0.02584  total_val_loss: 0.2074  val_loss_cls: 0.02733  val_loss_box_reg: 0.06047  val_loss_mask: 0.08773  val_loss_rpn_cls: 0.0004981  val_loss_rpn_loc: 0.02176    time: 1.6012  last_time: 1.4807  data_time: 0.0067  last_data_time: 0.0062   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:52:22 d2.utils.events]: \u001b[0m eta: 1:25:59  iter: 16539  total_loss: 0.1979  loss_cls: 0.0236  loss_box_reg: 0.06073  loss_mask: 0.08128  loss_rpn_cls: 0.002172  loss_rpn_loc: 0.02559  total_val_loss: 0.1798  val_loss_cls: 0.02298  val_loss_box_reg: 0.05403  val_loss_mask: 0.08222  val_loss_rpn_cls: 0.001004  val_loss_rpn_loc: 0.01977    time: 1.6011  last_time: 1.4729  data_time: 0.0071  last_data_time: 0.0079   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:53:04 d2.utils.events]: \u001b[0m eta: 1:25:27  iter: 16559  total_loss: 0.2091  loss_cls: 0.02605  loss_box_reg: 0.07335  loss_mask: 0.08046  loss_rpn_cls: 0.001344  loss_rpn_loc: 0.02595  total_val_loss: 0.2038  val_loss_cls: 0.02886  val_loss_box_reg: 0.06726  val_loss_mask: 0.08064  val_loss_rpn_cls: 0.0008319  val_loss_rpn_loc: 0.02286    time: 1.6009  last_time: 1.4032  data_time: 0.0070  last_data_time: 0.0070   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:53:46 d2.utils.events]: \u001b[0m eta: 1:24:55  iter: 16579  total_loss: 0.2193  loss_cls: 0.03013  loss_box_reg: 0.07631  loss_mask: 0.08022  loss_rpn_cls: 0.001779  loss_rpn_loc: 0.02704  total_val_loss: 0.2094  val_loss_cls: 0.02813  val_loss_box_reg: 0.06125  val_loss_mask: 0.08709  val_loss_rpn_cls: 0.0008115  val_loss_rpn_loc: 0.02202    time: 1.6007  last_time: 1.4344  data_time: 0.0074  last_data_time: 0.0071   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:54:28 d2.utils.events]: \u001b[0m eta: 1:24:23  iter: 16599  total_loss: 0.1908  loss_cls: 0.02272  loss_box_reg: 0.06488  loss_mask: 0.07544  loss_rpn_cls: 0.002644  loss_rpn_loc: 0.02624  total_val_loss: 0.1825  val_loss_cls: 0.02262  val_loss_box_reg: 0.055  val_loss_mask: 0.0794  val_loss_rpn_cls: 0.0006312  val_loss_rpn_loc: 0.01941    time: 1.6006  last_time: 1.4294  data_time: 0.0073  last_data_time: 0.0061   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:55:11 d2.utils.events]: \u001b[0m eta: 1:23:53  iter: 16619  total_loss: 0.1991  loss_cls: 0.0244  loss_box_reg: 0.06559  loss_mask: 0.07779  loss_rpn_cls: 0.002531  loss_rpn_loc: 0.02816  total_val_loss: 0.1969  val_loss_cls: 0.02827  val_loss_box_reg: 0.05998  val_loss_mask: 0.07802  val_loss_rpn_cls: 0.001168  val_loss_rpn_loc: 0.02091    time: 1.6005  last_time: 1.4943  data_time: 0.0073  last_data_time: 0.0054   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:55:54 d2.utils.events]: \u001b[0m eta: 1:23:24  iter: 16639  total_loss: 0.2199  loss_cls: 0.03228  loss_box_reg: 0.07585  loss_mask: 0.08073  loss_rpn_cls: 0.002249  loss_rpn_loc: 0.02976  total_val_loss: 0.1998  val_loss_cls: 0.0305  val_loss_box_reg: 0.06451  val_loss_mask: 0.0797  val_loss_rpn_cls: 0.001351  val_loss_rpn_loc: 0.02308    time: 1.6003  last_time: 1.4291  data_time: 0.0076  last_data_time: 0.0069   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:56:36 d2.utils.events]: \u001b[0m eta: 1:22:55  iter: 16659  total_loss: 0.2163  loss_cls: 0.03378  loss_box_reg: 0.07421  loss_mask: 0.07832  loss_rpn_cls: 0.002741  loss_rpn_loc: 0.02807  total_val_loss: 0.1935  val_loss_cls: 0.0259  val_loss_box_reg: 0.06153  val_loss_mask: 0.08374  val_loss_rpn_cls: 0.0007568  val_loss_rpn_loc: 0.02101    time: 1.6002  last_time: 1.4204  data_time: 0.0077  last_data_time: 0.0073   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:57:19 d2.utils.events]: \u001b[0m eta: 1:22:25  iter: 16679  total_loss: 0.1921  loss_cls: 0.02571  loss_box_reg: 0.06588  loss_mask: 0.0741  loss_rpn_cls: 0.001297  loss_rpn_loc: 0.02631  total_val_loss: 0.2163  val_loss_cls: 0.03135  val_loss_box_reg: 0.07114  val_loss_mask: 0.0884  val_loss_rpn_cls: 0.0007743  val_loss_rpn_loc: 0.02584    time: 1.6001  last_time: 1.4479  data_time: 0.0071  last_data_time: 0.0060   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:58:01 d2.utils.events]: \u001b[0m eta: 1:21:56  iter: 16699  total_loss: 0.2251  loss_cls: 0.02987  loss_box_reg: 0.07605  loss_mask: 0.07842  loss_rpn_cls: 0.002637  loss_rpn_loc: 0.0297  total_val_loss: 0.2034  val_loss_cls: 0.02705  val_loss_box_reg: 0.06262  val_loss_mask: 0.08623  val_loss_rpn_cls: 0.0008521  val_loss_rpn_loc: 0.02127    time: 1.5999  last_time: 1.4893  data_time: 0.0066  last_data_time: 0.0055   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:58:44 d2.utils.events]: \u001b[0m eta: 1:21:28  iter: 16719  total_loss: 0.2146  loss_cls: 0.02961  loss_box_reg: 0.06523  loss_mask: 0.081  loss_rpn_cls: 0.001887  loss_rpn_loc: 0.02666  total_val_loss: 0.1726  val_loss_cls: 0.02036  val_loss_box_reg: 0.05313  val_loss_mask: 0.08175  val_loss_rpn_cls: 0.000775  val_loss_rpn_loc: 0.01897    time: 1.5998  last_time: 1.5202  data_time: 0.0073  last_data_time: 0.0077   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 00:59:25 d2.utils.events]: \u001b[0m eta: 1:20:57  iter: 16739  total_loss: 0.2315  loss_cls: 0.0289  loss_box_reg: 0.07678  loss_mask: 0.08478  loss_rpn_cls: 0.00283  loss_rpn_loc: 0.03101  total_val_loss: 0.1918  val_loss_cls: 0.02768  val_loss_box_reg: 0.06209  val_loss_mask: 0.07936  val_loss_rpn_cls: 0.001349  val_loss_rpn_loc: 0.02066    time: 1.5997  last_time: 1.5176  data_time: 0.0072  last_data_time: 0.0064   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:00:09 d2.utils.events]: \u001b[0m eta: 1:20:27  iter: 16759  total_loss: 0.1971  loss_cls: 0.02659  loss_box_reg: 0.06321  loss_mask: 0.0786  loss_rpn_cls: 0.002558  loss_rpn_loc: 0.02654  total_val_loss: 0.2249  val_loss_cls: 0.03431  val_loss_box_reg: 0.07108  val_loss_mask: 0.08923  val_loss_rpn_cls: 0.0016  val_loss_rpn_loc: 0.0239    time: 1.5996  last_time: 1.4531  data_time: 0.0070  last_data_time: 0.0066   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:00:51 d2.utils.events]: \u001b[0m eta: 1:19:58  iter: 16779  total_loss: 0.2022  loss_cls: 0.02685  loss_box_reg: 0.06829  loss_mask: 0.07837  loss_rpn_cls: 0.002327  loss_rpn_loc: 0.0249  total_val_loss: 0.2195  val_loss_cls: 0.0311  val_loss_box_reg: 0.07092  val_loss_mask: 0.08495  val_loss_rpn_cls: 0.001088  val_loss_rpn_loc: 0.02478    time: 1.5994  last_time: 1.4959  data_time: 0.0069  last_data_time: 0.0076   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:01:34 d2.utils.events]: \u001b[0m eta: 1:19:30  iter: 16799  total_loss: 0.2447  loss_cls: 0.034  loss_box_reg: 0.09045  loss_mask: 0.08217  loss_rpn_cls: 0.002046  loss_rpn_loc: 0.0289  total_val_loss: 0.2137  val_loss_cls: 0.03496  val_loss_box_reg: 0.06999  val_loss_mask: 0.08247  val_loss_rpn_cls: 0.001046  val_loss_rpn_loc: 0.02341    time: 1.5993  last_time: 1.5544  data_time: 0.0065  last_data_time: 0.0060   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:02:16 d2.utils.events]: \u001b[0m eta: 1:18:57  iter: 16819  total_loss: 0.1891  loss_cls: 0.02588  loss_box_reg: 0.05889  loss_mask: 0.07504  loss_rpn_cls: 0.00226  loss_rpn_loc: 0.02394  total_val_loss: 0.2047  val_loss_cls: 0.0293  val_loss_box_reg: 0.06949  val_loss_mask: 0.08075  val_loss_rpn_cls: 0.001209  val_loss_rpn_loc: 0.02221    time: 1.5991  last_time: 1.4368  data_time: 0.0067  last_data_time: 0.0059   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:02:59 d2.utils.events]: \u001b[0m eta: 1:18:28  iter: 16839  total_loss: 0.2162  loss_cls: 0.0311  loss_box_reg: 0.0725  loss_mask: 0.07847  loss_rpn_cls: 0.002634  loss_rpn_loc: 0.02706  total_val_loss: 0.1865  val_loss_cls: 0.02458  val_loss_box_reg: 0.05961  val_loss_mask: 0.07938  val_loss_rpn_cls: 0.000856  val_loss_rpn_loc: 0.02195    time: 1.5990  last_time: 1.4594  data_time: 0.0066  last_data_time: 0.0078   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:03:41 d2.utils.events]: \u001b[0m eta: 1:18:02  iter: 16859  total_loss: 0.2196  loss_cls: 0.02648  loss_box_reg: 0.06944  loss_mask: 0.08103  loss_rpn_cls: 0.001267  loss_rpn_loc: 0.02837  total_val_loss: 0.2002  val_loss_cls: 0.02665  val_loss_box_reg: 0.06404  val_loss_mask: 0.07949  val_loss_rpn_cls: 0.0006992  val_loss_rpn_loc: 0.02239    time: 1.5989  last_time: 1.6252  data_time: 0.0067  last_data_time: 0.0062   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:04:23 d2.utils.events]: \u001b[0m eta: 1:17:30  iter: 16879  total_loss: 0.203  loss_cls: 0.026  loss_box_reg: 0.05991  loss_mask: 0.08004  loss_rpn_cls: 0.002283  loss_rpn_loc: 0.02791  total_val_loss: 0.2069  val_loss_cls: 0.02844  val_loss_box_reg: 0.06979  val_loss_mask: 0.08959  val_loss_rpn_cls: 0.00109  val_loss_rpn_loc: 0.02228    time: 1.5988  last_time: 1.5638  data_time: 0.0067  last_data_time: 0.0069   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:05:05 d2.utils.events]: \u001b[0m eta: 1:16:58  iter: 16899  total_loss: 0.1944  loss_cls: 0.02346  loss_box_reg: 0.06023  loss_mask: 0.07947  loss_rpn_cls: 0.00198  loss_rpn_loc: 0.02386  total_val_loss: 0.2077  val_loss_cls: 0.02719  val_loss_box_reg: 0.06394  val_loss_mask: 0.08502  val_loss_rpn_cls: 0.001059  val_loss_rpn_loc: 0.02164    time: 1.5986  last_time: 1.5060  data_time: 0.0063  last_data_time: 0.0062   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:05:48 d2.utils.events]: \u001b[0m eta: 1:16:29  iter: 16919  total_loss: 0.2083  loss_cls: 0.0283  loss_box_reg: 0.06734  loss_mask: 0.07882  loss_rpn_cls: 0.002313  loss_rpn_loc: 0.03047  total_val_loss: 0.1966  val_loss_cls: 0.02645  val_loss_box_reg: 0.06631  val_loss_mask: 0.08026  val_loss_rpn_cls: 0.001008  val_loss_rpn_loc: 0.02355    time: 1.5985  last_time: 1.4449  data_time: 0.0066  last_data_time: 0.0065   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:06:30 d2.utils.events]: \u001b[0m eta: 1:15:59  iter: 16939  total_loss: 0.2194  loss_cls: 0.03107  loss_box_reg: 0.07805  loss_mask: 0.07943  loss_rpn_cls: 0.00192  loss_rpn_loc: 0.02886  total_val_loss: 0.1892  val_loss_cls: 0.0228  val_loss_box_reg: 0.05934  val_loss_mask: 0.07987  val_loss_rpn_cls: 0.0009772  val_loss_rpn_loc: 0.02049    time: 1.5983  last_time: 1.5677  data_time: 0.0067  last_data_time: 0.0059   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:07:13 d2.utils.events]: \u001b[0m eta: 1:15:28  iter: 16959  total_loss: 0.2148  loss_cls: 0.02988  loss_box_reg: 0.07301  loss_mask: 0.07944  loss_rpn_cls: 0.002115  loss_rpn_loc: 0.02649  total_val_loss: 0.2043  val_loss_cls: 0.02745  val_loss_box_reg: 0.06412  val_loss_mask: 0.08608  val_loss_rpn_cls: 0.0007678  val_loss_rpn_loc: 0.0219    time: 1.5982  last_time: 1.5209  data_time: 0.0065  last_data_time: 0.0076   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:07:56 d2.utils.events]: \u001b[0m eta: 1:14:57  iter: 16979  total_loss: 0.218  loss_cls: 0.02974  loss_box_reg: 0.07035  loss_mask: 0.08743  loss_rpn_cls: 0.002354  loss_rpn_loc: 0.03001  total_val_loss: 0.209  val_loss_cls: 0.02889  val_loss_box_reg: 0.07261  val_loss_mask: 0.08646  val_loss_rpn_cls: 0.0008717  val_loss_rpn_loc: 0.02562    time: 1.5981  last_time: 1.5966  data_time: 0.0077  last_data_time: 0.0077   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:08:42 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\testing_images\\0_SideLane_addedversion_Testing_COCO.json\n",
      "\u001b[32m[09/27 01:08:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/27 01:08:42 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/27 01:08:42 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/27 01:08:42 d2.data.common]: \u001b[0mSerialized dataset takes 6.03 MiB\n",
      "\u001b[32m[09/27 01:08:42 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[09/27 01:08:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 566 batches\n",
      "\u001b[32m[09/27 01:08:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/566. Dataloading: 0.0004 s/iter. Inference: 0.0701 s/iter. Eval: 0.0065 s/iter. Total: 0.0771 s/iter. ETA=0:00:42\n",
      "\u001b[32m[09/27 01:08:53 d2.evaluation.evaluator]: \u001b[0mInference done 80/566. Dataloading: 0.0006 s/iter. Inference: 0.0700 s/iter. Eval: 0.0027 s/iter. Total: 0.0733 s/iter. ETA=0:00:35\n",
      "\u001b[32m[09/27 01:08:58 d2.evaluation.evaluator]: \u001b[0mInference done 147/566. Dataloading: 0.0006 s/iter. Inference: 0.0700 s/iter. Eval: 0.0038 s/iter. Total: 0.0744 s/iter. ETA=0:00:31\n",
      "\u001b[32m[09/27 01:09:03 d2.evaluation.evaluator]: \u001b[0mInference done 213/566. Dataloading: 0.0006 s/iter. Inference: 0.0707 s/iter. Eval: 0.0038 s/iter. Total: 0.0751 s/iter. ETA=0:00:26\n",
      "\u001b[32m[09/27 01:09:08 d2.evaluation.evaluator]: \u001b[0mInference done 280/566. Dataloading: 0.0006 s/iter. Inference: 0.0708 s/iter. Eval: 0.0037 s/iter. Total: 0.0751 s/iter. ETA=0:00:21\n",
      "\u001b[32m[09/27 01:09:13 d2.evaluation.evaluator]: \u001b[0mInference done 351/566. Dataloading: 0.0006 s/iter. Inference: 0.0703 s/iter. Eval: 0.0033 s/iter. Total: 0.0742 s/iter. ETA=0:00:15\n",
      "\u001b[32m[09/27 01:09:18 d2.evaluation.evaluator]: \u001b[0mInference done 420/566. Dataloading: 0.0006 s/iter. Inference: 0.0704 s/iter. Eval: 0.0030 s/iter. Total: 0.0740 s/iter. ETA=0:00:10\n",
      "\u001b[32m[09/27 01:09:23 d2.evaluation.evaluator]: \u001b[0mInference done 484/566. Dataloading: 0.0006 s/iter. Inference: 0.0706 s/iter. Eval: 0.0035 s/iter. Total: 0.0746 s/iter. ETA=0:00:06\n",
      "\u001b[32m[09/27 01:09:28 d2.evaluation.evaluator]: \u001b[0mInference done 549/566. Dataloading: 0.0006 s/iter. Inference: 0.0709 s/iter. Eval: 0.0034 s/iter. Total: 0.0749 s/iter. ETA=0:00:01\n",
      "\u001b[32m[09/27 01:09:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:42.474327 (0.075712 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/27 01:09:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.070905 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/27 01:09:30 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/27 01:09:30 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\coco_instances_results.json\n",
      "\u001b[32m[09/27 01:09:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.23s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.934\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.928\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.937\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.937\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.951\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.941\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.958\n",
      "\u001b[32m[09/27 01:09:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 93.358 | 99.008 | 98.997 |  nan  | 92.827 | 93.668 |\n",
      "\u001b[32m[09/27 01:09:30 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/27 01:09:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 93.358 | background | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.35s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.861\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.828\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.882\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.881\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.895\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.866\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.913\n",
      "\u001b[32m[09/27 01:09:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 86.090 | 99.008 | 98.954 |  nan  | 82.770 | 88.204 |\n",
      "\u001b[32m[09/27 01:09:31 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/27 01:09:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 86.090 | background | nan  |\n",
      "\u001b[32m[09/27 01:09:31 d2.engine.defaults]: \u001b[0mEvaluation results for test_data in csv format:\n",
      "\u001b[32m[09/27 01:09:31 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/27 01:09:31 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/27 01:09:31 d2.evaluation.testing]: \u001b[0mcopypaste: 93.3582,99.0080,98.9966,nan,92.8266,93.6680\n",
      "\u001b[32m[09/27 01:09:31 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/27 01:09:31 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/27 01:09:31 d2.evaluation.testing]: \u001b[0mcopypaste: 86.0896,99.0080,98.9538,nan,82.7700,88.2038\n",
      "\u001b[32m[09/27 01:09:31 d2.utils.events]: \u001b[0m eta: 1:14:27  iter: 16999  total_loss: 0.216  loss_cls: 0.02609  loss_box_reg: 0.07203  loss_mask: 0.08275  loss_rpn_cls: 0.002158  loss_rpn_loc: 0.02647  total_val_loss: 0.2138  val_loss_cls: 0.03184  val_loss_box_reg: 0.06635  val_loss_mask: 0.08578  val_loss_rpn_cls: 0.0009293  val_loss_rpn_loc: 0.02266    time: 1.5979  last_time: 1.3174  data_time: 0.0071  last_data_time: 0.0090   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:10:14 d2.utils.events]: \u001b[0m eta: 1:13:56  iter: 17019  total_loss: 0.1791  loss_cls: 0.02226  loss_box_reg: 0.05792  loss_mask: 0.07998  loss_rpn_cls: 0.0021  loss_rpn_loc: 0.02462  total_val_loss: 0.2018  val_loss_cls: 0.02608  val_loss_box_reg: 0.06446  val_loss_mask: 0.08561  val_loss_rpn_cls: 0.0005898  val_loss_rpn_loc: 0.0226    time: 1.5978  last_time: 1.3696  data_time: 0.0067  last_data_time: 0.0062   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:10:56 d2.utils.events]: \u001b[0m eta: 1:13:24  iter: 17039  total_loss: 0.2244  loss_cls: 0.03076  loss_box_reg: 0.07519  loss_mask: 0.08003  loss_rpn_cls: 0.002564  loss_rpn_loc: 0.02862  total_val_loss: 0.1943  val_loss_cls: 0.02655  val_loss_box_reg: 0.06125  val_loss_mask: 0.08604  val_loss_rpn_cls: 0.0009584  val_loss_rpn_loc: 0.02092    time: 1.5977  last_time: 1.4741  data_time: 0.0074  last_data_time: 0.0075   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:11:38 d2.utils.events]: \u001b[0m eta: 1:12:50  iter: 17059  total_loss: 0.2087  loss_cls: 0.02845  loss_box_reg: 0.07142  loss_mask: 0.07627  loss_rpn_cls: 0.002483  loss_rpn_loc: 0.02945  total_val_loss: 0.1991  val_loss_cls: 0.02937  val_loss_box_reg: 0.06437  val_loss_mask: 0.0815  val_loss_rpn_cls: 0.00111  val_loss_rpn_loc: 0.02185    time: 1.5975  last_time: 1.4469  data_time: 0.0073  last_data_time: 0.0093   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:12:20 d2.utils.events]: \u001b[0m eta: 1:12:18  iter: 17079  total_loss: 0.1938  loss_cls: 0.02488  loss_box_reg: 0.06475  loss_mask: 0.07961  loss_rpn_cls: 0.002339  loss_rpn_loc: 0.02488  total_val_loss: 0.203  val_loss_cls: 0.03211  val_loss_box_reg: 0.06504  val_loss_mask: 0.0827  val_loss_rpn_cls: 0.001201  val_loss_rpn_loc: 0.02203    time: 1.5974  last_time: 1.3923  data_time: 0.0070  last_data_time: 0.0070   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:13:03 d2.utils.events]: \u001b[0m eta: 1:11:46  iter: 17099  total_loss: 0.1848  loss_cls: 0.02387  loss_box_reg: 0.05782  loss_mask: 0.07595  loss_rpn_cls: 0.001329  loss_rpn_loc: 0.02407  total_val_loss: 0.2003  val_loss_cls: 0.03028  val_loss_box_reg: 0.06723  val_loss_mask: 0.08325  val_loss_rpn_cls: 0.0007192  val_loss_rpn_loc: 0.02219    time: 1.5972  last_time: 1.4744  data_time: 0.0071  last_data_time: 0.0088   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:13:46 d2.utils.events]: \u001b[0m eta: 1:11:19  iter: 17119  total_loss: 0.219  loss_cls: 0.02731  loss_box_reg: 0.06979  loss_mask: 0.08099  loss_rpn_cls: 0.002445  loss_rpn_loc: 0.02696  total_val_loss: 0.207  val_loss_cls: 0.02994  val_loss_box_reg: 0.06707  val_loss_mask: 0.08561  val_loss_rpn_cls: 0.001247  val_loss_rpn_loc: 0.02306    time: 1.5971  last_time: 1.5452  data_time: 0.0071  last_data_time: 0.0069   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:14:28 d2.utils.events]: \u001b[0m eta: 1:10:51  iter: 17139  total_loss: 0.22  loss_cls: 0.0313  loss_box_reg: 0.07507  loss_mask: 0.08186  loss_rpn_cls: 0.002523  loss_rpn_loc: 0.02844  total_val_loss: 0.204  val_loss_cls: 0.03032  val_loss_box_reg: 0.06566  val_loss_mask: 0.08811  val_loss_rpn_cls: 0.0009461  val_loss_rpn_loc: 0.02301    time: 1.5970  last_time: 1.4858  data_time: 0.0074  last_data_time: 0.0078   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:15:11 d2.utils.events]: \u001b[0m eta: 1:10:21  iter: 17159  total_loss: 0.2058  loss_cls: 0.03051  loss_box_reg: 0.07001  loss_mask: 0.0784  loss_rpn_cls: 0.001888  loss_rpn_loc: 0.02627  total_val_loss: 0.2117  val_loss_cls: 0.03089  val_loss_box_reg: 0.07195  val_loss_mask: 0.07943  val_loss_rpn_cls: 0.001026  val_loss_rpn_loc: 0.02523    time: 1.5969  last_time: 1.4840  data_time: 0.0072  last_data_time: 0.0062   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:15:53 d2.utils.events]: \u001b[0m eta: 1:09:49  iter: 17179  total_loss: 0.1863  loss_cls: 0.02705  loss_box_reg: 0.06053  loss_mask: 0.0701  loss_rpn_cls: 0.002941  loss_rpn_loc: 0.02506  total_val_loss: 0.1914  val_loss_cls: 0.02495  val_loss_box_reg: 0.06368  val_loss_mask: 0.08499  val_loss_rpn_cls: 0.0009194  val_loss_rpn_loc: 0.02102    time: 1.5967  last_time: 1.4614  data_time: 0.0074  last_data_time: 0.0072   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:16:36 d2.utils.events]: \u001b[0m eta: 1:09:20  iter: 17199  total_loss: 0.2096  loss_cls: 0.02975  loss_box_reg: 0.07325  loss_mask: 0.07471  loss_rpn_cls: 0.002455  loss_rpn_loc: 0.0303  total_val_loss: 0.2017  val_loss_cls: 0.02652  val_loss_box_reg: 0.06374  val_loss_mask: 0.08056  val_loss_rpn_cls: 0.001201  val_loss_rpn_loc: 0.0225    time: 1.5966  last_time: 1.4449  data_time: 0.0072  last_data_time: 0.0070   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:17:19 d2.utils.events]: \u001b[0m eta: 1:08:50  iter: 17219  total_loss: 0.2084  loss_cls: 0.02617  loss_box_reg: 0.06995  loss_mask: 0.07845  loss_rpn_cls: 0.001874  loss_rpn_loc: 0.02748  total_val_loss: 0.1843  val_loss_cls: 0.02338  val_loss_box_reg: 0.05518  val_loss_mask: 0.08267  val_loss_rpn_cls: 0.0008636  val_loss_rpn_loc: 0.01823    time: 1.5965  last_time: 1.5385  data_time: 0.0068  last_data_time: 0.0061   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:18:02 d2.utils.events]: \u001b[0m eta: 1:08:21  iter: 17239  total_loss: 0.2199  loss_cls: 0.03037  loss_box_reg: 0.07733  loss_mask: 0.0808  loss_rpn_cls: 0.002388  loss_rpn_loc: 0.02858  total_val_loss: 0.195  val_loss_cls: 0.02316  val_loss_box_reg: 0.06088  val_loss_mask: 0.0817  val_loss_rpn_cls: 0.0005302  val_loss_rpn_loc: 0.0214    time: 1.5964  last_time: 1.6062  data_time: 0.0074  last_data_time: 0.0100   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:18:44 d2.utils.events]: \u001b[0m eta: 1:07:51  iter: 17259  total_loss: 0.1943  loss_cls: 0.02743  loss_box_reg: 0.06479  loss_mask: 0.07997  loss_rpn_cls: 0.001899  loss_rpn_loc: 0.02201  total_val_loss: 0.2111  val_loss_cls: 0.03367  val_loss_box_reg: 0.06923  val_loss_mask: 0.08356  val_loss_rpn_cls: 0.001409  val_loss_rpn_loc: 0.02472    time: 1.5963  last_time: 1.5271  data_time: 0.0071  last_data_time: 0.0062   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:19:27 d2.utils.events]: \u001b[0m eta: 1:07:22  iter: 17279  total_loss: 0.2183  loss_cls: 0.02672  loss_box_reg: 0.07523  loss_mask: 0.07919  loss_rpn_cls: 0.001807  loss_rpn_loc: 0.02926  total_val_loss: 0.2028  val_loss_cls: 0.02701  val_loss_box_reg: 0.06436  val_loss_mask: 0.08384  val_loss_rpn_cls: 0.001292  val_loss_rpn_loc: 0.02359    time: 1.5962  last_time: 1.5020  data_time: 0.0074  last_data_time: 0.0086   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:20:10 d2.utils.events]: \u001b[0m eta: 1:06:53  iter: 17299  total_loss: 0.2039  loss_cls: 0.02332  loss_box_reg: 0.06669  loss_mask: 0.08571  loss_rpn_cls: 0.001744  loss_rpn_loc: 0.02391  total_val_loss: 0.1921  val_loss_cls: 0.02653  val_loss_box_reg: 0.05759  val_loss_mask: 0.08735  val_loss_rpn_cls: 0.0007364  val_loss_rpn_loc: 0.01999    time: 1.5961  last_time: 1.4362  data_time: 0.0081  last_data_time: 0.0075   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:20:53 d2.utils.events]: \u001b[0m eta: 1:06:22  iter: 17319  total_loss: 0.1867  loss_cls: 0.02357  loss_box_reg: 0.06663  loss_mask: 0.06871  loss_rpn_cls: 0.001828  loss_rpn_loc: 0.02665  total_val_loss: 0.1969  val_loss_cls: 0.02751  val_loss_box_reg: 0.06391  val_loss_mask: 0.0799  val_loss_rpn_cls: 0.001668  val_loss_rpn_loc: 0.02168    time: 1.5959  last_time: 1.4415  data_time: 0.0077  last_data_time: 0.0092   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:21:35 d2.utils.events]: \u001b[0m eta: 1:05:52  iter: 17339  total_loss: 0.1968  loss_cls: 0.02669  loss_box_reg: 0.06267  loss_mask: 0.07726  loss_rpn_cls: 0.001906  loss_rpn_loc: 0.02397  total_val_loss: 0.2049  val_loss_cls: 0.02942  val_loss_box_reg: 0.06764  val_loss_mask: 0.08589  val_loss_rpn_cls: 0.001078  val_loss_rpn_loc: 0.02395    time: 1.5958  last_time: 1.5665  data_time: 0.0077  last_data_time: 0.0071   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:22:18 d2.utils.events]: \u001b[0m eta: 1:05:22  iter: 17359  total_loss: 0.201  loss_cls: 0.02301  loss_box_reg: 0.06779  loss_mask: 0.08097  loss_rpn_cls: 0.001421  loss_rpn_loc: 0.02522  total_val_loss: 0.186  val_loss_cls: 0.02378  val_loss_box_reg: 0.05922  val_loss_mask: 0.08316  val_loss_rpn_cls: 0.0009493  val_loss_rpn_loc: 0.02088    time: 1.5957  last_time: 1.4089  data_time: 0.0081  last_data_time: 0.0083   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:23:01 d2.utils.events]: \u001b[0m eta: 1:04:54  iter: 17379  total_loss: 0.2035  loss_cls: 0.02688  loss_box_reg: 0.06674  loss_mask: 0.07797  loss_rpn_cls: 0.002992  loss_rpn_loc: 0.02625  total_val_loss: 0.2074  val_loss_cls: 0.03215  val_loss_box_reg: 0.06705  val_loss_mask: 0.08189  val_loss_rpn_cls: 0.001158  val_loss_rpn_loc: 0.02547    time: 1.5956  last_time: 1.4916  data_time: 0.0078  last_data_time: 0.0074   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:23:44 d2.utils.events]: \u001b[0m eta: 1:04:25  iter: 17399  total_loss: 0.2089  loss_cls: 0.0284  loss_box_reg: 0.07041  loss_mask: 0.08138  loss_rpn_cls: 0.002594  loss_rpn_loc: 0.02518  total_val_loss: 0.202  val_loss_cls: 0.02973  val_loss_box_reg: 0.06811  val_loss_mask: 0.08444  val_loss_rpn_cls: 0.001262  val_loss_rpn_loc: 0.0225    time: 1.5955  last_time: 1.3881  data_time: 0.0078  last_data_time: 0.0064   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:24:26 d2.utils.events]: \u001b[0m eta: 1:03:57  iter: 17419  total_loss: 0.1915  loss_cls: 0.02335  loss_box_reg: 0.06743  loss_mask: 0.07725  loss_rpn_cls: 0.001846  loss_rpn_loc: 0.02483  total_val_loss: 0.19  val_loss_cls: 0.02669  val_loss_box_reg: 0.06044  val_loss_mask: 0.07871  val_loss_rpn_cls: 0.0007348  val_loss_rpn_loc: 0.02075    time: 1.5954  last_time: 1.5331  data_time: 0.0076  last_data_time: 0.0109   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:25:09 d2.utils.events]: \u001b[0m eta: 1:03:29  iter: 17439  total_loss: 0.2088  loss_cls: 0.02884  loss_box_reg: 0.06534  loss_mask: 0.0804  loss_rpn_cls: 0.00216  loss_rpn_loc: 0.02529  total_val_loss: 0.1929  val_loss_cls: 0.02736  val_loss_box_reg: 0.06274  val_loss_mask: 0.08463  val_loss_rpn_cls: 0.001013  val_loss_rpn_loc: 0.02126    time: 1.5952  last_time: 1.5887  data_time: 0.0072  last_data_time: 0.0071   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:25:51 d2.utils.events]: \u001b[0m eta: 1:02:58  iter: 17459  total_loss: 0.2257  loss_cls: 0.02906  loss_box_reg: 0.07449  loss_mask: 0.08196  loss_rpn_cls: 0.00256  loss_rpn_loc: 0.03232  total_val_loss: 0.2094  val_loss_cls: 0.02812  val_loss_box_reg: 0.0676  val_loss_mask: 0.08479  val_loss_rpn_cls: 0.0007752  val_loss_rpn_loc: 0.02389    time: 1.5951  last_time: 1.3893  data_time: 0.0078  last_data_time: 0.0068   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:26:34 d2.utils.events]: \u001b[0m eta: 1:02:26  iter: 17479  total_loss: 0.2182  loss_cls: 0.02744  loss_box_reg: 0.07347  loss_mask: 0.07675  loss_rpn_cls: 0.001687  loss_rpn_loc: 0.02529  total_val_loss: 0.2052  val_loss_cls: 0.02854  val_loss_box_reg: 0.06609  val_loss_mask: 0.087  val_loss_rpn_cls: 0.0007358  val_loss_rpn_loc: 0.02288    time: 1.5950  last_time: 1.5930  data_time: 0.0074  last_data_time: 0.0076   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:27:16 d2.utils.events]: \u001b[0m eta: 1:01:55  iter: 17499  total_loss: 0.1941  loss_cls: 0.02722  loss_box_reg: 0.06058  loss_mask: 0.07666  loss_rpn_cls: 0.001638  loss_rpn_loc: 0.02221  total_val_loss: 0.1842  val_loss_cls: 0.02311  val_loss_box_reg: 0.05968  val_loss_mask: 0.07706  val_loss_rpn_cls: 0.0006972  val_loss_rpn_loc: 0.02077    time: 1.5949  last_time: 1.4741  data_time: 0.0075  last_data_time: 0.0083   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:27:59 d2.utils.events]: \u001b[0m eta: 1:01:26  iter: 17519  total_loss: 0.2067  loss_cls: 0.02699  loss_box_reg: 0.07258  loss_mask: 0.08199  loss_rpn_cls: 0.001722  loss_rpn_loc: 0.02693  total_val_loss: 0.1987  val_loss_cls: 0.02473  val_loss_box_reg: 0.06527  val_loss_mask: 0.08663  val_loss_rpn_cls: 0.0009322  val_loss_rpn_loc: 0.02163    time: 1.5948  last_time: 1.5424  data_time: 0.0081  last_data_time: 0.0070   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:28:42 d2.utils.events]: \u001b[0m eta: 1:00:55  iter: 17539  total_loss: 0.2032  loss_cls: 0.02384  loss_box_reg: 0.06212  loss_mask: 0.07803  loss_rpn_cls: 0.002289  loss_rpn_loc: 0.02615  total_val_loss: 0.2001  val_loss_cls: 0.02249  val_loss_box_reg: 0.06647  val_loss_mask: 0.08178  val_loss_rpn_cls: 0.0009732  val_loss_rpn_loc: 0.02265    time: 1.5946  last_time: 1.5390  data_time: 0.0081  last_data_time: 0.0066   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:29:24 d2.utils.events]: \u001b[0m eta: 1:00:25  iter: 17559  total_loss: 0.1833  loss_cls: 0.02385  loss_box_reg: 0.05287  loss_mask: 0.07879  loss_rpn_cls: 0.002025  loss_rpn_loc: 0.02479  total_val_loss: 0.2041  val_loss_cls: 0.02814  val_loss_box_reg: 0.06385  val_loss_mask: 0.08353  val_loss_rpn_cls: 0.0007963  val_loss_rpn_loc: 0.02255    time: 1.5945  last_time: 1.4381  data_time: 0.0076  last_data_time: 0.0069   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:30:06 d2.utils.events]: \u001b[0m eta: 0:59:57  iter: 17579  total_loss: 0.2104  loss_cls: 0.02902  loss_box_reg: 0.07823  loss_mask: 0.07305  loss_rpn_cls: 0.002801  loss_rpn_loc: 0.02927  total_val_loss: 0.1864  val_loss_cls: 0.02485  val_loss_box_reg: 0.05907  val_loss_mask: 0.08577  val_loss_rpn_cls: 0.0007193  val_loss_rpn_loc: 0.02071    time: 1.5944  last_time: 1.4596  data_time: 0.0078  last_data_time: 0.0064   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:30:49 d2.utils.events]: \u001b[0m eta: 0:59:32  iter: 17599  total_loss: 0.2279  loss_cls: 0.02963  loss_box_reg: 0.07657  loss_mask: 0.07643  loss_rpn_cls: 0.003396  loss_rpn_loc: 0.03157  total_val_loss: 0.1977  val_loss_cls: 0.02668  val_loss_box_reg: 0.06392  val_loss_mask: 0.08354  val_loss_rpn_cls: 0.0007628  val_loss_rpn_loc: 0.02175    time: 1.5943  last_time: 1.5896  data_time: 0.0077  last_data_time: 0.0065   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:31:32 d2.utils.events]: \u001b[0m eta: 0:59:02  iter: 17619  total_loss: 0.2426  loss_cls: 0.0343  loss_box_reg: 0.08468  loss_mask: 0.08337  loss_rpn_cls: 0.002162  loss_rpn_loc: 0.0302  total_val_loss: 0.2028  val_loss_cls: 0.02959  val_loss_box_reg: 0.06869  val_loss_mask: 0.08306  val_loss_rpn_cls: 0.0009587  val_loss_rpn_loc: 0.02366    time: 1.5942  last_time: 1.4871  data_time: 0.0080  last_data_time: 0.0065   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:32:15 d2.utils.events]: \u001b[0m eta: 0:58:34  iter: 17639  total_loss: 0.2125  loss_cls: 0.02889  loss_box_reg: 0.07352  loss_mask: 0.0841  loss_rpn_cls: 0.002107  loss_rpn_loc: 0.02874  total_val_loss: 0.2016  val_loss_cls: 0.02973  val_loss_box_reg: 0.06645  val_loss_mask: 0.07878  val_loss_rpn_cls: 0.001227  val_loss_rpn_loc: 0.02474    time: 1.5941  last_time: 1.4729  data_time: 0.0077  last_data_time: 0.0061   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:32:58 d2.utils.events]: \u001b[0m eta: 0:58:02  iter: 17659  total_loss: 0.2119  loss_cls: 0.03007  loss_box_reg: 0.07036  loss_mask: 0.0867  loss_rpn_cls: 0.001954  loss_rpn_loc: 0.02701  total_val_loss: 0.217  val_loss_cls: 0.03207  val_loss_box_reg: 0.07063  val_loss_mask: 0.08658  val_loss_rpn_cls: 0.0009159  val_loss_rpn_loc: 0.02309    time: 1.5940  last_time: 1.4209  data_time: 0.0079  last_data_time: 0.0064   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:33:41 d2.utils.events]: \u001b[0m eta: 0:57:37  iter: 17679  total_loss: 0.2283  loss_cls: 0.03067  loss_box_reg: 0.08198  loss_mask: 0.07854  loss_rpn_cls: 0.001899  loss_rpn_loc: 0.02761  total_val_loss: 0.1988  val_loss_cls: 0.02916  val_loss_box_reg: 0.06547  val_loss_mask: 0.08568  val_loss_rpn_cls: 0.0008119  val_loss_rpn_loc: 0.02166    time: 1.5939  last_time: 1.4941  data_time: 0.0077  last_data_time: 0.0074   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:34:24 d2.utils.events]: \u001b[0m eta: 0:57:06  iter: 17699  total_loss: 0.2121  loss_cls: 0.02826  loss_box_reg: 0.06678  loss_mask: 0.07978  loss_rpn_cls: 0.001571  loss_rpn_loc: 0.02885  total_val_loss: 0.1898  val_loss_cls: 0.02605  val_loss_box_reg: 0.06315  val_loss_mask: 0.0831  val_loss_rpn_cls: 0.0007859  val_loss_rpn_loc: 0.02251    time: 1.5938  last_time: 1.4186  data_time: 0.0079  last_data_time: 0.0061   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:35:07 d2.utils.events]: \u001b[0m eta: 0:56:36  iter: 17719  total_loss: 0.1911  loss_cls: 0.02623  loss_box_reg: 0.06415  loss_mask: 0.07696  loss_rpn_cls: 0.001819  loss_rpn_loc: 0.02644  total_val_loss: 0.2104  val_loss_cls: 0.0307  val_loss_box_reg: 0.06524  val_loss_mask: 0.08142  val_loss_rpn_cls: 0.001264  val_loss_rpn_loc: 0.02364    time: 1.5937  last_time: 1.5675  data_time: 0.0078  last_data_time: 0.0071   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:35:49 d2.utils.events]: \u001b[0m eta: 0:56:06  iter: 17739  total_loss: 0.2133  loss_cls: 0.02599  loss_box_reg: 0.06653  loss_mask: 0.08105  loss_rpn_cls: 0.001239  loss_rpn_loc: 0.02479  total_val_loss: 0.1964  val_loss_cls: 0.02459  val_loss_box_reg: 0.05802  val_loss_mask: 0.08455  val_loss_rpn_cls: 0.001101  val_loss_rpn_loc: 0.02049    time: 1.5935  last_time: 1.4487  data_time: 0.0078  last_data_time: 0.0058   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:36:31 d2.utils.events]: \u001b[0m eta: 0:55:33  iter: 17759  total_loss: 0.2101  loss_cls: 0.02839  loss_box_reg: 0.06717  loss_mask: 0.07747  loss_rpn_cls: 0.001919  loss_rpn_loc: 0.02714  total_val_loss: 0.2169  val_loss_cls: 0.03255  val_loss_box_reg: 0.07113  val_loss_mask: 0.08083  val_loss_rpn_cls: 0.0009115  val_loss_rpn_loc: 0.02395    time: 1.5934  last_time: 1.5787  data_time: 0.0074  last_data_time: 0.0082   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:37:14 d2.utils.events]: \u001b[0m eta: 0:55:02  iter: 17779  total_loss: 0.2299  loss_cls: 0.02974  loss_box_reg: 0.07881  loss_mask: 0.08836  loss_rpn_cls: 0.002172  loss_rpn_loc: 0.03206  total_val_loss: 0.1855  val_loss_cls: 0.02521  val_loss_box_reg: 0.05715  val_loss_mask: 0.08269  val_loss_rpn_cls: 0.0006783  val_loss_rpn_loc: 0.02029    time: 1.5933  last_time: 1.4874  data_time: 0.0078  last_data_time: 0.0065   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:37:56 d2.utils.events]: \u001b[0m eta: 0:54:31  iter: 17799  total_loss: 0.2027  loss_cls: 0.02473  loss_box_reg: 0.06618  loss_mask: 0.08192  loss_rpn_cls: 0.001504  loss_rpn_loc: 0.02529  total_val_loss: 0.2047  val_loss_cls: 0.02786  val_loss_box_reg: 0.07114  val_loss_mask: 0.08377  val_loss_rpn_cls: 0.000755  val_loss_rpn_loc: 0.02405    time: 1.5931  last_time: 1.4403  data_time: 0.0071  last_data_time: 0.0069   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:38:38 d2.utils.events]: \u001b[0m eta: 0:54:04  iter: 17819  total_loss: 0.2223  loss_cls: 0.032  loss_box_reg: 0.06968  loss_mask: 0.08365  loss_rpn_cls: 0.001361  loss_rpn_loc: 0.02522  total_val_loss: 0.2017  val_loss_cls: 0.0271  val_loss_box_reg: 0.06644  val_loss_mask: 0.08508  val_loss_rpn_cls: 0.0009378  val_loss_rpn_loc: 0.02524    time: 1.5930  last_time: 1.5721  data_time: 0.0075  last_data_time: 0.0056   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:39:21 d2.utils.events]: \u001b[0m eta: 0:53:32  iter: 17839  total_loss: 0.2023  loss_cls: 0.0276  loss_box_reg: 0.06575  loss_mask: 0.07891  loss_rpn_cls: 0.001921  loss_rpn_loc: 0.02487  total_val_loss: 0.224  val_loss_cls: 0.029  val_loss_box_reg: 0.07566  val_loss_mask: 0.08855  val_loss_rpn_cls: 0.002318  val_loss_rpn_loc: 0.02333    time: 1.5929  last_time: 1.6008  data_time: 0.0073  last_data_time: 0.0068   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:40:04 d2.utils.events]: \u001b[0m eta: 0:53:02  iter: 17859  total_loss: 0.2087  loss_cls: 0.02802  loss_box_reg: 0.06799  loss_mask: 0.07666  loss_rpn_cls: 0.001955  loss_rpn_loc: 0.0275  total_val_loss: 0.1998  val_loss_cls: 0.02838  val_loss_box_reg: 0.06353  val_loss_mask: 0.0855  val_loss_rpn_cls: 0.0005945  val_loss_rpn_loc: 0.02161    time: 1.5928  last_time: 1.4807  data_time: 0.0074  last_data_time: 0.0081   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:40:46 d2.utils.events]: \u001b[0m eta: 0:52:35  iter: 17879  total_loss: 0.2118  loss_cls: 0.02802  loss_box_reg: 0.07381  loss_mask: 0.08059  loss_rpn_cls: 0.00196  loss_rpn_loc: 0.02691  total_val_loss: 0.1967  val_loss_cls: 0.03032  val_loss_box_reg: 0.06289  val_loss_mask: 0.08135  val_loss_rpn_cls: 0.001251  val_loss_rpn_loc: 0.02294    time: 1.5927  last_time: 1.5438  data_time: 0.0079  last_data_time: 0.0074   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:41:29 d2.utils.events]: \u001b[0m eta: 0:52:06  iter: 17899  total_loss: 0.21  loss_cls: 0.02625  loss_box_reg: 0.07506  loss_mask: 0.07721  loss_rpn_cls: 0.00258  loss_rpn_loc: 0.02732  total_val_loss: 0.1989  val_loss_cls: 0.02648  val_loss_box_reg: 0.06462  val_loss_mask: 0.08508  val_loss_rpn_cls: 0.0008592  val_loss_rpn_loc: 0.02333    time: 1.5926  last_time: 1.3671  data_time: 0.0073  last_data_time: 0.0056   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:42:12 d2.utils.events]: \u001b[0m eta: 0:51:38  iter: 17919  total_loss: 0.2274  loss_cls: 0.03389  loss_box_reg: 0.0721  loss_mask: 0.07842  loss_rpn_cls: 0.001541  loss_rpn_loc: 0.02745  total_val_loss: 0.2069  val_loss_cls: 0.02874  val_loss_box_reg: 0.067  val_loss_mask: 0.08475  val_loss_rpn_cls: 0.0008844  val_loss_rpn_loc: 0.02304    time: 1.5925  last_time: 1.4445  data_time: 0.0077  last_data_time: 0.0078   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:42:54 d2.utils.events]: \u001b[0m eta: 0:51:08  iter: 17939  total_loss: 0.205  loss_cls: 0.02863  loss_box_reg: 0.06795  loss_mask: 0.07431  loss_rpn_cls: 0.001659  loss_rpn_loc: 0.02627  total_val_loss: 0.2051  val_loss_cls: 0.02653  val_loss_box_reg: 0.06732  val_loss_mask: 0.08603  val_loss_rpn_cls: 0.0008986  val_loss_rpn_loc: 0.02062    time: 1.5924  last_time: 1.2323  data_time: 0.0078  last_data_time: 0.0063   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:43:36 d2.utils.events]: \u001b[0m eta: 0:50:36  iter: 17959  total_loss: 0.2112  loss_cls: 0.02991  loss_box_reg: 0.07215  loss_mask: 0.07571  loss_rpn_cls: 0.002235  loss_rpn_loc: 0.02657  total_val_loss: 0.1912  val_loss_cls: 0.02929  val_loss_box_reg: 0.06352  val_loss_mask: 0.07743  val_loss_rpn_cls: 0.0006061  val_loss_rpn_loc: 0.0221    time: 1.5922  last_time: 1.4647  data_time: 0.0073  last_data_time: 0.0067   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:44:19 d2.utils.events]: \u001b[0m eta: 0:50:06  iter: 17979  total_loss: 0.2024  loss_cls: 0.02633  loss_box_reg: 0.05967  loss_mask: 0.08348  loss_rpn_cls: 0.001732  loss_rpn_loc: 0.0248  total_val_loss: 0.224  val_loss_cls: 0.03132  val_loss_box_reg: 0.07238  val_loss_mask: 0.0885  val_loss_rpn_cls: 0.001085  val_loss_rpn_loc: 0.02461    time: 1.5921  last_time: 1.5694  data_time: 0.0076  last_data_time: 0.0085   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:45:05 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\testing_images\\0_SideLane_addedversion_Testing_COCO.json\n",
      "\u001b[32m[09/27 01:45:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/27 01:45:05 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/27 01:45:05 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/27 01:45:05 d2.data.common]: \u001b[0mSerialized dataset takes 6.03 MiB\n",
      "\u001b[32m[09/27 01:45:05 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[09/27 01:45:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 566 batches\n",
      "\u001b[32m[09/27 01:45:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/566. Dataloading: 0.0003 s/iter. Inference: 0.0694 s/iter. Eval: 0.0067 s/iter. Total: 0.0764 s/iter. ETA=0:00:42\n",
      "\u001b[32m[09/27 01:45:14 d2.evaluation.evaluator]: \u001b[0mInference done 80/566. Dataloading: 0.0006 s/iter. Inference: 0.0694 s/iter. Eval: 0.0028 s/iter. Total: 0.0728 s/iter. ETA=0:00:35\n",
      "\u001b[32m[09/27 01:45:19 d2.evaluation.evaluator]: \u001b[0mInference done 147/566. Dataloading: 0.0006 s/iter. Inference: 0.0695 s/iter. Eval: 0.0038 s/iter. Total: 0.0739 s/iter. ETA=0:00:30\n",
      "\u001b[32m[09/27 01:45:24 d2.evaluation.evaluator]: \u001b[0mInference done 213/566. Dataloading: 0.0006 s/iter. Inference: 0.0702 s/iter. Eval: 0.0037 s/iter. Total: 0.0745 s/iter. ETA=0:00:26\n",
      "\u001b[32m[09/27 01:45:29 d2.evaluation.evaluator]: \u001b[0mInference done 280/566. Dataloading: 0.0006 s/iter. Inference: 0.0704 s/iter. Eval: 0.0037 s/iter. Total: 0.0747 s/iter. ETA=0:00:21\n",
      "\u001b[32m[09/27 01:45:34 d2.evaluation.evaluator]: \u001b[0mInference done 351/566. Dataloading: 0.0006 s/iter. Inference: 0.0701 s/iter. Eval: 0.0033 s/iter. Total: 0.0740 s/iter. ETA=0:00:15\n",
      "\u001b[32m[09/27 01:45:39 d2.evaluation.evaluator]: \u001b[0mInference done 420/566. Dataloading: 0.0006 s/iter. Inference: 0.0703 s/iter. Eval: 0.0030 s/iter. Total: 0.0738 s/iter. ETA=0:00:10\n",
      "\u001b[32m[09/27 01:45:44 d2.evaluation.evaluator]: \u001b[0mInference done 483/566. Dataloading: 0.0006 s/iter. Inference: 0.0706 s/iter. Eval: 0.0034 s/iter. Total: 0.0747 s/iter. ETA=0:00:06\n",
      "\u001b[32m[09/27 01:45:49 d2.evaluation.evaluator]: \u001b[0mInference done 547/566. Dataloading: 0.0006 s/iter. Inference: 0.0711 s/iter. Eval: 0.0034 s/iter. Total: 0.0751 s/iter. ETA=0:00:01\n",
      "\u001b[32m[09/27 01:45:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:42.610371 (0.075954 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/27 01:45:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.071160 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/27 01:45:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/27 01:45:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\coco_instances_results.json\n",
      "\u001b[32m[09/27 01:45:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.22s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.934\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.930\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.937\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.938\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.952\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.942\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.958\n",
      "\u001b[32m[09/27 01:45:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 93.385 | 99.008 | 98.998 |  nan  | 92.954 | 93.689 |\n",
      "\u001b[32m[09/27 01:45:51 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/27 01:45:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 93.385 | background | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.41s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.860\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.828\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.882\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.881\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.894\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.865\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.913\n",
      "\u001b[32m[09/27 01:45:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 86.025 | 99.008 | 98.954 |  nan  | 82.775 | 88.224 |\n",
      "\u001b[32m[09/27 01:45:52 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/27 01:45:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 86.025 | background | nan  |\n",
      "\u001b[32m[09/27 01:45:52 d2.engine.defaults]: \u001b[0mEvaluation results for test_data in csv format:\n",
      "\u001b[32m[09/27 01:45:52 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/27 01:45:52 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/27 01:45:52 d2.evaluation.testing]: \u001b[0mcopypaste: 93.3852,99.0080,98.9976,nan,92.9542,93.6889\n",
      "\u001b[32m[09/27 01:45:52 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/27 01:45:52 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/27 01:45:52 d2.evaluation.testing]: \u001b[0mcopypaste: 86.0254,99.0080,98.9537,nan,82.7749,88.2235\n",
      "\u001b[32m[09/27 01:45:52 d2.utils.events]: \u001b[0m eta: 0:49:36  iter: 17999  total_loss: 0.202  loss_cls: 0.02862  loss_box_reg: 0.06978  loss_mask: 0.08343  loss_rpn_cls: 0.001568  loss_rpn_loc: 0.0284  total_val_loss: 0.1927  val_loss_cls: 0.02754  val_loss_box_reg: 0.06069  val_loss_mask: 0.08826  val_loss_rpn_cls: 0.0006262  val_loss_rpn_loc: 0.02332    time: 1.5920  last_time: 1.5070  data_time: 0.0074  last_data_time: 0.0077   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:46:35 d2.utils.events]: \u001b[0m eta: 0:49:09  iter: 18019  total_loss: 0.206  loss_cls: 0.02577  loss_box_reg: 0.06972  loss_mask: 0.075  loss_rpn_cls: 0.001207  loss_rpn_loc: 0.02755  total_val_loss: 0.1989  val_loss_cls: 0.0252  val_loss_box_reg: 0.06406  val_loss_mask: 0.08094  val_loss_rpn_cls: 0.0007304  val_loss_rpn_loc: 0.02298    time: 1.5919  last_time: 1.5087  data_time: 0.0077  last_data_time: 0.0058   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:47:17 d2.utils.events]: \u001b[0m eta: 0:48:39  iter: 18039  total_loss: 0.197  loss_cls: 0.02565  loss_box_reg: 0.06592  loss_mask: 0.08004  loss_rpn_cls: 0.002199  loss_rpn_loc: 0.02597  total_val_loss: 0.1913  val_loss_cls: 0.02674  val_loss_box_reg: 0.05894  val_loss_mask: 0.08401  val_loss_rpn_cls: 0.001234  val_loss_rpn_loc: 0.0211    time: 1.5918  last_time: 1.4656  data_time: 0.0077  last_data_time: 0.0073   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:48:00 d2.utils.events]: \u001b[0m eta: 0:48:10  iter: 18059  total_loss: 0.1998  loss_cls: 0.02468  loss_box_reg: 0.0614  loss_mask: 0.07707  loss_rpn_cls: 0.001508  loss_rpn_loc: 0.02794  total_val_loss: 0.206  val_loss_cls: 0.02958  val_loss_box_reg: 0.0669  val_loss_mask: 0.0812  val_loss_rpn_cls: 0.0008302  val_loss_rpn_loc: 0.0245    time: 1.5917  last_time: 1.5209  data_time: 0.0076  last_data_time: 0.0065   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:48:43 d2.utils.events]: \u001b[0m eta: 0:47:41  iter: 18079  total_loss: 0.2099  loss_cls: 0.02819  loss_box_reg: 0.07209  loss_mask: 0.0822  loss_rpn_cls: 0.002447  loss_rpn_loc: 0.0308  total_val_loss: 0.201  val_loss_cls: 0.0304  val_loss_box_reg: 0.06765  val_loss_mask: 0.08751  val_loss_rpn_cls: 0.0007743  val_loss_rpn_loc: 0.02295    time: 1.5916  last_time: 1.5001  data_time: 0.0081  last_data_time: 0.0124   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:49:26 d2.utils.events]: \u001b[0m eta: 0:47:14  iter: 18099  total_loss: 0.2264  loss_cls: 0.03007  loss_box_reg: 0.07375  loss_mask: 0.07722  loss_rpn_cls: 0.0017  loss_rpn_loc: 0.02895  total_val_loss: 0.1938  val_loss_cls: 0.0221  val_loss_box_reg: 0.06318  val_loss_mask: 0.07531  val_loss_rpn_cls: 0.001158  val_loss_rpn_loc: 0.02308    time: 1.5915  last_time: 1.5289  data_time: 0.0072  last_data_time: 0.0074   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:50:09 d2.utils.events]: \u001b[0m eta: 0:46:45  iter: 18119  total_loss: 0.2221  loss_cls: 0.03183  loss_box_reg: 0.07912  loss_mask: 0.07657  loss_rpn_cls: 0.001561  loss_rpn_loc: 0.03064  total_val_loss: 0.1918  val_loss_cls: 0.02669  val_loss_box_reg: 0.06302  val_loss_mask: 0.0843  val_loss_rpn_cls: 0.0007808  val_loss_rpn_loc: 0.02091    time: 1.5914  last_time: 1.3925  data_time: 0.0082  last_data_time: 0.0079   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:50:51 d2.utils.events]: \u001b[0m eta: 0:46:14  iter: 18139  total_loss: 0.183  loss_cls: 0.02559  loss_box_reg: 0.06031  loss_mask: 0.07658  loss_rpn_cls: 0.001698  loss_rpn_loc: 0.02694  total_val_loss: 0.2126  val_loss_cls: 0.03145  val_loss_box_reg: 0.06638  val_loss_mask: 0.08388  val_loss_rpn_cls: 0.001134  val_loss_rpn_loc: 0.0234    time: 1.5913  last_time: 1.4791  data_time: 0.0077  last_data_time: 0.0051   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:51:34 d2.utils.events]: \u001b[0m eta: 0:45:44  iter: 18159  total_loss: 0.2223  loss_cls: 0.0287  loss_box_reg: 0.07738  loss_mask: 0.08056  loss_rpn_cls: 0.001885  loss_rpn_loc: 0.03213  total_val_loss: 0.1921  val_loss_cls: 0.0248  val_loss_box_reg: 0.06237  val_loss_mask: 0.08437  val_loss_rpn_cls: 0.00126  val_loss_rpn_loc: 0.02198    time: 1.5912  last_time: 1.4718  data_time: 0.0073  last_data_time: 0.0065   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:52:17 d2.utils.events]: \u001b[0m eta: 0:45:15  iter: 18179  total_loss: 0.2036  loss_cls: 0.0257  loss_box_reg: 0.06401  loss_mask: 0.08672  loss_rpn_cls: 0.001964  loss_rpn_loc: 0.02566  total_val_loss: 0.2021  val_loss_cls: 0.03015  val_loss_box_reg: 0.06351  val_loss_mask: 0.08355  val_loss_rpn_cls: 0.000763  val_loss_rpn_loc: 0.02262    time: 1.5911  last_time: 1.4380  data_time: 0.0071  last_data_time: 0.0066   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:52:59 d2.utils.events]: \u001b[0m eta: 0:44:44  iter: 18199  total_loss: 0.2083  loss_cls: 0.02897  loss_box_reg: 0.06867  loss_mask: 0.08079  loss_rpn_cls: 0.001656  loss_rpn_loc: 0.0254  total_val_loss: 0.2057  val_loss_cls: 0.02708  val_loss_box_reg: 0.06236  val_loss_mask: 0.07893  val_loss_rpn_cls: 0.0009708  val_loss_rpn_loc: 0.02315    time: 1.5910  last_time: 1.5386  data_time: 0.0079  last_data_time: 0.0066   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:53:42 d2.utils.events]: \u001b[0m eta: 0:44:14  iter: 18219  total_loss: 0.2077  loss_cls: 0.02803  loss_box_reg: 0.07541  loss_mask: 0.07685  loss_rpn_cls: 0.002077  loss_rpn_loc: 0.02854  total_val_loss: 0.2133  val_loss_cls: 0.02998  val_loss_box_reg: 0.06797  val_loss_mask: 0.0824  val_loss_rpn_cls: 0.001471  val_loss_rpn_loc: 0.02357    time: 1.5909  last_time: 1.4631  data_time: 0.0074  last_data_time: 0.0055   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:54:24 d2.utils.events]: \u001b[0m eta: 0:43:44  iter: 18239  total_loss: 0.2074  loss_cls: 0.02758  loss_box_reg: 0.06788  loss_mask: 0.08336  loss_rpn_cls: 0.00171  loss_rpn_loc: 0.02432  total_val_loss: 0.2009  val_loss_cls: 0.02751  val_loss_box_reg: 0.06223  val_loss_mask: 0.08902  val_loss_rpn_cls: 0.0008832  val_loss_rpn_loc: 0.02299    time: 1.5907  last_time: 1.4938  data_time: 0.0078  last_data_time: 0.0093   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:55:07 d2.utils.events]: \u001b[0m eta: 0:43:15  iter: 18259  total_loss: 0.2008  loss_cls: 0.02583  loss_box_reg: 0.06676  loss_mask: 0.07578  loss_rpn_cls: 0.001482  loss_rpn_loc: 0.02837  total_val_loss: 0.1973  val_loss_cls: 0.02657  val_loss_box_reg: 0.06039  val_loss_mask: 0.08384  val_loss_rpn_cls: 0.001015  val_loss_rpn_loc: 0.02098    time: 1.5907  last_time: 1.4183  data_time: 0.0075  last_data_time: 0.0083   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:55:50 d2.utils.events]: \u001b[0m eta: 0:42:45  iter: 18279  total_loss: 0.1979  loss_cls: 0.02571  loss_box_reg: 0.06203  loss_mask: 0.08282  loss_rpn_cls: 0.001489  loss_rpn_loc: 0.02608  total_val_loss: 0.1966  val_loss_cls: 0.02714  val_loss_box_reg: 0.06062  val_loss_mask: 0.08254  val_loss_rpn_cls: 0.0007453  val_loss_rpn_loc: 0.01974    time: 1.5906  last_time: 1.5141  data_time: 0.0081  last_data_time: 0.0074   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:56:32 d2.utils.events]: \u001b[0m eta: 0:42:14  iter: 18299  total_loss: 0.2089  loss_cls: 0.02585  loss_box_reg: 0.062  loss_mask: 0.07947  loss_rpn_cls: 0.002393  loss_rpn_loc: 0.02855  total_val_loss: 0.2094  val_loss_cls: 0.03171  val_loss_box_reg: 0.07161  val_loss_mask: 0.08414  val_loss_rpn_cls: 0.0009681  val_loss_rpn_loc: 0.02511    time: 1.5904  last_time: 1.4983  data_time: 0.0079  last_data_time: 0.0061   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:57:15 d2.utils.events]: \u001b[0m eta: 0:41:44  iter: 18319  total_loss: 0.2065  loss_cls: 0.02801  loss_box_reg: 0.06632  loss_mask: 0.07948  loss_rpn_cls: 0.001714  loss_rpn_loc: 0.02878  total_val_loss: 0.2066  val_loss_cls: 0.02927  val_loss_box_reg: 0.0688  val_loss_mask: 0.08388  val_loss_rpn_cls: 0.0009306  val_loss_rpn_loc: 0.02304    time: 1.5904  last_time: 1.5178  data_time: 0.0076  last_data_time: 0.0092   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:57:57 d2.utils.events]: \u001b[0m eta: 0:41:15  iter: 18339  total_loss: 0.2074  loss_cls: 0.02848  loss_box_reg: 0.06787  loss_mask: 0.08441  loss_rpn_cls: 0.001768  loss_rpn_loc: 0.02334  total_val_loss: 0.2214  val_loss_cls: 0.03094  val_loss_box_reg: 0.0641  val_loss_mask: 0.0845  val_loss_rpn_cls: 0.001261  val_loss_rpn_loc: 0.0224    time: 1.5902  last_time: 1.4459  data_time: 0.0079  last_data_time: 0.0081   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:58:39 d2.utils.events]: \u001b[0m eta: 0:40:43  iter: 18359  total_loss: 0.2039  loss_cls: 0.02849  loss_box_reg: 0.06005  loss_mask: 0.07532  loss_rpn_cls: 0.002563  loss_rpn_loc: 0.02549  total_val_loss: 0.2017  val_loss_cls: 0.02739  val_loss_box_reg: 0.06569  val_loss_mask: 0.08264  val_loss_rpn_cls: 0.00133  val_loss_rpn_loc: 0.02085    time: 1.5901  last_time: 1.3880  data_time: 0.0074  last_data_time: 0.0075   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 01:59:22 d2.utils.events]: \u001b[0m eta: 0:40:13  iter: 18379  total_loss: 0.2125  loss_cls: 0.03084  loss_box_reg: 0.06989  loss_mask: 0.07622  loss_rpn_cls: 0.001974  loss_rpn_loc: 0.02828  total_val_loss: 0.2031  val_loss_cls: 0.02666  val_loss_box_reg: 0.06222  val_loss_mask: 0.08627  val_loss_rpn_cls: 0.0007696  val_loss_rpn_loc: 0.02124    time: 1.5900  last_time: 1.3760  data_time: 0.0078  last_data_time: 0.0066   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:00:04 d2.utils.events]: \u001b[0m eta: 0:39:42  iter: 18399  total_loss: 0.1956  loss_cls: 0.02479  loss_box_reg: 0.06184  loss_mask: 0.08303  loss_rpn_cls: 0.001182  loss_rpn_loc: 0.02232  total_val_loss: 0.2067  val_loss_cls: 0.02825  val_loss_box_reg: 0.06598  val_loss_mask: 0.08065  val_loss_rpn_cls: 0.0007782  val_loss_rpn_loc: 0.02283    time: 1.5899  last_time: 1.5223  data_time: 0.0081  last_data_time: 0.0096   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:00:46 d2.utils.events]: \u001b[0m eta: 0:39:13  iter: 18419  total_loss: 0.1872  loss_cls: 0.02341  loss_box_reg: 0.06205  loss_mask: 0.07705  loss_rpn_cls: 0.001532  loss_rpn_loc: 0.02422  total_val_loss: 0.184  val_loss_cls: 0.02349  val_loss_box_reg: 0.05925  val_loss_mask: 0.07566  val_loss_rpn_cls: 0.0007614  val_loss_rpn_loc: 0.02081    time: 1.5898  last_time: 1.5697  data_time: 0.0074  last_data_time: 0.0088   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:01:29 d2.utils.events]: \u001b[0m eta: 0:38:43  iter: 18439  total_loss: 0.2122  loss_cls: 0.03033  loss_box_reg: 0.07144  loss_mask: 0.07578  loss_rpn_cls: 0.002187  loss_rpn_loc: 0.02854  total_val_loss: 0.1957  val_loss_cls: 0.02698  val_loss_box_reg: 0.06397  val_loss_mask: 0.08576  val_loss_rpn_cls: 0.001154  val_loss_rpn_loc: 0.02105    time: 1.5897  last_time: 1.5280  data_time: 0.0074  last_data_time: 0.0070   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:02:12 d2.utils.events]: \u001b[0m eta: 0:38:14  iter: 18459  total_loss: 0.1931  loss_cls: 0.02541  loss_box_reg: 0.05902  loss_mask: 0.0781  loss_rpn_cls: 0.001316  loss_rpn_loc: 0.02509  total_val_loss: 0.198  val_loss_cls: 0.02488  val_loss_box_reg: 0.06103  val_loss_mask: 0.08165  val_loss_rpn_cls: 0.0009572  val_loss_rpn_loc: 0.02243    time: 1.5896  last_time: 1.5771  data_time: 0.0075  last_data_time: 0.0061   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:02:54 d2.utils.events]: \u001b[0m eta: 0:37:44  iter: 18479  total_loss: 0.2026  loss_cls: 0.02625  loss_box_reg: 0.06486  loss_mask: 0.07661  loss_rpn_cls: 0.001621  loss_rpn_loc: 0.02623  total_val_loss: 0.2201  val_loss_cls: 0.02923  val_loss_box_reg: 0.07041  val_loss_mask: 0.08654  val_loss_rpn_cls: 0.001052  val_loss_rpn_loc: 0.02466    time: 1.5894  last_time: 1.4902  data_time: 0.0074  last_data_time: 0.0076   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:03:37 d2.utils.events]: \u001b[0m eta: 0:37:14  iter: 18499  total_loss: 0.2208  loss_cls: 0.03075  loss_box_reg: 0.06983  loss_mask: 0.07984  loss_rpn_cls: 0.002182  loss_rpn_loc: 0.02876  total_val_loss: 0.2178  val_loss_cls: 0.03034  val_loss_box_reg: 0.07078  val_loss_mask: 0.08707  val_loss_rpn_cls: 0.0007746  val_loss_rpn_loc: 0.02304    time: 1.5893  last_time: 1.5926  data_time: 0.0074  last_data_time: 0.0071   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:04:19 d2.utils.events]: \u001b[0m eta: 0:36:45  iter: 18519  total_loss: 0.1984  loss_cls: 0.02621  loss_box_reg: 0.06273  loss_mask: 0.08261  loss_rpn_cls: 0.001837  loss_rpn_loc: 0.02926  total_val_loss: 0.1836  val_loss_cls: 0.02636  val_loss_box_reg: 0.05818  val_loss_mask: 0.08423  val_loss_rpn_cls: 0.0005965  val_loss_rpn_loc: 0.02013    time: 1.5892  last_time: 1.4627  data_time: 0.0077  last_data_time: 0.0079   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:05:02 d2.utils.events]: \u001b[0m eta: 0:36:16  iter: 18539  total_loss: 0.221  loss_cls: 0.03104  loss_box_reg: 0.07045  loss_mask: 0.07284  loss_rpn_cls: 0.001473  loss_rpn_loc: 0.03558  total_val_loss: 0.2142  val_loss_cls: 0.03042  val_loss_box_reg: 0.07037  val_loss_mask: 0.08555  val_loss_rpn_cls: 0.001103  val_loss_rpn_loc: 0.0245    time: 1.5891  last_time: 1.5363  data_time: 0.0075  last_data_time: 0.0106   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:05:44 d2.utils.events]: \u001b[0m eta: 0:35:47  iter: 18559  total_loss: 0.2001  loss_cls: 0.02462  loss_box_reg: 0.06529  loss_mask: 0.08145  loss_rpn_cls: 0.002079  loss_rpn_loc: 0.02746  total_val_loss: 0.1954  val_loss_cls: 0.0263  val_loss_box_reg: 0.06436  val_loss_mask: 0.08181  val_loss_rpn_cls: 0.0009269  val_loss_rpn_loc: 0.02191    time: 1.5890  last_time: 1.4221  data_time: 0.0075  last_data_time: 0.0074   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:06:27 d2.utils.events]: \u001b[0m eta: 0:35:17  iter: 18579  total_loss: 0.2179  loss_cls: 0.03001  loss_box_reg: 0.07092  loss_mask: 0.08346  loss_rpn_cls: 0.001928  loss_rpn_loc: 0.02785  total_val_loss: 0.1986  val_loss_cls: 0.02576  val_loss_box_reg: 0.06538  val_loss_mask: 0.08196  val_loss_rpn_cls: 0.000826  val_loss_rpn_loc: 0.02208    time: 1.5889  last_time: 1.5439  data_time: 0.0082  last_data_time: 0.0096   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:07:10 d2.utils.events]: \u001b[0m eta: 0:34:47  iter: 18599  total_loss: 0.2089  loss_cls: 0.02867  loss_box_reg: 0.07111  loss_mask: 0.08134  loss_rpn_cls: 0.001792  loss_rpn_loc: 0.02642  total_val_loss: 0.204  val_loss_cls: 0.02932  val_loss_box_reg: 0.06472  val_loss_mask: 0.0847  val_loss_rpn_cls: 0.001157  val_loss_rpn_loc: 0.0219    time: 1.5888  last_time: 1.3906  data_time: 0.0079  last_data_time: 0.0074   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:07:52 d2.utils.events]: \u001b[0m eta: 0:34:17  iter: 18619  total_loss: 0.2005  loss_cls: 0.02504  loss_box_reg: 0.06668  loss_mask: 0.0764  loss_rpn_cls: 0.001761  loss_rpn_loc: 0.02534  total_val_loss: 0.186  val_loss_cls: 0.02503  val_loss_box_reg: 0.06063  val_loss_mask: 0.08052  val_loss_rpn_cls: 0.0004777  val_loss_rpn_loc: 0.02032    time: 1.5887  last_time: 1.5882  data_time: 0.0077  last_data_time: 0.0078   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:08:35 d2.utils.events]: \u001b[0m eta: 0:33:48  iter: 18639  total_loss: 0.2223  loss_cls: 0.02798  loss_box_reg: 0.07602  loss_mask: 0.07836  loss_rpn_cls: 0.003026  loss_rpn_loc: 0.03128  total_val_loss: 0.2035  val_loss_cls: 0.03075  val_loss_box_reg: 0.06946  val_loss_mask: 0.08308  val_loss_rpn_cls: 0.00112  val_loss_rpn_loc: 0.02326    time: 1.5886  last_time: 1.5031  data_time: 0.0083  last_data_time: 0.0075   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:09:18 d2.utils.events]: \u001b[0m eta: 0:33:18  iter: 18659  total_loss: 0.2055  loss_cls: 0.0278  loss_box_reg: 0.06874  loss_mask: 0.0806  loss_rpn_cls: 0.001768  loss_rpn_loc: 0.02484  total_val_loss: 0.2052  val_loss_cls: 0.02599  val_loss_box_reg: 0.06647  val_loss_mask: 0.08536  val_loss_rpn_cls: 0.001402  val_loss_rpn_loc: 0.02274    time: 1.5885  last_time: 1.4313  data_time: 0.0078  last_data_time: 0.0084   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:10:00 d2.utils.events]: \u001b[0m eta: 0:32:45  iter: 18679  total_loss: 0.2068  loss_cls: 0.02712  loss_box_reg: 0.07378  loss_mask: 0.08133  loss_rpn_cls: 0.001688  loss_rpn_loc: 0.02652  total_val_loss: 0.1824  val_loss_cls: 0.02271  val_loss_box_reg: 0.05522  val_loss_mask: 0.08209  val_loss_rpn_cls: 0.0007754  val_loss_rpn_loc: 0.02057    time: 1.5884  last_time: 1.4766  data_time: 0.0077  last_data_time: 0.0066   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:10:42 d2.utils.events]: \u001b[0m eta: 0:32:15  iter: 18699  total_loss: 0.1923  loss_cls: 0.02527  loss_box_reg: 0.06258  loss_mask: 0.07652  loss_rpn_cls: 0.001732  loss_rpn_loc: 0.02585  total_val_loss: 0.1865  val_loss_cls: 0.02655  val_loss_box_reg: 0.05514  val_loss_mask: 0.08289  val_loss_rpn_cls: 0.0008526  val_loss_rpn_loc: 0.02084    time: 1.5883  last_time: 1.3810  data_time: 0.0075  last_data_time: 0.0070   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:11:25 d2.utils.events]: \u001b[0m eta: 0:31:45  iter: 18719  total_loss: 0.2021  loss_cls: 0.02621  loss_box_reg: 0.06544  loss_mask: 0.07402  loss_rpn_cls: 0.001554  loss_rpn_loc: 0.02758  total_val_loss: 0.2096  val_loss_cls: 0.03088  val_loss_box_reg: 0.06523  val_loss_mask: 0.08416  val_loss_rpn_cls: 0.0007705  val_loss_rpn_loc: 0.02353    time: 1.5882  last_time: 1.4066  data_time: 0.0075  last_data_time: 0.0085   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:12:08 d2.utils.events]: \u001b[0m eta: 0:31:17  iter: 18739  total_loss: 0.2291  loss_cls: 0.03103  loss_box_reg: 0.07894  loss_mask: 0.08274  loss_rpn_cls: 0.001483  loss_rpn_loc: 0.02862  total_val_loss: 0.2175  val_loss_cls: 0.03251  val_loss_box_reg: 0.07332  val_loss_mask: 0.08353  val_loss_rpn_cls: 0.001192  val_loss_rpn_loc: 0.02549    time: 1.5881  last_time: 1.3527  data_time: 0.0081  last_data_time: 0.0072   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:12:51 d2.utils.events]: \u001b[0m eta: 0:30:49  iter: 18759  total_loss: 0.2162  loss_cls: 0.02899  loss_box_reg: 0.07088  loss_mask: 0.07934  loss_rpn_cls: 0.00229  loss_rpn_loc: 0.02707  total_val_loss: 0.1957  val_loss_cls: 0.02522  val_loss_box_reg: 0.0625  val_loss_mask: 0.08311  val_loss_rpn_cls: 0.0006682  val_loss_rpn_loc: 0.02225    time: 1.5880  last_time: 1.5688  data_time: 0.0073  last_data_time: 0.0077   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:13:33 d2.utils.events]: \u001b[0m eta: 0:30:19  iter: 18779  total_loss: 0.228  loss_cls: 0.03281  loss_box_reg: 0.07766  loss_mask: 0.08294  loss_rpn_cls: 0.002402  loss_rpn_loc: 0.02798  total_val_loss: 0.2075  val_loss_cls: 0.02833  val_loss_box_reg: 0.0613  val_loss_mask: 0.08686  val_loss_rpn_cls: 0.000918  val_loss_rpn_loc: 0.02212    time: 1.5879  last_time: 1.5410  data_time: 0.0081  last_data_time: 0.0085   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:14:16 d2.utils.events]: \u001b[0m eta: 0:29:49  iter: 18799  total_loss: 0.1983  loss_cls: 0.02668  loss_box_reg: 0.06409  loss_mask: 0.07788  loss_rpn_cls: 0.001743  loss_rpn_loc: 0.02479  total_val_loss: 0.1824  val_loss_cls: 0.02693  val_loss_box_reg: 0.06071  val_loss_mask: 0.08142  val_loss_rpn_cls: 0.0007946  val_loss_rpn_loc: 0.02103    time: 1.5878  last_time: 1.4740  data_time: 0.0073  last_data_time: 0.0064   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:14:59 d2.utils.events]: \u001b[0m eta: 0:29:20  iter: 18819  total_loss: 0.2055  loss_cls: 0.02962  loss_box_reg: 0.06976  loss_mask: 0.07553  loss_rpn_cls: 0.002662  loss_rpn_loc: 0.02785  total_val_loss: 0.2207  val_loss_cls: 0.03356  val_loss_box_reg: 0.07501  val_loss_mask: 0.08399  val_loss_rpn_cls: 0.00135  val_loss_rpn_loc: 0.02533    time: 1.5877  last_time: 1.5895  data_time: 0.0074  last_data_time: 0.0085   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:15:41 d2.utils.events]: \u001b[0m eta: 0:28:50  iter: 18839  total_loss: 0.2002  loss_cls: 0.02779  loss_box_reg: 0.06366  loss_mask: 0.08165  loss_rpn_cls: 0.001031  loss_rpn_loc: 0.02609  total_val_loss: 0.1904  val_loss_cls: 0.02523  val_loss_box_reg: 0.06012  val_loss_mask: 0.08498  val_loss_rpn_cls: 0.0007921  val_loss_rpn_loc: 0.01998    time: 1.5876  last_time: 1.4969  data_time: 0.0075  last_data_time: 0.0077   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:16:24 d2.utils.events]: \u001b[0m eta: 0:28:19  iter: 18859  total_loss: 0.206  loss_cls: 0.02588  loss_box_reg: 0.06855  loss_mask: 0.07511  loss_rpn_cls: 0.001348  loss_rpn_loc: 0.02326  total_val_loss: 0.2089  val_loss_cls: 0.03008  val_loss_box_reg: 0.06308  val_loss_mask: 0.09025  val_loss_rpn_cls: 0.0008729  val_loss_rpn_loc: 0.0228    time: 1.5875  last_time: 1.3784  data_time: 0.0072  last_data_time: 0.0080   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:17:07 d2.utils.events]: \u001b[0m eta: 0:27:49  iter: 18879  total_loss: 0.2088  loss_cls: 0.02602  loss_box_reg: 0.06613  loss_mask: 0.08009  loss_rpn_cls: 0.001867  loss_rpn_loc: 0.02751  total_val_loss: 0.196  val_loss_cls: 0.02632  val_loss_box_reg: 0.06359  val_loss_mask: 0.08188  val_loss_rpn_cls: 0.0008612  val_loss_rpn_loc: 0.02197    time: 1.5874  last_time: 1.4814  data_time: 0.0080  last_data_time: 0.0093   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:17:52 d2.utils.events]: \u001b[0m eta: 0:27:20  iter: 18899  total_loss: 0.2046  loss_cls: 0.02803  loss_box_reg: 0.07122  loss_mask: 0.08277  loss_rpn_cls: 0.001644  loss_rpn_loc: 0.02744  total_val_loss: 0.1938  val_loss_cls: 0.02613  val_loss_box_reg: 0.06001  val_loss_mask: 0.08516  val_loss_rpn_cls: 0.00081  val_loss_rpn_loc: 0.0217    time: 1.5874  last_time: 1.4716  data_time: 0.0084  last_data_time: 0.0122   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:18:35 d2.utils.events]: \u001b[0m eta: 0:26:50  iter: 18919  total_loss: 0.213  loss_cls: 0.03023  loss_box_reg: 0.07393  loss_mask: 0.0812  loss_rpn_cls: 0.002569  loss_rpn_loc: 0.02945  total_val_loss: 0.1955  val_loss_cls: 0.03001  val_loss_box_reg: 0.06728  val_loss_mask: 0.08501  val_loss_rpn_cls: 0.001347  val_loss_rpn_loc: 0.02318    time: 1.5873  last_time: 1.4998  data_time: 0.0079  last_data_time: 0.0078   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:19:17 d2.utils.events]: \u001b[0m eta: 0:26:21  iter: 18939  total_loss: 0.2015  loss_cls: 0.0263  loss_box_reg: 0.0655  loss_mask: 0.07357  loss_rpn_cls: 0.00109  loss_rpn_loc: 0.02581  total_val_loss: 0.2007  val_loss_cls: 0.02627  val_loss_box_reg: 0.06018  val_loss_mask: 0.0807  val_loss_rpn_cls: 0.0009445  val_loss_rpn_loc: 0.02226    time: 1.5872  last_time: 1.5414  data_time: 0.0078  last_data_time: 0.0094   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:20:00 d2.utils.events]: \u001b[0m eta: 0:25:52  iter: 18959  total_loss: 0.2131  loss_cls: 0.02596  loss_box_reg: 0.07142  loss_mask: 0.07637  loss_rpn_cls: 0.002256  loss_rpn_loc: 0.02799  total_val_loss: 0.197  val_loss_cls: 0.02543  val_loss_box_reg: 0.06255  val_loss_mask: 0.08479  val_loss_rpn_cls: 0.0007778  val_loss_rpn_loc: 0.02258    time: 1.5871  last_time: 1.4815  data_time: 0.0085  last_data_time: 0.0099   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:20:42 d2.utils.events]: \u001b[0m eta: 0:25:23  iter: 18979  total_loss: 0.208  loss_cls: 0.02673  loss_box_reg: 0.06798  loss_mask: 0.07764  loss_rpn_cls: 0.001916  loss_rpn_loc: 0.02838  total_val_loss: 0.1982  val_loss_cls: 0.02686  val_loss_box_reg: 0.06632  val_loss_mask: 0.08496  val_loss_rpn_cls: 0.0009634  val_loss_rpn_loc: 0.02241    time: 1.5870  last_time: 1.5150  data_time: 0.0078  last_data_time: 0.0081   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:21:25 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\testing_images\\0_SideLane_addedversion_Testing_COCO.json\n",
      "\u001b[32m[09/27 02:21:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/27 02:21:25 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/27 02:21:25 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/27 02:21:25 d2.data.common]: \u001b[0mSerialized dataset takes 6.03 MiB\n",
      "\u001b[32m[09/27 02:21:25 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[09/27 02:21:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 566 batches\n",
      "\u001b[32m[09/27 02:21:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/566. Dataloading: 0.0004 s/iter. Inference: 0.0693 s/iter. Eval: 0.0063 s/iter. Total: 0.0760 s/iter. ETA=0:00:42\n",
      "\u001b[32m[09/27 02:21:34 d2.evaluation.evaluator]: \u001b[0mInference done 80/566. Dataloading: 0.0006 s/iter. Inference: 0.0699 s/iter. Eval: 0.0027 s/iter. Total: 0.0732 s/iter. ETA=0:00:35\n",
      "\u001b[32m[09/27 02:21:39 d2.evaluation.evaluator]: \u001b[0mInference done 146/566. Dataloading: 0.0006 s/iter. Inference: 0.0702 s/iter. Eval: 0.0036 s/iter. Total: 0.0745 s/iter. ETA=0:00:31\n",
      "\u001b[32m[09/27 02:21:44 d2.evaluation.evaluator]: \u001b[0mInference done 212/566. Dataloading: 0.0006 s/iter. Inference: 0.0710 s/iter. Eval: 0.0036 s/iter. Total: 0.0753 s/iter. ETA=0:00:26\n",
      "\u001b[32m[09/27 02:21:49 d2.evaluation.evaluator]: \u001b[0mInference done 278/566. Dataloading: 0.0006 s/iter. Inference: 0.0713 s/iter. Eval: 0.0035 s/iter. Total: 0.0755 s/iter. ETA=0:00:21\n",
      "\u001b[32m[09/27 02:21:54 d2.evaluation.evaluator]: \u001b[0mInference done 348/566. Dataloading: 0.0006 s/iter. Inference: 0.0709 s/iter. Eval: 0.0032 s/iter. Total: 0.0748 s/iter. ETA=0:00:16\n",
      "\u001b[32m[09/27 02:21:59 d2.evaluation.evaluator]: \u001b[0mInference done 417/566. Dataloading: 0.0006 s/iter. Inference: 0.0709 s/iter. Eval: 0.0029 s/iter. Total: 0.0745 s/iter. ETA=0:00:11\n",
      "\u001b[32m[09/27 02:22:05 d2.evaluation.evaluator]: \u001b[0mInference done 480/566. Dataloading: 0.0006 s/iter. Inference: 0.0712 s/iter. Eval: 0.0033 s/iter. Total: 0.0752 s/iter. ETA=0:00:06\n",
      "\u001b[32m[09/27 02:22:10 d2.evaluation.evaluator]: \u001b[0mInference done 545/566. Dataloading: 0.0006 s/iter. Inference: 0.0716 s/iter. Eval: 0.0033 s/iter. Total: 0.0755 s/iter. ETA=0:00:01\n",
      "\u001b[32m[09/27 02:22:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:42.829314 (0.076345 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/27 02:22:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:40 (0.071564 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/27 02:22:12 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/27 02:22:12 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\coco_instances_results.json\n",
      "\u001b[32m[09/27 02:22:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.24s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.934\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.929\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.937\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.937\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.952\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.941\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.959\n",
      "\u001b[32m[09/27 02:22:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 93.379 | 99.006 | 98.995 |  nan  | 92.856 | 93.749 |\n",
      "\u001b[32m[09/27 02:22:12 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/27 02:22:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 93.379 | background | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.33s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.860\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.828\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.880\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.881\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.894\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.866\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.913\n",
      "\u001b[32m[09/27 02:22:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 86.021 | 99.006 | 98.951 |  nan  | 82.779 | 88.021 |\n",
      "\u001b[32m[09/27 02:22:12 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/27 02:22:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 86.021 | background | nan  |\n",
      "\u001b[32m[09/27 02:22:12 d2.engine.defaults]: \u001b[0mEvaluation results for test_data in csv format:\n",
      "\u001b[32m[09/27 02:22:12 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/27 02:22:12 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/27 02:22:12 d2.evaluation.testing]: \u001b[0mcopypaste: 93.3785,99.0057,98.9951,nan,92.8563,93.7489\n",
      "\u001b[32m[09/27 02:22:12 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/27 02:22:12 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/27 02:22:12 d2.evaluation.testing]: \u001b[0mcopypaste: 86.0207,99.0057,98.9514,nan,82.7791,88.0210\n",
      "\u001b[32m[09/27 02:22:13 d2.utils.events]: \u001b[0m eta: 0:24:53  iter: 18999  total_loss: 0.2146  loss_cls: 0.02936  loss_box_reg: 0.07077  loss_mask: 0.07873  loss_rpn_cls: 0.002295  loss_rpn_loc: 0.0281  total_val_loss: 0.192  val_loss_cls: 0.02274  val_loss_box_reg: 0.05925  val_loss_mask: 0.0808  val_loss_rpn_cls: 0.0008731  val_loss_rpn_loc: 0.0196    time: 1.5869  last_time: 1.5233  data_time: 0.0072  last_data_time: 0.0064   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:22:55 d2.utils.events]: \u001b[0m eta: 0:24:23  iter: 19019  total_loss: 0.2167  loss_cls: 0.02745  loss_box_reg: 0.07105  loss_mask: 0.08257  loss_rpn_cls: 0.00175  loss_rpn_loc: 0.02824  total_val_loss: 0.2092  val_loss_cls: 0.0298  val_loss_box_reg: 0.06566  val_loss_mask: 0.08335  val_loss_rpn_cls: 0.0009828  val_loss_rpn_loc: 0.02294    time: 1.5868  last_time: 1.4050  data_time: 0.0074  last_data_time: 0.0052   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:23:38 d2.utils.events]: \u001b[0m eta: 0:23:53  iter: 19039  total_loss: 0.2186  loss_cls: 0.03098  loss_box_reg: 0.07567  loss_mask: 0.07827  loss_rpn_cls: 0.001933  loss_rpn_loc: 0.02917  total_val_loss: 0.215  val_loss_cls: 0.03039  val_loss_box_reg: 0.07623  val_loss_mask: 0.08862  val_loss_rpn_cls: 0.001076  val_loss_rpn_loc: 0.02537    time: 1.5867  last_time: 1.3794  data_time: 0.0079  last_data_time: 0.0073   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:24:20 d2.utils.events]: \u001b[0m eta: 0:23:23  iter: 19059  total_loss: 0.2096  loss_cls: 0.02676  loss_box_reg: 0.06795  loss_mask: 0.08126  loss_rpn_cls: 0.001812  loss_rpn_loc: 0.02591  total_val_loss: 0.2137  val_loss_cls: 0.02918  val_loss_box_reg: 0.0701  val_loss_mask: 0.086  val_loss_rpn_cls: 0.001163  val_loss_rpn_loc: 0.02281    time: 1.5866  last_time: 1.4872  data_time: 0.0079  last_data_time: 0.0063   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:25:03 d2.utils.events]: \u001b[0m eta: 0:22:52  iter: 19079  total_loss: 0.2139  loss_cls: 0.02511  loss_box_reg: 0.06363  loss_mask: 0.08251  loss_rpn_cls: 0.002275  loss_rpn_loc: 0.02511  total_val_loss: 0.1881  val_loss_cls: 0.02739  val_loss_box_reg: 0.06095  val_loss_mask: 0.07894  val_loss_rpn_cls: 0.0007206  val_loss_rpn_loc: 0.02119    time: 1.5865  last_time: 1.5767  data_time: 0.0073  last_data_time: 0.0069   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:25:46 d2.utils.events]: \u001b[0m eta: 0:22:22  iter: 19099  total_loss: 0.2043  loss_cls: 0.02514  loss_box_reg: 0.06327  loss_mask: 0.07768  loss_rpn_cls: 0.002234  loss_rpn_loc: 0.02843  total_val_loss: 0.1964  val_loss_cls: 0.02568  val_loss_box_reg: 0.06047  val_loss_mask: 0.08249  val_loss_rpn_cls: 0.001192  val_loss_rpn_loc: 0.02159    time: 1.5864  last_time: 1.5087  data_time: 0.0084  last_data_time: 0.0078   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:26:28 d2.utils.events]: \u001b[0m eta: 0:21:50  iter: 19119  total_loss: 0.1925  loss_cls: 0.02483  loss_box_reg: 0.06017  loss_mask: 0.07266  loss_rpn_cls: 0.002086  loss_rpn_loc: 0.02442  total_val_loss: 0.175  val_loss_cls: 0.02289  val_loss_box_reg: 0.05483  val_loss_mask: 0.07724  val_loss_rpn_cls: 0.001007  val_loss_rpn_loc: 0.01996    time: 1.5863  last_time: 1.4218  data_time: 0.0075  last_data_time: 0.0072   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:27:11 d2.utils.events]: \u001b[0m eta: 0:21:22  iter: 19139  total_loss: 0.2016  loss_cls: 0.02493  loss_box_reg: 0.065  loss_mask: 0.07813  loss_rpn_cls: 0.001992  loss_rpn_loc: 0.02683  total_val_loss: 0.2224  val_loss_cls: 0.03166  val_loss_box_reg: 0.07379  val_loss_mask: 0.08239  val_loss_rpn_cls: 0.0008476  val_loss_rpn_loc: 0.02599    time: 1.5862  last_time: 1.5176  data_time: 0.0072  last_data_time: 0.0067   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:27:54 d2.utils.events]: \u001b[0m eta: 0:20:52  iter: 19159  total_loss: 0.2197  loss_cls: 0.02902  loss_box_reg: 0.0764  loss_mask: 0.07826  loss_rpn_cls: 0.001653  loss_rpn_loc: 0.02807  total_val_loss: 0.2071  val_loss_cls: 0.02882  val_loss_box_reg: 0.06763  val_loss_mask: 0.08489  val_loss_rpn_cls: 0.0009823  val_loss_rpn_loc: 0.02146    time: 1.5861  last_time: 1.4854  data_time: 0.0075  last_data_time: 0.0058   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:28:37 d2.utils.events]: \u001b[0m eta: 0:20:23  iter: 19179  total_loss: 0.2351  loss_cls: 0.02908  loss_box_reg: 0.07796  loss_mask: 0.08054  loss_rpn_cls: 0.002903  loss_rpn_loc: 0.02906  total_val_loss: 0.1904  val_loss_cls: 0.02628  val_loss_box_reg: 0.06215  val_loss_mask: 0.08251  val_loss_rpn_cls: 0.001061  val_loss_rpn_loc: 0.02205    time: 1.5860  last_time: 1.4951  data_time: 0.0080  last_data_time: 0.0092   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:29:19 d2.utils.events]: \u001b[0m eta: 0:19:53  iter: 19199  total_loss: 0.2073  loss_cls: 0.02917  loss_box_reg: 0.0659  loss_mask: 0.07918  loss_rpn_cls: 0.001842  loss_rpn_loc: 0.02759  total_val_loss: 0.1916  val_loss_cls: 0.02707  val_loss_box_reg: 0.0602  val_loss_mask: 0.08407  val_loss_rpn_cls: 0.0009038  val_loss_rpn_loc: 0.0223    time: 1.5859  last_time: 1.4590  data_time: 0.0079  last_data_time: 0.0068   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:30:02 d2.utils.events]: \u001b[0m eta: 0:19:23  iter: 19219  total_loss: 0.2176  loss_cls: 0.02795  loss_box_reg: 0.06948  loss_mask: 0.0858  loss_rpn_cls: 0.001493  loss_rpn_loc: 0.02543  total_val_loss: 0.21  val_loss_cls: 0.02805  val_loss_box_reg: 0.06794  val_loss_mask: 0.08172  val_loss_rpn_cls: 0.0006927  val_loss_rpn_loc: 0.02465    time: 1.5858  last_time: 1.5907  data_time: 0.0074  last_data_time: 0.0065   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:30:45 d2.utils.events]: \u001b[0m eta: 0:18:54  iter: 19239  total_loss: 0.1974  loss_cls: 0.02633  loss_box_reg: 0.06527  loss_mask: 0.08019  loss_rpn_cls: 0.001494  loss_rpn_loc: 0.02582  total_val_loss: 0.191  val_loss_cls: 0.0243  val_loss_box_reg: 0.05753  val_loss_mask: 0.07994  val_loss_rpn_cls: 0.001201  val_loss_rpn_loc: 0.01884    time: 1.5857  last_time: 1.4775  data_time: 0.0076  last_data_time: 0.0084   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:31:27 d2.utils.events]: \u001b[0m eta: 0:18:23  iter: 19259  total_loss: 0.1921  loss_cls: 0.02323  loss_box_reg: 0.0615  loss_mask: 0.0813  loss_rpn_cls: 0.0009088  loss_rpn_loc: 0.02657  total_val_loss: 0.1836  val_loss_cls: 0.02639  val_loss_box_reg: 0.05866  val_loss_mask: 0.08378  val_loss_rpn_cls: 0.0008311  val_loss_rpn_loc: 0.02103    time: 1.5856  last_time: 1.4731  data_time: 0.0074  last_data_time: 0.0081   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:32:09 d2.utils.events]: \u001b[0m eta: 0:17:54  iter: 19279  total_loss: 0.2169  loss_cls: 0.02934  loss_box_reg: 0.07043  loss_mask: 0.08608  loss_rpn_cls: 0.001861  loss_rpn_loc: 0.03151  total_val_loss: 0.2041  val_loss_cls: 0.02763  val_loss_box_reg: 0.0685  val_loss_mask: 0.08479  val_loss_rpn_cls: 0.001029  val_loss_rpn_loc: 0.02344    time: 1.5855  last_time: 1.5125  data_time: 0.0073  last_data_time: 0.0067   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:32:52 d2.utils.events]: \u001b[0m eta: 0:17:24  iter: 19299  total_loss: 0.2247  loss_cls: 0.03013  loss_box_reg: 0.08255  loss_mask: 0.07825  loss_rpn_cls: 0.001633  loss_rpn_loc: 0.03494  total_val_loss: 0.1882  val_loss_cls: 0.0263  val_loss_box_reg: 0.06169  val_loss_mask: 0.08339  val_loss_rpn_cls: 0.0009735  val_loss_rpn_loc: 0.02155    time: 1.5854  last_time: 1.4663  data_time: 0.0082  last_data_time: 0.0078   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:33:34 d2.utils.events]: \u001b[0m eta: 0:16:54  iter: 19319  total_loss: 0.196  loss_cls: 0.02332  loss_box_reg: 0.06123  loss_mask: 0.07779  loss_rpn_cls: 0.001412  loss_rpn_loc: 0.02547  total_val_loss: 0.2061  val_loss_cls: 0.02785  val_loss_box_reg: 0.06944  val_loss_mask: 0.08095  val_loss_rpn_cls: 0.0009273  val_loss_rpn_loc: 0.02237    time: 1.5853  last_time: 1.5422  data_time: 0.0071  last_data_time: 0.0068   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:34:17 d2.utils.events]: \u001b[0m eta: 0:16:24  iter: 19339  total_loss: 0.19  loss_cls: 0.02563  loss_box_reg: 0.06473  loss_mask: 0.07956  loss_rpn_cls: 0.001865  loss_rpn_loc: 0.02584  total_val_loss: 0.1997  val_loss_cls: 0.02864  val_loss_box_reg: 0.06445  val_loss_mask: 0.08486  val_loss_rpn_cls: 0.000889  val_loss_rpn_loc: 0.0209    time: 1.5852  last_time: 1.5572  data_time: 0.0069  last_data_time: 0.0093   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:34:59 d2.utils.events]: \u001b[0m eta: 0:15:55  iter: 19359  total_loss: 0.2038  loss_cls: 0.02464  loss_box_reg: 0.06785  loss_mask: 0.07608  loss_rpn_cls: 0.002659  loss_rpn_loc: 0.02684  total_val_loss: 0.198  val_loss_cls: 0.02898  val_loss_box_reg: 0.06357  val_loss_mask: 0.08164  val_loss_rpn_cls: 0.001017  val_loss_rpn_loc: 0.02189    time: 1.5851  last_time: 1.4809  data_time: 0.0077  last_data_time: 0.0060   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:35:42 d2.utils.events]: \u001b[0m eta: 0:15:25  iter: 19379  total_loss: 0.219  loss_cls: 0.03069  loss_box_reg: 0.07408  loss_mask: 0.07769  loss_rpn_cls: 0.001584  loss_rpn_loc: 0.02491  total_val_loss: 0.183  val_loss_cls: 0.0239  val_loss_box_reg: 0.05587  val_loss_mask: 0.08016  val_loss_rpn_cls: 0.0008374  val_loss_rpn_loc: 0.01955    time: 1.5851  last_time: 1.5507  data_time: 0.0074  last_data_time: 0.0079   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:36:25 d2.utils.events]: \u001b[0m eta: 0:14:55  iter: 19399  total_loss: 0.1983  loss_cls: 0.02984  loss_box_reg: 0.0656  loss_mask: 0.07724  loss_rpn_cls: 0.002509  loss_rpn_loc: 0.02658  total_val_loss: 0.2262  val_loss_cls: 0.03201  val_loss_box_reg: 0.07442  val_loss_mask: 0.09193  val_loss_rpn_cls: 0.000888  val_loss_rpn_loc: 0.02349    time: 1.5850  last_time: 1.5603  data_time: 0.0080  last_data_time: 0.0082   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:37:08 d2.utils.events]: \u001b[0m eta: 0:14:26  iter: 19419  total_loss: 0.1938  loss_cls: 0.02372  loss_box_reg: 0.05982  loss_mask: 0.08073  loss_rpn_cls: 0.001461  loss_rpn_loc: 0.02387  total_val_loss: 0.2062  val_loss_cls: 0.02875  val_loss_box_reg: 0.06751  val_loss_mask: 0.08106  val_loss_rpn_cls: 0.0007027  val_loss_rpn_loc: 0.0225    time: 1.5849  last_time: 1.6157  data_time: 0.0078  last_data_time: 0.0098   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:37:50 d2.utils.events]: \u001b[0m eta: 0:13:56  iter: 19439  total_loss: 0.2116  loss_cls: 0.02937  loss_box_reg: 0.07531  loss_mask: 0.07873  loss_rpn_cls: 0.00154  loss_rpn_loc: 0.02688  total_val_loss: 0.1832  val_loss_cls: 0.02354  val_loss_box_reg: 0.0574  val_loss_mask: 0.08341  val_loss_rpn_cls: 0.001141  val_loss_rpn_loc: 0.02021    time: 1.5848  last_time: 1.4271  data_time: 0.0078  last_data_time: 0.0081   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:38:33 d2.utils.events]: \u001b[0m eta: 0:13:26  iter: 19459  total_loss: 0.1997  loss_cls: 0.02628  loss_box_reg: 0.06388  loss_mask: 0.07755  loss_rpn_cls: 0.001435  loss_rpn_loc: 0.02463  total_val_loss: 0.2091  val_loss_cls: 0.02907  val_loss_box_reg: 0.06939  val_loss_mask: 0.0893  val_loss_rpn_cls: 0.001551  val_loss_rpn_loc: 0.02244    time: 1.5847  last_time: 1.4142  data_time: 0.0079  last_data_time: 0.0081   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:39:16 d2.utils.events]: \u001b[0m eta: 0:12:56  iter: 19479  total_loss: 0.2268  loss_cls: 0.03165  loss_box_reg: 0.07986  loss_mask: 0.07789  loss_rpn_cls: 0.001851  loss_rpn_loc: 0.02852  total_val_loss: 0.2071  val_loss_cls: 0.0268  val_loss_box_reg: 0.063  val_loss_mask: 0.08145  val_loss_rpn_cls: 0.001368  val_loss_rpn_loc: 0.02145    time: 1.5846  last_time: 1.4717  data_time: 0.0080  last_data_time: 0.0061   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:39:59 d2.utils.events]: \u001b[0m eta: 0:12:27  iter: 19499  total_loss: 0.2271  loss_cls: 0.03201  loss_box_reg: 0.08196  loss_mask: 0.08274  loss_rpn_cls: 0.002469  loss_rpn_loc: 0.02976  total_val_loss: 0.1943  val_loss_cls: 0.02736  val_loss_box_reg: 0.05924  val_loss_mask: 0.08491  val_loss_rpn_cls: 0.001001  val_loss_rpn_loc: 0.02233    time: 1.5845  last_time: 1.5889  data_time: 0.0076  last_data_time: 0.0074   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:40:41 d2.utils.events]: \u001b[0m eta: 0:11:57  iter: 19519  total_loss: 0.2042  loss_cls: 0.02851  loss_box_reg: 0.06117  loss_mask: 0.08441  loss_rpn_cls: 0.002  loss_rpn_loc: 0.03042  total_val_loss: 0.1935  val_loss_cls: 0.02607  val_loss_box_reg: 0.06502  val_loss_mask: 0.08448  val_loss_rpn_cls: 0.0009136  val_loss_rpn_loc: 0.02054    time: 1.5844  last_time: 1.4130  data_time: 0.0073  last_data_time: 0.0056   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:41:23 d2.utils.events]: \u001b[0m eta: 0:11:27  iter: 19539  total_loss: 0.202  loss_cls: 0.0312  loss_box_reg: 0.06426  loss_mask: 0.07702  loss_rpn_cls: 0.002236  loss_rpn_loc: 0.02902  total_val_loss: 0.1895  val_loss_cls: 0.02551  val_loss_box_reg: 0.06226  val_loss_mask: 0.07885  val_loss_rpn_cls: 0.000462  val_loss_rpn_loc: 0.02145    time: 1.5844  last_time: 1.6763  data_time: 0.0071  last_data_time: 0.0072   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:42:06 d2.utils.events]: \u001b[0m eta: 0:10:57  iter: 19559  total_loss: 0.2308  loss_cls: 0.03122  loss_box_reg: 0.08259  loss_mask: 0.08478  loss_rpn_cls: 0.002365  loss_rpn_loc: 0.02985  total_val_loss: 0.2015  val_loss_cls: 0.02826  val_loss_box_reg: 0.06373  val_loss_mask: 0.08586  val_loss_rpn_cls: 0.0006572  val_loss_rpn_loc: 0.02216    time: 1.5843  last_time: 1.5163  data_time: 0.0076  last_data_time: 0.0082   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:42:48 d2.utils.events]: \u001b[0m eta: 0:10:27  iter: 19579  total_loss: 0.2126  loss_cls: 0.02783  loss_box_reg: 0.075  loss_mask: 0.08042  loss_rpn_cls: 0.001684  loss_rpn_loc: 0.0259  total_val_loss: 0.2086  val_loss_cls: 0.02677  val_loss_box_reg: 0.06656  val_loss_mask: 0.08868  val_loss_rpn_cls: 0.0008506  val_loss_rpn_loc: 0.02158    time: 1.5842  last_time: 1.4757  data_time: 0.0076  last_data_time: 0.0075   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:43:31 d2.utils.events]: \u001b[0m eta: 0:09:57  iter: 19599  total_loss: 0.1932  loss_cls: 0.02564  loss_box_reg: 0.06178  loss_mask: 0.08118  loss_rpn_cls: 0.0015  loss_rpn_loc: 0.025  total_val_loss: 0.2122  val_loss_cls: 0.02783  val_loss_box_reg: 0.07084  val_loss_mask: 0.0819  val_loss_rpn_cls: 0.001514  val_loss_rpn_loc: 0.02485    time: 1.5841  last_time: 1.3848  data_time: 0.0074  last_data_time: 0.0074   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:44:14 d2.utils.events]: \u001b[0m eta: 0:09:28  iter: 19619  total_loss: 0.2221  loss_cls: 0.03343  loss_box_reg: 0.07914  loss_mask: 0.07647  loss_rpn_cls: 0.001074  loss_rpn_loc: 0.0276  total_val_loss: 0.2007  val_loss_cls: 0.02905  val_loss_box_reg: 0.0652  val_loss_mask: 0.08329  val_loss_rpn_cls: 0.001191  val_loss_rpn_loc: 0.02313    time: 1.5840  last_time: 1.5744  data_time: 0.0079  last_data_time: 0.0087   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:44:57 d2.utils.events]: \u001b[0m eta: 0:08:58  iter: 19639  total_loss: 0.1956  loss_cls: 0.0261  loss_box_reg: 0.06278  loss_mask: 0.08108  loss_rpn_cls: 0.002043  loss_rpn_loc: 0.02542  total_val_loss: 0.1994  val_loss_cls: 0.02699  val_loss_box_reg: 0.06118  val_loss_mask: 0.08399  val_loss_rpn_cls: 0.0006804  val_loss_rpn_loc: 0.02117    time: 1.5839  last_time: 1.4573  data_time: 0.0074  last_data_time: 0.0073   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:45:38 d2.utils.events]: \u001b[0m eta: 0:08:28  iter: 19659  total_loss: 0.1963  loss_cls: 0.02528  loss_box_reg: 0.06693  loss_mask: 0.07363  loss_rpn_cls: 0.001727  loss_rpn_loc: 0.02582  total_val_loss: 0.1987  val_loss_cls: 0.02733  val_loss_box_reg: 0.06382  val_loss_mask: 0.08336  val_loss_rpn_cls: 0.001788  val_loss_rpn_loc: 0.02332    time: 1.5838  last_time: 1.4635  data_time: 0.0070  last_data_time: 0.0097   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:46:21 d2.utils.events]: \u001b[0m eta: 0:07:58  iter: 19679  total_loss: 0.2039  loss_cls: 0.02808  loss_box_reg: 0.06757  loss_mask: 0.07856  loss_rpn_cls: 0.002453  loss_rpn_loc: 0.02612  total_val_loss: 0.2169  val_loss_cls: 0.02896  val_loss_box_reg: 0.06745  val_loss_mask: 0.08305  val_loss_rpn_cls: 0.0008396  val_loss_rpn_loc: 0.02438    time: 1.5837  last_time: 1.4562  data_time: 0.0077  last_data_time: 0.0095   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:47:03 d2.utils.events]: \u001b[0m eta: 0:07:28  iter: 19699  total_loss: 0.1982  loss_cls: 0.02737  loss_box_reg: 0.07217  loss_mask: 0.08136  loss_rpn_cls: 0.001147  loss_rpn_loc: 0.0252  total_val_loss: 0.2012  val_loss_cls: 0.02689  val_loss_box_reg: 0.06254  val_loss_mask: 0.08412  val_loss_rpn_cls: 0.0009692  val_loss_rpn_loc: 0.02052    time: 1.5836  last_time: 1.5153  data_time: 0.0081  last_data_time: 0.0094   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:47:46 d2.utils.events]: \u001b[0m eta: 0:06:58  iter: 19719  total_loss: 0.2298  loss_cls: 0.03125  loss_box_reg: 0.07815  loss_mask: 0.0833  loss_rpn_cls: 0.001332  loss_rpn_loc: 0.0291  total_val_loss: 0.1952  val_loss_cls: 0.02686  val_loss_box_reg: 0.06254  val_loss_mask: 0.08604  val_loss_rpn_cls: 0.0006921  val_loss_rpn_loc: 0.02184    time: 1.5836  last_time: 1.5174  data_time: 0.0079  last_data_time: 0.0090   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:48:29 d2.utils.events]: \u001b[0m eta: 0:06:28  iter: 19739  total_loss: 0.1904  loss_cls: 0.02564  loss_box_reg: 0.06297  loss_mask: 0.07547  loss_rpn_cls: 0.001672  loss_rpn_loc: 0.02806  total_val_loss: 0.2048  val_loss_cls: 0.0295  val_loss_box_reg: 0.06278  val_loss_mask: 0.08677  val_loss_rpn_cls: 0.0008936  val_loss_rpn_loc: 0.02144    time: 1.5835  last_time: 1.4894  data_time: 0.0080  last_data_time: 0.0070   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:49:12 d2.utils.events]: \u001b[0m eta: 0:05:58  iter: 19759  total_loss: 0.2207  loss_cls: 0.02793  loss_box_reg: 0.0726  loss_mask: 0.08763  loss_rpn_cls: 0.00255  loss_rpn_loc: 0.02523  total_val_loss: 0.1952  val_loss_cls: 0.02896  val_loss_box_reg: 0.06045  val_loss_mask: 0.08494  val_loss_rpn_cls: 0.001472  val_loss_rpn_loc: 0.02099    time: 1.5834  last_time: 1.5106  data_time: 0.0075  last_data_time: 0.0076   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:49:54 d2.utils.events]: \u001b[0m eta: 0:05:28  iter: 19779  total_loss: 0.2162  loss_cls: 0.02594  loss_box_reg: 0.06071  loss_mask: 0.07614  loss_rpn_cls: 0.002481  loss_rpn_loc: 0.02866  total_val_loss: 0.2047  val_loss_cls: 0.03121  val_loss_box_reg: 0.06663  val_loss_mask: 0.08295  val_loss_rpn_cls: 0.0008374  val_loss_rpn_loc: 0.02371    time: 1.5833  last_time: 1.4195  data_time: 0.0070  last_data_time: 0.0053   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:50:37 d2.utils.events]: \u001b[0m eta: 0:04:59  iter: 19799  total_loss: 0.2119  loss_cls: 0.02401  loss_box_reg: 0.06929  loss_mask: 0.0862  loss_rpn_cls: 0.001254  loss_rpn_loc: 0.02442  total_val_loss: 0.1954  val_loss_cls: 0.02592  val_loss_box_reg: 0.06184  val_loss_mask: 0.08415  val_loss_rpn_cls: 0.0007435  val_loss_rpn_loc: 0.02105    time: 1.5832  last_time: 1.4391  data_time: 0.0077  last_data_time: 0.0083   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:51:19 d2.utils.events]: \u001b[0m eta: 0:04:29  iter: 19819  total_loss: 0.1958  loss_cls: 0.02585  loss_box_reg: 0.06307  loss_mask: 0.07944  loss_rpn_cls: 0.001453  loss_rpn_loc: 0.02258  total_val_loss: 0.1898  val_loss_cls: 0.02523  val_loss_box_reg: 0.06088  val_loss_mask: 0.08618  val_loss_rpn_cls: 0.0008694  val_loss_rpn_loc: 0.0205    time: 1.5831  last_time: 1.5519  data_time: 0.0070  last_data_time: 0.0064   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:52:01 d2.utils.events]: \u001b[0m eta: 0:03:59  iter: 19839  total_loss: 0.2178  loss_cls: 0.02846  loss_box_reg: 0.07291  loss_mask: 0.08652  loss_rpn_cls: 0.002029  loss_rpn_loc: 0.02703  total_val_loss: 0.2001  val_loss_cls: 0.02549  val_loss_box_reg: 0.06367  val_loss_mask: 0.08191  val_loss_rpn_cls: 0.001222  val_loss_rpn_loc: 0.02223    time: 1.5830  last_time: 1.4927  data_time: 0.0072  last_data_time: 0.0070   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:52:44 d2.utils.events]: \u001b[0m eta: 0:03:29  iter: 19859  total_loss: 0.2169  loss_cls: 0.02811  loss_box_reg: 0.06872  loss_mask: 0.07896  loss_rpn_cls: 0.00176  loss_rpn_loc: 0.02946  total_val_loss: 0.2187  val_loss_cls: 0.0326  val_loss_box_reg: 0.07303  val_loss_mask: 0.08402  val_loss_rpn_cls: 0.001045  val_loss_rpn_loc: 0.02573    time: 1.5829  last_time: 1.4341  data_time: 0.0072  last_data_time: 0.0064   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:53:27 d2.utils.events]: \u001b[0m eta: 0:02:59  iter: 19879  total_loss: 0.2013  loss_cls: 0.02763  loss_box_reg: 0.06814  loss_mask: 0.07974  loss_rpn_cls: 0.001581  loss_rpn_loc: 0.02456  total_val_loss: 0.1963  val_loss_cls: 0.02538  val_loss_box_reg: 0.06126  val_loss_mask: 0.08392  val_loss_rpn_cls: 0.0005403  val_loss_rpn_loc: 0.02181    time: 1.5828  last_time: 1.5416  data_time: 0.0066  last_data_time: 0.0061   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:54:09 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 19899  total_loss: 0.2335  loss_cls: 0.03244  loss_box_reg: 0.07971  loss_mask: 0.08074  loss_rpn_cls: 0.001853  loss_rpn_loc: 0.02919  total_val_loss: 0.1885  val_loss_cls: 0.02997  val_loss_box_reg: 0.06212  val_loss_mask: 0.08118  val_loss_rpn_cls: 0.001032  val_loss_rpn_loc: 0.02154    time: 1.5827  last_time: 1.4435  data_time: 0.0067  last_data_time: 0.0077   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:54:52 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 19919  total_loss: 0.194  loss_cls: 0.02558  loss_box_reg: 0.06327  loss_mask: 0.08187  loss_rpn_cls: 0.001534  loss_rpn_loc: 0.02241  total_val_loss: 0.1948  val_loss_cls: 0.02638  val_loss_box_reg: 0.06066  val_loss_mask: 0.08507  val_loss_rpn_cls: 0.0007835  val_loss_rpn_loc: 0.02109    time: 1.5826  last_time: 1.5169  data_time: 0.0077  last_data_time: 0.0109   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:55:34 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 19939  total_loss: 0.1991  loss_cls: 0.02717  loss_box_reg: 0.06772  loss_mask: 0.07478  loss_rpn_cls: 0.001711  loss_rpn_loc: 0.02862  total_val_loss: 0.192  val_loss_cls: 0.02808  val_loss_box_reg: 0.06314  val_loss_mask: 0.07995  val_loss_rpn_cls: 0.0009904  val_loss_rpn_loc: 0.02216    time: 1.5826  last_time: 1.5118  data_time: 0.0073  last_data_time: 0.0072   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:56:17 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 19959  total_loss: 0.2011  loss_cls: 0.0263  loss_box_reg: 0.06492  loss_mask: 0.07813  loss_rpn_cls: 0.001904  loss_rpn_loc: 0.02602  total_val_loss: 0.2051  val_loss_cls: 0.02884  val_loss_box_reg: 0.06684  val_loss_mask: 0.0803  val_loss_rpn_cls: 0.001284  val_loss_rpn_loc: 0.02267    time: 1.5825  last_time: 1.4736  data_time: 0.0071  last_data_time: 0.0071   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:57:01 d2.utils.events]: \u001b[0m eta: 0:00:29  iter: 19979  total_loss: 0.2049  loss_cls: 0.02507  loss_box_reg: 0.06979  loss_mask: 0.08315  loss_rpn_cls: 0.002661  loss_rpn_loc: 0.02679  total_val_loss: 0.2063  val_loss_cls: 0.02774  val_loss_box_reg: 0.06264  val_loss_mask: 0.08398  val_loss_rpn_cls: 0.001033  val_loss_rpn_loc: 0.02213    time: 1.5824  last_time: 1.5903  data_time: 0.0071  last_data_time: 0.0077   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:57:49 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 19999  total_loss: 0.1893  loss_cls: 0.02456  loss_box_reg: 0.0577  loss_mask: 0.0812  loss_rpn_cls: 0.001856  loss_rpn_loc: 0.02273  total_val_loss: 0.2075  val_loss_cls: 0.02864  val_loss_box_reg: 0.06468  val_loss_mask: 0.08329  val_loss_rpn_cls: 0.000938  val_loss_rpn_loc: 0.02348    time: 1.5823  last_time: 1.4768  data_time: 0.0070  last_data_time: 0.0059   lr: 2.5e-05  max_mem: 15220M\n",
      "\u001b[32m[09/27 02:57:50 d2.engine.hooks]: \u001b[0mOverall training speed: 19998 iterations in 8:47:22 (1.5823 s / it)\n",
      "\u001b[32m[09/27 02:57:50 d2.engine.hooks]: \u001b[0mTotal training time: 12:52:05 (4:04:43 on hooks)\n",
      "\u001b[32m[09/27 02:57:50 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\testing_images\\0_SideLane_addedversion_Testing_COCO.json\n",
      "\u001b[32m[09/27 02:57:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/27 02:57:50 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/27 02:57:50 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/27 02:57:50 d2.data.common]: \u001b[0mSerialized dataset takes 6.03 MiB\n",
      "\u001b[32m[09/27 02:57:50 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[09/27 02:57:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 566 batches\n",
      "\u001b[32m[09/27 02:57:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/566. Dataloading: 0.0004 s/iter. Inference: 0.0699 s/iter. Eval: 0.0067 s/iter. Total: 0.0770 s/iter. ETA=0:00:42\n",
      "\u001b[32m[09/27 02:57:59 d2.evaluation.evaluator]: \u001b[0mInference done 80/566. Dataloading: 0.0006 s/iter. Inference: 0.0699 s/iter. Eval: 0.0028 s/iter. Total: 0.0732 s/iter. ETA=0:00:35\n",
      "\u001b[32m[09/27 02:58:04 d2.evaluation.evaluator]: \u001b[0mInference done 146/566. Dataloading: 0.0006 s/iter. Inference: 0.0702 s/iter. Eval: 0.0039 s/iter. Total: 0.0746 s/iter. ETA=0:00:31\n",
      "\u001b[32m[09/27 02:58:09 d2.evaluation.evaluator]: \u001b[0mInference done 212/566. Dataloading: 0.0006 s/iter. Inference: 0.0707 s/iter. Eval: 0.0038 s/iter. Total: 0.0752 s/iter. ETA=0:00:26\n",
      "\u001b[32m[09/27 02:58:14 d2.evaluation.evaluator]: \u001b[0mInference done 279/566. Dataloading: 0.0006 s/iter. Inference: 0.0709 s/iter. Eval: 0.0037 s/iter. Total: 0.0753 s/iter. ETA=0:00:21\n",
      "\u001b[32m[09/27 02:58:19 d2.evaluation.evaluator]: \u001b[0mInference done 350/566. Dataloading: 0.0006 s/iter. Inference: 0.0705 s/iter. Eval: 0.0034 s/iter. Total: 0.0744 s/iter. ETA=0:00:16\n",
      "\u001b[32m[09/27 02:58:24 d2.evaluation.evaluator]: \u001b[0mInference done 419/566. Dataloading: 0.0006 s/iter. Inference: 0.0705 s/iter. Eval: 0.0031 s/iter. Total: 0.0741 s/iter. ETA=0:00:10\n",
      "\u001b[32m[09/27 02:58:29 d2.evaluation.evaluator]: \u001b[0mInference done 483/566. Dataloading: 0.0006 s/iter. Inference: 0.0707 s/iter. Eval: 0.0035 s/iter. Total: 0.0748 s/iter. ETA=0:00:06\n",
      "\u001b[32m[09/27 02:58:34 d2.evaluation.evaluator]: \u001b[0mInference done 548/566. Dataloading: 0.0006 s/iter. Inference: 0.0711 s/iter. Eval: 0.0034 s/iter. Total: 0.0751 s/iter. ETA=0:00:01\n",
      "\u001b[32m[09/27 02:58:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:42.603790 (0.075943 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/27 02:58:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.071110 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/27 02:58:36 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/27 02:58:36 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\coco_instances_results.json\n",
      "\u001b[32m[09/27 02:58:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.23s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.934\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.930\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.938\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.937\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.952\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.942\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.958\n",
      "\u001b[32m[09/27 02:58:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 93.414 | 99.009 | 98.998 |  nan  | 92.967 | 93.786 |\n",
      "\u001b[32m[09/27 02:58:36 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/27 02:58:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 93.414 | background | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.42s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.862\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.990\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.828\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.883\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.881\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.895\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.865\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.914\n",
      "\u001b[32m[09/27 02:58:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 86.163 | 99.009 | 98.953 |  nan  | 82.842 | 88.269 |\n",
      "\u001b[32m[09/27 02:58:36 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/27 02:58:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 86.163 | background | nan  |\n",
      "\u001b[32m[09/27 02:58:36 d2.engine.defaults]: \u001b[0mEvaluation results for test_data in csv format:\n",
      "\u001b[32m[09/27 02:58:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/27 02:58:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/27 02:58:36 d2.evaluation.testing]: \u001b[0mcopypaste: 93.4139,99.0085,98.9981,nan,92.9670,93.7856\n",
      "\u001b[32m[09/27 02:58:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/27 02:58:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/27 02:58:36 d2.evaluation.testing]: \u001b[0mcopypaste: 86.1629,99.0085,98.9528,nan,82.8417,88.2690\n"
     ]
    }
   ],
   "source": [
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c25510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7683a1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/27 02:58:37 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\model_final.pth ...\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultPredictor\n",
    "#weight_output = \"models\\\\March 2025\\\\Feb_March_Day_Night_15000_iters_v2\" #model testing, remove \n",
    "cfg.merge_from_file(f\"{weight_output}\\\\config.yml\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST  = 0.6\n",
    "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.3\n",
    "cfg.MODEL.WEIGHTS = os.path.join(weight_output,\"model_final.pth\")\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cee98de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d61a7855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "import cv2\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_samples(samples, \n",
    "                 met        = {}, \n",
    "                 is_gt      = True, \n",
    "                 predictor  = None):\n",
    "  n = len(samples)\n",
    "  nrows = int(-(-n/3)) # ceil\n",
    "  ncols = 3\n",
    "  fig, axs = plt.subplots(nrows   = nrows, \n",
    "                          ncols   = ncols, \n",
    "                          figsize = (21, 7))\n",
    "  for i,s in enumerate(samples):\n",
    "    row = i//ncols\n",
    "    col = i%ncols\n",
    "    ax = axs[row][col] if len(axs.shape)==2 else axs[i]\n",
    "    img = cv2.imread(s[\"file_name\"])\n",
    "    v = Visualizer(img[:,:, ::-1], metadata=met, scale=0.5)\n",
    "    if is_gt:\n",
    "      # visualize ground-truths\n",
    "      v = v.draw_dataset_dict(s)\n",
    "    else:\n",
    "      # predict\n",
    "      outputs = predictor(img)\n",
    "      # visualize prediction results\n",
    "      instances = outputs[\"instances\"].to(\"cpu\")\n",
    "      v = v.draw_instance_predictions(instances)\n",
    "\n",
    "    ax.imshow(v.get_image())\n",
    "    ax.axis(\"off\")\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "def plot_random_samples(name_ds, n=3, predictor=None):\n",
    "  # access\n",
    "  ds = DatasetCatalog.get(name_ds)\n",
    "  met = MetadataCatalog.get(name_ds)\n",
    "  samples = random.sample(ds, n)\n",
    "  # plot samples with ground-truths\n",
    "  plot_samples(samples, met)\n",
    "  # plot predictions\n",
    "  plot_samples(samples, \n",
    "               met        = met, \n",
    "               predictor  = predictor, \n",
    "               is_gt      = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffe3f590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot_random_samples(test_dataset_name, predictor = predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e530c5b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\model_final.pth\n",
      "\u001b[32m[09/27 02:58:38 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\model_final.pth ...\n",
      "\u001b[32m[09/27 02:58:38 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/27 02:58:38 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/27 02:58:38 d2.data.datasets.coco]: \u001b[0mLoaded 566 images in COCO format from D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\testing_images\\0_SideLane_addedversion_Testing_COCO.json\n",
      "\u001b[32m[09/27 02:58:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/27 02:58:38 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/27 02:58:38 d2.data.common]: \u001b[0mSerializing 566 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/27 02:58:38 d2.data.common]: \u001b[0mSerialized dataset takes 6.03 MiB\n",
      "\u001b[32m[09/27 02:58:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 566 batches\n",
      "\u001b[32m[09/27 02:58:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/566. Dataloading: 0.0004 s/iter. Inference: 0.0695 s/iter. Eval: 0.0060 s/iter. Total: 0.0759 s/iter. ETA=0:00:42\n",
      "\u001b[32m[09/27 02:58:47 d2.evaluation.evaluator]: \u001b[0mInference done 80/566. Dataloading: 0.0005 s/iter. Inference: 0.0698 s/iter. Eval: 0.0026 s/iter. Total: 0.0729 s/iter. ETA=0:00:35\n",
      "\u001b[32m[09/27 02:58:52 d2.evaluation.evaluator]: \u001b[0mInference done 147/566. Dataloading: 0.0005 s/iter. Inference: 0.0698 s/iter. Eval: 0.0037 s/iter. Total: 0.0740 s/iter. ETA=0:00:30\n",
      "\u001b[32m[09/27 02:58:57 d2.evaluation.evaluator]: \u001b[0mInference done 213/566. Dataloading: 0.0005 s/iter. Inference: 0.0704 s/iter. Eval: 0.0036 s/iter. Total: 0.0747 s/iter. ETA=0:00:26\n",
      "\u001b[32m[09/27 02:59:02 d2.evaluation.evaluator]: \u001b[0mInference done 280/566. Dataloading: 0.0005 s/iter. Inference: 0.0708 s/iter. Eval: 0.0035 s/iter. Total: 0.0749 s/iter. ETA=0:00:21\n",
      "\u001b[32m[09/27 02:59:07 d2.evaluation.evaluator]: \u001b[0mInference done 351/566. Dataloading: 0.0005 s/iter. Inference: 0.0704 s/iter. Eval: 0.0032 s/iter. Total: 0.0741 s/iter. ETA=0:00:15\n",
      "\u001b[32m[09/27 02:59:12 d2.evaluation.evaluator]: \u001b[0mInference done 421/566. Dataloading: 0.0005 s/iter. Inference: 0.0703 s/iter. Eval: 0.0029 s/iter. Total: 0.0738 s/iter. ETA=0:00:10\n",
      "\u001b[32m[09/27 02:59:17 d2.evaluation.evaluator]: \u001b[0mInference done 484/566. Dataloading: 0.0005 s/iter. Inference: 0.0706 s/iter. Eval: 0.0034 s/iter. Total: 0.0745 s/iter. ETA=0:00:06\n",
      "\u001b[32m[09/27 02:59:22 d2.evaluation.evaluator]: \u001b[0mInference done 549/566. Dataloading: 0.0006 s/iter. Inference: 0.0710 s/iter. Eval: 0.0033 s/iter. Total: 0.0749 s/iter. ETA=0:00:01\n",
      "\u001b[32m[09/27 02:59:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:42.511525 (0.075778 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/27 02:59:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:39 (0.070986 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/27 02:59:24 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/27 02:59:24 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\coco_instances_results.json\n",
      "\u001b[32m[09/27 02:59:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.22s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.925\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.980\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.980\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.926\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.929\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.195\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.930\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.944\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.934\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.950\n",
      "\u001b[32m[09/27 02:59:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 92.528 | 98.019 | 98.010 |  nan  | 92.579 | 92.850 |\n",
      "\u001b[32m[09/27 02:59:24 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/27 02:59:24 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 92.528 | background | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.32s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.853\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.980\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.980\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.824\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.874\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.874\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.887\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.858\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.906\n",
      "\u001b[32m[09/27 02:59:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 85.295 | 98.019 | 97.963 |  nan  | 82.402 | 87.439 |\n",
      "\u001b[32m[09/27 02:59:25 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/27 02:59:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 85.295 | background | nan  |\n",
      "\u001b[32m[09/27 02:59:25 d2.engine.defaults]: \u001b[0mEvaluation results for test_data in csv format:\n",
      "\u001b[32m[09/27 02:59:25 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/27 02:59:25 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/27 02:59:25 d2.evaluation.testing]: \u001b[0mcopypaste: 92.5280,98.0189,98.0097,nan,92.5789,92.8503\n",
      "\u001b[32m[09/27 02:59:25 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/27 02:59:25 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/27 02:59:25 d2.evaluation.testing]: \u001b[0mcopypaste: 85.2952,98.0189,97.9635,nan,82.4020,87.4386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bbox',\n",
       "              {'AP': 92.52802260880163,\n",
       "               'AP50': 98.01886438643864,\n",
       "               'AP75': 98.00971723449445,\n",
       "               'APs': nan,\n",
       "               'APm': 92.57892622146531,\n",
       "               'APl': 92.85030556856351,\n",
       "               'AP-cow': 92.52802260880163,\n",
       "               'AP-background': nan}),\n",
       "             ('segm',\n",
       "              {'AP': 85.29519638092074,\n",
       "               'AP50': 98.01886438643864,\n",
       "               'AP75': 97.96348428726671,\n",
       "               'APs': nan,\n",
       "               'APm': 82.40203457036547,\n",
       "               'APl': 87.43856856684276,\n",
       "               'AP-cow': 85.29519638092074,\n",
       "               'AP-background': nan})])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.data import build_detection_test_loader\n",
    "# update newly trained weight file here\n",
    "#cfg.MODEL.WEIGHTS = f\"models\\\\April 2025\\April_Day_Night_10000_iters_v2\\\\model_final.pth\"\n",
    "\n",
    "print(cfg.MODEL.WEIGHTS)\n",
    "model_type=\"maskrcnn\"\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6\n",
    "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.3\n",
    "cfg.DATASETS.TEST=(test_dataset_name,)\n",
    "predictor=DefaultPredictor(cfg)\n",
    "if model_type == \"maskrcnn\":\n",
    "    eval_tasks = (\"segm\",)\n",
    "elif model_type == \"retinanet\":\n",
    "    eval_tasks = (\"bbox\",)\n",
    "    \n",
    "evaluator = COCOEvaluator(test_dataset_name,cfg,\n",
    "                          distributed=False,\n",
    "                          output_dir=weight_output)\n",
    "\n",
    "\n",
    "trainer.test(cfg, predictor.model, evaluators=evaluator)  # testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d469a86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\model_final.pth\n",
      "\u001b[32m[09/27 02:59:25 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\model_final.pth ...\n",
      "\u001b[32m[09/27 02:59:25 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/27 02:59:25 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/27 02:59:26 d2.data.datasets.coco]: \u001b[0mLoaded 2260 images in COCO format from D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\training_images\\0_SideLane_addedversion_Training_COCO.json\n",
      "\u001b[32m[09/27 02:59:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/27 02:59:27 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/27 02:59:27 d2.data.common]: \u001b[0mSerializing 2260 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/27 02:59:27 d2.data.common]: \u001b[0mSerialized dataset takes 25.12 MiB\n",
      "\u001b[32m[09/27 02:59:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 2260 batches\n",
      "\u001b[32m[09/27 02:59:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/2260. Dataloading: 0.0004 s/iter. Inference: 0.0732 s/iter. Eval: 0.0036 s/iter. Total: 0.0772 s/iter. ETA=0:02:53\n",
      "\u001b[32m[09/27 02:59:35 d2.evaluation.evaluator]: \u001b[0mInference done 77/2260. Dataloading: 0.0005 s/iter. Inference: 0.0706 s/iter. Eval: 0.0055 s/iter. Total: 0.0767 s/iter. ETA=0:02:47\n",
      "\u001b[32m[09/27 02:59:40 d2.evaluation.evaluator]: \u001b[0mInference done 139/2260. Dataloading: 0.0006 s/iter. Inference: 0.0733 s/iter. Eval: 0.0047 s/iter. Total: 0.0787 s/iter. ETA=0:02:46\n",
      "\u001b[32m[09/27 02:59:45 d2.evaluation.evaluator]: \u001b[0mInference done 204/2260. Dataloading: 0.0006 s/iter. Inference: 0.0733 s/iter. Eval: 0.0043 s/iter. Total: 0.0783 s/iter. ETA=0:02:40\n",
      "\u001b[32m[09/27 02:59:50 d2.evaluation.evaluator]: \u001b[0mInference done 275/2260. Dataloading: 0.0006 s/iter. Inference: 0.0721 s/iter. Eval: 0.0038 s/iter. Total: 0.0764 s/iter. ETA=0:02:31\n",
      "\u001b[32m[09/27 02:59:56 d2.evaluation.evaluator]: \u001b[0mInference done 350/2260. Dataloading: 0.0006 s/iter. Inference: 0.0709 s/iter. Eval: 0.0030 s/iter. Total: 0.0745 s/iter. ETA=0:02:22\n",
      "\u001b[32m[09/27 03:00:01 d2.evaluation.evaluator]: \u001b[0mInference done 415/2260. Dataloading: 0.0006 s/iter. Inference: 0.0714 s/iter. Eval: 0.0029 s/iter. Total: 0.0750 s/iter. ETA=0:02:18\n",
      "\u001b[32m[09/27 03:00:06 d2.evaluation.evaluator]: \u001b[0mInference done 479/2260. Dataloading: 0.0006 s/iter. Inference: 0.0717 s/iter. Eval: 0.0032 s/iter. Total: 0.0755 s/iter. ETA=0:02:14\n",
      "\u001b[32m[09/27 03:00:11 d2.evaluation.evaluator]: \u001b[0mInference done 547/2260. Dataloading: 0.0006 s/iter. Inference: 0.0712 s/iter. Eval: 0.0036 s/iter. Total: 0.0753 s/iter. ETA=0:02:09\n",
      "\u001b[32m[09/27 03:00:16 d2.evaluation.evaluator]: \u001b[0mInference done 615/2260. Dataloading: 0.0006 s/iter. Inference: 0.0708 s/iter. Eval: 0.0037 s/iter. Total: 0.0752 s/iter. ETA=0:02:03\n",
      "\u001b[32m[09/27 03:00:21 d2.evaluation.evaluator]: \u001b[0mInference done 679/2260. Dataloading: 0.0006 s/iter. Inference: 0.0711 s/iter. Eval: 0.0038 s/iter. Total: 0.0755 s/iter. ETA=0:01:59\n",
      "\u001b[32m[09/27 03:00:26 d2.evaluation.evaluator]: \u001b[0mInference done 749/2260. Dataloading: 0.0006 s/iter. Inference: 0.0708 s/iter. Eval: 0.0039 s/iter. Total: 0.0752 s/iter. ETA=0:01:53\n",
      "\u001b[32m[09/27 03:00:31 d2.evaluation.evaluator]: \u001b[0mInference done 811/2260. Dataloading: 0.0006 s/iter. Inference: 0.0711 s/iter. Eval: 0.0040 s/iter. Total: 0.0757 s/iter. ETA=0:01:49\n",
      "\u001b[32m[09/27 03:00:36 d2.evaluation.evaluator]: \u001b[0mInference done 874/2260. Dataloading: 0.0006 s/iter. Inference: 0.0715 s/iter. Eval: 0.0039 s/iter. Total: 0.0761 s/iter. ETA=0:01:45\n",
      "\u001b[32m[09/27 03:00:41 d2.evaluation.evaluator]: \u001b[0mInference done 938/2260. Dataloading: 0.0006 s/iter. Inference: 0.0718 s/iter. Eval: 0.0038 s/iter. Total: 0.0762 s/iter. ETA=0:01:40\n",
      "\u001b[32m[09/27 03:00:46 d2.evaluation.evaluator]: \u001b[0mInference done 996/2260. Dataloading: 0.0006 s/iter. Inference: 0.0720 s/iter. Eval: 0.0042 s/iter. Total: 0.0768 s/iter. ETA=0:01:37\n",
      "\u001b[32m[09/27 03:00:51 d2.evaluation.evaluator]: \u001b[0mInference done 1067/2260. Dataloading: 0.0006 s/iter. Inference: 0.0717 s/iter. Eval: 0.0041 s/iter. Total: 0.0764 s/iter. ETA=0:01:31\n",
      "\u001b[32m[09/27 03:00:56 d2.evaluation.evaluator]: \u001b[0mInference done 1129/2260. Dataloading: 0.0006 s/iter. Inference: 0.0718 s/iter. Eval: 0.0043 s/iter. Total: 0.0767 s/iter. ETA=0:01:26\n",
      "\u001b[32m[09/27 03:01:01 d2.evaluation.evaluator]: \u001b[0mInference done 1191/2260. Dataloading: 0.0006 s/iter. Inference: 0.0720 s/iter. Eval: 0.0043 s/iter. Total: 0.0770 s/iter. ETA=0:01:22\n",
      "\u001b[32m[09/27 03:01:06 d2.evaluation.evaluator]: \u001b[0mInference done 1262/2260. Dataloading: 0.0006 s/iter. Inference: 0.0718 s/iter. Eval: 0.0042 s/iter. Total: 0.0766 s/iter. ETA=0:01:16\n",
      "\u001b[32m[09/27 03:01:11 d2.evaluation.evaluator]: \u001b[0mInference done 1332/2260. Dataloading: 0.0006 s/iter. Inference: 0.0717 s/iter. Eval: 0.0041 s/iter. Total: 0.0764 s/iter. ETA=0:01:10\n",
      "\u001b[32m[09/27 03:01:16 d2.evaluation.evaluator]: \u001b[0mInference done 1404/2260. Dataloading: 0.0006 s/iter. Inference: 0.0714 s/iter. Eval: 0.0040 s/iter. Total: 0.0760 s/iter. ETA=0:01:05\n",
      "\u001b[32m[09/27 03:01:21 d2.evaluation.evaluator]: \u001b[0mInference done 1472/2260. Dataloading: 0.0006 s/iter. Inference: 0.0715 s/iter. Eval: 0.0038 s/iter. Total: 0.0759 s/iter. ETA=0:00:59\n",
      "\u001b[32m[09/27 03:01:26 d2.evaluation.evaluator]: \u001b[0mInference done 1538/2260. Dataloading: 0.0006 s/iter. Inference: 0.0716 s/iter. Eval: 0.0037 s/iter. Total: 0.0760 s/iter. ETA=0:00:54\n",
      "\u001b[32m[09/27 03:01:31 d2.evaluation.evaluator]: \u001b[0mInference done 1603/2260. Dataloading: 0.0006 s/iter. Inference: 0.0718 s/iter. Eval: 0.0037 s/iter. Total: 0.0760 s/iter. ETA=0:00:49\n",
      "\u001b[32m[09/27 03:01:36 d2.evaluation.evaluator]: \u001b[0mInference done 1674/2260. Dataloading: 0.0006 s/iter. Inference: 0.0716 s/iter. Eval: 0.0036 s/iter. Total: 0.0758 s/iter. ETA=0:00:44\n",
      "\u001b[32m[09/27 03:01:41 d2.evaluation.evaluator]: \u001b[0mInference done 1745/2260. Dataloading: 0.0006 s/iter. Inference: 0.0715 s/iter. Eval: 0.0035 s/iter. Total: 0.0756 s/iter. ETA=0:00:38\n",
      "\u001b[32m[09/27 03:01:46 d2.evaluation.evaluator]: \u001b[0mInference done 1810/2260. Dataloading: 0.0006 s/iter. Inference: 0.0716 s/iter. Eval: 0.0035 s/iter. Total: 0.0757 s/iter. ETA=0:00:34\n",
      "\u001b[32m[09/27 03:01:51 d2.evaluation.evaluator]: \u001b[0mInference done 1870/2260. Dataloading: 0.0006 s/iter. Inference: 0.0716 s/iter. Eval: 0.0037 s/iter. Total: 0.0760 s/iter. ETA=0:00:29\n",
      "\u001b[32m[09/27 03:01:57 d2.evaluation.evaluator]: \u001b[0mInference done 1935/2260. Dataloading: 0.0006 s/iter. Inference: 0.0717 s/iter. Eval: 0.0037 s/iter. Total: 0.0760 s/iter. ETA=0:00:24\n",
      "\u001b[32m[09/27 03:02:02 d2.evaluation.evaluator]: \u001b[0mInference done 1997/2260. Dataloading: 0.0006 s/iter. Inference: 0.0718 s/iter. Eval: 0.0038 s/iter. Total: 0.0762 s/iter. ETA=0:00:20\n",
      "\u001b[32m[09/27 03:02:07 d2.evaluation.evaluator]: \u001b[0mInference done 2065/2260. Dataloading: 0.0006 s/iter. Inference: 0.0718 s/iter. Eval: 0.0037 s/iter. Total: 0.0761 s/iter. ETA=0:00:14\n",
      "\u001b[32m[09/27 03:02:12 d2.evaluation.evaluator]: \u001b[0mInference done 2128/2260. Dataloading: 0.0006 s/iter. Inference: 0.0719 s/iter. Eval: 0.0037 s/iter. Total: 0.0762 s/iter. ETA=0:00:10\n",
      "\u001b[32m[09/27 03:02:17 d2.evaluation.evaluator]: \u001b[0mInference done 2190/2260. Dataloading: 0.0006 s/iter. Inference: 0.0720 s/iter. Eval: 0.0038 s/iter. Total: 0.0764 s/iter. ETA=0:00:05\n",
      "\u001b[32m[09/27 03:02:22 d2.evaluation.evaluator]: \u001b[0mInference done 2257/2260. Dataloading: 0.0006 s/iter. Inference: 0.0720 s/iter. Eval: 0.0037 s/iter. Total: 0.0764 s/iter. ETA=0:00:00\n",
      "\u001b[32m[09/27 03:02:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:52.688677 (0.076580 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/27 03:02:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:42 (0.072027 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/27 03:02:23 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/27 03:02:23 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\coco_instances_results.json\n",
      "\u001b[32m[09/27 03:02:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.88s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.09s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.957\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.980\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.980\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.953\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.961\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.956\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.971\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.964\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.975\n",
      "\u001b[32m[09/27 03:02:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 95.734 | 98.020 | 98.009 |  nan  | 95.318 | 96.116 |\n",
      "\u001b[32m[09/27 03:02:24 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/27 03:02:24 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 95.734 | background | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=1.35s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.09s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.871\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.980\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.980\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.847\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.886\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.891\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.905\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.882\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.918\n",
      "\u001b[32m[09/27 03:02:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 87.148 | 98.020 | 97.978 |  nan  | 84.670 | 88.622 |\n",
      "\u001b[32m[09/27 03:02:25 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/27 03:02:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP     | category   | AP   |\n",
      "|:-----------|:-------|:-----------|:-----|\n",
      "| cow        | 87.148 | background | nan  |\n",
      "\u001b[32m[09/27 03:02:25 d2.engine.defaults]: \u001b[0mEvaluation results for training_data in csv format:\n",
      "\u001b[32m[09/27 03:02:25 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/27 03:02:25 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/27 03:02:25 d2.evaluation.testing]: \u001b[0mcopypaste: 95.7341,98.0197,98.0089,nan,95.3179,96.1161\n",
      "\u001b[32m[09/27 03:02:25 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[09/27 03:02:25 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/27 03:02:25 d2.evaluation.testing]: \u001b[0mcopypaste: 87.1475,98.0197,97.9779,nan,84.6701,88.6217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bbox',\n",
       "              {'AP': 95.73406891364596,\n",
       "               'AP50': 98.01968983850475,\n",
       "               'AP75': 98.00887171462344,\n",
       "               'APs': nan,\n",
       "               'APm': 95.31791277157325,\n",
       "               'APl': 96.1161283990425,\n",
       "               'AP-cow': 95.73406891364596,\n",
       "               'AP-background': nan}),\n",
       "             ('segm',\n",
       "              {'AP': 87.14753194867284,\n",
       "               'AP50': 98.01968983850475,\n",
       "               'AP75': 97.97787475003868,\n",
       "               'APs': nan,\n",
       "               'APm': 84.67012826607439,\n",
       "               'APl': 88.62166489358756,\n",
       "               'AP-cow': 87.14753194867284,\n",
       "               'AP-background': nan})])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, pascal_voc_evaluation\n",
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "# update newly trained weight file here\n",
    "#cfg.MODEL.WEIGHTS = f\"{weight_output}\\\\model_final.pth\"\n",
    "\n",
    "print(cfg.MODEL.WEIGHTS)\n",
    "model_type=\"maskrcnn\"\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6\n",
    "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.3\n",
    "cfg.DATASETS.TEST=(training_dataset_name,)\n",
    "predictor=DefaultPredictor(cfg)\n",
    "if model_type == \"maskrcnn\":\n",
    "    eval_tasks = (\"segm\",)\n",
    "elif model_type == \"retinanet\":\n",
    "    eval_tasks = (\"bbox\",)\n",
    "    \n",
    "evaluator = COCOEvaluator(training_dataset_name,cfg,\n",
    "                          distributed=False,\n",
    "                          output_dir=weight_output)\n",
    "\n",
    "\n",
    "trainer.test(cfg, predictor.model, evaluators=evaluator)  # trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8715008f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "# from detectron2.engine import DefaultPredictor\n",
    "# from detectron2.data import build_detection_test_loader\n",
    "# # update newly trained weight file here\n",
    "# #cfg.MODEL.WEIGHTS = f\"{weight_output}\\\\model_final.pth\"\n",
    "\n",
    "# print(cfg.MODEL.WEIGHTS)\n",
    "# model_type=\"maskrcnn\"\n",
    "# cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.6\n",
    "# cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.3\n",
    "# predictor=DefaultPredictor(cfg)\n",
    "# if model_type == \"maskrcnn\":\n",
    "#     eval_tasks = (\"segm\",)\n",
    "# elif model_type == \"retinanet\":\n",
    "#     eval_tasks = (\"bbox\",)\n",
    "    \n",
    "# evaluator = COCOEvaluator(val_dataset_name,cfg,\n",
    "#                           distributed=False,\n",
    "#                           output_dir=weight_output)\n",
    "\n",
    "# val_loader = build_detection_test_loader(cfg,val_dataset_name)\n",
    "# inference_on_dataset(trainer.model,val_loader,evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3ba442",
   "metadata": {},
   "source": [
    "import ast\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def moving_average(a, n=3):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "#weight_output = \"models\\model_4000_iter1\" #iter1 is the best for now\n",
    "#weight_output = \"models\\model_4000iter1_6000_iter8\" #iter1 is the best for now\n",
    "#weight_output = \"models\\\\base_yoshii_model_Sumiyoshi_anchor_v1_15000_iters2\"\n",
    "metrics_file = f'{weight_output}\\\\metrics.json'\n",
    "print(metrics_file)\n",
    "\n",
    "with open(metrics_file, 'r') as f:\n",
    "    metrics = [eval(l[:-1].replace('NaN','0')) for l in f.readlines()]\n",
    "    f.close()\n",
    "\n",
    "train_loss = [float(v['loss_box_reg']) for v in metrics if 'loss_box_reg' in v.keys()]\n",
    "val_loss = [float(v['val_loss_box_reg']) for v in metrics if 'val_loss_box_reg' in v.keys()]\n",
    "\n",
    "N = 40\n",
    "\n",
    "train_loss_avg = moving_average(train_loss, n=N)\n",
    "val_loss_avg = moving_average(val_loss, n=N)\n",
    "\n",
    "plt.plot(range(20 * N - 1, 20 * len(train_loss), 20), train_loss_avg, label='train loss')\n",
    "plt.plot(range(20 * N - 1, 20 * len(train_loss), 20), val_loss_avg, label='val loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "405787ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\\Side Lane September 2025\\Base_rtx8000_26_September_2025_20000_v1\\metrics.json\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAniVJREFUeJzs3Xd4VNXWwOHfzKT3XoAUSugh9CZSJBTBEkVERFFEUC9cC5+oKFauF68FC6KIih1BlKYgEiNNivRO6BBKElJIJ3Xm++NkZjLJJKRPMlnv8/DklD1n9k5CsrLL2iqdTqdDCCGEEKKRU1u6AkIIIYQQtUGCGiGEEEJYBQlqhBBCCGEVJKgRQgghhFWQoEYIIYQQVkGCGiGEEEJYBQlqhBBCCGEVJKgRQgghhFWwsXQF6otWq+XKlSu4urqiUqksXR0hhBBCVIJOpyMzM5NmzZqhVlfcF9NkgporV64QFBRk6WoIIYQQohouXrxIixYtKizTZIIaV1dXQPmkuLm5UVBQwIYNGxg+fDi2trYWrl3daiptbSrtBGmrtWoqbW0q7QRpa23IyMggKCjI8Hu8Ik0mqNEPObm5uRmCGicnJ9zc3JrEN1pTaGtTaSdIW61VU2lrU2knSFtrU2WmjshEYSGEEEJYBQlqhBBCCGEVJKgRQgghhFVoMnNqhBBCWDedTkdhYSFFRUWWropBQUEBNjY25ObmNqh61YXqtlWj0WBjY1Mr6VYkqBFCCNHo5efnEx8fT05OjqWrYkKn0xEQEMDFixetPkdaTdrq5OREYGAgdnZ2NaqDBDVCCCEaNa1Wy7lz59BoNDRr1gw7O7sGE0BotVqysrJwcXG5YeK4xq46bdXpdOTn55OUlMS5c+cICwur0edJghohhBCNWn5+PlqtlqCgIJycnCxdHRNarZb8/HwcHByaRFBTnbY6Ojpia2vLhQsXDK+vLuv+DAshhGgyrD1osGa19bWT7wAhhBBCWAUJaoQQQghhFSSoEUIIIaxAaGgoH3zwgcWfYUkyUVgIIYSwgMGDB9O1a9daCyJ2796Ns7NzrTyrsZKemiYmO6+Qr7edY/vpZEtXRQghxA3oEwpWhq+vb4Nb/VXfJKhpYt76PZbXfj3GY9/tRavVWbo6QghR63Q6HTn5hRb5p9NV7ufqww8/zObNm/nwww9RqVSoVCrOnz/Ppk2bUKlU/P777/To0QN7e3v+/vtvzpw5w5133om/vz8uLi706tWLP//80+SZpYeOVCoVX3zxBXfddRdOTk6EhYWxZs2aKn0u4+LiuPPOO3FxccHNzY17772XxMREw/2DBw8yZMgQXF1d8fDwYPDgwezZsweACxcucPvtt+Pp6YmzszOdOnVi3bp1VXr/qpLhpyZmX9w1ADLzCknOysPPrfr5AMSNrTscz8urjvD2PV0Y2sHf0tURokm4XlBEx1f+sMh7H3tjBE52N/7V+uGHH3Ly5Ek6d+7MG2+8ASg9LefPnwfghRde4N1336VVq1Z4enpy8eJFRo0axZtvvom9vT3ffvstt99+OydOnCA4OLjc93n99dd5++23eeedd5g/fz4TJkzgwoULeHl53bCOWq3WENBs3ryZwsJCpk2bxrhx49i0aRMAEyZMoFu3bnz66aeoVCp27NiBra0tANOmTSM/P58tW7bg7OzMsWPHcHFxueH71oQENU1IfqGWU1ezDOcXr+VYJKjJzivE0VaDWt0wMn7WFa1Wx79+2AfAZ1vOSlAjhDBwd3fHzs4OJycnAgICytx/4403GDZsmOHcy8uLiIgIw/mcOXNYuXIla9asYfr06eW+z8MPP8z48eMB+O9//8tHH33Erl27GDly5A3rGBMTw+HDhzl37hxBQUEAfPvtt3Tq1Indu3fTq1cv4uLimDlzJu3bt0er1eLv74+bmxug9PKMGTOG8PBwAFq1alWJz0zNSFDThJxMzCK/UGs4v5h6nR4h9VuH2IQMxn22ky4t3Plucp/6ffN6Fpdq3IPGusM3IRoWR1sNx94YYbH3rg09e/Y0Oc/KyuK1115j7dq1xMfHU1hYyPXr14mLi6vwOV26dDEcOzs74+bmxtWrVytVh+PHjxMUFGQIaAA6duyIh4cHx48fp1evXsyYMYNHH32U7777jqFDhzJy5EhD8PXkk0/yxBNPsGHDBiIjIxkzZoxJfeqCzKlpInQ6uGvhTpNr8em59V6PV1YdJf16AVtPJZsEWNYoNiHTcJySnW/BmgjRtKhUKpzsbCzyr7b2nCq9iunZZ59l5cqV/Pe//2Xr1q0cOHCA8PBw8vMr/tmiHwoq+bnRamvvZ+9rr73G0aNHGT16NH/99Rd9+/Zl5cqVADz66KOcPXuWBx98kMOHD9OzZ0/mz59fa+9tjgQ1TcR1M7vAJ2fl1WsdirQ6YhMyDOdxqdn1+v717UyScagvPu16pScQCiGaBjs7O4qKzPxwNmPbtm08/PDD3HXXXYSHhxMQEGCYf1NXOnTowMWLF7l48aLh2rFjx0hLS6Njx46Ga23btuWZZ57hjz/+4LbbbuPrr7823AsKCuLxxx9nxYoV/N///R+ff/55ndZZgpomIqNEMD9zRDsAUuo5qDl6JZ2MXOPSxOPxmRWUbvySMo2f3+z8IlYfuGLB2gghGprQ0FD++ecfzp8/T3JycoU9KGFhYaxYsYIDBw5w8OBB7r///lrtcTEnMjKS8PBwJkyYwL59+9i1axcTJ05k0KBB9OzZk+vXrzN9+nQ2bdrEhQsX2LZtG/v376dDhw4APP300/zxxx+cO3eOffv2sXHjRsO9uiJBTRORXqB0iYb5uRDorkwOTs5SIp3j8RnEHE8s97WVcT2/iN8OXSErr/x8CttOp5icr9p/uUbv2dAllQoan152QHprhBAGzz77LBqNho4dO+Lr61vh/Jh58+bh6elJ//79uf322xkxYgTdu3ev0/qpVCpWr16Np6cnAwcOJDIyklatWrFs2TIANBoNKSkpTJw4kbZt23LfffcRGRnJa6+9BkBRURHTpk2jQ4cOjBw5krZt2/LJJ5/UaZ1lonAToe+p8XdzwMfFHlCGn3ILirj1w60AdAx0o6WvM/Pv61allUnnkrN5948TrD0cz4N9Q5gT1dlsucOX0wCI6tqMVQeusOtcKjqdrtbGoBuakj01epl5hbg52JopLYRoatq2bcuOHTtMroWGhpr94yc0NJS//vrL5Nq0adNMzksPR5l7TlpaWoV1Kv2M4OBgVq9ebbasnZ0dP/74o+Fcq9WSkZGBg4Pyh3Ndz58xR3pqmoi04qDGz80e/+Jl3BdTc/jjaIKhzLH4DNYeiufolQy2nEyqVK/ClpNJDHl3E2sPxwPw3c4LZsst3RXHusPKe43u0gw7jZrMvEIuXbtek2Y1aObmLCWbCXSEEELUDglqmojEHKU3pJWPM2F+Lvi42JGdX8SCjafLlJ3wxU4mLt7F4m3nb/jcd/44YXLezt+1TJnCIi0vrDhsOG8f4EobPyUB04kE651Xow9g2gcYPyf6IT8hhBC1T4KaJiL+uhLUtPFzRa1W0S3YE1By15Smn8w757djN3yug626wnPAZJ5NK19nmns4EuTlCMCVdOvsqckrLDJ8Hj+faMw3Ud8rzoQQoimRoKYJ0Gp1JBbHDm39lR4Sb2e7Sr02MSOX9OsFZu8VaXWcS84xuXYtx7SsVqsjs/iXu0oF0c8MQq1WEeiuBDWWyJVTH/Q9MrYaFS08HRnZSckYam6ejRBCiNohQU0TcDHtOgVaFXY2akK8lYROnpUMavr8N4Z+c2M4l6zklNlwNIHxi3ZyNimLfXHXSM7Kw9XehvfHKRkkr2XnszH2KicSMolNyKDDK+t5/dejAHg726MpnoCsX4EVn2adPTX6oScfF3tUKhUBxe211p4pIYRoCGT1UxNwuni/p1Y+zoagwsvJGNQ422n45V/9+WXvJT7feg6AsT1asHzvJQBy8ov4cVcc3YI8eKJ4L6OoBdu4qY0PAP3beDOknR+grO6Z9PVu/N3saeHpRF6hlj+PKym53RyM326BHkpPzUUrnSisH2bSrzRr4am097KVtlcIIRoC6alpAk5fVXpZwvyMabdL9tQEejjSPsCNUeGBhmv39jLu9QGw6cRVQ3ACyryb348oq5na+bvi7mhLsJeT4X5iRh57L1wzeYazvTGo6dxM2fBs74VrxFth70WSoadG+Tw3Kw7irlhpz5QQQjQEEtQ0AfqducP8jFu+ezkbc6X0ClUmDXs72xuudQx0M3nGycQsjl5JN/v8Nv6uqFQqbg0vu9NsSSWDl5Y+zoYg6PU1N56Q3Njoe2p8XU17ai6k5EgCPiGEqCMS1DQB+qCmja8xqOkY6I6LvQ2tfJx5amhbAIK8HJnQJ5jHB7XG2d4Gd0fTJHGx5Sy/7hbkAcDwjhUHNSWXM6tUKh4bpGxDfzTefLDUmOnb6l08/NTW3xU7jZqU7HwupORU9FIhhKi00NBQPvjgg3LvP/zww0RFRdVbfSxNghorV6TVcSapePjJ3zj8FODuwJ7ZkcT83yDDJFaVSsWbd4Xzwq3tAfh1+gA+vr8bD/cPNXnmzBHteKBvsOE8qLjHpUeIJ3OiOtPa13R3Wb1QbyeTc/2KoIup18nJL397hdIKihr+7t6l59Q42Gro0sIdgMHvbuJiqgQ2QghR2ySosXLzok+QV6gEAUGepkGFg62mwi0Kgr2duK1LM5MAxslOw5SbW/HGHZ2ZPboDK//V3+Q1D/YNMQmCugV7sHPWUMb3DmLhgz1Mynq72ONVPLfnbFL5O3afT87meLyyu/enm84Q/tofHLiYVn6jGwBjUGOcu9SlhYfhWD8JWwghRO2RoMbKLdh4xnCsqcJ+TiW18XNl63NDuK9XED891g87GzVqtYpHb25lSOJXkn4eCUBkB38C3B2Ye3cX2ge4lSnbzEPpJbqaaT5fTZFWx+B3N3Hrh1u5mpHL/9bHklug5b9rj1erLfVFP/zk62L8XOjnLoH5PVmEEE3HokWLaNasWZmdtu+8804eeeQRAM6cOcOdd96Jv78/Li4u9OrViz///LNG75uXl8eTTz6Jn58fDg4ODBgwgN27dxvuX7t2jQkTJuDr64ujoyNhYWF89dVXAOTn5zN9+nQCAwNxcHAgJCSEuXPn1qg+tU2WdFuxkr84hzev2ZBNkJcTb43pUqmyLX2Mc3fu6dGiwrJ+rg5ABokZ5pPSnU8x9uAcKTFR2damYW+CmVLcU+NdIqgZ2TkAX1d7kjLzuCyroISoOzodFFhoiNfWSck0egNjx47l3//+Nxs3bmTo0KEApKamsn79etatWwdAVlYWo0aN4s0338Te3p5vv/2W22+/nRMnThAcHFzR48v13HPP8csvv/DNN98QEhLC22+/zYgRIzh9+jReXl68/PLLHDt2jN9//x0fHx9Onz7N9evKz6uPPvqINWvW8NNPPxEcHMzFixe5ePFitepRVySosWIlMwEPb1F/81DaBbjy1cO9aOnjbNg8szz+bsov/cQM056ao1fSCXR3ZMPRRMO1khOVHW0b7rduQZHWkFm55PCTSqVi9ugOPLX0gFVv5CmExRXkwH+bWea9X7wCdubnFZbk6enJrbfeypIlSwxBzc8//4yPjw9DhgwBICIigoiICMNr5syZw8qVK1mzZg3Tp0+vctWys7P59NNP+frrr7n11lsB+Pzzz4mOjubLL79k5syZxMXF0a1bN3r2VLZ3CQ0NNbw+Li6OsLAwBgwYgEqlIiQkpMp1qGsy/GTF9FsQeDrZYmZLpjo1pL0foT43/o/t66oEPSV7ak4mZjL6o78Z9M5GPtlk3HBz++kUw7G5PaYaitRsZehJo1bh6WSauVmS8Akh9CZMmMAvv/xCXp7y8++HH37gvvvuQ61Wfr5lZWXx7LPP0qFDBzw8PHBxceH48ePExcVV6/3OnDlDQUEBN910k+Gara0tvXv35vhxZUj/iSeeYOnSpXTt2pXnnnuO7du3G8o+/PDDHDhwgHbt2vHkk0+yYcOG6ja9zjTcP3dFpRUUacnKLSyz9UFCce+H0lvSMH+JtvRRJi//tOcir93REXsbDTvPKsGLfs8ovb9PJxuOc/KL6q+SVaRPvOflbIe61DymFsWTtRMyciks0mKjabjBmRCNlq2T0mNiqfeupNtvvx2dTsfatWvp1asXW7du5f333zfcf/bZZ4mOjubdd9+lTZs2ODo6cs8995Cfn1/BU2vm1ltv5cKFC6xbt47o6GiGDh3KtGnTePfdd+nevTvnzp3j999/588//+Tee+8lMjKSn3/+uc7qU1US1FiBCZ//w+4LqeycNdRkuCehuKcmwM2+vJda3M1hvqhUyoTg538+RK+WXuw+b5qJeEg7XzaeSDK5Vt4mmw2BfuWTuU1DfV3ssdOoyS/SkpCRawhyhBC1SKWq1BCQpTk4OHD33Xfzww8/cPr0adq1a0f37t0N97dt28bDDz/MXXfdBSg9N+fPn6/2+7Vu3Ro7Ozu2bdtmGDoqKChg9+7dPP3004Zyvr6+PPTQQzz00EPcfPPNzJw5k3fffRcANzc3xo0bx7hx47jnnnsYOXIkqampeHl5VbtetalafyYuWLCA0NBQHBwc6NOnD7t27aqw/PLly2nfvj0ODg6Eh4cbJkHpJSYm8vDDD9OsWTOcnJwYOXIkp06dMikzePBgVCqVyb/HH3+8OtW3Kjqdjl3nU9HpIPpYosk9fVBzo3ktluTjYk/flt4ArDpwhZdWHuHXg6Z/YfVv7cNNbbxNrjXkoEY/X0af/6cktVplGILafialzH0hRNMyYcIE1q5dy+LFi5kwYYLJvbCwMFasWMGBAwc4ePAg999/f5nVUlXh7OzME088wcyZM1m/fj3Hjh1jypQp5OTkMHnyZABeeeUVVq9ezenTpzl69Ci//fYbHTp0AGDevHn8+OOPxMbGcvLkSZYvX05AQAAeHh7VrlNtq3JQs2zZMmbMmMGrr77Kvn37iIiIYMSIEVy9etVs+e3btzN+/HgmT57M/v37iYqKIioqiiNHjgDKL+WoqCjOnj3L6tWr2b9/PyEhIURGRpKdbZq7ZMqUKcTHxxv+vf3229VosnXRD3UAONtrACgs0jJ33XEWbFTmo/g34J4agPfujajw/s1tfVj8cC+Taw01qDl2JYPZq5Tv7U7Nyi5hB7gtQpnAuPZQfL3VSwjRMN1yyy14eXlx4sQJ7r//fpN78+bNw9PTk/79+3P77bczYsQIk56c6njrrbcYM2YMDz74IN27d+f06dP88ccfeHoqKSfs7OyYNWsWXbp0YeDAgWg0GpYuXQqAq6srb7/9Nj179qRXr16cP3+edevWGeYANQRVHn6aN28eU6ZMYdKkSQAsXLjQEGW+8MILZcp/+OGHjBw5kpkzZwLK7O3o6Gg+/vhjFi5cyKlTp9i5cydHjhyhU6dOAHz66acEBATw448/8uijjxqe5eTkREBAxan4m5q4Eplps3IL0Wp1LNkVx2dbzhquB7g5NNQpNYBxs8fSno4MY3A7P0N+m/6tvQ29Gw0xqPlxVxyzVhw2nIc39zBbrmuQkllYP6FYCNF0qdVqrlwxP/8nNDSUv/76y+TatGnTTM5vNBz19ddfm5w7ODjw0Ucf8dFHH5ktP3v2bGbPnm323pQpU5gyZUqF72dpVQpq8vPz2bt3L7NmzTJcU6vVREZGsmPHDrOv2bFjBzNmzDC5NmLECFatWgVgmPXt4GDsqler1djb2/P333+bBDU//PAD33//PQEBAdx+++28/PLLODmZn5OQl5dneDZARoaSkbagoMDwT3/emJ29alzm/FdsIi+vPlqmTHigM2cTG3Zb7W3U5BVqsbNR42irxlaj5vZwf4K9nAz1/vDeLvxxLJHZq4+RX6glMycXB1uN4RmW/pqWDGgAurZwNVsXFzvlr5pr2XnVrqul21qfpK3Wp7bbWVBQgE6nQ6vV1mh4pi7o84Xp62fNatJWrVaLTqejoKAAjUZjcq8q3ydVCmqSk5MpKirC39/f5Lq/vz+xsbFmX5OQkGC2fEJCAgDt27cnODiYWbNm8dlnn+Hs7Mz777/PpUuXiI83ds/ff//9hISE0KxZMw4dOsTzzz/PiRMnWLFihdn3nTt3Lq+//nqZ6xs2bDAJhKKjoyvX+AYqOk6NfhRx44nkMvfbuWs5e0BZkteQ2/rvDrDyvIYxLfPxtgcbNRzZuYkjpco560CFBh0qVq79A/eyc3Et0k5lMZbxv5OjRsc/m81n/rx6XSl7Oe06r3/zOx09dDjbmi16Qw35a1rbpK3Wp7baaWNjQ0BAAFlZWXW6MqgmMjPNbwhsjarT1vz8fK5fv86WLVsoLDRd+ZqTU/lEihZf/WRra8uKFSuYPHkyXl5eaDQaIiMjufXWW00y4k6dOtVwHB4eTmBgIEOHDuXMmTO0bt26zHNnzZpl0kOUkZFBUFAQw4cPx83NjYKCAqKjoxk2bBi2ttX8jdIA/L70IFw2nSDcxteZB/oGczw+gxmRYbjaqRpFWx+rZLnXD24k7XoBPfsNJMzfmL3Ykl/T/XFpUDxh/rbwAJ6ObEOIl/lexGs5+bx5YBM6VHx/WkOflp58/0gvs2XLYy3fv5UhbbU+td3O3NxcLl68iIuLi0mvf0Og0+nIzMzE1dW1wr32rEFN2pqbm4ujoyMDBw4s8zXUj7RURpWCGh8fHzQaDYmJpr9EExMTy53rEhAQcMPyPXr04MCBA6Snp5Ofn4+vry99+vQxZDQ0p0+fPgCcPn3abFBjb2+PvX3ZCbK2trYm/4lKnzc251PKRrB//t9gk3N9111jb6ueu5MtadcLyC7UmW2PJdp5LCELgKHt/fh4Qo8Ky3q72qBSKZncAf45d63a9bWWr2llSFutT221s6ioCJVKhVqtblCTVgHDMIy+ftasJm1Vq9WoVCqz3xNV+R6p0rva2dnRo0cPYmJiDNe0Wi0xMTH069fP7Gv69etnUh6ULkdz5d3d3fH19eXUqVPs2bOHO++8s9y6HDhwAIDAwMCqNMGqaLU6k72RAML8XMopbT3cHZVv8PSchjPv4NAlZV+q8BbuNyyrUasMbRBCCFF7qjz8NGPGDB566CF69uxJ7969+eCDD8jOzjashpo4cSLNmzc37Nz51FNPMWjQIN577z1Gjx7N0qVL2bNnD4sWLTI8c/ny5fj6+hIcHMzhw4d56qmniIqKYvjw4YCS2nnJkiWMGjUKb29vDh06xDPPPMPAgQPp0qVymyxao79PJ5NboMVWo2LnrKEs3HyG8b2rt8lZY6Lf+To+veEs6Tp4KQ2AiBYelSof7OVEWk76jQsKISqt5JQF0bjU1teuykHNuHHjSEpK4pVXXiEhIYGuXbuyfv16w2TguLg4k26n/v37s2TJEmbPns2LL75IWFgYq1atonPnzoYy8fHxzJgxg8TERAIDA5k4cSIvv/yy4b6dnR1//vmnIYAKCgpizJgx5S47awoKirRM+2EfAKHezni72PPS6I4WrlX9aOPnQkzsVU5dzbJ0VQDIyivkbLLSY1aZnhqAjoFuht4dUDIqa9TWPd4uRF3RD0/k5OTg6Gg+RYRo2PSTgWs6HFmticLTp08vd4fQTZs2lbk2duxYxo4dW+7znnzySZ588sly7wcFBbF58+Yq19OaHbqUTmaeMkP8hVvbW7g29SvM3xWAU4kNI6iJjc9Ap1N25PZxqVyiw87N3WH3RcN5fPp12TJBiGrSaDR4eHgYksA6OTk1mEm5Wq2W/Px8cnNzm8Scmqq2VafTkZOTw9WrV/Hw8CiznLuqLL76SVRPUqayBUK3YA+GdvC/QWnrop831BB6ahIzcrlnoZKjKdC98n8hDgzzNTk/m5QtQY0QNaBffFJedntL0el0XL9+HUdHxwYTaNWVmrTVw8OjVpLrSlDTSCVnKbkYKtszYE3aFAc1yVl5/BWbyC3t6zeo02p1rNh/meYejoz/fKfhenzxXluVEeztxLieQSzbo/TWnEnKYmBb3xu8SghRHpVKRWBgIH5+fg0qeWFBQQFbtmxh4MCBVr+irbpttbW1rXEPjZ4ENY2UfifophjUONsbv21nrzzC9ln1G9R8uvkM7/xxosz1cb1aVOk5/7unC57OdizcfIbzydk3foEQ4oY0Gk2t/YKsDRqNhsLCQhwcHKw+qGkIbbXuAT4rlmLoqTGTUrcJGNtDCSCupOeSmFH5HpLasKjEvloAo8MDeW9sBP++JazKzwryUoasLqc1nJVcQgjRWElQ00jpd+duij01ALNvM670Gv7+FrLyCisoXbtKDxU/HRnGmB4tTPahqqzmxZt5XromQY0QQtSUDD81IjqdjulL9nPgYprhL/sQ76Y5ubRk8rr06wV0fvUPPri3C/UxDU+rNeZTCPNzMazGqg795OBL166j0+msfiKhEELUJempaUQyrhey9nC8yVBF+wA3C9bIsl4a1cHk/OmfDvHeIQ2fbTlXZ+9ZWKQlI1fpFerc3I0V/+pfo+cFeTlib6MmK6+wQazmEkKIxkyCmkYk7XrZ3Wf93Zrm8BPAlIGt+PC+ribX4rJVfBBzmoKiqm17X1np142rKlb96yZcHWo2Gc7eRkPfVt4AxBxvWEtRhRCisZGgphFJK7XX0eppNzX54YrWvsa9rvQJeQu1Os4m1c1qIn3mYFcHG2w0tfPfZ3gnZfXWmoNXmB9zilve3cTVep78LIQQ1kCCmkYkrbiXwMPJlt0vRRIR5GHZCjUALX2cDce/Te9PK1dlvsufxxN54ZdDbD+dXKvvN/XbPQBk5tbexORRnQOxUas4Hp/Be9EnOZuczXc7L9Ta84UQoqmQicKNSFqOMvzUIcANX9emO+xUkrO9Df8a3JrkrDza+DoT5q7jbKbKkEfm4KV0Xh7dgdzCohon6csrLOJacW9Z5+a1N5fJ09mOAWE+bDqRZLiWnVdUa88XQoimQoKaRkQ/n8PT2boTOFXVcyOVva8KCgro4aMl+rIa/QKl4/EZ3P/FPwDsnDWUAHeHar/P7nPXALCzUbN62oCaVbqUMD8Xk6AmMVOGn4QQoqpk+KkR0a96cndsmgn3KsPfEfoVT7wt7eiVdLPXK+u3Q1cAuKdHi1rfUVufr0YvLiWnVp8vhBBNgQQ1jcivB5Rfqn1beVm4Jg2bh6P5nqwjlzOq/czCIi2/HlQ+//1bmw+aaqJ5qc0s49MlGZ8QQlSVBDWNRHpOAVeKN0wc1rFp7cpdVa39jJOHd78UaTg+UoOemrm/x5Kdr8xzKd2rUhv0m3TqJWflk1sg82qEEKIqJKhpJOJSleEIX1d7nOxkKlRFJt8Uwm1dAllwf3d8Xe1ZNrUvAEcvVy+oySss4su/jQn96iKoaenjzM1hPibXEqqw67cQQgiZKNxo6IOaYK+muS1CVTjZ2fDx/d0N5/qsy1fSc8nJL6xyUJiYnmdyXlf7bX3xUE8upubw+Pf7OH01i3PJ2YSWWLIuhBCiYtJT00hIUFN9bo422BUnytPvbl4V13KMr7m/TzDqWp4krGdvo6GNnytdmrsDcOBiWp28jxBCWCsJahoJfVATJEFNlalUKryclRVjJQOUyriamUvM8UQAOgS68d+7wmu9fqV1C/YA4J9zKXX+XkIIYU0kqGkkLkpPTY3og5onf9xParZpYKPT6fjvuuN8FHPK5HphkZaoj7fx0V+nAfB0qp/8QIPb+QGw61xqmbpWVkGRlqy82st6LIQQjYEENY2EDD/VjLeLEtScT8nh9V+Pmtw7m5zNoi1nmRd9kpx8YyCw98I1w4ozULanqA9BXk6083dFq4Nd1eytGbtwBwP+9xeZuQU3LiyEEFZCgppGQKfTkVC8wWFgDTLiNmX6nhqA1QeucD3fuFz6fLJx88t9F9IMx7vOpZo8I7+wbnb+NqdXS8/iOlyr8muz8wo5cDGNtJwC9sWl1XLNhBCi4ZKgpgHTanX8evAKTy87YPiFKns+VU8LT9Nl2Et3xxmOfzsUbzh+4Mt/0Ol0nEnK4r3okyav6VqPG4h2C1KCmupkQT5XIki7ni9DUEKIpkOWdDdg86JP8vHG0ybXHGw1FqpN49bW39XkXD+cdyElm5X7L5vcu5qZx9fbzhvO37o7nIIiLXd0bV7n9dRrF6DU95/ieTUle5pu5HyKMaiRXDdCiKZEemoasG93nLd0FaxG6f2gvtp2niKtjkHvbCpTNjYhk0L9jpjALe39eLBfKO7lbL9QF9r4uWBTvHT8lvc2VWno63CJJIMJGXkVlBRCCOsiQU0DpdPpyKvHORzWzs/NgY3PDubNuzobrq0/kmA4vrNrM/zdlKG9P48lGjYPfXJoGH5u9T+PycFWw6u3dwQgLaegSntB7S4xFyhB9pASQjQhEtQ0UAkZuWWCmvfHRVioNtahpY8zd0Q0M5z/FXvVcPzW3V145x7l87v+aAKXioenLLl56IP9QmlZnFE4vpLDSG+vjzWZHKyfYC6EEE2BBDUN1J7zxlUvo8IDOPDKMO7q1sKCNbIOrg62/CdK6a35Zd8lQNn2wNFOQ0TxROCkzDzOFk+2tfQSev1qtxv11JxKzGTP+VQ+2XTG5HqiDD8JIZoQCWoaqM0nkwB4bGArPpnQAw+nyk8UFRUb0SnAZP8mn+IcNubmzAS61/7mlVURUBzUXEkrv8flXHI2w97fwj0Ldxiu3V7cI3UuOZvd51PLe6kQQlgVCWoamEOX0th74Rr7Lig9NX1LTXAVNefras8793QxnJdcWVQ6wZ6mjvZ5qqyA4vk8SZnl97isOxxvcv50ZJhJ+8Yu3EG2ZBcWQjQBEtQ0IHmFRYz7bCdjPt1uGP6IqMfcKE2Jfsk0gHeJXpvXbu+EPo65r1dQfVerDH3dUirYLqFkXhqALi3cyyz9j03IqP3KCSFEAyN5ahqQi6k5XC8wZrr1c7WvUn4SUXkBJVY0tfN3MRxHdWtOVLfmpGTl1esS7vLoh8ZSssrvqSndi6MfMvv3LW2YX7xv1ZHLGfQIsdykZyGEqA/SU9OAnE/OMTkvkSpF1DK1WsV9vYII83Phwb6hZe57u9hjo7H8fw9v5+Kemqzye2pKTyLWB2xPDQ2jXXHSwSuytFsI0QRY/qe2MCiZCRZAq5Oopi69NaYL0TMG4V5PG1VWh34jzpRs094YrVbHyXQVuQVFXL5mGrDo5wXZaNTc0VWZMPzZ5rOk5xSw9VQSH/x5Eq1EzEIIKyTDTw1IUvEQg61GRUGRjvfGSl6apk4f1KRm51NQpMW2uPfox90XWXBMw6ElB8gusTkngEplnNzsWWLVXMQbGwzHbf1dGRUeWJdVF0KIeidBTQNyrXgy6FNDw5h0U0uc7eXL09T5ONtjZ6Mmv1BLfFouwd5K3pyFW84BsPV0ikn5W9r7mZx7OZvvhapoNZUQQjRWMvzUgFzLKQDA09lOAhoBKHN/9DuMX7xmnHPlUur7I8TbiX8Nbs388d1MrpeX3yi1gtVUQgjRWFUrqFmwYAGhoaE4ODjQp08fdu3aVWH55cuX0759exwcHAgPD2fdunUm9xMTE3n44Ydp1qwZTk5OjBw5klOnTpmUyc3NZdq0aXh7e+Pi4sKYMWNITEysTvUbLH1Pjack2hMlBHkqvTMXi7duOB6fwekk0/lX9/UK5rmR7csEw/Y25v+LX0mTicNCCOtT5aBm2bJlzJgxg1dffZV9+/YRERHBiBEjuHr1qtny27dvZ/z48UyePJn9+/cTFRVFVFQUR44cAZSNG6Oiojh79iyrV69m//79hISEEBkZSXa28Qf3M888w6+//sry5cvZvHkzV65c4e67765msxumazlKUFM6AZxo2lr7KkvOj15Rcs3EHC8bzEe0cDf72s7N3ekR4snd3ZrjYGv8734iMbMOaiqEEJZV5aBm3rx5TJkyhUmTJtGxY0cWLlyIk5MTixcvNlv+ww8/ZOTIkcycOZMOHTowZ84cunfvzscffwzAqVOn2LlzJ59++im9evWiXbt2fPrpp1y/fp0ff/wRgPT0dL788kvmzZvHLbfcQo8ePfjqq6/Yvn07O3furEHzGxb98JPkphEl9Qr1BGBX8e7b+sSM3b2VDU/VKuhcTlBjq1HzyxP9mTeuK+ufGsiLo9oDcOhSOgmV3CRTCCEaiyoFNfn5+ezdu5fIyEjjA9RqIiMj2bFjh9nX7Nixw6Q8wIgRIwzl8/KUCYsODsZkaGq1Gnt7e/7++28A9u7dS0FBgclz2rdvT3BwcLnv29hcSMkmNTsfjVpl8f2GRMPSu6WSNO9EYibbzySz6YSyL1gXLx3fP9KTH6f0xc3hxr17oT7OTB3Ymu7BHgBEm+nxEUKIxqxKs1GTk5MpKirC39/f5Lq/vz+xsbFmX5OQkGC2fEJCAmAMTmbNmsVnn32Gs7Mz77//PpcuXSI+Pt7wDDs7Ozw8PMp9Tml5eXmGgAkgI0Ppui8oKDD805/XxO7z13gv+hQtPB15957waj0jK6+Qoe9tBqBXiAdONjWvV0m11daGzlrb6WavprWvM2eSsrn/838M15s76+jewhVbW9sqtXlIWx/2xaWx7VQS9/VoVhdVrlXW+nU1p6m0tam0E6SttfncyrD4EhtbW1tWrFjB5MmT8fLyQqPREBkZya233oquBsnn5s6dy+uvv17m+oYNG3BycjKcR0dHV/s9AE6mq9gbp+FS0jXWrbtYrWesuaCmUKt0mjnmppSZSF1batrWxsIa2xmgVnOmRMdqZDMtfo7Va2t6qgrQcPR8AuvWXa7FWtYta/y6lqeptLWptBOkrTWRk5Nz40LFqhTU+Pj4oNFoyqw6SkxMJCAgwOxrAgICbli+R48eHDhwgPT0dPLz8/H19aVPnz707NnT8Iz8/HzS0tJMemsqet9Zs2YxY8YMw3lGRgZBQUEMHz4cNzc3CgoKiI6OZtiwYdjaVn9iblhiFguObScPO0aNGlLl1+t0OpZ+vRdQ5ksM6N6RUX2Dq10fc2qrrQ2dNbez6FA825YfBuCBPkG8OKJNtdsaGp/BFyd2kl3N79n6Zs1f19KaSlubSjtB2lob9CMtlVGloMbOzo4ePXoQExNDVFQUAFqtlpiYGKZPn272Nf369SMmJoann37acC06Opp+/fqVKevurkx2PHXqFHv27GHOnDmAEvTY2toSExPDmDFjADhx4gRxcXFmnwNgb2+Pvb19meu2trYmn+zS51UV6OkMQNr1AnQqDXblLKE1JyUrjxEfbCG5xL4+7k72dfaNX9O2NhbW2M6B7fwBJaixs7ExtK86bQ31dQMgNbuAQp0aRzvNDV7RMFjj17U8TaWtTaWdIG2t6fMqq8qrn2bMmMHnn3/ON998w/Hjx3niiSfIzs5m0qRJAEycOJFZs2YZyj/11FOsX7+e9957j9jYWF577TX27NljEgQtX76cTZs2GZZ1Dxs2jKioKIYPHw4owc7kyZOZMWMGGzduZO/evUyaNIl+/frRt2/fqjahVrk72mKjVtLSL9h4mqsZlV9R8lfsVZOABqBrkPlVLKJp83GxJ7KDMjft9oiabW/g7mhrSN5XejNMIYRozKo8p2bcuHEkJSXxyiuvkJCQQNeuXVm/fr1hMnBcXBxqtTFW6t+/P0uWLGH27Nm8+OKLhIWFsWrVKjp37mwoEx8fz4wZM0hMTCQwMJCJEyfy8ssvm7zv+++/j1qtZsyYMeTl5TFixAg++eST6ra71qjVKrxd7EjMyOPDmFN8+fc5Dr823GT/nfIUldpUcOEDPWjj51pXVRWN3Mf3dyMhPZdQH+caT8TzcbEjK6+QlOx8WvnWUgWFEMLCqjVRePr06eUON23atKnMtbFjxzJ27Nhyn/fkk0/y5JNPVvieDg4OLFiwgAULFlSprvWhmYcjiRnKSqusvEJiEzLpEOh2w9eV3H/n5jAfRnY2Pz9ICAAHWw2hPs618ixvF3vOp+SQkiV7QAkhrIfs/VQLhpbaRHB/XFqlXqfflXtgW98ye/YIUZe8ixM8lh7+FEKIxkyCmlpwT48gk/ODF9Nu+JrcgiK+3XEBgFva+Za78aAQdcHbRZlEnyJBjRDCikhQUwsC3B34ZEJ3mrkrWZHjUm+8pv7I5XTDcY8QrzqrmxDm+LgoQfTVTNkqQQhhPSSoqSWjwgP5sHgI6XIldkC+Wjyfpn2AK+Hl7NsjRF0J9lISUJ4ttdu3EEI0ZhLU1KIWnsqeTVfSrpdZ2VSaful3y1qa+ClEVbT1V1bZnbqaZeGaCCFE7ZGgphb5uTpgo1ZRqNXdsFtf31Pj51o2QaAQda2NnwsAyVl5XMuWeTVCCOsgQU0t0qhV+BRPwCy5XNscfVDjK0GNsABnexuaeyg9i9JbI4SwFhLU1DI/t8oFNacSMwEI9pbhJ2EZYf5Kb83J4u9FIYRo7CSoqWW+xT01VysIavILtRyPV36RRMgkYWEh7QKUeTWHL6XfoKQQQjQOEtTUssr01MSl5pBfpMXZTmNYhSJEfevXyhuAv08nW7gmQghROySoqWV+rkqumu92XuCfsylmyySkK5OIm3s6VmqPKCHqQrcgT0BJQZBbUGTh2gghRM1JUFPL9Eu0kzLzGLdoJ9ripd05+YV8suk0vx+O54Ev/wEgwN3RYvUUwsXBuPVbVl6hBWsihBC1o1obWorylc47M+S9TUwb0oYjl9MN2yLoZebWbKdlIWpCo1bhYm9DVl4hmbmFhpV7QgjRWElQU8ta+ZoGNRdScnju50Nmy/YKle0RhGW5OuiDGgmwhRCNnww/1TJXB1u+n9znhuU6NXNj+i1t6qFGQpTPxV75uyYrV4afhBCNnwQ1dWBAmI/Z624l5jDMHt0RNwfb+qqSEGa5Fn9PZkhQI4SwAhLU1JFvH+lN1yAPHhvUiuYejnQP9uD7R409OF7OdhasnRAK1+LAWoafhBDWQObU1JGBbX0Z2NYXgBdGtkelUhlWQgE083CwVNWEMNCvgJLVT0IIayBBTT3Q56JRq1X8/fwQCop0hr+QhbAkfQbs88nZFq6JEELUnAw/1bMWnk5lln0LYSl9i7MKbzklWYWFEI2fBDVCNGE9QpSswudTsskv1Fq4NkIIUTMS1AjRhHk722GnUaPTQWJGrqWrI4QQNSJBjRBNmFqtIsBdmbR+MTXHwrURQoiakaBGiCYuwE0Jau7/4h8L10QIIWpGghohmrhgbyfDcUGRzKsRQjReEtQI0cS9PaaL4fjfS/ZbsCZCCFEzEtQI0cSp1SrD8fqjCeh0ugpKCyFEwyVBjRCCN+/qbDhOkFVQQohGSoIaIQQT+oQQ5ucCwMnELAvXRgghqkeCGiEEgGFpd3JmnoVrIoQQ1SNBjRACUBLxAaRm51u4JkIIUT0S1AghAPByVja3TJGgRgjRSElQI4QAwNtF31Mjw09CiMZJghohBACeTjL8JIRo3CSoEUIA4FU8p0aGn4QQjZUENUIIoOTwkwQ1QojGSYIaIQRg7KlJzZKgRgjROElQI4QAjEu6M/MKySsssnBthBCi6qoV1CxYsIDQ0FAcHBzo06cPu3btqrD88uXLad++PQ4ODoSHh7Nu3TqT+1lZWUyfPp0WLVrg6OhIx44dWbhwoUmZwYMHo1KpTP49/vjj1am+EMIMNwdbNMX7QF3LLrBwbYQQouqqHNQsW7aMGTNm8Oqrr7Jv3z4iIiIYMWIEV69eNVt++/btjB8/nsmTJ7N//36ioqKIioriyJEjhjIzZsxg/fr1fP/99xw/fpynn36a6dOns2bNGpNnTZkyhfj4eMO/t99+u6rVF0KUQ61WGVZApciybiFEI1TloGbevHlMmTKFSZMmGXpUnJycWLx4sdnyH374ISNHjmTmzJl06NCBOXPm0L17dz7++GNDme3bt/PQQw8xePBgQkNDmTp1KhEREWV6gJycnAgICDD8c3Nzq2r1hRAVkKzCQojGzKYqhfPz89m7dy+zZs0yXFOr1URGRrJjxw6zr9mxYwczZswwuTZixAhWrVplOO/fvz9r1qzhkUceoVmzZmzatImTJ0/y/vvvm7zuhx9+4PvvvycgIIDbb7+dl19+GScnJ7Pvm5eXR16e8a/NjIwMAAoKCgz/9OfWrqm0tam0E+qurZ5Oyo+Eq+nXG8znUb6u1qeptBOkrbX53MqoUlCTnJxMUVER/v7+Jtf9/f2JjY01+5qEhASz5RMSEgzn8+fPZ+rUqbRo0QIbGxvUajWff/45AwcONJS5//77CQkJoVmzZhw6dIjnn3+eEydOsGLFCrPvO3fuXF5//fUy1zds2GASCEVHR9+44VaiqbS1qbQTar+teRlqQM22PQewuby/Vp9dU/J1tT5NpZ0gba2JnJycSpetUlBTV+bPn8/OnTtZs2YNISEhbNmyhWnTptGsWTMiIyMBmDp1qqF8eHg4gYGBDB06lDNnztC6desyz5w1a5ZJD1FGRgZBQUEMHz4cNzc3CgoKiI6OZtiwYdja2tZ9Iy2oqbS1qbQT6q6tu4qOsz/lIgEhYYyKbFNrz60J+bpan6bSTpC21gb9SEtlVCmo8fHxQaPRkJiYaHI9MTGRgIAAs68JCAiosPz169d58cUXWblyJaNHjwagS5cuHDhwgHfffdcQ1JTWp08fAE6fPm02qLG3t8fe3r7MdVtbW5NPdulza9ZU2tpU2gm131YfVwcA0nILG9znUL6u1qeptBOkrTV9XmVVaaKwnZ0dPXr0ICYmxnBNq9USExNDv379zL6mX79+JuVB6ZrSl9fPb1GrTaui0WjQarXl1uXAgQMABAYGVqUJQogK6LMKJ6TnWrgmQghRdVUefpoxYwYPPfQQPXv2pHfv3nzwwQdkZ2czadIkACZOnEjz5s2ZO3cuAE899RSDBg3ivffeY/To0SxdupQ9e/awaNEiANzc3Bg0aBAzZ87E0dGRkJAQNm/ezLfffsu8efMAOHPmDEuWLGHUqFF4e3tz6NAhnnnmGQYOHEiXLl1q63MhRJPXLcgTgL9PJXMtOx/P4tVQQgjRGFQ5qBk3bhxJSUm88sorJCQk0LVrV9avX2+YDBwXF2fS69K/f3+WLFnC7NmzefHFFwkLC2PVqlV07tzZUGbp0qXMmjWLCRMmkJqaSkhICG+++aYhuZ6dnR1//vmnIYAKCgpizJgxzJ49u6btF0KUEN7CnRBvJy6k5HA8PoP+bXwsXSUhhKi0ak0Unj59OtOnTzd7b9OmTWWujR07lrFjx5b7vICAAL766qty7wcFBbF58+Yq11MIUXUtfZy5kJLDhdQc+lu6MkIIUQWy95MQwkSotzMA51OyLVwTIYSoGglqhBAmWng6AnD52nUL10QIIapGghohhAkfFyUVwrUc2SpBCNG4SFAjhDDhZdj/yfrTugshrIsENUIIE/qg5ppsaimEaGQkqBFCmPAssVO3TqezcG2EEKLyJKgRQpjwclKCmvwiLdn5RRaujRBCVJ4ENUIIE452GpztNAAkZsh2CUKIxkOCGiFEGSH6XDXJkqtGCNF4SFAjhCijpa8S1JyToEYI0YhIUCOEKCPU2wmACyk5Fq6JEEJUngQ1QogyvJ0lAZ8QovGRoEYIUYaHky0A6dclAZ8QovGQoEYIUYY+qEnLkaBGCNF4SFAjhCjD3VHJVZN2XYafhBCNhwQ1QogypKdGCNEYSVAjhCjDszircGZuIScSMi1cGyGEqBwJaoQQZbg72mKjVgHwy75LFq6NEEJUjgQ1QogyNGoV04a0AeBK2nUL10YIISpHghohhFlt/V0B2f9JCNF4SFAjhDArwF1JwLf7/DXiJLOwEKIRkKBGCGFWMw9Hw/Gag5ctWBMhhKgcCWqEEGYFujuiUuYKczUzz7KVEUKISpCgRghRrpdHdwQgNVuS8AkhGj4JaoQQ5fJ2UfLV/HYonsxcScQnhGjYJKgRQpTLx8XecPzvH/dbsCZCCHFjEtQIIcrl52oMajadSCK3oMiCtRFCiIpJUCOEKFcbPxeejgwznMuWCUKIhkyCGiFEuVQqFU9HtuXmMB8AjlxJt3CNhBCifBLUCCFuqHNzdwCOXsmwcE2EEKJ8EtQIIW6oczMlqFnyTxxHpbdGCNFASVAjhLihzs3dDMd3LdhuwZoIIUT5JKgRQtxQsJeT4Ti/SGvBmgghRPkkqBFC3JBKpaJbsIelqyGEEBWSoEYIUSmfT+xpOM4vlN4aIUTDI0GNEKJSvJzsUBdvcHktR/aCEkI0PBLUCCEqRa1W4eWsZBhOkl27hRANULWCmgULFhAaGoqDgwN9+vRh165dFZZfvnw57du3x8HBgfDwcNatW2dyPysri+nTp9OiRQscHR3p2LEjCxcuNCmTm5vLtGnT8Pb2xsXFhTFjxpCYmFid6gshqinEW5kwfDJRMgsLIRqeKgc1y5YtY8aMGbz66qvs27ePiIgIRowYwdWrV82W3759O+PHj2fy5Mns37+fqKgooqKiOHLkiKHMjBkzWL9+Pd9//z3Hjx/n6aefZvr06axZs8ZQ5plnnuHXX39l+fLlbN68mStXrnD33XdXo8lCiOrq0kLJV3PokuSqEUI0PFUOaubNm8eUKVOYNGmSoUfFycmJxYsXmy3/4YcfMnLkSGbOnEmHDh2YM2cO3bt35+OPPzaU2b59Ow899BCDBw8mNDSUqVOnEhERYegBSk9P58svv2TevHnccsst9OjRg6+++ort27ezc+fOajZdCFFVxqAmzbIVEUIIM6oU1OTn57N3714iIyOND1CriYyMZMeOHWZfs2PHDpPyACNGjDAp379/f9asWcPly5fR6XRs3LiRkydPMnz4cAD27t1LQUGByXPat29PcHBwue8rhKh9XVp4AMp2CQWSr0YI0cDYVKVwcnIyRUVF+Pv7m1z39/cnNjbW7GsSEhLMlk9ISDCcz58/n6lTp9KiRQtsbGxQq9V8/vnnDBw40PAMOzs7PDw8KnxOSXl5eeTlGSczZmQoe9YUFBQY/unPrV1TaWtTaSdYrq0t3OxwdbAhM7eQwxdTCS/eE6ouydfV+jSVdoK0tTafWxlVCmrqyvz589m5cydr1qwhJCSELVu2MG3aNJo1a1aml6ey5s6dy+uvv17m+oYNG3ByMmZHjY6Orna9G5um0tam0k6wTFuDHdUczVXz9brtDG2uq7f3la+r9Wkq7QRpa03k5ORUumyVghofHx80Gk2ZVUeJiYkEBASYfU1AQECF5a9fv86LL77IypUrGT16NABdunThwIEDvPvuu0RGRhIQEEB+fj5paWkmvTUVve+sWbOYMWOG4TwjI4OgoCCGDx+Om5sbBQUFREdHM2zYMGxtbavyaWh0mkpbm0o7wbJtTXA/z9H1J8lxCmDUqG51/n7ydbU+TaWdIG2tDfqRlsqoUlBjZ2dHjx49iImJISoqCgCtVktMTAzTp083+5p+/foRExPD008/bbgWHR1Nv379AONwkFptOr1Ho9Gg1Spj9j169MDW1paYmBjGjBkDwIkTJ4iLizM8pzR7e3vs7e3LXLe1tTX5ZJc+t2ZNpa1NpZ1gmbZGBHsBcDwhq17fW76u1qeptBOkrTV9XmVVefhpxowZPPTQQ/Ts2ZPevXvzwQcfkJ2dzaRJkwCYOHEizZs3Z+7cuQA89dRTDBo0iPfee4/Ro0ezdOlS9uzZw6JFiwBwc3Nj0KBBzJw5E0dHR0JCQti8eTPffvst8+bNA8Dd3Z3JkyczY8YMvLy8cHNz49///jf9+vWjb9++VW2CEKIGOjZTduy+nHadtJx8PJzsLFwjIYRQVDmoGTduHElJSbzyyiskJCTQtWtX1q9fb5gMHBcXZ9Lr0r9/f5YsWcLs2bN58cUXCQsLY9WqVXTu3NlQZunSpcyaNYsJEyaQmppKSEgIb775Jo8//rihzPvvv49arWbMmDHk5eUxYsQIPvnkk5q0XQhRDW4Otvi52nM1M48LKTkS1AghGoxqTRSePn16ucNNmzZtKnNt7NixjB07ttznBQQE8NVXX1X4ng4ODixYsIAFCxZUqa5CiNoX7OXE1cw84lJziAjysHR1hBACkL2fhBDVEOylrCC8eK3yqxKEEKKuSVAjhKiyIH1QkypBjRCi4ZCgRghRZfqemjgJaoQQDYgENUKIKgv2lqBGCNHwSFAjhKgyfU/NlbRc2QNKCNFgSFAjhKgyXxd77GzUFGl1xKflWro6QggBSFAjhKgGtVpFkKcjIENQQoiGQ4IaIUS1yLJuIURDI0GNEKJaSq6Ayi/U8r/1sTz/8yFyC4osXDMhRFNVrYzCQggRVCKo2XwyiU83nQGgZ6gnY3sGWbJqQogmSnpqhBDVElwiAd+Ry+mG6zHHr1qqSkKIJk56aoQQ1aLPVXPoUjqHLhmDmq2nksgrLMLeRmOpqgkhmijpqRFCVEuot7PJuUatAiA7v4itJ5MtUSUhRBMnQY0QolocbE17YhY/3IveLb0AePTbPaTnFFiiWkKIJkyCGiGsUV5WvbzN7NEdUKvgu8m9GdTWFzuN8UfKwUtp9VIHIYTQk6BGCGtz/m94Kwg2vVXnbzV5QEti59zKzWG+AGTmGntnkrPy6vz9hRCiJAlqhLA2f7wEOi1smgvaut2XSaVSYWdj/DHyf8PbGY4vpl6v0/cWQojSJKgRwppkp0D8AeP5tvfr9e0HtvVlYr8QQDINCyHqnwQ1QliTXx4xPY95A4rqd8Ju92BPQMlfI4QQ9UmCGiGsScLhste2z6/XKgR5KRtd/nMulTNJ9TNhWQghQIIaIaxHYR7kpCjHD64yXr+wTemxOfxzvVQjyNPJcDzus53k5BfWy/sKIYRkFBaisctOgXX/ByjJ79DYQ6vBMGk9fDUSTv+p/ANofxvYOtRpdXxd7Q3HyVl53Db/b4Z19KdPSy9uae9fp+8thGjapKdGiEZMvXcxvNMKjq6EoyuUi26BoFKBX4eyL/h6FOh0dVonlUrF/peHYatRgqyzSdl8tvksj3y9p07fVwghJKgRopFyzE9Gs/65sjdaDSku4AFuLUzvXd6r5LGpY57OduyZPYxuwR51/l5CCKEnw09CNDbXLqBZMZXhF3car937Ldi7gYsf+HU0XvfvCBmXTF9/8EdoeXOdV9Pd0ZY5d3bmtvnGIConvxAnO/mxI4SoG9JTI0RDlHIGUs+BtqjsvZWPoS4Z0PSdBh3vhNZDwL+TMvSk17yn8bjLOOXjpd11U2czOjd357vJvQ3nyZn59fbeQoimR4IaIRqKc1vhrRB4zR3md4ePusLW90zLaLVweZ/ptTZDy39m+D2gtgEHd+j/pHItLa7O59WUdHOYLy08lWXeSVm59fa+QoimR4IaIRqKb26D3DTTaxvfND3PSoSiUnsqeYSU/0zv1vDIBpgcDb7tQKWGwlzlOfWomYcS1Gw7nVKv7yuEaFokqBGiIfMIVnbcPvkH5KTCtXMA6NyDOdz8for6PwM+bSp+RoseSkCjsQW35sq1a+frtt6l3NNdmbC87nB8vb6vEKJpkRl7QtS1uJ3KEFCLnuWXKSix+eN9S8CzJXzaTxkqinkddi0C7zYQ3BcAnXcYZ91H0n7IKDRVqYtPGKRfhKRYw7PqQ7/W3oCyvLuwSIuNRv6eEkLUPvnJIuqftghi5sCp6Dp8D62SYdfSspJg8Qj4YijkZpRfTt9zYu8G7UaBa4Dx3q5FyseU07D/ewC0vR+rXn18i3PXXI2t3uurqbmHI462GvKLtJxJyq7X9xZCNB0S1Ij6dXAZvOEFW9+FH+6pu/f55RH4jx98dzcUWTBN/08TjccX/ym/nD53TEAXZfWSo2eFj9WF3FS9+vgXL/e+vLd6r68mtVplyFnzzY7z9freQoimQ4IaUb92f256fu28MsRSmxKPKBl2Ac7EwIm1tfv8yko+DXHbjefntpje1+lg3XOw4jHY+7VyLSxS+ahSwdTN5p/bvCfY2Ju/dyOtb1E+XtoNmfU7WXhcryAAjsdX0GMlhBA1IEGNqD/XzpfNkfJhBMzvCUkna+UtHAquYfPTBNOL+gCnvh343vT8/N9wbA388ijk5yg9N7s+g0NLlUAMoM0wY/lmXeGpg9B7Ktz9hfH6gyuqXye3ZtC8B6Cr92BPv6w7OasBDAsKIaySBDWifhRcVwIYAFQQ3N94ryjPOG+khrqf/wxVxmXl5KanlY9HV8Kh5bXy/CrR74o98n/Kxyv74KcH4fBy2LMYTvxuWt4/XEmeV5JnKIx6B7qMhQm/wLTdSs6Zmmg/Wvl4/LeaPaeKvJ2V3qWULEnAJ4SoGxLUiPqRcsZ4HD5WyX5b0u7P4Y+XzGfQTT0HSydAwuGK3yMzAd+sY8qxrTPc8rKyYghgxaOQmVD9+ldVXqayygig63gI6lv2fuJR5Xj0PJh5FiatM80GXFpYJPi2rXnd2t+ufDy3peLJy7XMp3j37pz8InLyC9lwNIEtJ5Pq7f2FENZPghpRP1JLBDXD5ygTYkvb8bHSg1FS8mkls27sb7BoCOz8FD7uBcdWm5bLiEd1ucTQ1tOHQGMDo0tk5H2vHSy5r8ZNqZRrF5SPjp5Kz8qod0zvn/4TThev/vLvBM7e4OBWP3Xzbavkq9EWGAOreuBsp8HBVvmRszE2ianf7WXi4l1sPZXEuWRZESWEqDkJakT90PfUhN+rLFcO6We+XOn5L6v/ZTzWFsD6FyD5pLKqSKstfs0qmNcBm18mKcXCRoCzj3Kv1WDo+YjxGSd/VyblJhypaYsqVpwkD89Q5WNgF3gpAbo9qJxf3qN89GoFgRFlXl7n9JteJh2vt7dUqVSE+bkCMG2JcauHB7/cxdiF28t7mRBCVFq1gpoFCxYQGhqKg4MDffr0YdeuXRWWX758Oe3bt8fBwYHw8HDWrVtncl+lUpn99847xr9uQ0NDy9x/6623qlN9YQkXin9p6eeMOLgrGyzau0GvKcZycTuN+WXiD1W8DDq5eHLx6T8B415GOn0goXfTU9Csu/H816dg4U3ww72mSe9qS2E+bJ+vHPu0M163dYROUcZz9yB4NEa5Xt/82isfbzSkV8v+b7j54bPkrHwS0mVfKCFEzVQ5qFm2bBkzZszg1VdfZd++fURERDBixAiuXr1qtvz27dsZP348kydPZv/+/URFRREVFcWRI8a/lOPj403+LV68GJVKxZgxY0ye9cYbb5iU+/e//13V6gtLKCqA81uV47DhxutRn8Lz5+HWt+HBlcq+RLoiSL8Eicfg8yFmH2dwpfiv/VIp/3U+7U3LeYbC1I1lX3/qD2UTydp2aJkxGOtf6nvUPdh43GoQOHnV/vtXhj7Pzek/63Vzy8Ht/Nj07GAe7h9a5t4TP+zltTVHKdLWX32EENalykHNvHnzmDJlCpMmTaJjx44sXLgQJycnFi9ebLb8hx9+yMiRI5k5cyYdOnRgzpw5dO/enY8//thQJiAgwOTf6tWrGTJkCK1atTJ5lqurq0k5Z2fnqlZfWELqWWUTRTsX8OtgvK7WFP9TK/lT9L0am/+nLDfWFifNu2sRPHcOgvqYPnfVE5BxBeIPmlzWtRtlvh7dHyp7TT9MVJv0vVK9p0JAZ9N77s2Nx07etf/eldVyENg4KjmCLlbc01rbQn2cee2OTnQvTsantz8uja+3n2djrPk/kIQQ4kaqtPdTfn4+e/fuZdasWYZrarWayMhIduzYYfY1O3bsYMaMGSbXRowYwapVq8yWT0xMZO3atXzzzTdl7r311lvMmTOH4OBg7r//fp555hlsbMw3IS8vj7w8Yz6MjAxllUdBQYHhn/7c2lm0rfnZ2CyfhArQeodRVFh+dl+NRzDqpONKT0exoqGvoe14t3Iy9gdUpzegSruAZkvxMul5HUyekeLcFkdbNzDX1sEvowobia71UNR/vY5m5wK0lw9QlJ5YKz0mqtPR2CwbbzgvbDkEXel6qOyw1bdNp0Jbza9Jjb+mKls0He5AfXgZRcfWoA3sfuPX1LIP7u3Cyv1XSMnO59udxgSMCek5Ju0q2da/T6dw6dp17uvVot7rWx+ays+lptJOkLbW5nMro0pBTXJyMkVFRfj7+5tc9/f3JzbW/F4yCQkJZssnJJhfXvvNN9/g6urK3XffbXL9ySefpHv37nh5ebF9+3ZmzZpFfHw88+bNM/ucuXPn8vrrr5e5vmHDBpycnAzn0dF1uP9QA2OJtoYm/UnEVWWFTVy+BwdLzacqqW2WKx1KXfv7EqSZvMaFwLQcepcqd7j5/WhVtlz0GkDRjdp5cj0hydl0BdSHllB0ZAWHWzxInq07V93MrMqqpDv3G7dEyHBowaYTuehOlm1vL/ee+GccJCY9mOsVfD4qoyZf09YpajoD8bF72JtXs3pUVyhw/JKakp3Gs1cf43ysMtennbsOu+IdOzdsiObpncqPrMzzh2huxR21TeXnUlNpJ0hbayInJ6fSZRvcLt2LFy9mwoQJODg4mFwv2dvTpUsX7OzseOyxx5g7dy729mVTxs+aNcvkNRkZGQQFBTF8+HDc3NwoKCggOjqaYcOGYWtrW+b11sSSbdX8ug4uKcfNx79Pc/cK/sIuHIp2aQLqC8o+SDr/cPrfM71sOd1Iira5oNk8Vzn17UD7hz+ioKCA85VtZ1ZP+PBrAGy1uXSPU7ZvKJi2DzyCK3hhBfYbDx0nr+HW8p6jHYE2P4shNUiiVxtfU9XRXFj1I81cwX9UOUN29cDlVDLrv91ncu2LE0okM6F3EJeSc3DJvcrMe26GncrQXodufRjQxoLDd3WkqfxcairtBGlrbdCPtFRGlYIaHx8fNBoNiYmme8YkJiYSEBBg9jUBAQGVLr9161ZOnDjBsmXLytwrrU+fPhQWFnL+/HnatWtX5r69vb3ZYMfW1tbkk1363JrVe1s3v6NsAQBw3xJsfVpWXN7WFiatVVYn7f8B1ai3y6/vkBeU3C5HVqAaNLPqX1PP5spS6lLzcWxjV8HN/2f+NemXlfkyx1fDHR+Do0f5TfFuqcwVMn8X7B3KuVc1Nfqaeip7MamzElBb8P/ALR0C+PC+rqRfL+CV1aZ5c37YVZzAEA3DLmcZrl8v1Fn1/9um8nOpqbQTpK01fV5lVWmisJ2dHT169CAmJsZwTavVEhMTQ79+5vOO9OvXz6Q8KF1T5sp/+eWX9OjRg4iIG+ftOHDgAGq1Gj8/v6o0QdSnjf8xHrfoVfnXjX5fWRUV0r/icr2nwCO/GzdprKq7Py977Wo5eVt2LoT3OyqZiY//CltKJdPT58wBJVgqN6BpQFwDlY8Z8fW6Aqo0lUrFnV2b82DfEPq3Lr/35emfDhmOU7JlqwUhRFlV/sk7Y8YMPv/8c7755huOHz/OE088QXZ2NpMmKYnPJk6caDKR+KmnnmL9+vW89957xMbG8tprr7Fnzx6mTzcdVsjIyGD58uU8+uijZd5zx44dfPDBBxw8eJCzZ8/yww8/8Mwzz/DAAw/g6elZ1SaI+pBfYgzU1glcqhB8qtVg71L7dSrNtx28nAz3/wRjv1auJZmfG8aZv0zPj6yAAz8ag4GT6433HtlQ61WtE/qgpigPrl+zbF1QgpslU/reuCDw8qojHLyYVrcVEkI0OlUOasaNG8e7777LK6+8QteuXTlw4ADr1683TAaOi4sjPj7eUL5///4sWbKERYsWERERwc8//8yqVavo3Nl0qevSpUvR6XSMHz+e0uzt7Vm6dCmDBg2iU6dOvPnmmzzzzDMsWlQ7myCKWqDTwd/vw7aPlPOS2yI8/rdl6lQZGltoOwICuyrnSSdMAzI9/T5OeplXYNXjxk0pt31ovGdbO0NLdc7WARyLV31lxldc1oLujAg0e/3NdfWXDVkI0ThUa6Lw9OnTy/S06G3atKnMtbFjxzJ27NgKnzl16lSmTp1q9l737t3ZuXNnlesp6lHiUfjzNeW4w22wvTgPUVBf8G5tsWpVmmcouLWAjEsQtwPaDDXe0+mUXDsA9y+HJSW+l4/8Au1HGe/3fqzeqlwr3JrB9VRlCKr0DuEW8lC/EL7ZcQF7GzU/PNqH5u52bI29Qmqe6Wafu86l8sM/F5jQJ8RCNRVCNDSNYOBfNArHfzUefzbIOEG4v/ngt8FRqaD1YOX4bKnsw0d+UZIHArS8GR75w3jv0i7IugrZxQnjbnmpzqtaq1yLJ+xnXrFsPUp4cXQH5t0bwd6Xh9Ez1AsfF3te7V7Eisf7MO/eCPbMjuTJW5Td19/49RjX84v4Ze8l/vXDXnILzOzyLoRoMiSoEbVDv0EjQF6J5XdtIuu/LtXVqnhbhu3z4fNbIDtFOT9YHKC1Hans0xTcV5nIrFIrGXl3FPdKNeum7GnVmOiX2KecqbhcPbK30XB39xa42Jt2JIc3d+fu7i3wcbHnmWFt8XGxI69Qy4KNp/m/5QdZdziB73desFCthRANgQQ1ouZ0Oriyv+z1bg9aZrPG6iq5QuvyXmVfpNSzxRtmAkNeNN539ITg4hV8+vk04ffWTz1rU/Oeysc48xnBGyqVSsWANspO7B9vPG24fiVNNsUUoimToEbUXG4a5KSYXhv3A9z5sdniDVbpxIBb3oaPugE68O0A/qX2cSq9WWVn0w1YG4XQAcrHi7vK5Oxp6EaFl51AXFCkNVNSCNFUSFAjai6teN8eR09oNwq6PQDtR1u2TtWh1piepxh7ABj2Rtn77W6F2z8CVDBsDriabgfSKHi1hPa3ATo4utLStamSW9r7MbqLaWCTmGHsqbmeX0ReocyxEaIpaXDbJIhGJj8HVhSv+PFqBeN/tGx9aqrvv2DnJ6bXgvtBq0Hmy/d4CLpOAE0j/q/UdiTE/gYXGtcQlI1GzYL7u9Ol+Rnm/q7kFzqTlMVPey6SmJ7LZ1vOkpVXyNSBrXhxVOldxYQQ1kh6aoTRua1lk8zdyP7vIKk4X0h190xqSEb8F16Ig8jXlBwut38Ij6wHm7Jbbhg05oAGjJmbr+yDgsY3J2XSTS2J6toMgDNJ2Tz38yHeiz5JVp6yI/yiLWfRai2XMVkIUX8kqGlqdDrY9TkcW2N6vSAXvrkNvrvLuOqnMpJOGI+7PVA7dbQklUpZwTTgGXj+HPR42NI1qntercDFH4ry4fxWS9emyuxs1Lw/riteznbllonPaHzBmhCi6iSoaWrOboJ1z8JPD4K2xHwDffI4UPZsOrupcs/Tp9fvdHfjWr4tjFQqJasywNZ5lq1LNalUKu7tGVTu/UFvb2TtoYabNVkIUTskqGlqYtcajzOKE679/jx8WmKD0T2L4ds74Xqa+Wec3wZ/vARnNxsnCXe6q06qK+qJPhNywiGLbm5ZE9NvaUMLT9MUAp2auQFQqNUxbck+S1RLCFGPJKhpai7vNR5/0BnidsKucvbQ+l8I/Pq06bXkU/D1KCXh3Ld3GJPueUqq+kbNJ0xJJpifpWRIboRc7G347d8D2PDMQMO1RRN7mpTRNdKATQhRORLUNCWFeZBw2PTa4hGgK87t4R1W9jV7vzLd4PHoqrJlVBrwaVdr1RQWYGNvzNOT2nCyC1eVh5Mdbf1d2fjsYDbPHExzD0cWP2wMbK7lFJh9XZFWx0+7L3Il7Xp9VVUIUQckqGlCVFePgrb4h7p9qXT+HaPg33vgzgXg7Aej3jXe+y5K+Rh/0Ljcuc/jxvt2Lo1nZ2pRPq/ijUcb0JYJ1dXSx5kQb2cAbmnvj5+rsnotLtXMDuzAV9vO8dwvhxi3qOEua1+1/zLf7TgvvU1CVECCmiZEpd/KoM0wmBUHPR8x3tTvpN3tAZh5CnpPMd67+A/8eD98NlDZ0RngpqchsKty3PPhOq65qBf674FG3FNTnpY+SoBz5mqW2fu/HlTml11Mvd4gl39/suk0Ty87wMurj7IvLs3S1RGiwZKgpglRXd6tHDTvoXz0bW+86dmy7Atu/9B4fGKt6T23QLhrIdz5CQx9tXYrKizDinpqSmsX4ArAycRMs/fzCo3bKxy+nE5OfiFTvt3DO3/EVur5VzNzeeTr3Ww7nVzzypaSmVvAB9GnDOeyikuI8klQ04SoLu5SDoL7KB9bDTbe9OtY9gU9Hob/O1H2+pCXil/TAbpNKLt9gGicfIvnRZWed2UF2vorQc1nW86SkWs6r+b01SxiE4zBzp0LttHxlT+IPpbIgo1nDEn89PbFXePez3bwxVZjGoTZK4/wV+xVJnzxT7l1OHQpjWHzNrPpRNUmYm84mkh+iT2t4lKzq/R6IZoSCWqaCIf8VFTpccoKF/1u1L7t4LEtcO930Ly7+Re6BpieP7gSBsyo28oKy2jRE1DBtXOQmWjp2tSqgWG+huNb3t1ETr4xUNl7QRlStdWozL720MU0k/Mv/z7HrnOp/GftcXILitBqdZwuMaxV3pyXuz7ZzqmrWUz7wXRpeZFWx4p9l7hqJkHg19vO8X/LlY1G2xf3Nl26JpOZhSiPBDVNgU5HaMpG5di/E9i7Gu8FRkDHO5QEbOVpN0r56BECrW9p/NsCCPMc3Ev01hyybF1qWbC3E809lBw2yVn5dHzlD6Z8q6QjOJesTB4e3zuYUeHGIN7HRclQfORKusmzSq6Qav/yeqZ8u8dk+GrZ7otl3r9Iq6OoeK7O9QLTTTZX7b/MjJ8O0u+tv3hjbSzRl1XodDr2nE/ltV+PGcpNubkVABdTc8zO+9HpdA1yPpAQ9UmCmiZAdfJ32iWsVk5Cb676A6I+hX7TYcLy2q2YaHi82ygfU89Zth51YP3Tpt/70ccSSb9ewPlkZTgn1NuZBfd35/aIZozuEsh9vZS9zP67LpZb3t1EclYeAHEppiuoYmKvcrlEoLPVzLyaAyV6ezyd7EjLyefOBdt449djbD2VBCiBz3c74/gtTsOBS+ncs1BZieXtbMc3j/TmtohAnO00ZOcX8e2O8ybP1+l03LdoJ6M+2kphiaEqIZoaCWqaANWZP40nvR6t+gMcPWDEm8a/4oX18iqeMF5y2wwr4epgy4uj2jOso7/h2qVrOZxPUYKalj7OqFQq5o/vxoL7u9Paz9lQ7mxyNh/FnGLP+VRSsvMrfB9zw0gl59GkZOfT9Y1oDl5MY/G2c2af95+1xgnKTwxuzaC2vtjbaHhupDK5/811xzl8ydiDlH69gH/OpRKbkGlojxBNkQQ1TYC6OItw0aAXjct2hTDHSxni4Jr19dQATB3Yms8n9iSihZKn6ejlDMMk4VAfZ5OynZqZ5nL6dscFQ++Ji70N/Vt742RnnCTfv7U3AAkZubwffdLQm6LT6dhwtPw5SltPle3ZOXQ5w3Ac1a254XhivxAGtPGhoEjHqgOXDde3lHhGarZxIvTBi2ks+SdOctuIJkOCGmt3aS+qq0cpUtmg7fagpWsjGjpP6+2pKamFpxMAz/1yqMQ1032j2vq7MnOE+d7Je3q0YMmUvmyaOdhwrV8rJai5mHqdD2NO8crqo+w+n8rvRxI4kZiJo62Gz0tt26Dn62rPq7d3ZFzPFibXx/ZogY+LveFcpVIxpocS5Gw7ncxzPx9k/ZEEnvxxv6FMYomeojsXbOPFlYdpOWtdmVVfQlgjmfFp7Yp7aa66huPj7HuDwqLJM/TUnFd2cbfS5frNSwUwALaasn/jTRvSBl8Xe5PgB6BvKy8A/Fwd+N+YcLaeSmZiv1Dm/XnSZD/QhZvOkFAcZEwd2IphHf3Z+OxgbNQq9l9MMwQjt3YOYNJNLcnPz2flvovka5WJ+4HuZTN1dw3yBCA2IZPYhEx+2nPJ5H5iRi5xKTnM/f24yfWXVh5h/vhuFX5ehGjspKfG2qUru2jn2PtZuCKiUXBvAWpbKMqH9Es3Lt9Ile6VeX9cRLllSw7/gDL01Kelt+F8XK9gPr6/O+5OtvxrsOnwbkzsVY5eUYaSHuynbPra0seZIC8nbm7jYyjn5mALKD0xfiWqpu9RKinYywl7m/J/dK86cJmXVh3m9yMJJtd/PXiF+HRZDi6smwQ11q74F1OOnfcNCgqB0jPjU7yx6dVjFZdtxPTLu/Xu6tainJJgZ6PmlduU5JRD2/ux9skBeDrbmS377PB2/Gtwa/zd7E2uh/m5mAwjAXg62zEqPAAbtYo7ujYzXPdzMHb1RJaY1KynUasM2z6U5OqgdLwfuZxhMk+nZF0upkpQI6ybDD9ZuzQlZ8Z1CWpEZQVGKAHNysfh+fMV5zBqpPzdjMM65c1zKemRAS3pGepJa18XnO3L/7GpUql4bmR7nhvZnnsX7mDXeSWxX+lJyHrz7u1KRm4Bfq7G+gxrriW4RXOGdPDHq5zg6e7uzXk/+hSOdhpSi1dP3do5gH/OpXKheMm5h5Mt+18eRpFWR5uXfgcwDIUJYa2kp8aaabWQpGxzkGUfcIPCQhQL7qt8zE2DS7stWpW60qmZG9OGtOZ/Y8JNlnhXpEsLjwoDmtJuDjMOL5XuudFzsNWYBDQAzZzhnXvCubNrc7OvAWUV1/E5I9n+wi3cEdGMfq28mTGsHa19XQxl2ge4olKpsNGouSNC6QlKTG8YQY1Op+NQqkqCLFHrJKixZts+gPxMdKjIcgi0dG1EY9F1ArgU/6KPXVtx2UZKpVIxc0R7xhUn2KsLwzoZg6XSQ0+1xcFWw0fju/Hj1L4EuDvQIdCYLbyNnzHACSiecFw6iMgtKOKb7ec5ctk0a3JdW380kS9PaHjoq72y3FzUKglqrNXlvRDzOgC6gC7oVDLSKCpJYws3P6scp1rfjt31pa2fMcDIyi2soGTtKbnHVecSeXb8XJWgqnRQ89uheF5dc5Tb5v9tyKxcH5YWr9g6m5zNzrOpJvcOX0rngz9PUiCZkUU1SFBjrTb+13BYdOdCC1ZENEruxRNnrXgFVF1Tq1Xc1iUQtQru6Vn+ROTa1DPUi3t6tODh/qHc3d34nvqemtLDT8euGJP8fbvjQr3UEeBKmrEeaw9fAZQhqauZudz+8d988OcpPoo5VW/1EdZDghprlVi8cuXhdcbVLEJUlgQ1teKDcV3Z9VIk7QPc6uX9NGoV746N4LU7OmFXYtl3QPHE6MTMXM4mZfHhn6e4lp3P4m3GzNHL914kt8Rmm0VaHV/+fY6TiZm1WkedTmfSY6Rf8v7xX6fp/WaM4fr8v05zz6fb+Xmv8Xtw59kUnll2gOSsPNm8U5glYxLWJjcDDi6FTOWvHwI6W7Y+onHSBzXZScr3lEP9/FK2NjYadZ3Np6kK/WqvxIw8HvjiH66k5/LFVtOs0Zm5hUQt2MbPT/THxd6Gz7ac4e31J3C01XB8zshaqcc/Z1PIyS8it8A4tKRfZv7T3rK7m++5cI09F64R4OaAo52a+xbtBGDl/svc3yeY/94VXiv1EtZDemqsza9Pwe8zlWOPEHBwr7i8EOY4eRmzC5/dZNGqiJrzc7NHo1aRX6jlSvEQVGaeMs+njZ+LYc5NbEImU77ZA8D64uR91wuKaqVX5EJKNuMW7WTS16Yr6pKz8jh9NavCHDoPfPkP/10Xa3JN9rQS5khQY22OrjAe95tmuXqIxq/NMOXjhe2WrYeoMXsbjWHDzdImD2hpcr7jbAppOfmkXzfuFRWXmlPjOhyPzzA5d7PV4VK8RD5y3uYbvn7vhWtlrl26dl0CG2FCghpr1v42S9dANGZ+HZSPKactWw9RKx4pFbzoDW7nyztjI7BRG5MsxiZkcumasefk4rWaBzXnkk2f8Ux4EQ625f8K6tNS2V8ryKvsPl16N7+9kVve20xWXv2sLhMNnwQ11iSnxNLIno+Ae/nJu4S4If0E8xRZhWINhrTz4407OxHo7sCQdr54O9sR/cxAAt0dGdTWl1Nv3mrozflxVxxFJYacrmbkVes9f957ibm/H0en03EuOctw/btJPfGyB99S84383exxdbDh1+kDWPZYP078ZyS/PzXQMDz20fhuTBvSmoFtjUvXzyVns/NMSrXqJ6yPTBS2JsknlY9uLeC29y1bF9H4ebdRPqbFQWEe2Fh+wquomYn9QpnYL9TsPZVKRbsAV7afSWH1gSsm965mlg1qoo8lsv1MMs+PbI+Dbdnd3Ffuv8Szyw8CMKJTAMlZynYOb90dTt9WXqyLhbl3dWLc57vIK1QmDv/waF9a+zqjKt6aw95Gg70N/PH0QEDZL4uIZhRpdSzYeJp50crPvH/OpZjdJ0s0PdXqqVmwYAGhoaE4ODjQp08fdu3aVWH55cuX0759exwcHAgPD2fdunUm91Uqldl/77zzjqFMamoqEyZMwM3NDQ8PDyZPnkxWVlbpt2rakoon0vm2s2w9hHVw8Qc7V9Bp4dp5S9dG1INeoV5mr1/NNM1vs+5wPFO+3cNX287zwZ+nWLDxNJfTjMNV1/OLeGXVUcP53Z9sJ7F4Gbd3id6ZTs3cOPGfW3nzrs68cWcn2vi5GAKakjyd7Uw2EdWoVTw5NIz/RCmrO88m1V/iQNGwVTmoWbZsGTNmzODVV19l3759REREMGLECK5evWq2/Pbt2xk/fjyTJ09m//79REVFERUVxZEjRwxl4uPjTf4tXrwYlUrFmDFjDGUmTJjA0aNHiY6O5rfffmPLli1MnTq1Gk22YlcOKB/1cyGEqAmVCrxbK8eJRysuK6xCyf2qAG5qowxHfbXtPD3mRLNsdxx/HkvkXz/sM5RZuPkM7/xxgjd+Vb5H1h9JoMMr6w2rq/T0+Wi8Xcpu0jmhT0i5PUgVCfJyAowThkvm2RFNU5WDmnnz5jFlyhQmTZpEx44dWbhwIU5OTixevNhs+Q8//JCRI0cyc+ZMOnTowJw5c+jevTsff/yxoUxAQIDJv9WrVzNkyBBatVKWlB4/fpz169fzxRdf0KdPHwYMGMD8+fNZunQpV65cMfu+TdK5LcrHkJssWw9hPfQB8rYPLFoNUT9cHWw58MowWvo4c3tEMx7oE2K4l5Kdz/O/HObRb/eYfe0fRxMpLNLy+Pd7K3yP0vNoaqKFpzKJ+NK1HBZtOUvHV9az/XQyAFqtjuhjiaTl5Nfa+4mGr0pzavLz89m7dy+zZs0yXFOr1URGRrJjxw6zr9mxYwczZswwuTZixAhWrVpltnxiYiJr167lm2++MXmGh4cHPXv2NFyLjIxErVbzzz//cNddd5V5Tl5eHnl5xnHgjAzlr4SCggLDP/25Vci4jG3qGXQqNYXN+0CJdlldW8vRVNoJ9djWPtOxPfgjxB+kIOUCuDWr2/czQ76u9cvZVsWGp5Q/jGITKs4m3MLT0WSV1OGLpsuuf/93f+5Z9A/ZecYeFFc7Va2108/ZBpUKsvOLmPu7Mvx+/xf/8NPU3vxxNJEvt11gbI/m/DeqEzqdzuzQVl2rjbauO5zAz/suM/euToZEig1RXX3/VuV5VQpqkpOTKSoqwt/fdEKWv78/sbGxZl+TkJBgtnxCQoLZ8t988w2urq7cfffdJs/w8/MzrbiNDV5eXuU+Z+7cubz++utlrm/YsAEnJyfDeXR0tNnXNzb9T72FL3DNsSVb//rbbBlraeuNNJV2Qv20daBTKzxzznJozQIueVmuF1C+rvUvtwj0vybauWs5kW7s3H+iQxGBTpmsPK9mf4py/a6FOw33n48o5OSeLbzZDTbFq/jjkprOnjo2x2wwlKmNdvo7aEi4bhqs3LvIOM9z+d7L2KfHsfK8mkfaFtHGQvlIK2qrVge7klQEOukIMW6uTn4RHEpV8d1pZSL2nCWbGBXc8Df6rO3v35ycyqcUaHCrnxYvXsyECRNwcKhZNDpr1iyTHqKMjAyCgoIYPnw4bm5uFBQUEB0dzbBhw7C1ta1ptS0rJwWb/ccBcL/5MUb1HGVy26raWoGm0k6o37aqHXbDjvl0c8+gy6hRN35BLZOvq2U9v0sJQh4Y1JmX1xwzXL91yAA6BLoyHuj3v02G1U0A9/ZozqNRnQznowHjso/abef1gMu8sLLiOV/fFwcFvye58/v4+g3MK9PWTzef5cedSj6oLc8OJLB4A9IPYk7z3S7jdhYZ9j4MH9EdrQ6Tvb0airr6/tWPtFRGlYIaHx8fNBoNiYmJJtcTExMJCAgw+5qAgIBKl9+6dSsnTpxg2bJlZZ5ReiJyYWEhqamp5b6vvb099vZlx25tbW1NPtmlzxuluL8BHfi2R9PvMcourlRYRVsroam0E+qpra0Hw475qC9sQ23Bz6t8XS1j63NDSM3Ox9ne9NdFgKeToY72NqY/dYa0969U/Wujnff1CeXmdv7c8+l24kvsQt6npRdX0q+bbL9QoNVxOT0fbxc7XB3q9/Nbsq2XruUQ6O6Ipjjh4eZTxjw7A9/dwleTetG5mTsLNpnuz3XkSgbTlx5iX9w1/nhmIH6uDXMoqra/f6vyrCqFenZ2dvTo0YOYGONOqlqtlpiYGPr162f2Nf369TMpD0rXlLnyX375JT169CAiIqLMM9LS0ti71zgB7a+//kKr1dKnT5+qNME6nS7+/IYNs2w9hHUK6gtqG0iPk6XdTVCQlxMRQR608nE2ue7lZFzF9N69xp/ZN4f5MKKT+T8260pzD0c2PjuY/S8PY/nj/Yj5v0F8+XAvXrmtk0m5Cyk5DH53k8nqrfr296lkBvxvI08vO2C4lpptOpl50le7+c9aY6+Yb3HywczcQmJir3Itp4A/jpp2FljSF1vPctcn28q0wxKq3H81Y8YMPv/8c7755huOHz/OE088QXZ2NpMmTQJg4sSJJhOJn3rqKdavX897771HbGwsr732Gnv27GH69Okmz83IyGD58uU8+uijZd6zQ4cOjBw5kilTprBr1y62bdvG9OnTue+++2jWrP4nLjY4ccV787QaYtl6COtk7wLNuivHcTsrLiusllqtYunUvoZzG43x10ffVt6cf2s0Z/47iu8m90Gtrv8JuQ62Gjyd7egV6kVrXxdc7G2I7ODHfb2CygzVbD2VTHYdbK2w82wK8enXTbIxl/b9zgsA/HrwChtPXOW5nw9yLlnJs/PmXZ0N5UomQNw5a6ghq7LesSuVH5KpTclZecSlGOe47D6fyn/WHmd/XBobjplP7VKfqjynZty4cSQlJfHKK6+QkJBA165dWb9+vWEycFxcHGq18Ruof//+LFmyhNmzZ/Piiy8SFhbGqlWr6Ny5s8lzly5dik6nY/z48Wbf94cffmD69OkMHToUtVrNmDFj+Oijj6pafetTVAjpl5Rj3/aWrYuwXoERcGkXXD1247LCavVt5c0bd3YixNvZ7H2NBYKZiqhUKt4a04U37wrn/346QEJGLjvPKtvJHLiYxk1tfG7whMrbGHvVsAO5u6Mt6566meYeZfetOp5gDEYmfWW6Y/k9PVpw5HIGP+6KM1z74dE+aNQqHuofyjt/nDBcP3O1bpPPFhZpmfT1bjyc7Pjovq5cSMnB0U7DmE+3c+nadboFe7D8sX58tvmM4TXnkrOJqOCZ9aFaE4WnT59epqdFb9OmTWWujR07lrFjx1b4zKlTp1aYTM/Ly4slS5ZUqZ5NQmY8aAtBbQuu9dvlK5oQQ76aD6H3VHBvYdn6CIupTpI8S9OoVXxwXzcAnlq6n9UHrrDrXGqtBTUpWXmGgAYg/XoB3++8wOODWuNU6rdskpktJwAC3Bywt9HQPsDV5HqYn7IcatqQNly6lsOPuy4CtbPJaEmxCRnsOX+NO7s2w0at5nJaDltPKTl/fFzs+Gb7eUp2QO2PS+PgpTTOl+i1OZGYRYRf6SfXr4Y3fVpUTbryDY57c1CXN0VYiBpqNdh4fGyNxaohRE31LN4KYvf51BuUrDxz+Xw+3XSGbm9sYP5fZ8gpHunKyS8kJ9981mP/4hVPo8IDTa77lchLM/fuLuydHQlAQkZurWZQfv7nQ8xedYTw1zbQ/60Yjscb2/TVNmNAU7I3bv5fp7lSYnuMQ5fTqWDkrV5IUNPYpemDmiDL1kNYN+/WcNPTyvG+b5RhTyEaoV6hngBsP5PCxdTyezueWXaAkR9sYde5VAqLKs4No1911S3Yg7/+b5DhulYHH208wy/nlF+1KVnlT6S9vYsSzPi62hvm1jw1NKxMOS9nO5zsNOh0mKz2qgmtVsfBS+mG82s5BXy340KZct2DPdjy3BCWFc+t2nQiyRCk2ahVZOYWEl+7HUhVJkFNY5dePPbqEVJxOSFqqtdkQKVsnHqp4k1shWiowvxcsSnubbj57Y2cMNPLcjE1h5X7LxObkMm9n+3gnQ0nypQpKb64tyLMz4VQM/ON9iSryc4rNOx23tzDkelD2nBbl0C2PjeE/40J58F+xp/hE/qEsP2FW3jSTFCjUqkMq6FSsswPZVXVlfTrZa7tMtOT9c7YCJp7ONKnlTddgzwM131c7OnXWtkn7GymZedVSVDTmOl0kFI8SctDempEHfMIhtAByrG+h1CIRkajVjGul/Hn5QsrDpncX38knpvf3mhy7bPNZ8nJL793Mq64xyfA3RG1WsXCB3rg5mA6mebVX48b9sXycbHj2RHt+Pj+7gR5OTGuV3CZXD/NPBzLnXjtXbxjeXIFPT+VtXRXHAP+p7TXy9mOTyZ0N1vu1Ju30trXmO74lvbGyTOjwwMMO7yfyZCgRlRX9Mtw8EflWIafRH3Qf5+lS1AjGq//RBlX3+6PSzO592HMabOvuefTHSzacoaP/zrF1QzjsM/ZpCyW71VWoHZq5gbAyM4B7Hopkik3tzSUW30w3jBJ+KH+oTWqv3fxpqAp2TXvqXlhxWHDcVTX5tzaOYBBbX0N10K9nZh3bwS2GtNwYerAVowKD2BUeADPDGtLz1BP7GzUWHhKTcPbJkFUwfb5xmOfst2UQtQ6/aqnjMuWrYcQNaBSqdj14lB6/1dJXHotOx9PZzuKtDrOJClLpVv5OnM2KdvwmmPxGRyLV5Zjv7vhJHY2ap4aGmZYZu3tbMewDsZ9Dh1sNcwY1o7Pt54zee++rby4u3vNVg/qe2oqmqNTGaXnFN3XOwiVSsVH47sx5N1NqFUq1j11M052ZUMFB1sNn0zoYTjvHerFvpduIWbD+hrVqaakp6axKig1Btq8h/lyQtQmz1Dl45UDlqyFEDXm5+ZAqLeyufHRKxmkXy9gyT8XyC/UYmejZuW/Kt4jKr9Qa5I3BiiTdNDRTsMn47uaXPNxKbt9T1V5uyhBzYGLaTV6znc7jZOBv32kN239leXk7o62/P7Uzax7coDZgMYcG40a+wawH5XlayCqJ7HEBm73fifLuUX90G/FcWUfLL5VmdclRCPVqZmyZfe0Jfvo+Z9oXl6t/Fxt5++Ku6MtL9/WsdLPeuV282V7t/Q0Ofcssb1Edenz6/wVe5WrmdVfAaXPQzN/fDcGlhhyAvB3czBZTt5YSFDTWO3/XvnY6S7oeIdl6yKaDhc/6FD8/Ra3XVkJJUQj1aeVMrk1/XoBBUXGAP2FW5Xs7JMHtOT8W6NN5pi4O5bdXPHD+7pyR4T5LXtKl9fWwh8C/Vv70LJ4Ly5zq7cqIzO3gNji7Mb6z4M1kKCmMTq6EvZ+pRz3nGzZuoim59a3jcfxh8ovJ0QD90CfkDKrfboHe5TJNNwzxNjbMuvW9rx9TxeeGNwaAFd7G4Z3DEClKn/Vj4+9MZBJv15QG1WnXfFQUXlBzZtrjzFrxSE+2XSa1QdM58Bdy87nnT9OoNMp83Ma6m7f1SEThRsbnQ7+elM59gw1LrEVor64BUKfJ+CfT2HlVDjyC4xfCmr5G0k0Lmq1ilHhgbg62JCZqyzZXjKlb5lyjw9ujVqtIjU7n9simuFib0ORVkffVt50CHDF0a7i4f9pnYp4fZ/y61a/9Lmm2vi5wFEMm2GWlJFbUGaC8uC2frg72bLjTArTluwz7KjdzMz+VI2ZBDWNTcYVSDmlHE/ZCBX8dSBEnek+UQlqAE79AcdXK0OhQjRCg9r68tuheGzUKhxsywYotho104a0MbmmUatMhqUq4mUPfz49gF0X0hnbs3b2TdMHI/Hpueh0OvIKtbz1eyyHL6cTWWIVll7/t2IY2zOIr7efN62bc83n+DQkEtQ0NlkJyke35uBkPeOgopHx7wjjl8GP45Tz479JUCMarWlD2uDmaMtjA1vV2XuEeDvRJsC91p4X6KEMGf0Ve5W2s38nsoM/vx9Rfj/svXCtTPns/KIyAQ1gyE5sLaS/uLHJSlI+ulh4K1Qh2o2Eh9cpx+f/tmxdhKiBDoFu/PeucELMbHHQUDVzNw4bFRTpDAFNSTeH+XDk9RFmr6/4V38iO/jVaSBnCdJT09hkJSofXcp2LwpR7/w6KB+zEiD1HBxfA04+Sq+NnZNl6yaEFWvh6Yi9jZq8wvI32wxwc8DF3oYfp/Rl/Oc7aR/gyl3dmnNH12YEujvyxUO96rHG9UOCmsYm66ry0blyY7lC1ClHT7B1hoJs+KQvFBbnzDi3Be7+zLJ1E8KKOdvb8MsT/bHRqHh7/Qn+ir1apszTw9oC0K+1N+ffGl3fVbQICWoam/gDyke35hathhCAMlHdvQUknzAGNACHloK9Kwx6ToZKhagjnZsrc3T+N6YLBy+mMbSDHyM+2MLJRGWrh+ZWtrKpMmROTWOSnw0nfleOO95p2boIoefV0vz13Z/Du2GQV73kYEKIyvF1tSeyoz8qlYpPJvSgY6Abn5az27a1k6CmMUmKBV2RMvTkX/n03ULUqZufNT23czE9//4e0BbVX32EaMLa+Lmw7qmbuTU80NJVsQgJahqL/BxYNU051k/OFKIhCOqlrIJy9oObnoKoT0zvX9ypZMEWQog6JnNqGou9X0HSceU4oItl6yJEaaE3wbMnlTk2OanG6+1GwYl1kHAYwu+xXP2EEE2C9NQ0FqdjjMc9H7FcPYQojz67tZMX3LMY7vgYQm9Wrm37QFnybSnJp2VujxBNgAQ1jYU+P82wN8C7tWXrIsSNdB4D3R8EzxDjtSXjlL3L6tvF3fBxD/j0JvhsIBz+uf7rIISoFxLUNAZFBZB0QjnuGGXRqghRJQHhxuPkExC3o37e9/JeWDpB2UV89+fKtbQLEH8QfpkMuen1Uw8hRL2SoKYxSDkN2gKwcwWPYEvXRojK8wiGqZug9VDlfPPbdf+eV4/D57dA7G/w2c3mV14lHi17LTsZfpsBVw7UeRWFEHVDgprGQP8D2K+D7MotGp9m3WDoy8px/IG6HYI69Sd80s/02hEzw036ns+S9n4Ne76ERYOgILfsfSFEgydBTWNw9ZjyUXLTiMbKtz2o1HD9GmRcqZ3AJj8bFo+Etc9Cdoqyqebmt4Bynt28p/F489tQmKdMHk44rDwr5bTxvn6loWi4dDpIPAaF+ZauiWhAZEl3Qxd/CLa+pxz7dbJsXYSoLltH8A5T5tV8PUoJbEa9Cz0eqv4zY9cqc3TidsDJ9ZB+0Xiv9VAI6g2b5irnzn4wJUbpjfn1Kci8AutmKkNOJ9aWfXbSSaW+9i5l74mG4fDPsOJR6PoARC2wdG1EAyE9NQ1VwmH4+jZlToBes64Wq44QNTbkReXjtfNQlA+/Pll2vktOKly7YP71+VmQcMTYy3Nhu/GePqBxCYCbnoYHfoHBL0CbYabv7dPO+Jp935gPaABWPQ5zm8Pmd2DTW0qvjmg4spKUgAbgwPeWrYtoUKSnpqH6erTpCo2Rb0EL69smXjQhHe9Uej9SThmvpZ4DnzbG82/vUAL6LvfB6HeVTTGLaX56AC78Df2mg2uAkpCypLFfQ6e7TK/dtRCu7Ic2kcq5bzsqRadVPm78j/LRxh56T1Uye7v4mn9NQa5STua91T19D5wQpUhPTUOkLTINaIa+An2fkB+WonFTqaDXZNNr+76Bq7HKcXaKEtCAssv3Tw8ZemVUukLUF/5W7u34GDbMLvv80IFlrzn7QNgw08SAg19U5te0GwUu/pWr+7HV8PlQeLeNMmRV0sVd8M3t8KY/rHxM9rmqD4lHTM+1WsvUQzQ4EtQ0RCUnLNq7Q/vbLFcXIWpT76lw73cQNlw53/4RfNJHCV4SDpqWPRMDsWtRb30Xn8xyJu46uBuPnb0rV4fBzyvza8b/qGzt8FIiRL5W/AxfY69OSVf2GycPn9tieu/Xp4zXDi0zzoETdePaBSWQLCnhoGmwqS2CXZ9D6tn6rZuwOBl+aoiSiv9ybdYNHo0Btcay9RGitqg10PEOZaLwqQ3G63NbKHNmQNla4fo15a/xZRPQAP3NPavlILj3G/j9BWXvqeqydYD+T4KjJ7S+Rdll/MAS6D4RNHZKD0xJJXtRC3LLLg/f+Ca0u9U08aCoPRe2AzoI6gOFuUpCxUWDwa0FPL4V1vxbyVEEStD7QpwlayvqmQQ1DU1RIfw0UTn27SABjbBObYaanusDGlB6Spx9YfW/yr7u1rfBsyW0vFlZUQVw92c1r49aAz0eNp73n15+2aRYJct3xhX4sHhzWQcPePoQvFWcHHPhALjrMzi8HKIWlj8PB5ShE7V0mleKVgurpynH/p3Aq7US1ABkXIK3W5qWl8zRTY78T2poSg49NetmuXoIUZd8wuC2983fC4xQejpsnU0u67zbQJ/HoO1wY0BTH+742PT8n4Uwvwese9Z4zT3IdCgMlPk1p/9U5uGc/9v8sxOPwf9CIPqV2q2ztTqxFnTFc5a8WkHrITd+Tek5UMKqSVBTG/IyITOxdp5VcmVIyb8chbA2PR+Bh80sqQ6MUCb0PhqtLM8upnMPKVu2PnR/EF5JhRH/NV5Lu2A6fHbTk8rHO8vJl/L1aDi41PRawXX4tB/kZcC2D2u3ztbq2GrjceuhSm92s+4Vv+bH+8xfTz2n9LgJqyJBTU0dW6PMB/jpwdp5XnJxUBN+L9jY1c4zhWioQgfAgytNfzE5eSkf/TvBsNfRBiszarQ9J5t5QD1Ra6DfNJi6uey92z6A8LHKcdcJ5gM1UHpuQFnl9c9nSvLAktb827j6S5R1YQcc/1U5jvpUybCuVsOUv2DGcbBxUO6F36vMhwoboZxf2m2c93Q9DfYshr8/gI+6wtoZ9dwIUddkTk1NufgpHzMTaud5l/cqH2VLBNFUtL5FyV/z7R3QrewfB0X3fMO2X7+mr37FlCU166ps0LlosPFaj4eNS8ZVquJAbRWc3ajMDSq5/HzVtPKTxe37Fpvzf0OwDEWVkXEFvhppPPdpazxWqcCtGfxrh9L70mqIEuwkn4JTfyhl4g8pE8DfL/Vzdd+3kHVVWZEnf0RahWr11CxYsIDQ0FAcHBzo06cPu3btqrD88uXLad++PQ4ODoSHh7Nu3boyZY4fP84dd9yBu7s7zs7O9OrVi7g446z1wYMHo1KpTP49/vjj1al+7dLnuchKrPl+Nlqtcew99OaKywphTTyC4Mn9cLOZv5wdPUl1qWTSvPrQrBvcMR8ixsOUjebzR7UeAsPegP7/Nr1+g+y3qtSzuOVeUk6Ormo8PTcJh+HS3rp7fukVZubyC3m1Uiag6ydd+4RBrynK8f5vYcs75p99cj38xxfi/ql8fUr+rC/Irf/cRAlHyqYWEEA1gpply5YxY8YMXn31Vfbt20dERAQjRozg6tWrZstv376d8ePHM3nyZPbv309UVBRRUVEcOWJMnnTmzBkGDBhA+/bt2bRpE4cOHeLll1/GwcHB5FlTpkwhPj7e8O/tt9+uavVrn2uA8rEwF3LTavas9DjlGRo7ZV6BEKJh6j5RyVbc/AbzOQDuX670QNk4mL9/01Mw7gdo0RsA19wrqGJ/heUPKVul6H+BZidDRnwtNaCGdDpl2fvV48oWEgsHwBe3QPql2nuPy/tgbjCsng7fRZneq2zSxA63Kx/PbSmbgbq0v+ZUfD8zAf5ZBK95wOsesH6Wsq3Hgt5K+ytKAKirZnJAnc50FCAnVeldWngTfHsnpMUpn/NFQ+CzQcp5E1fl4ad58+YxZcoUJk2aBMDChQtZu3Ytixcv5oUXXihT/sMPP2TkyJHMnDkTgDlz5hAdHc3HH3/MwoULAXjppZcYNWqUSZDSunXrMs9ycnIiICCgqlWuW7aOyqqH3HRlsrCjZ/WfdSpa+ejTDjS2tVM/IYRltR2u/OvxsNKj4dNW2dQT4JaXlcnQGhtlqOTSLnwyj6PeX9wzkZumrIj0CIHPhyi/tKIWQtfxtV/PwjxYcq+yf9aNlsmfXA+rnlCOx5XofYpdB32m1rwuyaeV9gLs/870nmtg5YeKWg1SVtn99oxyrrGH8HvgwA/KuVsL8G4N5zbD+a2Ql1X+JqZLxkH8AeP5zk+UpIxpxXuVxR8wH+TmpBJ57Fk06V/DQ6vL3jdHp1OWruvrqbaFiPuU4Ez/fjotxO1UdqnPK166vm4m3L+scu9hpaoU1OTn57N3715mzZpluKZWq4mMjGTHjh1mX7Njxw5mzDDtUh4xYgSrVq0CQKvVsnbtWp577jlGjBjB/v37admyJbNmzSIqKsrkdT/88APff/89AQEB3H777bz88ss4OTmZfd+8vDzy8oyb0GVkZABQUFBg+Kc/rykblwBUuekUXotD51k2GKsUbRE2vz+PCtD6tqeoFuqlV5ttbciaSjtB2too+Uco/3Q61AOfR+fWHF3E/aDVgbYAVcuh2Oz7ltCUjZBS4nUf90TbaQxq/V/hqx5He/pPioa+XmGPhXrvYlRHfqHors+VOSc3oDqwBJuzmwAoGPGWMgdF38OgMu3U1xxfa+jm1/31JvoBOO2ZjRR1n3TD97rR11S973vMZegq6v8MujaR6KryvRDxIIQORnVuCzr/TmDrjM3h5Wi7PoB25Nug02H73+I8QnObU/jAanQhxmSOqkPLoDAXm5IBjV5cid97nw+h4MWkMsORut1f4JyfDOc2UZBUHKCWlH5RWYXl1Upp++4vUO/+DNW1c8Yy2oKywR3Aiimm7xW3k8L8fIttqVNX/1er8jyVTlf5iSBXrlyhefPmbN++nX79+hmuP/fcc2zevJl//ik7JmlnZ8c333zD+PHGvyw++eQTXn/9dRITE0lISCAwMBAnJyf+85//MGTIENavX8+LL77Ixo0bGTRoEACLFi0iJCSEZs2acejQIZ5//nl69+7NihUrzNb1tdde4/XXXy9zfcmSJeUGQtXV69x8mqXt5mizcZz2H12tZ3hmnWLgKaX7c2O7OWQ4WWj5qhDCYtomrKZD/C+VKptpH8je0MexL8gg2bUjWpWNyS+zO/crSTyTXDqwPWxWeY8BwK4ggyGxL+FQqPzFv7HdHDxzztImcS222utsav8fcm2Le6F1OoYffQbHgtQyz8nXOLO+83x06pqtQRl8/CXccy8azi963sT+kMnoVLWztkWlLUSnUhuCNf3nCpTP618d/weAQ34qI44+Xeb1hSo7bHT5Za6v7/wRebYeyolOS78z7+KXaZxqsT94MnHegwznNkXXGXZ0BnZF2RwLHMt1Oy96XKi4l+y6rSeHgh6iz9kPzN7f3PZV0pyr+cd1A5WTk8P9999Peno6bm5uFZa1+OonbfE45J133skzzyhdhF27dmX79u0sXLjQENRMnWrs0gwPDycwMJChQ4dy5swZs0NVs2bNMukhysjIICgoiOHDh+Pm5kZBQQHR0dEMGzYMW9uaDfWot5+CjbvpmPYnbR98r/yx84qesfFNOAXajncx4K4nalSf0mqzrQ1ZU2knSFutVUF+JHt/8qVb5p9o+04D/87YfDXMbFnXvHgGn3jVcK7zDqPwkT/BzhnViXWwX7nuUxjPqFtvRb3lLdAWoR38kulf8jot6r9eR1NozL475MTLJu8V6ZuMtsNNaP54AVV6HCozAQ2AXVE2dxx8BJ1LAIUPrlYy/pprp7mvqU6rzBsqysd2/0V0KjWq4p6iwKjXCKjDZKS6UwGospS5K6558YwOzUMXOgjV6Q1wtFRZVDDmC7Q7F6DKvoq27a1o/vkEgMiuwehCBkDKKWwX9iv9NkTYxdH1xAy0Xe6D/GzU5/5AVZQNQMf45WXep/CRP1Gf/QvNpjcN1+263E33kbPRvfcVqhIZk7XB/VHHbWfQydcpmLYPPILLb3B+trKjfA2Dz9Lq6v+qfqSlMqrUIh8fHzQaDYmJponmEhMTy53rEhAQUGF5Hx8fbGxs6NjRdKldhw4d+PvvcrJwAn369AHg9OnTZoMae3t77O3ty1y3tbU1+WSXPq+WTnfCxjmoclKwjd+njONW1dkYANTtRqKuox/ctdLWRqCptBOkrdbokld/ujzwH2Nbnz8P77ZVfumPX6psveDeoszGmaqUU9ge+0UZato533g9Nw3bPZ/B30p5TbcJ4Fu8JFqngx/GwunoCuukObkOzdmNcKHEz+SejxSvetqtnHd9wLC6S5WVgO32D6DvE8qcQ5VGWeFWiq0uD9tt85UUFsseMG1Pi95w58eQk4JNcO8bfNZq6IGfYedCZV5TdhI2K6dAyE1lt6l5IQ5VYR42Ln7Q+U4AZZgs9Qyc+gOba2egzRAl87EZ6uLPs2bnx2bvGzj7opr0O7Y+YRDUA/o+ZtiCQxPSD42trbJdiH5I7JE/UCfFQtx2AGzP/QW9p5h/9vm/4bu7lXQD03eDXe2OXEDt/1+tyrOqtPrJzs6OHj16EBMTY7im1WqJiYkxGY4qqV+/fiblAaKjow3l7ezs6NWrFydOmC7ZO3nyJCEh5Q/BHDhwAIDAwMCqNKFu+IQZl2BfO1/112cmQMIh5bjlwFqrlhDCCjh6wrRdMHkDhA2DuxfB0Ffg9o/Av7Np2bUzlAy6+kBDr2SunB/ugf/4w1//UX4plgxoWpfYk6vPE8XJBlVK/qwLpf7IjHwd/DoYz4e8aHr/yC/w2UD4MAI+6atsUpqTCid+B20hAOo/X4FN/y0T0ADQdoTyszW4b4WfnloREA5RC0wyWHNhm3HZdOjNcPfnSoCmz01Wkj5ITDqpZIouDi4AdG4tyLNxrfj9I+6HviX2Onv8b6XtoPSqObjDv/cpW3aE36Ncv/1DCO4Hk/9UPkcR9xtfX/rrX9LxX6EoT9krS/97x4pUue9pxowZPPTQQ/Ts2ZPevXvzwQcfkJ2dbVgNNXHiRJo3b87cuXMBeOqppxg0aBDvvfceo0ePZunSpezZs4dFixYZnjlz5kzGjRvHwIEDDXNqfv31VzZt2gQoS76XLFnCqFGj8Pb25tChQzzzzDMMHDiQLl261MKnoRb4tldmzyedULr27Jxv/BpQJoi9VyIHh2sDCNKEEA2LV0ug1GaNPR5S/q36l3GVTEkqtbK1w/pSq1L1q2e2vFM2d8uIN2HhZmXfrT5Tlcmrvu2UTTxBOXf2hUHPg4MbDH5RWfXZ93Fwbw6PxsAXxYFRUYk5J/lZyi/8v+bA+a1omvekpaoDmktmJr/qdRl3w09Lrev7BGQnwbYPjNccPOChXyuefOtT/DN812dwdCVkF6c4ufdbCsNG8cdva7jj4CPG8sP/YxpoNuumbMeRmwFhkcZUISV5t1b+GV7TFR5Zbzy3sYMHVsD3d8OhZcrKKPcWym73Y75UAmKAKweMr7l6TPmdc3K90vNW3qrblDNw8R8lN1N+ljKJ3EKTkW+kykHNuHHjSEpK4pVXXiEhIYGuXbuyfv16/P2VWfhxcXGoS+w4279/f5YsWcLs2bN58cUXCQsLY9WqVXTubPwL46677mLhwoXMnTuXJ598knbt2vHLL78wYMAAQOnN+fPPPw0BVFBQEGPGjGH27Nk0GJ6hysedC+D4GvjXzvKXBpa0ocTYddiIBvuNIoRooKI+Uf79MNZ0PyqPEOj9GOz4RMmB5eBRfi4tW2e450ul52XqJqVnQD8nw7uNMagZ+ip0ijK+zi0QJvxkPG/RU8nLs2Rs2feI/U35ww9QX95DF/aYr4vGDh7fpgRJ9U2tgWGvK8lUD/6oXPNuc+Ofy77tjcf6gAYMwY5ObUNR/2fQbH8fWg5SkjKe+Uv5B8UBhY3SW1QTLXoaj9MuGAPYFVPgrkVKYHP1mLGMfqk7KFmbh5VaXJOZCAU5So9bfpaSm6j4a0hQXwjqBcPmNKjfW9WaJTR9+nSmT59u9p6+d6WksWPHMnasmW/yEh555BEeeeQRs/eCgoLYvNnMnisNSXCJ4bf0i3B2E3S4rfzyOp0SQf/zqXLu4AGj3yu/vBBCVOTuRbDnK+Xnz95v4Na3ley6Uzcpy4HbjoQfxylD5P2mK2XyM2Hiamg12PicgHDT5+qHQcD0l3d5gvso+V8ySiXi2/5RmaI6jxBUE36G9c8rQdRtHzSMX5DFy6sB0yG28rToqez/ddh0si++7aBQGWrTDn4RTcS9xmAt8nVlOG7YG0pAUxsc3CFkQNmhwuvXlEDTyUfZQNWcbR8o+62F3KRsrJx8CmLeMC2vD2gALu5U/nW8S+lJtHOmIWwnafHVT1ajdNKlUxvMBzVFBUrUm50EvUskqRr3ndmJdEIIUSmOnsZtJkbMBdviVZjO3jDgaeX40RhlHk2rW5ShpsoIHwsn1ivzRkruuVQeB3eY9g9sn6/s63UmBjb/r0yxC1430+yBT7D1ClY2NW1I2kQqdfYMhYEzb1xepYK7PjMNasYvMw3QVCrTPf0Cu8BjdfDH+vgflUnkJYfQ9HKSK37tiilKoj9tFfLMbPsATv+pfK3HfF2FitYNy4dV1kKlgpK7CO/7RklnXdrV40r3X3YSbCz+odK8h0wQFkLUHtty0ko4+yi/sNVV+NHv3wmm7YR7v6386+xdYMgspdemfdncXdqwkRwIfrThziFs3h1ejIdpu8GzkjnDSq6U8moN7UaWX7YuObhB5GvQZhjYu8F9S5TjkmxLzPns/pAyV0avooCm3ShlwvLsJCVwBmW6RUEOxP6GZnEkQSlba74PYg1IT01tuvV/SjfkPwsh/iCs+Tc4eZv+p975adnXdZ9Y9poQQliDwAgYPU9ZQJEUCz5tKer9L/j9d0vXrGLV2bU78jVl3sl9S2q9OlWiUinL1PXaj1bmx2TGw9/vK5OSN/1PWYV22/vKR/0covKM/cZ0PpWZXjt1/AFCnbMsOoQoQU1t0thC1/uV5X8fFE+EPrle6Zo7s1E5L5n6GpR9VjrcUb/1FEKI+tRrsul5Y9/yojwDnlH+NUSu/sq/e79RzvXL91UqpZcpoEvZJd6BEdB1gvLHecmABkyH0ko44zuCrrVa8aqRoKYueAQpOR7++dT8EJSjp5JbQFuoLI908qr/OgohhGi6SvemTFyt7Pj9WXHOtZueVuYTlbeK162ZMhfKwV0Z5tr1OUVebbiS4CdBjVUKH2tc2VSSSwBM3VipDeaEEEKIeuHkpfybHK0MU3W888avaX2L8XjU22gLCmDdurqrYyVIUFNXfEuMN9o4wszTYOuoTKCqreV7QgghRG0KquMtKeqY/HatK/Yl0mJ7BFUuEZ8QQgghqk2WdNclfQKnLvdath5CCCFEEyA9NXVp4ho4u1GZPS6EEEKIOiVBTV3yCJIcNEIIIUQ9keEnIYQQQlgFCWqEEEIIYRUkqBFCCCGEVZCgRgghhBBWQYIaIYQQQlgFCWqEEEIIYRUkqBFCCCGEVZCgRgghhBBWQYIaIYQQQlgFCWqEEEIIYRUkqBFCCCGEVZCgRgghhBBWQYIaIYQQQliFJrNLt06nAyAjIwOAgoICcnJyyMjIwNbW1pJVq3NNpa1NpZ0gbbVWTaWtTaWdIG2tDfrf2/rf4xVpMkFNZmYmAEFBQRauiRBCCCGqKjMzE3d39wrLqHSVCX2sgFar5cqVK7i6uqJSqcjIyCAoKIiLFy/i5ub2/+3da0xUV9cH8P+AzABVGBAZGBUEUWwVqdA6pa3YlIlASaW1idaSqq31VkxttJTYG60fCtFGPxhL/KDSxEariWJSqY0XqLdRKwEVUSIUIW25tOIgRC23//PBd048ctH3eXDonFm/ZJJh73UOe82ac/bOzDkw1MN7rNwlV3fJE5BctcpdcnWXPAHJdTCQRFtbG8xmMzw8Br5qxm0+qfHw8MCYMWN6tfv5+Wn+jebgLrm6S56A5KpV7pKru+QJSK7/q4d9QuMgFwoLIYQQQhNkUSOEEEIITXDbRY3BYEBOTg4MBsNQD+Wxc5dc3SVPQHLVKnfJ1V3yBCRXZ3ObC4WFEEIIoW1u+0mNEEIIIbRFFjVCCCGE0ARZ1AghhBBCE2RRI4QQQghNcNtFzZYtWzBu3Dh4e3vDYrHg3LlzQz2kfuXm5uLZZ5/FiBEjEBwcjNdeew1VVVWqmJdeegk6nU71WL58uSqmvr4eaWlp8PX1RXBwMLKystDV1aWKKSkpQVxcHAwGA6KiolBQUPC401P58ssve+UxadIkpf/u3bvIzMzEyJEjMXz4cLzxxhtoampS7cMV8gSAcePG9cpVp9MhMzMTgOvW9Pjx43j11VdhNpuh0+lQWFio6ieJL774AqGhofDx8YHVasW1a9dUMS0tLcjIyICfnx+MRiMWL16M9vZ2VczFixcxY8YMeHt7Y+zYsVi/fn2vsezduxeTJk2Ct7c3YmJiUFRU5LRcOzs7kZ2djZiYGDzxxBMwm81YsGAB/vzzT9U++nof5OXluVSuALBo0aJeeaSkpKhitFBXAH0etzqdDhs2bFBiXKGujzK3OPOcOyjzMt3Q7t27qdfruX37dl6+fJlLliyh0WhkU1PTUA+tT8nJydyxYwcrKipYXl7OV155hWFhYWxvb1diZs6cySVLlrChoUF5tLa2Kv1dXV2cMmUKrVYry8rKWFRUxKCgIK5du1aJ+e233+jr68vVq1ezsrKSmzdvpqenJw8dOuS0XHNycjh58mRVHn/99ZfSv3z5co4dO5ZHjx7l+fPn+dxzz/H55593uTxJsrm5WZXn4cOHCYDFxcUkXbemRUVF/PTTT7lv3z4C4P79+1X9eXl59Pf3Z2FhIS9cuMDZs2czIiKCd+7cUWJSUlIYGxvLM2fO8MSJE4yKiuL8+fOV/tbWVppMJmZkZLCiooK7du2ij48Pt27dqsScOnWKnp6eXL9+PSsrK/nZZ5/Ry8uLly5dckqudrudVquVP/zwA69evUqbzcbp06czPj5etY/w8HCuW7dOVef7j21XyJUkFy5cyJSUFFUeLS0tqhgt1JWkKseGhgZu376dOp2ONTU1Sowr1PVR5hZnnXMHa152y0XN9OnTmZmZqfzc3d1Ns9nM3NzcIRzVo2tubiYA/vLLL0rbzJkzuWrVqn63KSoqooeHBxsbG5W2/Px8+vn58Z9//iFJfvzxx5w8ebJqu3nz5jE5OXlwExhATk4OY2Nj++yz2+308vLi3r17lbYrV64QAG02G0nXybMvq1at4vjx49nT00NSGzV9cELo6elhSEgIN2zYoLTZ7XYaDAbu2rWLJFlZWUkA/PXXX5WYn376iTqdjn/88QdJ8ttvv2VAQICSJ0lmZ2czOjpa+Xnu3LlMS0tTjcdisXDZsmWDmqNDX5Pfg86dO0cArKurU9rCw8O5adOmfrdxlVwXLlzI9PT0frfRcl3T09P58ssvq9pcsa4Pzi3OPOcO1rzsdl8/dXR0oLS0FFarVWnz8PCA1WqFzWYbwpE9utbWVgBAYGCgqv37779HUFAQpkyZgrVr1+L27dtKn81mQ0xMDEwmk9KWnJyMW7du4fLly0rM/a+LI8bZr8u1a9dgNpsRGRmJjIwM1NfXAwBKS0vR2dmpGuOkSZMQFhamjNGV8rxfR0cHdu7ciXfffRc6nU5p10pNHWpra9HY2Kgak7+/PywWi6qGRqMRzzzzjBJjtVrh4eGBs2fPKjGJiYnQ6/VKTHJyMqqqqnDz5k0l5t+UO3Dv2NXpdDAajar2vLw8jBw5EtOmTcOGDRtUH927Uq4lJSUIDg5GdHQ0VqxYgRs3bih9Wq1rU1MTDh48iMWLF/fqc7W6Pji3OOucO5jzstv8Q0uHv//+G93d3aoCAIDJZMLVq1eHaFSPrqenBx9++CFeeOEFTJkyRWl/6623EB4eDrPZjIsXLyI7OxtVVVXYt28fAKCxsbHPnB19A8XcunULd+7cgY+Pz+NMDQBgsVhQUFCA6OhoNDQ04KuvvsKMGTNQUVGBxsZG6PX6XhOCyWR6aA6OvoFinJnngwoLC2G327Fo0SKlTSs1vZ9jXH2N6f4xBwcHq/qHDRuGwMBAVUxERESvfTj6AgIC+s3dsQ9nu3v3LrKzszF//nzVP/v74IMPEBcXh8DAQJw+fRpr165FQ0MDNm7cCMB1ck1JScGcOXMQERGBmpoafPLJJ0hNTYXNZoOnp6dm6/rdd99hxIgRmDNnjqrd1era19zirHPuzZs3B21edrtFjavLzMxERUUFTp48qWpfunSp8jwmJgahoaFISkpCTU0Nxo8f7+xh/tdSU1OV51OnToXFYkF4eDj27NkzJIsNZ9m2bRtSU1NhNpuVNq3UVNy7aHju3Lkgifz8fFXf6tWrledTp06FXq/HsmXLkJub61J/Wv/NN99UnsfExGDq1KkYP348SkpKkJSUNIQje7y2b9+OjIwMeHt7q9pdra79zS2uxu2+fgoKCoKnp2evq7ebmpoQEhIyRKN6NCtXrsSPP/6I4uJijBkzZsBYi8UCAKiurgYAhISE9Jmzo2+gGD8/vyFbUBiNRkycOBHV1dUICQlBR0cH7HZ7rzE+LAdH30AxQ5VnXV0djhw5gvfee2/AOC3U1DGugY6/kJAQNDc3q/q7urrQ0tIyKHV29nHuWNDU1dXh8OHDqk9p+mKxWNDV1YXr168DcK1c7xcZGYmgoCDV+1VLdQWAEydOoKqq6qHHLvDvrmt/c4uzzrmDOS+73aJGr9cjPj4eR48eVdp6enpw9OhRJCQkDOHI+kcSK1euxP79+3Hs2LFeH1n2pby8HAAQGhoKAEhISMClS5dUJxXHCfapp55SYu5/XRwxQ/m6tLe3o6amBqGhoYiPj4eXl5dqjFVVVaivr1fG6Ip57tixA8HBwUhLSxswTgs1jYiIQEhIiGpMt27dwtmzZ1U1tNvtKC0tVWKOHTuGnp4eZWGXkJCA48ePo7OzU4k5fPgwoqOjERAQoMQMde6OBc21a9dw5MgRjBw58qHblJeXw8PDQ/mqxlVyfdDvv/+OGzduqN6vWqmrw7Zt2xAfH4/Y2NiHxv4b6/qwucVZ59xBnZf/X5cVa8Tu3btpMBhYUFDAyspKLl26lEajUXX19r/JihUr6O/vz5KSEtXtgbdv3yZJVldXc926dTx//jxra2t54MABRkZGMjExUdmH47a7WbNmsby8nIcOHeKoUaP6vO0uKyuLV65c4ZYtW5x+q/OaNWtYUlLC2tpanjp1ilarlUFBQWxubiZ57/bCsLAwHjt2jOfPn2dCQgITEhJcLk+H7u5uhoWFMTs7W9XuyjVta2tjWVkZy8rKCIAbN25kWVmZcsdPXl4ejUYjDxw4wIsXLzI9Pb3PW7qnTZvGs2fP8uTJk5wwYYLq1l+73U6TycS3336bFRUV3L17N319fXvdDjts2DB+8803vHLlCnNycgb91t+Bcu3o6ODs2bM5ZswYlpeXq45dx10hp0+f5qZNm1heXs6amhru3LmTo0aN4oIFC1wq17a2Nn700Ue02Wysra3lkSNHGBcXxwkTJvDu3bvKPrRQV4fW1lb6+voyPz+/1/auUteHzS2k8865gzUvu+WihiQ3b97MsLAw6vV6Tp8+nWfOnBnqIfULQJ+PHTt2kCTr6+uZmJjIwMBAGgwGRkVFMSsrS/U3TUjy+vXrTE1NpY+PD4OCgrhmzRp2dnaqYoqLi/n0009Tr9czMjJS+R3OMm/ePIaGhlKv13P06NGcN28eq6urlf47d+7w/fffZ0BAAH19ffn666+zoaFBtQ9XyNPh559/JgBWVVWp2l25psXFxX2+XxcuXEjy3m3dn3/+OU0mEw0GA5OSknrlf+PGDc6fP5/Dhw+nn58f33nnHba1taliLly4wBdffJEGg4GjR49mXl5er7Hs2bOHEydOpF6v5+TJk3nw4EGn5VpbW9vvsev4W0SlpaW0WCz09/ent7c3n3zySX799deqhYAr5Hr79m3OmjWLo0aNopeXF8PDw7lkyZJeE5IW6uqwdetW+vj40G6399reVer6sLmFdO45dzDmZd3/JSaEEEII4dLc7poaIYQQQmiTLGqEEEIIoQmyqBFCCCGEJsiiRgghhBCaIIsaIYQQQmiCLGqEEEIIoQmyqBFCCCGEJsiiRgghhBCaIIsaIYQQQmiCLGqEEEIIoQmyqBFCCCGEJsiiRgghhBCa8B9RZeodkf5diAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ast\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "\n",
    "def moving_average(a, n=3):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "#weight_output = \"models\\model_4000_iter1\" #iter1 is the best for now\n",
    "#weight_output = \"models\\model_4000iter1_6000_iter8\" #iter1 is the best for now\n",
    "\n",
    "#weight_output = \"models\\\\Side Lane June 2025\\Base_rtx8000_25_June_2025_5000_v1\"\n",
    "metrics_file = f'{weight_output}\\\\metrics.json'\n",
    "print(metrics_file)\n",
    "\n",
    "with open(metrics_file, 'r') as f:\n",
    "    metrics = [eval(l[:-1].replace('NaN','0')) for l in f.readlines()]\n",
    "    f.close()\n",
    "\n",
    "train_loss = [float(v['loss_box_reg']) for v in metrics if 'loss_box_reg' in v.keys()]\n",
    "val_loss = [float(v['val_loss_box_reg']) for v in metrics if 'val_loss_box_reg' in v.keys()]\n",
    "\n",
    "N = 40\n",
    "\n",
    "train_loss_avg = moving_average(train_loss, n=N)\n",
    "val_loss_avg = moving_average(val_loss, n=N)\n",
    "\n",
    "plt.plot(range(20 * N - 1, 20 * len(train_loss), 20), train_loss_avg, label='train loss')\n",
    "plt.plot(range(20 * N - 1, 20 * len(train_loss), 20), val_loss_avg, label='val loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf6f872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clone_from_super_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
