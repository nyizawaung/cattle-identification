{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/24 21:08:29 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from models\\Side Lane August 2025\\Base_rtx8000_10_August_2025_20000_v1\\model_best.pth ...\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "import matplotlib.pyplot as plt\n",
    "from detectron2.utils.logger import setup_logger\n",
    "#from defisheye import Defisheye\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "setup_logger()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "def mask_to_annotation_pixels(mask, step=3):\n",
    "    \"\"\"\n",
    "    Converts a boolean mask to x, y coordinates of polygon points by selecting every nth pixel.\n",
    "    \n",
    "    :param mask: 2D boolean numpy array\n",
    "    :param step: Step to pick points from the mask (default: 3)\n",
    "    :return: all_points_x, all_points_y\n",
    "    \"\"\"\n",
    "    all_points_x = []\n",
    "    all_points_y = []\n",
    "    \n",
    "    # Get non-zero pixel indices (y, x) from the mask\n",
    "    y_indices, x_indices = np.where(mask)\n",
    "    area = np.sum(mask)\n",
    "    print(area)\n",
    "    if area < 1000:\n",
    "        return None, None\n",
    "    # Skip masks with no valid points\n",
    "    if len(x_indices) == 0 or len(y_indices) == 0:\n",
    "        return None, None\n",
    "\n",
    "    # Select every nth point based on the step\n",
    "    all_points_x = x_indices[::step].tolist()\n",
    "    all_points_y = y_indices[::step].tolist()\n",
    "\n",
    "    return all_points_x, all_points_y\n",
    "\n",
    "def get_file_size(file_path):\n",
    "    \"\"\"\n",
    "    Returns the file size of an image.\n",
    "    \n",
    "    :param file_path: Path to the image filef\n",
    "    :return: File size in bytes\n",
    "    \"\"\"\n",
    "    return os.path.getsize(file_path)\n",
    "\n",
    "def load_existing_json(output_file):\n",
    "    \"\"\"\n",
    "    Loads existing JSON data with proper encoding and error handling.\n",
    "    \n",
    "    :param output_file: Path to the JSON file\n",
    "    :return: List of JSON annotations\n",
    "    \"\"\"\n",
    "    if os.path.exists(output_file):\n",
    "        try:\n",
    "            with open(output_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                return json.load(f)\n",
    "        except UnicodeDecodeError as e:\n",
    "            print(f\"Error reading JSON file: {e}\")\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "def convert_annotations_to_json(fine_name, predictions):\n",
    "    annotations = {}\n",
    "    annotations[\"filename\"] = fine_name\n",
    "    annotations[\"size\"] = 0  # You can set this to the size of the image file if needed\n",
    "    annotations[\"regions\"] = []\n",
    "    global total_instances\n",
    "    for i in range(len(predictions[\"instances\"].pred_classes)):\n",
    "        region = {}\n",
    "        mask = predictions[\"instances\"].pred_masks[i].cpu().numpy()\n",
    "        area = np.sum(mask)\n",
    "        #print(\"Area : \",area)\n",
    "        if area < 3000:\n",
    "            continue\n",
    "        contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for contour in contours:\n",
    "            if len(contour) > 2:  # Only consider valid polygons\n",
    "                region[\"shape_attributes\"] = {\n",
    "                    \"name\": \"polygon\",\n",
    "                    \"all_points_x\": contour[:, 0, 0].tolist(),\n",
    "                    \"all_points_y\": contour[:, 0, 1].tolist()\n",
    "                }\n",
    "                \n",
    "                region[\"region_attributes\"] = {\n",
    "                    # \"label\": MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).thing_classes[predictions[\"instances\"].pred_classes[i]]\n",
    "                    \"label\": \"cow\"\n",
    "                }\n",
    "                \n",
    "                annotations[\"regions\"].append(region)\n",
    "        \n",
    "                total_instances += 1\n",
    "                #print(\"total instances : \", total_instances)\n",
    "\n",
    "    return annotations\n",
    "\n",
    "def write_annotation_json(annotations, file_path):\n",
    "\n",
    "    # file_ = f\"{file_name}_auto_annotation.json\"\n",
    "    # file_path = os.path.join(output_dir, file_)\n",
    "    \n",
    "    # if not os.path.exists(output_dir):\n",
    "    #     os.makedirs(output_dir)\n",
    "\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(annotations, f, indent=4)\n",
    "\n",
    "def append_annotation_json(output_file, filename, file_size,mask, step=3):\n",
    "    \"\"\"\n",
    "    Appends the annotation for the given mask to a JSON file in the specified format.\n",
    "    \n",
    "    :param output_file: Path to the JSON file\n",
    "    :param filename: Image filename\n",
    "    :param mask: Boolean mask (2D numpy array)\n",
    "    :param step: Step for pixel selection\n",
    "    \"\"\"\n",
    "    global total_instances\n",
    "    \n",
    "    polygon_x, polygon_y = mask_to_annotation_pixels(mask, step)\n",
    "\n",
    "    # Skip if there are no valid y-values\n",
    "    if polygon_x is None or polygon_y is None:\n",
    "        print(f\"Skipping mask for {filename} because no valid polygon points were found.\")\n",
    "        return\n",
    "\n",
    "    # Get file size\n",
    "\n",
    "    total_instances += 1\n",
    "    # Create a dictionary for the current annotation\n",
    "    annotation = {\n",
    "        \"filename\": filename,\n",
    "        \"file_size\": file_size,\n",
    "        \"file_attributes\": {},\n",
    "        \"region_count\": 1,\n",
    "        \"region_id\": 0,\n",
    "        \"region_shape_attributes\": {\n",
    "            \"name\": \"polygon\",\n",
    "            \"all_points_x\": polygon_x,\n",
    "            \"all_points_y\": polygon_y\n",
    "        },\n",
    "        \"region_attributes\": {\n",
    "            \"cow\": \"cow\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Load existing data or create an empty list if the file doesn't exist\n",
    "    data = load_existing_json(output_file)\n",
    "    print(\"Writing total instanace No: \",total_instances)\n",
    "    # Append the new annotation to the list\n",
    "    data.append(annotation)\n",
    "\n",
    "    # Save the updated data back to the JSON file\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "def get_files_from_folder(path):\n",
    "\n",
    "    files = os.listdir(path)\n",
    "    return np.asarray(files)\n",
    "\n",
    "def resize_detect_and_annotate(folder,output_file,step=3):\n",
    "    images = get_files_from_folder(folder)\n",
    "    all_annotations = {}\n",
    "    for image in images:\n",
    "        try:\n",
    "            \n",
    "        \n",
    "            image_path = os.path.join(folder, image)\n",
    "            #print(image_path)\n",
    "            #resize_image_dir = folder + \"/resize/\" +image\n",
    "            frame = cv2.imread(image_path)\n",
    "            #if 'Cam6' in image_path:\n",
    "            #frame = cv2.resize(frame,(1152,768))\n",
    "            #else:\n",
    "            #    frame = cv2.resize(frame,(640,480))\n",
    "            #cv2.imwrite(resize_image_dir,frame)\n",
    "            #file_size = get_file_size(resize_image_dir)\n",
    "            \n",
    "            #colored_mask = np.zeros_like(frame)\n",
    "            outputs = predictor(frame)\n",
    "            all_annotations[image]=convert_annotations_to_json(image, outputs)\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "    write_annotation_json(all_annotations,output_file)\n",
    "\n",
    "def detect_and_annotate(folder, output_file, step=3):\n",
    "    \"\"\"\n",
    "    Processes a single image and its corresponding mask, then appends the annotation to a JSON file.\n",
    "    \n",
    "    :param image_path: Path to the image file\n",
    "    :param mask: Boolean mask (2D numpy array)\n",
    "    :param output_file: Path to the output JSON file\n",
    "    :param step: Step for pixel selection\n",
    "    \"\"\"\n",
    "    # Assuming the mask is already generated and passed to this function\n",
    "    images = get_files_from_folder(folder)\n",
    "    all_annotations = {}\n",
    "    for image in images:\n",
    "        image_path = Path(os.path.join(folder, image))\n",
    "        file_size = get_file_size(image_dir)\n",
    "        frame = cv2.imread(image_path)\n",
    "        colored_mask = np.zeros_like(frame)\n",
    "        outputs = predictor(frame)\n",
    "        all_annotations[image]=convert_annotations_to_json(image, outputs)\n",
    "        #break\n",
    "    write_annotation_json(all_annotations,output_file)\n",
    "\n",
    "\n",
    "def configure_model(model_path):\n",
    "    cfg = get_cfg()\n",
    "    cfg.set_new_allowed(True) #added this to solve the below problem // allow merging other config\n",
    "    # # loading initial weight file\n",
    "    # cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    cfg.merge_from_file(f\"{model_path}\\\\config.yml\")\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.75 #0.6\n",
    "    cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.4 #0.3\n",
    "    # cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "    cfg.MODEL.WEIGHTS = f\"{model_path}\\\\model_best.pth\"\n",
    "    # If you don't have a GPU and CUDA enabled, the next line is required\n",
    "    # cfg.MODEL.DEVICE = \"cpu\"\n",
    "    cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    \n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    return predictor\n",
    "\n",
    "#model_path = \"models\\\\Feb 2025\\\\07_Feb_2025_15000_iters_v1\"\n",
    "#model_path = \"models\\\\April 2025\\\\April_Day_Night_10000_iters_v2\" //latest April 2025 \n",
    "#model_path = \"models\\\\April 2025\\\\April_Day_Night_10000_base_Sumiyoshi_dec31_v1_human_clear_2024_dec_10000_iters_v2_iters_v2\" #better mask April 2025 best better mask\n",
    "#model_path = \"models\\\\April 2025\\\\April_Day_Night_15000_base_Sumiyoshi_2024_10000_iters_v4_iters_v1\" \n",
    "model_path = \"models\\\\Side Lane August 2025\\Base_rtx8000_10_August_2025_20000_v1\" \n",
    "#model_path = \"models\\\\base_Sumiyoshi_model_Sumiyoshi_anchor_v1_10000_iters1\" #october 2 report\n",
    "#model_path = \"models\\\\base_Detection_Model_T6_model_Sumiyoshi_anchor_v2_10000_iters1\"\n",
    "predictor = configure_model(model_path)\n",
    "#detect_and_annotate(image_dir,output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_path = \"models\\\\October 2024\\\\Sumiyoshi_oct2_2024_10000_iters_v4\" #october 2 report\n",
    "#model_path = \"models\\\\base_yoshii_model_Sumiyoshi_anchor_v1_15000_iters1\"\n",
    "# Example usage:\n",
    "cam_path = '1_Annotate_24_Sept_KNP'\n",
    "image_dir = rf\"D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\August 2025\\Daytime_2025-09-24\\\\{cam_path}\"\n",
    "output_file = fr\"{image_dir}\\{cam_path}_json.json\"\n",
    "total_instances = 0\n",
    "#model_path = \"models\\\\October 2024\\\\Sumiyoshi_oct2_2024_10000_iters_v2\" #october 2 report  Sumiyoshi_oct2_2024_2000_iters_v1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_detect_and_annotate(image_dir,output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = [r\"C:\\Users\\choni\\Pictures\\5-51.png\",\n",
    "                r\"C:\\Users\\choni\\Pictures\\5-52.png\",\n",
    "                r\"C:\\Users\\choni\\Pictures\\5-53.png\",\n",
    "                r\"C:\\Users\\choni\\Pictures\\5-54.png\"]\n",
    "    \n",
    "frames = []\n",
    "for image_path in images_path:\n",
    "    frame = cv2.imread(image_path)\n",
    "    frames.append(frame)\n",
    "results = predictor(frames)\n",
    "for result in results:\n",
    "    print(\"total boxes : \",len(result[\"instances\"].pred_boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = 'models\\\\March 2025\\\\Feb_March_Day_Night_15000_iters_v2/model_final.pth'\n",
    "model_config = 'models\\\\March 2025\\\\Feb_March_Day_Night_15000_iters_v2/config.yml'\n",
    "\n",
    "\n",
    "filelist = []\n",
    "filelist = [r\"C:\\Users\\choni\\Pictures\\5-51.png\",\n",
    "            r\"C:\\Users\\choni\\Pictures\\5-52.png\",\n",
    "            r\"C:\\Users\\choni\\Pictures\\5-53.png\",\n",
    "            r\"C:\\Users\\choni\\Pictures\\5-54.png\"]\n",
    "# for root, dirs, files in os.walk(root):\n",
    "#     for file in files:\n",
    "#         filelist.append(Path(os.path.join(root, file)))\n",
    "\n",
    "#with open(classes) as classes_file:\n",
    "class_names = {1}\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(cfg_filename=model_config)\n",
    "cfg.MODEL.WEIGHTS = model\n",
    "print(\"Initializing model\")\n",
    "pred = BatchPredictor(cfg=cfg, classes=class_names, batch_size=4, workers=0)\n",
    "print(\"Finsished initializing model\")   \n",
    "t1 = time.time()\n",
    "predictions = list(pred(filelist[0:3]))\n",
    "t2 = time.time()\n",
    "print(f'Time used: {t2-t1} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clone_from_super_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
