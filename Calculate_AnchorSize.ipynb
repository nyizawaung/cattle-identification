{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea41fd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbcdd95",
   "metadata": {},
   "source": [
    "### Register datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "491ecade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.logger import setup_logger\n",
    "logger = setup_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a627d7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cd2d719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib notebook\n",
    "def imgshow(title=\"\", image = None, size = 6):\n",
    "    w, h = image.shape[0], image.shape[1]\n",
    "    aspect_ratio = w/h\n",
    "    plt.figure(figsize=(size * aspect_ratio,size))\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "def cv2_imshow(im):\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(), plt.imshow(im), plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "112aa4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some configurations\n",
    "#@title Register dataset\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "import os\n",
    "cur_dir = os.getcwd()\n",
    "# dataset path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#data_dir = r\"D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\May 2025\\Combine\"\n",
    "data_dir = r\"D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\"\n",
    "\n",
    "training_dataset_name = \"testing_data\"\n",
    "training_json_file = os.path.join(data_dir, \"training_images\\\\0_SideLane_addedversion_Training_COCO.json\")\n",
    "training_img_dir = os.path.join(data_dir, \"training_images\")\n",
    "register_coco_instances(training_dataset_name, {}, training_json_file, training_img_dir)\n",
    "\n",
    "test_dataset_name = \"test_data\"\n",
    "test_json_file =  os.path.join(data_dir, \"testing_images\\\\0_SideLane_addedversion_Testing_COCO.json\")\n",
    "test_img_dir =  os.path.join(data_dir, \"testing_images\")\n",
    "register_coco_instances(test_dataset_name, {}, test_json_file, test_img_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd22160",
   "metadata": {},
   "source": [
    "### Training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c469d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42030153",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f\"{data_dir}\\\\detection_Tanaka_weights_with_initial\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "nc = 3\n",
    "device = \"cuda\"\n",
    "# Select a model\n",
    "config_file_url = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",
    "checkpoint_url = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",
    "#from detectron2.projects import point_rend\n",
    "#config_file = \"detectron2/projects/PointRend/configs/InstanceSegmentation/pointrend_rcnn_X_101_32x8d_FPN_3x_coco.yaml\"\n",
    "#checkpoint_file = \"detectron2://PointRend/InstanceSegmentation/pointrend_rcnn_X_101_32x8d_FPN_3x_coco/28119989/model_final_ba17b9.pkl\"# config_file = \"detectron2/projects/PointRend/configs/InstanceSegmentation/pointrend_rcnn_R_50_FPN_3x_coco.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0b8ebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a configuration file\n",
    "cfg = get_cfg()\n",
    "config_file = model_zoo.get_config_file(config_file_url)\n",
    "cfg.merge_from_file(config_file)\n",
    "# # # Download weights\n",
    "# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(checkpoint_url)\n",
    "# Create a configuration and set up the model and datasets\n",
    "# model_file = \"F:\\\\Mounting_Model_Data\\\\Yoshii\\\\maskrcnn_WH_Feb22_Yoshii\"\n",
    "# cfg = get_cfg()\n",
    "# # loading initial configuration file (can change here with above model file or previous dataset weight to update)\n",
    "# cfg.merge_from_file(f\"{model_file}\\\\config.yml\")\n",
    "# # loading initial weight file\n",
    "# cfg.MODEL.WEIGHTS = f\"{model_file}\\\\model_final.pth\"\n",
    "#from detectron2.projects import point_rend\n",
    "# Select a lighter model to train faster\n",
    "#config_file = \"detectron2/projects/PointRend/configs/InstanceSegmentation/pointrend_rcnn_R_50_FPN_3x_coco.yaml\"\n",
    "#checkpoint_file = \"detectron2://PointRend/InstanceSegmentation/pointrend_rcnn_R_50_FPN_3x_coco/164955410/model_final_edd263.pkl\"\n",
    "#config_file = \"detectron2/projects/PointRend/configs/InstanceSegmentation/pointrend_rcnn_X_101_32x8d_FPN_3x_coco.yaml\"\n",
    "#checkpoint_file = \"detectron2://PointRend/InstanceSegmentation/pointrend_rcnn_X_101_32x8d_FPN_3x_coco/28119989/model_final_ba17b9.pkl\"\n",
    "# Create a configuration file\n",
    "#cfg = get_cfg()\n",
    "# Add PointRend-specific config\n",
    "#point_rend.add_pointrend_config(cfg)\n",
    "#cfg.merge_from_file(config_file)\n",
    "#cfg = get_cfg()\n",
    "# Create a configuration and set up the model and datasets\n",
    "# model_file = \"F:\\\\Mounting_Model_Data\\\\Tanaka\\\\camera_comparasion\\\\new_camera\\\\version1\\\\version6\\\\Tanaka_roi_80_model_6_with_background_with_oversampled\"\n",
    "# # loading initial configuration file (can change here with above model file or previous dataset weight to update)\n",
    "# cfg.merge_from_file(f\"{model_file}\\\\config.yml\")\n",
    "# # loading initial weight file\n",
    "# cfg.MODEL.WEIGHTS = f\"{model_file}\\\\model_best.pth\"\n",
    "\n",
    "\n",
    "# Set datasets\n",
    "cfg.DATASETS.TRAIN = (training_dataset_name,)\n",
    "\n",
    "#cfg.INPUT.MIN_SIZE_TRAIN = (2192,)\n",
    "#cfg.INPUT.MAX_SIZE_TRAIN = 2992\n",
    "\n",
    "# Workers\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "# Options: TrainingSampler, RepeatFactorTrainingSampler\n",
    "cfg.DATALOADER.SAMPLER_TRAIN = \"TrainingSampler\"\n",
    "# Repeat threshold for RepeatFactorTrainingSampler\n",
    "cfg.DATALOADER.REPEAT_THRESHOLD = 0.3\n",
    "# Images per batch\n",
    "cfg.SOLVER.IMS_PER_BATCH = 16\n",
    "# Learning rate\n",
    "cfg.SOLVER.BASE_LR = 0.0005\n",
    "cfg.SOLVER.STEPS = (10000, 13000)\n",
    "# Iterations\n",
    "cfg.SOLVER.MAX_ITER = 15000\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 1000\n",
    "# NMS threshold used on RPN proposals\n",
    "cfg.MODEL.RPN.NMS_THRESH = 0.5\n",
    "# Evaluation\n",
    "cfg.TEST.EVAL_PERIOD = cfg.SOLVER.CHECKPOINT_PERIOD\n",
    "# Classes\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = nc\n",
    "cfg.MODEL.DEVICE = device\n",
    "cfg.OUTPUT_DIR = output_dir\n",
    "# New\n",
    "#cfg.MODEL.POINT_HEAD.NUM_CLASSES = nc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35611d75",
   "metadata": {},
   "source": [
    "### A trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f146d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "import detectron2.data.transforms as T\n",
    "from detectron2.data import DatasetMapper\n",
    "from detectron2.data import build_detection_train_loader\n",
    "class MyTrainer(DefaultTrainer):\n",
    "  @classmethod\n",
    "  def build_train_loader(cls, cfg):\n",
    "    #def build_evaluator(cls, cfg, training_dataset_name, output_folder=None):\n",
    "        # Set up data augmentation\n",
    "        augs = [T.ResizeShortestEdge(\n",
    "                    [500,640, 672, 704, 736, 768, 800],\n",
    "                    max_size=1333, sample_style=\"choice\"),\n",
    "                T.RandomBrightness(0.5, 1.5),\n",
    "                T.RandomSaturation(0.5, 1.5),\n",
    "                T.RandomFlip(prob=0.5,horizontal=True, vertical = False),\n",
    "                #T.RandomFlip(prob=0.5,horizontal=False, vertical = True),\n",
    "                #T.RandomRotation(angle = [-90, 90], sample_style  = \"range\", center = [[0.4, 0.6], [0.4, 0.6]], expand = False),\n",
    "#                 #transforms.MinIoURandomCrop(min_ious=(0.1, 0.3, 0.5, 0.7, 0.9), min_crop_size=0.3, mode_trials=1000, crop_trials=50)\n",
    "                ]\n",
    "                #transforms.RandomFlip(prob=0.5)\n",
    "        data_loader = build_detection_train_loader(cfg,\n",
    "            mapper=DatasetMapper(cfg, is_train=True, \n",
    "                                 augmentations=augs))\n",
    "        \n",
    "        #return build_detection_train_loader(cfg, mapper=custom_mapper) \n",
    "        return data_loader\n",
    "  @classmethod\n",
    "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "    if output_folder == None:\n",
    "      output_folder = cfg.OUTPUT_DIR\n",
    "    else:\n",
    "      output_folder = os.path.join(cfg.OUTPUT_DIR, output_folder)\n",
    "      os.makedirs(output_folder)\n",
    "    # Use \n",
    "    return COCOEvaluator(dataset_name, distributed=False, output_dir=output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e94cc9b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/26 13:19:01 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[09/26 13:19:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=[500, 640, 672, 704, 736, 768, 800], max_size=1333, sample_style='choice'), RandomBrightness(intensity_min=0.5, intensity_max=1.5), RandomSaturation(intensity_min=0.5, intensity_max=1.5), RandomFlip(prob=0.5)]\n",
      "\u001b[32m[09/26 13:19:02 d2.data.datasets.coco]: \u001b[0mLoading D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\training_images\\0_SideLane_addedversion_Training_COCO.json takes 1.04 seconds.\n",
      "\u001b[32m[09/26 13:19:02 d2.data.datasets.coco]: \u001b[0mLoaded 2260 images in COCO format from D:\\Nyi Zaw Aung\\815_CowDataChecking\\Sumiyoshi ToAnnotate\\September 2025\\training_images\\0_SideLane_addedversion_Training_COCO.json\n",
      "\u001b[32m[09/26 13:19:02 d2.data.build]: \u001b[0mRemoved 484 images with no usable annotations. 1776 images left.\n",
      "\u001b[32m[09/26 13:19:02 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|\n",
      "|    cow     | 8984         | background | 0            |\n",
      "|            |              |            |              |\n",
      "|   total    | 8984         |            |              |\u001b[0m\n",
      "\u001b[32m[09/26 13:19:02 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[09/26 13:19:02 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/26 13:19:02 d2.data.common]: \u001b[0mSerializing 1776 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/26 13:19:02 d2.data.common]: \u001b[0mSerialized dataset takes 25.01 MiB\n",
      "\u001b[32m[09/26 13:19:02 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=16\n"
     ]
    }
   ],
   "source": [
    "trainer = MyTrainer(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84ff25b",
   "metadata": {},
   "source": [
    "### Preprocessing Input Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33d67c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIN_SIZE_TRAIN (640, 672, 704, 736, 768, 800)\n",
      "MAX_SIZE_TRAIN 1333\n"
     ]
    }
   ],
   "source": [
    "print(\"MIN_SIZE_TRAIN\", cfg.INPUT.MIN_SIZE_TRAIN)\n",
    "print(\"MAX_SIZE_TRAIN\", cfg.INPUT.MAX_SIZE_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaf3b5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer._data_loader_iter = iter(trainer.data_loader)\n",
    "data = next(trainer._data_loader_iter)\n",
    "#or i in data:\n",
    "#  print(i['image'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2517bc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = trainer.model.preprocess_image(data)\n",
    "#print(images.tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2701401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "# for i, item in enumerate(images.tensor[:3]):\n",
    "#   img = np.moveaxis(item.to(\"cpu\").numpy(), 0, -1)\n",
    "#   pixel_mean = cfg.MODEL.PIXEL_MEAN\n",
    "#   pixel_std = cfg.MODEL.PIXEL_STD\n",
    "#   img = (img * pixel_std) + pixel_mean\n",
    "#   v = Visualizer(img, metadata={}, scale=0.5)\n",
    "#   v = v.overlay_instances(boxes=data[i]['instances'].get('gt_boxes'),)\n",
    "#   dpi = 80\n",
    "#   im_data = v.get_image()[:,:, ::-1]\n",
    "#   height, width, depth = im_data.shape\n",
    "#   figsize = width / float(dpi), height / float(dpi)\n",
    "#   fig = plt.figure(figsize=figsize)\n",
    "#   plt.imshow(im_data)\n",
    "#   plt.imshow(im_data)\n",
    "#   plt.axis(\"off\")\n",
    "#   plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e0a7f1",
   "metadata": {},
   "source": [
    "### Sampling training data and generating the default anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ef0dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7de04498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [05:41<00:00,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([80933, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "def get_gt_boxes_batch(data):\n",
    "  gt_boxes = [\n",
    "      item['instances'].get('gt_boxes').tensor \n",
    "      for item in data\n",
    "      ]\n",
    "  return torch.cat(gt_boxes)\n",
    "\n",
    "def get_gt_boxes(trainer, iterations):\n",
    "  trainer._data_loader_iter = iter(trainer.data_loader)\n",
    "  gt_boxes = [\n",
    "      get_gt_boxes_batch(next(trainer._data_loader_iter)) \n",
    "      for _ in tqdm(range(iterations))\n",
    "      ]\n",
    "  return torch.cat(gt_boxes)\n",
    "  \n",
    "gt_boxes = get_gt_boxes(trainer, 1000)\n",
    "print()\n",
    "print(gt_boxes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd19e9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17.8318) tensor(493.3333)\n"
     ]
    }
   ],
   "source": [
    "def boxes2wh(boxes):\n",
    "  x1y1 = boxes[:, :2]\n",
    "  x2y2 = boxes[:, 2:]\n",
    "  return x2y2 - x1y1\n",
    "\n",
    "gt_wh = boxes2wh(gt_boxes)\n",
    "print(gt_wh.min(), gt_wh.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8585a57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sizes [[32], [64], [128], [256], [512]]\n",
      "ratios [[0.5, 1.0, 2.0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"sizes\", cfg.MODEL.ANCHOR_GENERATOR.SIZES)\n",
    "print(\"ratios\", cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d74cdf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_anchors = trainer.model.proposal_generator.anchor_generator.generate_cell_anchors\n",
    "anchors = generate_anchors()\n",
    "ac_wh = boxes2wh(anchors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc895c6",
   "metadata": {},
   "source": [
    "### Generating sizes and ratios hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6a70703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wh2size(wh):\n",
    "  return torch.sqrt(gt_wh[:, 0]*gt_wh[:, 1])\n",
    "\n",
    "def wh2ratio(wh):\n",
    "  return wh[:, 1]/wh[:,0]\n",
    "\n",
    "gt_sizes = wh2size(gt_wh)\n",
    "gt_ratios = wh2ratio(gt_wh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90f52333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_ratio(ac_wh, gt_wh):\n",
    "  all_ratios = gt_wh[:, None] / ac_wh[None]\n",
    "  inverse_ratios = 1/all_ratios\n",
    "  ratios = torch.min(\n",
    "      all_ratios, inverse_ratios\n",
    "  )\n",
    "  worst = ratios.min(-1).values\n",
    "  best = worst.max(-1).values\n",
    "  return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "974806ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(ac_wh, gt_wh, EDGE_RATIO_THRESHOLD = 0.25):\n",
    "  ratio = best_ratio(ac_wh, gt_wh)\n",
    "  return (ratio * (ratio > EDGE_RATIO_THRESHOLD).float()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f25cc8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_recall(ac_wh, gt_wh, EDGE_RATIO_THRESHOLD = 0.25):\n",
    "  ratio = best_ratio(ac_wh, gt_wh)\n",
    "  best = (ratio > EDGE_RATIO_THRESHOLD).float().mean()\n",
    "  return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9548991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall tensor(1.)\n",
      "fitness tensor(0.7526)\n"
     ]
    }
   ],
   "source": [
    "print(\"recall\", best_recall(ac_wh, gt_wh))\n",
    "print(\"fitness\", fitness(ac_wh, gt_wh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4687410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import \n",
    "#plt.rcParams[\"figure.dpi\"] = 150\n",
    "from scipy.cluster.vq import kmeans\n",
    "def estimate_clusters(values, num_clusters, iter=100):\n",
    "  std = values.std(0).item()\n",
    "  k, _ = kmeans(values / std, num_clusters, iter=iter)\n",
    "  k *= std\n",
    "  return k\n",
    "\n",
    "def visualize_clusters(values, centers):\n",
    "  plt.hist(values, histtype='step')\n",
    "  plt.scatter(centers, [0]*len(centers), c= \"red\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d67867f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = estimate_clusters(gt_sizes, 5)\n",
    "#visualize_clusters(gt_sizes, sizes)\n",
    "ratios = estimate_clusters(gt_ratios, 3)\n",
    "#visualize_clusters(gt_ratios, ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6922e90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sizes [154.52798   86.867226 187.08473  121.45394  233.81372 ]\n",
      "ratios [2.155631   1.0543213  0.52571815]\n"
     ]
    }
   ],
   "source": [
    "fitness(boxes2wh(generate_anchors(sizes, ratios)), gt_wh)\n",
    "print(\"sizes\", sizes)\n",
    "print(\"ratios\", ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a280df",
   "metadata": {},
   "source": [
    "### Evolve the results using the Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6402092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve(sizes, ratios, \n",
    "           gt_wh, \n",
    "           iterations=10000, \n",
    "           probability=0.9, \n",
    "           muy=1, \n",
    "           sigma=0.05, \n",
    "           fit_fn=fitness, \n",
    "           verbose=False):\n",
    "  anchors = generate_anchors(tuple(sizes), tuple(ratios))\n",
    "  ac_wh = boxes2wh(anchors)\n",
    "  best_fit = fit_fn(ac_wh, gt_wh)\n",
    "  anchor_shape = len(sizes) + len(ratios)\n",
    "\n",
    "  pbar = tqdm(range(iterations), desc=f\"Evolving ratios and sizes:\")\n",
    "  for i, _ in enumerate(pbar):\n",
    "      # to mutate and how much\n",
    "      mutation = np.ones(anchor_shape)\n",
    "      mutate = np.random.random(anchor_shape) < probability\n",
    "      mutation = np.random.normal(muy, sigma, anchor_shape)*mutate\n",
    "      mutation = mutation.clip(0.3, 3.0)\n",
    "      # mutated\n",
    "      mutated_sizes = sizes.copy()*mutation[:len(sizes)]\n",
    "      mutated_ratios = ratios.copy()*mutation[-len(ratios):]\n",
    "      mutated_anchors = generate_anchors(\n",
    "          tuple(mutated_sizes), \n",
    "          tuple(mutated_ratios))\n",
    "      mutated_ac_wh = boxes2wh(mutated_anchors)\n",
    "      mutated_fit = fit_fn(mutated_ac_wh, gt_wh)\n",
    "\n",
    "      if mutated_fit > best_fit:\n",
    "        sizes = mutated_sizes.copy()\n",
    "        ratios = mutated_ratios.copy()\n",
    "        best_fit = mutated_fit\n",
    "        pbar.desc = (f\"Evolving ratios and sizes, Fitness = {best_fit:.4f}\")\n",
    "  return sizes, ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458b9903",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f035c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evolving ratios and sizes, Fitness = 0.8646: 100%|██████████| 10000/10000 [02:16<00:00, 73.29it/s]\n"
     ]
    }
   ],
   "source": [
    "e_sizes, e_ratios = evolve(sizes, ratios, gt_wh, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fa6dbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sizes [149.95695869  90.25478231 179.26082761 119.37182681 213.92048847]\n",
      "ratios [1.36056301 0.7196418  0.44608757]\n"
     ]
    }
   ],
   "source": [
    "print(\"sizes\", e_sizes)\n",
    "print(\"ratios\", e_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c76bc01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sizes [149.95695869, 90.25478231, 179.26082761, 119.37182681, 213.92048847]\n",
      "ratios [1.36056301, 0.71964180, 0.44608757]\n"
     ]
    }
   ],
   "source": [
    "#separate array with \", \" for each element\n",
    "e_sizes = np.array(e_sizes)\n",
    "e_ratios = np.array(e_ratios)\n",
    "e_sizes_str = np.array2string(e_sizes, separator=\", \", formatter={'float_kind': lambda x: \"%.8f\" % x})\n",
    "e_ratios_str = np.array2string(e_ratios, separator=\", \", formatter={'float_kind': lambda x: \"%.8f\" % x})\n",
    "print(\"sizes\", e_sizes_str)   \n",
    "print(\"ratios\", e_ratios_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bb47ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clone_from_super_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
