{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Head Only] Epoch 1/5 | Train Loss: 3.9304 | Val Loss: 3.7766 | Val Acc: 21.37%\n",
      "[Head Only] Epoch 2/5 | Train Loss: 3.5249 | Val Loss: 3.4329 | Val Acc: 23.04%\n",
      "[Head Only] Epoch 3/5 | Train Loss: 3.2590 | Val Loss: 3.2517 | Val Acc: 33.00%\n",
      "[Head Only] Epoch 4/5 | Train Loss: 3.0611 | Val Loss: 3.1609 | Val Acc: 35.36%\n",
      "[Head Only] Epoch 5/5 | Train Loss: 2.8906 | Val Loss: 2.9034 | Val Acc: 37.60%\n",
      "Best accuracy after head-only training: 37.60%\n",
      "[Fine-Tune] Epoch 1/120 | Train Loss: 1.4770 | Val Loss: 0.7936 | Val Acc: 76.54%\n",
      "âœ… New best model saved (Acc: 76.54%)\n",
      "[Fine-Tune] Epoch 2/120 | Train Loss: 0.6120 | Val Loss: 0.2963 | Val Acc: 91.13%\n",
      "âœ… New best model saved (Acc: 91.13%)\n",
      "[Fine-Tune] Epoch 3/120 | Train Loss: 0.3045 | Val Loss: 0.1639 | Val Acc: 94.90%\n",
      "âœ… New best model saved (Acc: 94.90%)\n",
      "[Fine-Tune] Epoch 4/120 | Train Loss: 0.1707 | Val Loss: 0.1070 | Val Acc: 97.04%\n",
      "âœ… New best model saved (Acc: 97.04%)\n",
      "[Fine-Tune] Epoch 5/120 | Train Loss: 0.1111 | Val Loss: 0.0593 | Val Acc: 98.25%\n",
      "âœ… New best model saved (Acc: 98.25%)\n",
      "[Fine-Tune] Epoch 6/120 | Train Loss: 0.0819 | Val Loss: 0.0514 | Val Acc: 98.40%\n",
      "âœ… New best model saved (Acc: 98.40%)\n",
      "[Fine-Tune] Epoch 7/120 | Train Loss: 0.0648 | Val Loss: 0.0339 | Val Acc: 98.93%\n",
      "âœ… New best model saved (Acc: 98.93%)\n",
      "[Fine-Tune] Epoch 8/120 | Train Loss: 0.0467 | Val Loss: 0.0492 | Val Acc: 98.35%\n",
      "[Fine-Tune] Epoch 9/120 | Train Loss: 0.0413 | Val Loss: 0.0269 | Val Acc: 99.27%\n",
      "âœ… New best model saved (Acc: 99.27%)\n",
      "[Fine-Tune] Epoch 10/120 | Train Loss: 0.0351 | Val Loss: 0.0342 | Val Acc: 98.77%\n",
      "ðŸ’¾ Checkpoint saved: identification_models_KNP\\ResNet101_August_v9\\checkpoints\\checkpoint_epoch_10.pth\n",
      "[Fine-Tune] Epoch 11/120 | Train Loss: 0.0229 | Val Loss: 0.0200 | Val Acc: 99.32%\n",
      "âœ… New best model saved (Acc: 99.32%)\n",
      "[Fine-Tune] Epoch 12/120 | Train Loss: 0.0173 | Val Loss: 0.0184 | Val Acc: 99.45%\n",
      "âœ… New best model saved (Acc: 99.45%)\n",
      "[Fine-Tune] Epoch 13/120 | Train Loss: 0.0151 | Val Loss: 0.0167 | Val Acc: 99.42%\n",
      "[Fine-Tune] Epoch 14/120 | Train Loss: 0.0124 | Val Loss: 0.0173 | Val Acc: 99.42%\n",
      "[Fine-Tune] Epoch 15/120 | Train Loss: 0.0142 | Val Loss: 0.0156 | Val Acc: 99.37%\n",
      "[Fine-Tune] Epoch 16/120 | Train Loss: 0.0117 | Val Loss: 0.0165 | Val Acc: 99.37%\n",
      "[Fine-Tune] Epoch 17/120 | Train Loss: 0.0108 | Val Loss: 0.0154 | Val Acc: 99.48%\n",
      "âœ… New best model saved (Acc: 99.48%)\n",
      "[Fine-Tune] Epoch 18/120 | Train Loss: 0.0101 | Val Loss: 0.0144 | Val Acc: 99.42%\n",
      "[Fine-Tune] Epoch 19/120 | Train Loss: 0.0102 | Val Loss: 0.0158 | Val Acc: 99.42%\n",
      "[Fine-Tune] Epoch 20/120 | Train Loss: 0.0092 | Val Loss: 0.0159 | Val Acc: 99.42%\n",
      "ðŸ’¾ Checkpoint saved: identification_models_KNP\\ResNet101_August_v9\\checkpoints\\checkpoint_epoch_20.pth\n",
      "[Fine-Tune] Epoch 21/120 | Train Loss: 0.0088 | Val Loss: 0.0152 | Val Acc: 99.40%\n",
      "[Fine-Tune] Epoch 22/120 | Train Loss: 0.0083 | Val Loss: 0.0158 | Val Acc: 99.42%\n",
      "[Fine-Tune] Epoch 23/120 | Train Loss: 0.0090 | Val Loss: 0.0151 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 24/120 | Train Loss: 0.0085 | Val Loss: 0.0154 | Val Acc: 99.50%\n",
      "âœ… New best model saved (Acc: 99.50%)\n",
      "[Fine-Tune] Epoch 25/120 | Train Loss: 0.0085 | Val Loss: 0.0142 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 26/120 | Train Loss: 0.0082 | Val Loss: 0.0149 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 27/120 | Train Loss: 0.0095 | Val Loss: 0.0145 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 28/120 | Train Loss: 0.0076 | Val Loss: 0.0145 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 29/120 | Train Loss: 0.0087 | Val Loss: 0.0151 | Val Acc: 99.53%\n",
      "âœ… New best model saved (Acc: 99.53%)\n",
      "[Fine-Tune] Epoch 30/120 | Train Loss: 0.0086 | Val Loss: 0.0144 | Val Acc: 99.50%\n",
      "ðŸ’¾ Checkpoint saved: identification_models_KNP\\ResNet101_August_v9\\checkpoints\\checkpoint_epoch_30.pth\n",
      "[Fine-Tune] Epoch 31/120 | Train Loss: 0.0074 | Val Loss: 0.0138 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 32/120 | Train Loss: 0.0070 | Val Loss: 0.0145 | Val Acc: 99.53%\n",
      "[Fine-Tune] Epoch 33/120 | Train Loss: 0.0085 | Val Loss: 0.0150 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 34/120 | Train Loss: 0.0072 | Val Loss: 0.0152 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 35/120 | Train Loss: 0.0080 | Val Loss: 0.0139 | Val Acc: 99.58%\n",
      "âœ… New best model saved (Acc: 99.58%)\n",
      "[Fine-Tune] Epoch 36/120 | Train Loss: 0.0074 | Val Loss: 0.0149 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 37/120 | Train Loss: 0.0074 | Val Loss: 0.0147 | Val Acc: 99.45%\n",
      "[Fine-Tune] Epoch 38/120 | Train Loss: 0.0083 | Val Loss: 0.0146 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 39/120 | Train Loss: 0.0080 | Val Loss: 0.0151 | Val Acc: 99.35%\n",
      "[Fine-Tune] Epoch 40/120 | Train Loss: 0.0072 | Val Loss: 0.0149 | Val Acc: 99.48%\n",
      "ðŸ’¾ Checkpoint saved: identification_models_KNP\\ResNet101_August_v9\\checkpoints\\checkpoint_epoch_40.pth\n",
      "[Fine-Tune] Epoch 41/120 | Train Loss: 0.0076 | Val Loss: 0.0152 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 42/120 | Train Loss: 0.0084 | Val Loss: 0.0149 | Val Acc: 99.40%\n",
      "[Fine-Tune] Epoch 43/120 | Train Loss: 0.0078 | Val Loss: 0.0144 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 44/120 | Train Loss: 0.0083 | Val Loss: 0.0141 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 45/120 | Train Loss: 0.0082 | Val Loss: 0.0145 | Val Acc: 99.45%\n",
      "[Fine-Tune] Epoch 46/120 | Train Loss: 0.0068 | Val Loss: 0.0151 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 47/120 | Train Loss: 0.0079 | Val Loss: 0.0146 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 48/120 | Train Loss: 0.0075 | Val Loss: 0.0148 | Val Acc: 99.45%\n",
      "[Fine-Tune] Epoch 49/120 | Train Loss: 0.0078 | Val Loss: 0.0149 | Val Acc: 99.42%\n",
      "[Fine-Tune] Epoch 50/120 | Train Loss: 0.0084 | Val Loss: 0.0153 | Val Acc: 99.50%\n",
      "ðŸ’¾ Checkpoint saved: identification_models_KNP\\ResNet101_August_v9\\checkpoints\\checkpoint_epoch_50.pth\n",
      "[Fine-Tune] Epoch 51/120 | Train Loss: 0.0081 | Val Loss: 0.0145 | Val Acc: 99.45%\n",
      "[Fine-Tune] Epoch 52/120 | Train Loss: 0.0083 | Val Loss: 0.0134 | Val Acc: 99.53%\n",
      "[Fine-Tune] Epoch 53/120 | Train Loss: 0.0089 | Val Loss: 0.0149 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 54/120 | Train Loss: 0.0077 | Val Loss: 0.0154 | Val Acc: 99.45%\n",
      "[Fine-Tune] Epoch 55/120 | Train Loss: 0.0064 | Val Loss: 0.0148 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 56/120 | Train Loss: 0.0075 | Val Loss: 0.0150 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 57/120 | Train Loss: 0.0080 | Val Loss: 0.0155 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 58/120 | Train Loss: 0.0081 | Val Loss: 0.0144 | Val Acc: 99.45%\n",
      "[Fine-Tune] Epoch 59/120 | Train Loss: 0.0077 | Val Loss: 0.0143 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 60/120 | Train Loss: 0.0090 | Val Loss: 0.0147 | Val Acc: 99.50%\n",
      "ðŸ’¾ Checkpoint saved: identification_models_KNP\\ResNet101_August_v9\\checkpoints\\checkpoint_epoch_60.pth\n",
      "[Fine-Tune] Epoch 61/120 | Train Loss: 0.0075 | Val Loss: 0.0143 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 62/120 | Train Loss: 0.0080 | Val Loss: 0.0149 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 63/120 | Train Loss: 0.0076 | Val Loss: 0.0144 | Val Acc: 99.45%\n",
      "[Fine-Tune] Epoch 64/120 | Train Loss: 0.0073 | Val Loss: 0.0139 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 65/120 | Train Loss: 0.0074 | Val Loss: 0.0150 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 66/120 | Train Loss: 0.0076 | Val Loss: 0.0141 | Val Acc: 99.45%\n",
      "[Fine-Tune] Epoch 67/120 | Train Loss: 0.0074 | Val Loss: 0.0141 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 68/120 | Train Loss: 0.0076 | Val Loss: 0.0148 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 69/120 | Train Loss: 0.0099 | Val Loss: 0.0145 | Val Acc: 99.45%\n",
      "[Fine-Tune] Epoch 70/120 | Train Loss: 0.0076 | Val Loss: 0.0138 | Val Acc: 99.50%\n",
      "ðŸ’¾ Checkpoint saved: identification_models_KNP\\ResNet101_August_v9\\checkpoints\\checkpoint_epoch_70.pth\n",
      "[Fine-Tune] Epoch 71/120 | Train Loss: 0.0073 | Val Loss: 0.0153 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 72/120 | Train Loss: 0.0080 | Val Loss: 0.0144 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 73/120 | Train Loss: 0.0080 | Val Loss: 0.0141 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 74/120 | Train Loss: 0.0064 | Val Loss: 0.0145 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 75/120 | Train Loss: 0.0080 | Val Loss: 0.0152 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 76/120 | Train Loss: 0.0089 | Val Loss: 0.0137 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 77/120 | Train Loss: 0.0072 | Val Loss: 0.0138 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 78/120 | Train Loss: 0.0070 | Val Loss: 0.0149 | Val Acc: 99.53%\n",
      "[Fine-Tune] Epoch 79/120 | Train Loss: 0.0090 | Val Loss: 0.0152 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 80/120 | Train Loss: 0.0082 | Val Loss: 0.0143 | Val Acc: 99.45%\n",
      "ðŸ’¾ Checkpoint saved: identification_models_KNP\\ResNet101_August_v9\\checkpoints\\checkpoint_epoch_80.pth\n",
      "[Fine-Tune] Epoch 81/120 | Train Loss: 0.0070 | Val Loss: 0.0152 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 82/120 | Train Loss: 0.0083 | Val Loss: 0.0147 | Val Acc: 99.45%\n",
      "[Fine-Tune] Epoch 83/120 | Train Loss: 0.0080 | Val Loss: 0.0143 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 84/120 | Train Loss: 0.0070 | Val Loss: 0.0149 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 85/120 | Train Loss: 0.0070 | Val Loss: 0.0146 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 86/120 | Train Loss: 0.0084 | Val Loss: 0.0142 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 87/120 | Train Loss: 0.0077 | Val Loss: 0.0149 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 88/120 | Train Loss: 0.0076 | Val Loss: 0.0154 | Val Acc: 99.45%\n",
      "[Fine-Tune] Epoch 89/120 | Train Loss: 0.0073 | Val Loss: 0.0146 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 90/120 | Train Loss: 0.0080 | Val Loss: 0.0144 | Val Acc: 99.53%\n",
      "ðŸ’¾ Checkpoint saved: identification_models_KNP\\ResNet101_August_v9\\checkpoints\\checkpoint_epoch_90.pth\n",
      "[Fine-Tune] Epoch 91/120 | Train Loss: 0.0081 | Val Loss: 0.0144 | Val Acc: 99.45%\n",
      "[Fine-Tune] Epoch 92/120 | Train Loss: 0.0074 | Val Loss: 0.0150 | Val Acc: 99.56%\n",
      "[Fine-Tune] Epoch 93/120 | Train Loss: 0.0074 | Val Loss: 0.0139 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 94/120 | Train Loss: 0.0086 | Val Loss: 0.0151 | Val Acc: 99.42%\n",
      "[Fine-Tune] Epoch 95/120 | Train Loss: 0.0075 | Val Loss: 0.0142 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 96/120 | Train Loss: 0.0081 | Val Loss: 0.0153 | Val Acc: 99.42%\n",
      "[Fine-Tune] Epoch 97/120 | Train Loss: 0.0087 | Val Loss: 0.0148 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 98/120 | Train Loss: 0.0069 | Val Loss: 0.0150 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 99/120 | Train Loss: 0.0100 | Val Loss: 0.0143 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 100/120 | Train Loss: 0.0078 | Val Loss: 0.0135 | Val Acc: 99.48%\n",
      "ðŸ’¾ Checkpoint saved: identification_models_KNP\\ResNet101_August_v9\\checkpoints\\checkpoint_epoch_100.pth\n",
      "[Fine-Tune] Epoch 101/120 | Train Loss: 0.0075 | Val Loss: 0.0141 | Val Acc: 99.53%\n",
      "[Fine-Tune] Epoch 102/120 | Train Loss: 0.0082 | Val Loss: 0.0145 | Val Acc: 99.53%\n",
      "[Fine-Tune] Epoch 103/120 | Train Loss: 0.0080 | Val Loss: 0.0148 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 104/120 | Train Loss: 0.0089 | Val Loss: 0.0146 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 105/120 | Train Loss: 0.0085 | Val Loss: 0.0150 | Val Acc: 99.45%\n",
      "[Fine-Tune] Epoch 106/120 | Train Loss: 0.0075 | Val Loss: 0.0144 | Val Acc: 99.53%\n",
      "[Fine-Tune] Epoch 107/120 | Train Loss: 0.0083 | Val Loss: 0.0143 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 108/120 | Train Loss: 0.0083 | Val Loss: 0.0138 | Val Acc: 99.53%\n",
      "[Fine-Tune] Epoch 109/120 | Train Loss: 0.0078 | Val Loss: 0.0148 | Val Acc: 99.58%\n",
      "[Fine-Tune] Epoch 110/120 | Train Loss: 0.0084 | Val Loss: 0.0138 | Val Acc: 99.53%\n",
      "ðŸ’¾ Checkpoint saved: identification_models_KNP\\ResNet101_August_v9\\checkpoints\\checkpoint_epoch_110.pth\n",
      "[Fine-Tune] Epoch 111/120 | Train Loss: 0.0080 | Val Loss: 0.0145 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 112/120 | Train Loss: 0.0079 | Val Loss: 0.0146 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 113/120 | Train Loss: 0.0080 | Val Loss: 0.0148 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 114/120 | Train Loss: 0.0079 | Val Loss: 0.0151 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 115/120 | Train Loss: 0.0075 | Val Loss: 0.0141 | Val Acc: 99.56%\n",
      "[Fine-Tune] Epoch 116/120 | Train Loss: 0.0086 | Val Loss: 0.0152 | Val Acc: 99.50%\n",
      "[Fine-Tune] Epoch 117/120 | Train Loss: 0.0080 | Val Loss: 0.0148 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 118/120 | Train Loss: 0.0071 | Val Loss: 0.0141 | Val Acc: 99.53%\n",
      "[Fine-Tune] Epoch 119/120 | Train Loss: 0.0083 | Val Loss: 0.0148 | Val Acc: 99.48%\n",
      "[Fine-Tune] Epoch 120/120 | Train Loss: 0.0089 | Val Loss: 0.0150 | Val Acc: 99.53%\n",
      "ðŸ’¾ Checkpoint saved: identification_models_KNP\\ResNet101_August_v9\\checkpoints\\checkpoint_epoch_120.pth\n",
      "Best accuracy after fine-tuning: 99.58%\n",
      "ðŸŽ¯ Training complete. Model saved!\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from helpers.helper import Helper\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import json\n",
    "# -----------------------\n",
    "# Model creation\n",
    "# -----------------------\n",
    "def create_model(num_classes, use_custom_head=True):\n",
    "    if use_custom_head:\n",
    "        model = timm.create_model('resnet101', pretrained=True, num_classes=0)  # no classifier\n",
    "        in_features = model.num_features\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    else:\n",
    "        # Simple version (just a linear classifier)\n",
    "        model = timm.create_model('resnet101', pretrained=True, num_classes=num_classes)\n",
    "    return model\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Phase 1: Train only head\n",
    "# -----------------------\n",
    "def train_head_only(model, train_loader, val_loader, device, num_epochs=5, lr=1e-3):\n",
    "    # Freeze backbone\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.fc.parameters(), lr=lr)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Validate\n",
    "        model.eval()\n",
    "        correct, total, val_loss = 0, 0, 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += preds.eq(labels).sum().item()\n",
    "\n",
    "        val_acc = 100 * correct / total\n",
    "        print(f\"[Head Only] Epoch {epoch+1}/{num_epochs} | \"\n",
    "              f\"Train Loss: {running_loss/len(train_loader):.4f} | \"\n",
    "              f\"Val Loss: {val_loss/len(val_loader):.4f} | \"\n",
    "              f\"Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "        best_acc = max(best_acc, val_acc)\n",
    "\n",
    "    print(f\"Best accuracy after head-only training: {best_acc:.2f}%\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Phase 2: Fine-tune full model\n",
    "# -----------------------\n",
    "def fine_tune_full(model, train_loader, val_loader, device, num_epochs=50, lr=1e-4, save_dir=\"checkpoints\"):\n",
    "    # Unfreeze backbone\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    os.makedirs(save_dir, exist_ok=True)  # make sure checkpoint dir exists\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Validate\n",
    "        model.eval()\n",
    "        correct, total, val_loss = 0, 0, 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += preds.eq(labels).sum().item()\n",
    "\n",
    "        val_acc = 100 * correct / total\n",
    "        print(f\"[Fine-Tune] Epoch {epoch+1}/{num_epochs} | \"\n",
    "              f\"Train Loss: {running_loss/len(train_loader):.4f} | \"\n",
    "              f\"Val Loss: {val_loss/len(val_loader):.4f} | \"\n",
    "              f\"Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, \"best_resnet101.pth\"))\n",
    "            print(f\"âœ… New best model saved (Acc: {best_acc:.2f}%)\")\n",
    "\n",
    "        # Save checkpoint every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            ckpt_path = os.path.join(save_dir, f\"checkpoint_epoch_{epoch+1}.pth\")\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'val_acc': val_acc,\n",
    "                'val_loss': val_loss/len(val_loader),\n",
    "            }, ckpt_path)\n",
    "            print(f\"ðŸ’¾ Checkpoint saved: {ckpt_path}\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"Best accuracy after fine-tuning: {best_acc:.2f}%\")\n",
    "    return model\n",
    "def get_transforms(image_size=224):\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.RandomRotation(30),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return train_transform, val_transform\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = create_model(num_classes=66, use_custom_head=False).to(device)\n",
    "\n",
    "train_dir = 'C:\\\\Identification dataset\\\\KNP_identification_dataset\\\\Training'\n",
    "val_dir = 'C:\\\\Identification dataset\\\\KNP_identification_dataset\\\\Validation' \n",
    "\n",
    "savePath = Helper.increment_path(Path(\"identification_models_KNP\\\\ResNet101_August_v\"),mkdir=True)\n",
    "os.makedirs(savePath, exist_ok=True)\n",
    "# Create transforms and datasets\n",
    "train_transform, val_transform = get_transforms()\n",
    "train_dataset = ImageFolder(train_dir, transform=train_transform)\n",
    "val_dataset = ImageFolder(val_dir, transform=val_transform)\n",
    "\n",
    "# Save class mapping\n",
    "class_mapping = {v: k for k, v in train_dataset.class_to_idx.items()}\n",
    "import json\n",
    "with open(f'{savePath}\\\\class_mapping.json', 'w') as f:\n",
    "    json.dump(class_mapping, f, indent=4)\n",
    "batch_size = 16\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=16,pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=16,pin_memory=True)\n",
    "# Phase 1\n",
    "checkpoint_dir=(str(savePath)+\"\\\\checkpoints\")\n",
    "model = train_head_only(model, train_loader, val_loader, device, num_epochs=5, lr=1e-3)\n",
    "\n",
    "# Phase 2\n",
    "model = fine_tune_full(model, train_loader, val_loader, device, num_epochs=120, lr=1e-4, save_dir=checkpoint_dir)\n",
    "\n",
    "torch.save(model.state_dict(), f\"{savePath}\\\\best_model.pth\")\n",
    "print(\"ðŸŽ¯ Training complete. Model saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Training complete. Model saved!\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), f\"{savePath}\\\\resnet_best.pth\")\n",
    "print(\"ðŸŽ¯ Training complete. Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight file saved to: identification_models_KNP\\ResNet101_August_v9\\epoch_120.pth\\weight_epoch_120_weights.pth\n",
      "Epoch: 120\n",
      "Validation Accuracy: 99.53%\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def convert_checkpoint_to_weight(checkpoint_path, output_dir):\n",
    "    # Check if the checkpoint file exists\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        print(f\"Error: Checkpoint file {checkpoint_path} does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "\n",
    "    # Extract the model state dict\n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        model_state_dict = checkpoint['model_state_dict']\n",
    "    else:\n",
    "        print(\"Error: The checkpoint does not contain a 'model_state_dict'.\")\n",
    "        return\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Generate the output file name\n",
    "    checkpoint_filename = os.path.basename(checkpoint_path)\n",
    "    weight_filename = checkpoint_filename.replace('checkpoint', 'weight').replace('.pth', '_weights.pth')\n",
    "    output_path = os.path.join(output_dir, weight_filename)\n",
    "\n",
    "    # Save the model state dict\n",
    "    torch.save(model_state_dict, output_path)\n",
    "\n",
    "    print(f\"Weight file saved to: {output_path}\")\n",
    "\n",
    "    # Print additional information from the checkpoint\n",
    "    if 'epoch' in checkpoint:\n",
    "        print(f\"Epoch: {checkpoint['epoch']}\")\n",
    "    if 'val_acc' in checkpoint:\n",
    "        print(f\"Validation Accuracy: {checkpoint['val_acc']:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    weight_path = 'identification_models_KNP\\ResNet101_August_v9\\checkpoints\\checkpoint_epoch_120.pth'\n",
    "    output_path  = 'identification_models_KNP\\ResNet101_August_v9\\epoch_120.pth'\n",
    "\n",
    "    convert_checkpoint_to_weight(weight_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clone_from_super_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
